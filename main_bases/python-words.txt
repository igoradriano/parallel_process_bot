indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » What’s New in Python » What’s New In Python 3.10
Quick search
  |
What’s New In Python 3.10
Release
3.10.8

Date
October 21, 2022

Editor
Pablo Galindo Salgado

This article explains the new features in Python 3.10, compared to 3.9. Python 3.10 was released on October 4, 2021. For full details, see the changelog.

Summary – Release highlights
New syntax features:

PEP 634, Structural Pattern Matching: Specification

PEP 635, Structural Pattern Matching: Motivation and Rationale

PEP 636, Structural Pattern Matching: Tutorial

bpo-12782, Parenthesized context managers are now officially allowed.

New features in the standard library:

PEP 618, Add Optional Length-Checking To zip.

Interpreter improvements:

PEP 626, Precise line numbers for debugging and other tools.

New typing features:

PEP 604, Allow writing union types as X | Y

PEP 613, Explicit Type Aliases

PEP 612, Parameter Specification Variables

Important deprecations, removals or restrictions:

PEP 644, Require OpenSSL 1.1.1 or newer

PEP 632, Deprecate distutils module.

PEP 623, Deprecate and prepare for the removal of the wstr member in PyUnicodeObject.

PEP 624, Remove Py_UNICODE encoder APIs

PEP 597, Add optional EncodingWarning

New Features
Parenthesized context managers
Using enclosing parentheses for continuation across multiple lines in context managers is now supported. This allows formatting a long collection of context managers in multiple lines in a similar way as it was previously possible with import statements. For instance, all these examples are now valid:

with (CtxManager() as example):
    ...

with (
    CtxManager1(),
    CtxManager2()
):
    ...

with (CtxManager1() as example,
      CtxManager2()):
    ...

with (CtxManager1(),
      CtxManager2() as example):
    ...

with (
    CtxManager1() as example1,
    CtxManager2() as example2
):
    ...
it is also possible to use a trailing comma at the end of the enclosed group:

with (
    CtxManager1() as example1,
    CtxManager2() as example2,
    CtxManager3() as example3,
):
    ...
This new syntax uses the non LL(1) capacities of the new parser. Check PEP 617 for more details.

(Contributed by Guido van Rossum, Pablo Galindo and Lysandros Nikolaou in bpo-12782 and bpo-40334.)

Better error messages
SyntaxErrors
When parsing code that contains unclosed parentheses or brackets the interpreter now includes the location of the unclosed bracket of parentheses instead of displaying SyntaxError: unexpected EOF while parsing or pointing to some incorrect location. For instance, consider the following code (notice the unclosed ‘{‘):

expected = {9: 1, 18: 2, 19: 2, 27: 3, 28: 3, 29: 3, 36: 4, 37: 4,
            38: 4, 39: 4, 45: 5, 46: 5, 47: 5, 48: 5, 49: 5, 54: 6,
some_other_code = foo()
Previous versions of the interpreter reported confusing places as the location of the syntax error:

File "example.py", line 3
    some_other_code = foo()
                    ^
SyntaxError: invalid syntax
but in Python 3.10 a more informative error is emitted:

File "example.py", line 1
    expected = {9: 1, 18: 2, 19: 2, 27: 3, 28: 3, 29: 3, 36: 4, 37: 4,
               ^
SyntaxError: '{' was never closed
In a similar way, errors involving unclosed string literals (single and triple quoted) now point to the start of the string instead of reporting EOF/EOL.

These improvements are inspired by previous work in the PyPy interpreter.

(Contributed by Pablo Galindo in bpo-42864 and Batuhan Taskaya in bpo-40176.)

SyntaxError exceptions raised by the interpreter will now highlight the full error range of the expression that constitutes the syntax error itself, instead of just where the problem is detected. In this way, instead of displaying (before Python 3.10):

>>>
>>> foo(x, z for z in range(10), t, w)
  File "<stdin>", line 1
    foo(x, z for z in range(10), t, w)
           ^
SyntaxError: Generator expression must be parenthesized
now Python 3.10 will display the exception as:

>>>
>>> foo(x, z for z in range(10), t, w)
  File "<stdin>", line 1
    foo(x, z for z in range(10), t, w)
           ^^^^^^^^^^^^^^^^^^^^
SyntaxError: Generator expression must be parenthesized
This improvement was contributed by Pablo Galindo in bpo-43914.

A considerable amount of new specialized messages for SyntaxError exceptions have been incorporated. Some of the most notable ones are as follows:

Missing : before blocks:

>>>
>>> if rocket.position > event_horizon
  File "<stdin>", line 1
    if rocket.position > event_horizon
                                      ^
SyntaxError: expected ':'
(Contributed by Pablo Galindo in bpo-42997.)

Unparenthesised tuples in comprehensions targets:

>>>
>>> {x,y for x,y in zip('abcd', '1234')}
  File "<stdin>", line 1
    {x,y for x,y in zip('abcd', '1234')}
     ^
SyntaxError: did you forget parentheses around the comprehension target?
(Contributed by Pablo Galindo in bpo-43017.)

Missing commas in collection literals and between expressions:

>>>
>>> items = {
... x: 1,
... y: 2
... z: 3,
  File "<stdin>", line 3
    y: 2
       ^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
(Contributed by Pablo Galindo in bpo-43822.)

Multiple Exception types without parentheses:

>>>
>>> try:
...     build_dyson_sphere()
... except NotEnoughScienceError, NotEnoughResourcesError:
  File "<stdin>", line 3
    except NotEnoughScienceError, NotEnoughResourcesError:
           ^
SyntaxError: multiple exception types must be parenthesized
(Contributed by Pablo Galindo in bpo-43149.)

Missing : and values in dictionary literals:

>>>
>>> values = {
... x: 1,
... y: 2,
... z:
... }
  File "<stdin>", line 4
    z:
     ^
SyntaxError: expression expected after dictionary key and ':'

>>> values = {x:1, y:2, z w:3}
  File "<stdin>", line 1
    values = {x:1, y:2, z w:3}
                        ^
SyntaxError: ':' expected after dictionary key
(Contributed by Pablo Galindo in bpo-43823.)

try blocks without except or finally blocks:

>>>
>>> try:
...     x = 2
... something = 3
  File "<stdin>", line 3
    something  = 3
    ^^^^^^^^^
SyntaxError: expected 'except' or 'finally' block
(Contributed by Pablo Galindo in bpo-44305.)

Usage of = instead of == in comparisons:

>>>
>>> if rocket.position = event_horizon:
  File "<stdin>", line 1
    if rocket.position = event_horizon:
                       ^
SyntaxError: cannot assign to attribute here. Maybe you meant '==' instead of '='?
(Contributed by Pablo Galindo in bpo-43797.)

Usage of * in f-strings:

>>>
>>> f"Black holes {*all_black_holes} and revelations"
  File "<stdin>", line 1
    (*all_black_holes)
     ^
SyntaxError: f-string: cannot use starred expression here
(Contributed by Pablo Galindo in bpo-41064.)

IndentationErrors
Many IndentationError exceptions now have more context regarding what kind of block was expecting an indentation, including the location of the statement:

>>>
>>> def foo():
...    if lel:
...    x = 2
  File "<stdin>", line 3
    x = 2
    ^
IndentationError: expected an indented block after 'if' statement in line 2
AttributeErrors
When printing AttributeError, PyErr_Display() will offer suggestions of similar attribute names in the object that the exception was raised from:

>>>
>>> collections.namedtoplo
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: module 'collections' has no attribute 'namedtoplo'. Did you mean: namedtuple?
(Contributed by Pablo Galindo in bpo-38530.)

Warning Notice this won’t work if PyErr_Display() is not called to display the error which can happen if some other custom error display function is used. This is a common scenario in some REPLs like IPython.
NameErrors
When printing NameError raised by the interpreter, PyErr_Display() will offer suggestions of similar variable names in the function that the exception was raised from:

>>>
>>> schwarzschild_black_hole = None
>>> schwarschild_black_hole
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'schwarschild_black_hole' is not defined. Did you mean: schwarzschild_black_hole?
(Contributed by Pablo Galindo in bpo-38530.)

Warning Notice this won’t work if PyErr_Display() is not called to display the error, which can happen if some other custom error display function is used. This is a common scenario in some REPLs like IPython.
PEP 626: Precise line numbers for debugging and other tools
PEP 626 brings more precise and reliable line numbers for debugging, profiling and coverage tools. Tracing events, with the correct line number, are generated for all lines of code executed and only for lines of code that are executed.

The f_lineno attribute of frame objects will always contain the expected line number.

The co_lnotab attribute of code objects is deprecated and will be removed in 3.12. Code that needs to convert from offset to line number should use the new co_lines() method instead.

PEP 634: Structural Pattern Matching
Structural pattern matching has been added in the form of a match statement and case statements of patterns with associated actions. Patterns consist of sequences, mappings, primitive data types as well as class instances. Pattern matching enables programs to extract information from complex data types, branch on the structure of data, and apply specific actions based on different forms of data.

Syntax and operations
The generic syntax of pattern matching is:

match subject:
    case <pattern_1>:
        <action_1>
    case <pattern_2>:
        <action_2>
    case <pattern_3>:
        <action_3>
    case _:
        <action_wildcard>
A match statement takes an expression and compares its value to successive patterns given as one or more case blocks. Specifically, pattern matching operates by:

using data with type and shape (the subject)

evaluating the subject in the match statement

comparing the subject with each pattern in a case statement from top to bottom until a match is confirmed.

executing the action associated with the pattern of the confirmed match

If an exact match is not confirmed, the last case, a wildcard _, if provided, will be used as the matching case. If an exact match is not confirmed and a wildcard case does not exist, the entire match block is a no-op.

Declarative approach
Readers may be aware of pattern matching through the simple example of matching a subject (data object) to a literal (pattern) with the switch statement found in C, Java or JavaScript (and many other languages). Often the switch statement is used for comparison of an object/expression with case statements containing literals.

More powerful examples of pattern matching can be found in languages such as Scala and Elixir. With structural pattern matching, the approach is “declarative” and explicitly states the conditions (the patterns) for data to match.

While an “imperative” series of instructions using nested “if” statements could be used to accomplish something similar to structural pattern matching, it is less clear than the “declarative” approach. Instead the “declarative” approach states the conditions to meet for a match and is more readable through its explicit patterns. While structural pattern matching can be used in its simplest form comparing a variable to a literal in a case statement, its true value for Python lies in its handling of the subject’s type and shape.

Simple pattern: match to a literal
Let’s look at this example as pattern matching in its simplest form: a value, the subject, being matched to several literals, the patterns. In the example below, status is the subject of the match statement. The patterns are each of the case statements, where literals represent request status codes. The associated action to the case is executed after a match:

def http_error(status):
    match status:
        case 400:
            return "Bad request"
        case 404:
            return "Not found"
        case 418:
            return "I'm a teapot"
        case _:
            return "Something's wrong with the internet"
If the above function is passed a status of 418, “I’m a teapot” is returned. If the above function is passed a status of 500, the case statement with _ will match as a wildcard, and “Something’s wrong with the internet” is returned. Note the last block: the variable name, _, acts as a wildcard and insures the subject will always match. The use of _ is optional.

You can combine several literals in a single pattern using | (“or”):

case 401 | 403 | 404:
    return "Not allowed"
Behavior without the wildcard
If we modify the above example by removing the last case block, the example becomes:

def http_error(status):
    match status:
        case 400:
            return "Bad request"
        case 404:
            return "Not found"
        case 418:
            return "I'm a teapot"
Without the use of _ in a case statement, a match may not exist. If no match exists, the behavior is a no-op. For example, if status of 500 is passed, a no-op occurs.

Patterns with a literal and variable
Patterns can look like unpacking assignments, and a pattern may be used to bind variables. In this example, a data point can be unpacked to its x-coordinate and y-coordinate:

# point is an (x, y) tuple
match point:
    case (0, 0):
        print("Origin")
    case (0, y):
        print(f"Y={y}")
    case (x, 0):
        print(f"X={x}")
    case (x, y):
        print(f"X={x}, Y={y}")
    case _:
        raise ValueError("Not a point")
The first pattern has two literals, (0, 0), and may be thought of as an extension of the literal pattern shown above. The next two patterns combine a literal and a variable, and the variable binds a value from the subject (point). The fourth pattern captures two values, which makes it conceptually similar to the unpacking assignment (x, y) = point.

Patterns and classes
If you are using classes to structure your data, you can use as a pattern the class name followed by an argument list resembling a constructor. This pattern has the ability to capture class attributes into variables:

class Point:
    x: int
    y: int

def location(point):
    match point:
        case Point(x=0, y=0):
            print("Origin is the point's location.")
        case Point(x=0, y=y):
            print(f"Y={y} and the point is on the y-axis.")
        case Point(x=x, y=0):
            print(f"X={x} and the point is on the x-axis.")
        case Point():
            print("The point is located somewhere else on the plane.")
        case _:
            print("Not a point")
Patterns with positional parameters
You can use positional parameters with some builtin classes that provide an ordering for their attributes (e.g. dataclasses). You can also define a specific position for attributes in patterns by setting the __match_args__ special attribute in your classes. If it’s set to (“x”, “y”), the following patterns are all equivalent (and all bind the y attribute to the var variable):

Point(1, var)
Point(1, y=var)
Point(x=1, y=var)
Point(y=var, x=1)
Nested patterns
Patterns can be arbitrarily nested. For example, if our data is a short list of points, it could be matched like this:

match points:
    case []:
        print("No points in the list.")
    case [Point(0, 0)]:
        print("The origin is the only point in the list.")
    case [Point(x, y)]:
        print(f"A single point {x}, {y} is in the list.")
    case [Point(0, y1), Point(0, y2)]:
        print(f"Two points on the Y axis at {y1}, {y2} are in the list.")
    case _:
        print("Something else is found in the list.")
Complex patterns and the wildcard
To this point, the examples have used _ alone in the last case statement. A wildcard can be used in more complex patterns, such as ('error', code, _). For example:

match test_variable:
    case ('warning', code, 40):
        print("A warning has been received.")
    case ('error', code, _):
        print(f"An error {code} occurred.")
In the above case, test_variable will match for (‘error’, code, 100) and (‘error’, code, 800).

Guard
We can add an if clause to a pattern, known as a “guard”. If the guard is false, match goes on to try the next case block. Note that value capture happens before the guard is evaluated:

match point:
    case Point(x, y) if x == y:
        print(f"The point is located on the diagonal Y=X at {x}.")
    case Point(x, y):
        print(f"Point is not on the diagonal.")
Other Key Features
Several other key features:

Like unpacking assignments, tuple and list patterns have exactly the same meaning and actually match arbitrary sequences. Technically, the subject must be a sequence. Therefore, an important exception is that patterns don’t match iterators. Also, to prevent a common mistake, sequence patterns don’t match strings.

Sequence patterns support wildcards: [x, y, *rest] and (x, y, *rest) work similar to wildcards in unpacking assignments. The name after * may also be _, so (x, y, *_) matches a sequence of at least two items without binding the remaining items.

Mapping patterns: {"bandwidth": b, "latency": l} captures the "bandwidth" and "latency" values from a dict. Unlike sequence patterns, extra keys are ignored. A wildcard **rest is also supported. (But **_ would be redundant, so is not allowed.)

Subpatterns may be captured using the as keyword:

case (Point(x1, y1), Point(x2, y2) as p2): ...
This binds x1, y1, x2, y2 like you would expect without the as clause, and p2 to the entire second item of the subject.

Most literals are compared by equality. However, the singletons True, False and None are compared by identity.

Named constants may be used in patterns. These named constants must be dotted names to prevent the constant from being interpreted as a capture variable:

from enum import Enum
class Color(Enum):
    RED = 0
    GREEN = 1
    BLUE = 2

match color:
    case Color.RED:
        print("I see red!")
    case Color.GREEN:
        print("Grass is green")
    case Color.BLUE:
        print("I'm feeling the blues :(")
For the full specification see PEP 634. Motivation and rationale are in PEP 635, and a longer tutorial is in PEP 636.

Optional EncodingWarning and encoding="locale" option
The default encoding of TextIOWrapper and open() is platform and locale dependent. Since UTF-8 is used on most Unix platforms, omitting encoding option when opening UTF-8 files (e.g. JSON, YAML, TOML, Markdown) is a very common bug. For example:

# BUG: "rb" mode or encoding="utf-8" should be used.
with open("data.json") as f:
    data = json.load(f)
To find this type of bug, an optional EncodingWarning is added. It is emitted when sys.flags.warn_default_encoding is true and locale-specific default encoding is used.

-X warn_default_encoding option and PYTHONWARNDEFAULTENCODING are added to enable the warning.

See Text Encoding for more information.

New Features Related to Type Hints
This section covers major changes affecting PEP 484 type hints and the typing module.

PEP 604: New Type Union Operator
A new type union operator was introduced which enables the syntax X | Y. This provides a cleaner way of expressing ‘either type X or type Y’ instead of using typing.Union, especially in type hints.

In previous versions of Python, to apply a type hint for functions accepting arguments of multiple types, typing.Union was used:

def square(number: Union[int, float]) -> Union[int, float]:
    return number ** 2
Type hints can now be written in a more succinct manner:

def square(number: int | float) -> int | float:
    return number ** 2
This new syntax is also accepted as the second argument to isinstance() and issubclass():

>>>
>>> isinstance(1, int | str)
True
See Union Type and PEP 604 for more details.

(Contributed by Maggie Moss and Philippe Prados in bpo-41428, with additions by Yurii Karabas and Serhiy Storchaka in bpo-44490.)

PEP 612: Parameter Specification Variables
Two new options to improve the information provided to static type checkers for PEP 484‘s Callable have been added to the typing module.

The first is the parameter specification variable. They are used to forward the parameter types of one callable to another callable – a pattern commonly found in higher order functions and decorators. Examples of usage can be found in typing.ParamSpec. Previously, there was no easy way to type annotate dependency of parameter types in such a precise manner.

The second option is the new Concatenate operator. It’s used in conjunction with parameter specification variables to type annotate a higher order callable which adds or removes parameters of another callable. Examples of usage can be found in typing.Concatenate.

See typing.Callable, typing.ParamSpec, typing.Concatenate, typing.ParamSpecArgs, typing.ParamSpecKwargs, and PEP 612 for more details.

(Contributed by Ken Jin in bpo-41559, with minor enhancements by Jelle Zijlstra in bpo-43783. PEP written by Mark Mendoza.)

PEP 613: TypeAlias
PEP 484 introduced the concept of type aliases, only requiring them to be top-level unannotated assignments. This simplicity sometimes made it difficult for type checkers to distinguish between type aliases and ordinary assignments, especially when forward references or invalid types were involved. Compare:

StrCache = 'Cache[str]'  # a type alias
LOG_PREFIX = 'LOG[DEBUG]'  # a module constant
Now the typing module has a special value TypeAlias which lets you declare type aliases more explicitly:

StrCache: TypeAlias = 'Cache[str]'  # a type alias
LOG_PREFIX = 'LOG[DEBUG]'  # a module constant
See PEP 613 for more details.

(Contributed by Mikhail Golubev in bpo-41923.)

PEP 647: User-Defined Type Guards
TypeGuard has been added to the typing module to annotate type guard functions and improve information provided to static type checkers during type narrowing. For more information, please see TypeGuard‘s documentation, and PEP 647.

(Contributed by Ken Jin and Guido van Rossum in bpo-43766. PEP written by Eric Traut.)

Other Language Changes
The int type has a new method int.bit_count(), returning the number of ones in the binary expansion of a given integer, also known as the population count. (Contributed by Niklas Fiekas in bpo-29882.)

The views returned by dict.keys(), dict.values() and dict.items() now all have a mapping attribute that gives a types.MappingProxyType object wrapping the original dictionary. (Contributed by Dennis Sweeney in bpo-40890.)

PEP 618: The zip() function now has an optional strict flag, used to require that all the iterables have an equal length.

Builtin and extension functions that take integer arguments no longer accept Decimals, Fractions and other objects that can be converted to integers only with a loss (e.g. that have the __int__() method but do not have the __index__() method). (Contributed by Serhiy Storchaka in bpo-37999.)

If object.__ipow__() returns NotImplemented, the operator will correctly fall back to object.__pow__() and object.__rpow__() as expected. (Contributed by Alex Shkop in bpo-38302.)

Assignment expressions can now be used unparenthesized within set literals and set comprehensions, as well as in sequence indexes (but not slices).

Functions have a new __builtins__ attribute which is used to look for builtin symbols when a function is executed, instead of looking into __globals__['__builtins__']. The attribute is initialized from __globals__["__builtins__"] if it exists, else from the current builtins. (Contributed by Mark Shannon in bpo-42990.)

Two new builtin functions – aiter() and anext() have been added to provide asynchronous counterparts to iter() and next(), respectively. (Contributed by Joshua Bronson, Daniel Pope, and Justin Wang in bpo-31861.)

Static methods (@staticmethod) and class methods (@classmethod) now inherit the method attributes (__module__, __name__, __qualname__, __doc__, __annotations__) and have a new __wrapped__ attribute. Moreover, static methods are now callable as regular functions. (Contributed by Victor Stinner in bpo-43682.)

Annotations for complex targets (everything beside simple name targets defined by PEP 526) no longer cause any runtime effects with from __future__ import annotations. (Contributed by Batuhan Taskaya in bpo-42737.)

Class and module objects now lazy-create empty annotations dicts on demand. The annotations dicts are stored in the object’s __dict__ for backwards compatibility. This improves the best practices for working with __annotations__; for more information, please see Annotations Best Practices. (Contributed by Larry Hastings in bpo-43901.)

Annotations consist of yield, yield from, await or named expressions are now forbidden under from __future__ import annotations due to their side effects. (Contributed by Batuhan Taskaya in bpo-42725.)

Usage of unbound variables, super() and other expressions that might alter the processing of symbol table as annotations are now rendered effectless under from __future__ import annotations. (Contributed by Batuhan Taskaya in bpo-42725.)

Hashes of NaN values of both float type and decimal.Decimal type now depend on object identity. Formerly, they always hashed to 0 even though NaN values are not equal to one another. This caused potentially quadratic runtime behavior due to excessive hash collisions when creating dictionaries and sets containing multiple NaNs. (Contributed by Raymond Hettinger in bpo-43475.)

A SyntaxError (instead of a NameError) will be raised when deleting the __debug__ constant. (Contributed by Dong-hee Na in bpo-45000.)

SyntaxError exceptions now have end_lineno and end_offset attributes. They will be None if not determined. (Contributed by Pablo Galindo in bpo-43914.)

New Modules
None yet.

Improved Modules
asyncio
Add missing connect_accepted_socket() method. (Contributed by Alex Grönholm in bpo-41332.)

argparse
Misleading phrase “optional arguments” was replaced with “options” in argparse help. Some tests might require adaptation if they rely on exact output match. (Contributed by Raymond Hettinger in bpo-9694.)

array
The index() method of array.array now has optional start and stop parameters. (Contributed by Anders Lorentsen and Zackery Spytz in bpo-31956.)

asynchat, asyncore, smtpd
These modules have been marked as deprecated in their module documentation since Python 3.6. An import-time DeprecationWarning has now been added to all three of these modules.

base64
Add base64.b32hexencode() and base64.b32hexdecode() to support the Base32 Encoding with Extended Hex Alphabet.

bdb
Add clearBreakpoints() to reset all set breakpoints. (Contributed by Irit Katriel in bpo-24160.)

bisect
Added the possibility of providing a key function to the APIs in the bisect module. (Contributed by Raymond Hettinger in bpo-4356.)

codecs
Add a codecs.unregister() function to unregister a codec search function. (Contributed by Hai Shi in bpo-41842.)

collections.abc
The __args__ of the parameterized generic for collections.abc.Callable are now consistent with typing.Callable. collections.abc.Callable generic now flattens type parameters, similar to what typing.Callable currently does. This means that collections.abc.Callable[[int, str], str] will have __args__ of (int, str, str); previously this was ([int, str], str). To allow this change, types.GenericAlias can now be subclassed, and a subclass will be returned when subscripting the collections.abc.Callable type. Note that a TypeError may be raised for invalid forms of parameterizing collections.abc.Callable which may have passed silently in Python 3.9. (Contributed by Ken Jin in bpo-42195.)

contextlib
Add a contextlib.aclosing() context manager to safely close async generators and objects representing asynchronously released resources. (Contributed by Joongi Kim and John Belmonte in bpo-41229.)

Add asynchronous context manager support to contextlib.nullcontext(). (Contributed by Tom Gringauz in bpo-41543.)

Add AsyncContextDecorator, for supporting usage of async context managers as decorators.

curses
The extended color functions added in ncurses 6.1 will be used transparently by curses.color_content(), curses.init_color(), curses.init_pair(), and curses.pair_content(). A new function, curses.has_extended_color_support(), indicates whether extended color support is provided by the underlying ncurses library. (Contributed by Jeffrey Kintscher and Hans Petter Jansson in bpo-36982.)

The BUTTON5_* constants are now exposed in the curses module if they are provided by the underlying curses library. (Contributed by Zackery Spytz in bpo-39273.)

dataclasses
__slots__
Added slots parameter in dataclasses.dataclass() decorator. (Contributed by Yurii Karabas in bpo-42269)

Keyword-only fields
dataclasses now supports fields that are keyword-only in the generated __init__ method. There are a number of ways of specifying keyword-only fields.

You can say that every field is keyword-only:

from dataclasses import dataclass

@dataclass(kw_only=True)
class Birthday:
    name: str
    birthday: datetime.date
Both name and birthday are keyword-only parameters to the generated __init__ method.

You can specify keyword-only on a per-field basis:

from dataclasses import dataclass

@dataclass
class Birthday:
    name: str
    birthday: datetime.date = field(kw_only=True)
Here only birthday is keyword-only. If you set kw_only on individual fields, be aware that there are rules about re-ordering fields due to keyword-only fields needing to follow non-keyword-only fields. See the full dataclasses documentation for details.

You can also specify that all fields following a KW_ONLY marker are keyword-only. This will probably be the most common usage:

from dataclasses import dataclass, KW_ONLY

@dataclass
class Point:
    x: float
    y: float
    _: KW_ONLY
    z: float = 0.0
    t: float = 0.0
Here, z and t are keyword-only parameters, while x and y are not. (Contributed by Eric V. Smith in bpo-43532.)

distutils
The entire distutils package is deprecated, to be removed in Python 3.12. Its functionality for specifying package builds has already been completely replaced by third-party packages setuptools and packaging, and most other commonly used APIs are available elsewhere in the standard library (such as platform, shutil, subprocess or sysconfig). There are no plans to migrate any other functionality from distutils, and applications that are using other functions should plan to make private copies of the code. Refer to PEP 632 for discussion.

The bdist_wininst command deprecated in Python 3.8 has been removed. The bdist_wheel command is now recommended to distribute binary packages on Windows. (Contributed by Victor Stinner in bpo-42802.)

doctest
When a module does not define __loader__, fall back to __spec__.loader. (Contributed by Brett Cannon in bpo-42133.)

encodings
encodings.normalize_encoding() now ignores non-ASCII characters. (Contributed by Hai Shi in bpo-39337.)

fileinput
Add encoding and errors parameters in fileinput.input() and fileinput.FileInput. (Contributed by Inada Naoki in bpo-43712.)

fileinput.hook_compressed() now returns TextIOWrapper object when mode is “r” and file is compressed, like uncompressed files. (Contributed by Inada Naoki in bpo-5758.)

faulthandler
The faulthandler module now detects if a fatal error occurs during a garbage collector collection. (Contributed by Victor Stinner in bpo-44466.)

gc
Add audit hooks for gc.get_objects(), gc.get_referrers() and gc.get_referents(). (Contributed by Pablo Galindo in bpo-43439.)

glob
Add the root_dir and dir_fd parameters in glob() and iglob() which allow to specify the root directory for searching. (Contributed by Serhiy Storchaka in bpo-38144.)

hashlib
The hashlib module requires OpenSSL 1.1.1 or newer. (Contributed by Christian Heimes in PEP 644 and bpo-43669.)

The hashlib module has preliminary support for OpenSSL 3.0.0. (Contributed by Christian Heimes in bpo-38820 and other issues.)

The pure-Python fallback of pbkdf2_hmac() is deprecated. In the future PBKDF2-HMAC will only be available when Python has been built with OpenSSL support. (Contributed by Christian Heimes in bpo-43880.)

hmac
The hmac module now uses OpenSSL’s HMAC implementation internally. (Contributed by Christian Heimes in bpo-40645.)

IDLE and idlelib
Make IDLE invoke sys.excepthook() (when started without ‘-n’). User hooks were previously ignored. (Contributed by Ken Hilton in bpo-43008.)

Rearrange the settings dialog. Split the General tab into Windows and Shell/Ed tabs. Move help sources, which extend the Help menu, to the Extensions tab. Make space for new options and shorten the dialog. The latter makes the dialog better fit small screens. (Contributed by Terry Jan Reedy in bpo-40468.) Move the indent space setting from the Font tab to the new Windows tab. (Contributed by Mark Roseman and Terry Jan Reedy in bpo-33962.)

The changes above were backported to a 3.9 maintenance release.

Add a Shell sidebar. Move the primary prompt (‘>>>’) to the sidebar. Add secondary prompts (’…’) to the sidebar. Left click and optional drag selects one or more lines of text, as with the editor line number sidebar. Right click after selecting text lines displays a context menu with ‘copy with prompts’. This zips together prompts from the sidebar with lines from the selected text. This option also appears on the context menu for the text. (Contributed by Tal Einat in bpo-37903.)

Use spaces instead of tabs to indent interactive code. This makes interactive code entries ‘look right’. Making this feasible was a major motivation for adding the shell sidebar. (Contributed by Terry Jan Reedy in bpo-37892.)

Highlight the new soft keywords match, case, and _ in pattern-matching statements. However, this highlighting is not perfect and will be incorrect in some rare cases, including some _-s in case patterns. (Contributed by Tal Einat in bpo-44010.)

New in 3.10 maintenance releases.

Apply syntax highlighting to .pyi files. (Contributed by Alex Waygood and Terry Jan Reedy in bpo-45447.)

Include prompts when saving Shell with inputs and outputs. (Contributed by Terry Jan Reedy in gh-95191.)

importlib.metadata
Feature parity with importlib_metadata 4.6 (history).

importlib.metadata entry points now provide a nicer experience for selecting entry points by group and name through a new importlib.metadata.EntryPoints class. See the Compatibility Note in the docs for more info on the deprecation and usage.

Added importlib.metadata.packages_distributions() for resolving top-level Python modules and packages to their importlib.metadata.Distribution.

inspect
When a module does not define __loader__, fall back to __spec__.loader. (Contributed by Brett Cannon in bpo-42133.)

Add inspect.get_annotations(), which safely computes the annotations defined on an object. It works around the quirks of accessing the annotations on various types of objects, and makes very few assumptions about the object it examines. inspect.get_annotations() can also correctly un-stringize stringized annotations. inspect.get_annotations() is now considered best practice for accessing the annotations dict defined on any Python object; for more information on best practices for working with annotations, please see Annotations Best Practices. Relatedly, inspect.signature(), inspect.Signature.from_callable(), and inspect.Signature.from_function() now call inspect.get_annotations() to retrieve annotations. This means inspect.signature() and inspect.Signature.from_callable() can also now un-stringize stringized annotations. (Contributed by Larry Hastings in bpo-43817.)

itertools
Add itertools.pairwise(). (Contributed by Raymond Hettinger in bpo-38200.)

linecache
When a module does not define __loader__, fall back to __spec__.loader. (Contributed by Brett Cannon in bpo-42133.)

os
Add os.cpu_count() support for VxWorks RTOS. (Contributed by Peixing Xin in bpo-41440.)

Add a new function os.eventfd() and related helpers to wrap the eventfd2 syscall on Linux. (Contributed by Christian Heimes in bpo-41001.)

Add os.splice() that allows to move data between two file descriptors without copying between kernel address space and user address space, where one of the file descriptors must refer to a pipe. (Contributed by Pablo Galindo in bpo-41625.)

Add O_EVTONLY, O_FSYNC, O_SYMLINK and O_NOFOLLOW_ANY for macOS. (Contributed by Dong-hee Na in bpo-43106.)

os.path
os.path.realpath() now accepts a strict keyword-only argument. When set to True, OSError is raised if a path doesn’t exist or a symlink loop is encountered. (Contributed by Barney Gale in bpo-43757.)

pathlib
Add slice support to PurePath.parents. (Contributed by Joshua Cannon in bpo-35498.)

Add negative indexing support to PurePath.parents. (Contributed by Yaroslav Pankovych in bpo-21041.)

Add Path.hardlink_to method that supersedes link_to(). The new method has the same argument order as symlink_to(). (Contributed by Barney Gale in bpo-39950.)

pathlib.Path.stat() and chmod() now accept a follow_symlinks keyword-only argument for consistency with corresponding functions in the os module. (Contributed by Barney Gale in bpo-39906.)

platform
Add platform.freedesktop_os_release() to retrieve operation system identification from freedesktop.org os-release standard file. (Contributed by Christian Heimes in bpo-28468.)

pprint
pprint.pprint() now accepts a new underscore_numbers keyword argument. (Contributed by sblondon in bpo-42914.)

pprint can now pretty-print dataclasses.dataclass instances. (Contributed by Lewis Gaul in bpo-43080.)

py_compile
Add --quiet option to command-line interface of py_compile. (Contributed by Gregory Schevchenko in bpo-38731.)

pyclbr
Add an end_lineno attribute to the Function and Class objects in the tree returned by pyclbr.readline() and pyclbr.readline_ex(). It matches the existing (start) lineno. (Contributed by Aviral Srivastava in bpo-38307.)

shelve
The shelve module now uses pickle.DEFAULT_PROTOCOL by default instead of pickle protocol 3 when creating shelves. (Contributed by Zackery Spytz in bpo-34204.)

statistics
Add covariance(), Pearson’s correlation(), and simple linear_regression() functions. (Contributed by Tymoteusz Wołodźko in bpo-38490.)

site
When a module does not define __loader__, fall back to __spec__.loader. (Contributed by Brett Cannon in bpo-42133.)

socket
The exception socket.timeout is now an alias of TimeoutError. (Contributed by Christian Heimes in bpo-42413.)

Add option to create MPTCP sockets with IPPROTO_MPTCP (Contributed by Rui Cunha in bpo-43571.)

Add IP_RECVTOS option to receive the type of service (ToS) or DSCP/ECN fields (Contributed by Georg Sauthoff in bpo-44077.)

ssl
The ssl module requires OpenSSL 1.1.1 or newer. (Contributed by Christian Heimes in PEP 644 and bpo-43669.)

The ssl module has preliminary support for OpenSSL 3.0.0 and new option OP_IGNORE_UNEXPECTED_EOF. (Contributed by Christian Heimes in bpo-38820, bpo-43794, bpo-43788, bpo-43791, bpo-43799, bpo-43920, bpo-43789, and bpo-43811.)

Deprecated function and use of deprecated constants now result in a DeprecationWarning. ssl.SSLContext.options has OP_NO_SSLv2 and OP_NO_SSLv3 set by default and therefore cannot warn about setting the flag again. The deprecation section has a list of deprecated features. (Contributed by Christian Heimes in bpo-43880.)

The ssl module now has more secure default settings. Ciphers without forward secrecy or SHA-1 MAC are disabled by default. Security level 2 prohibits weak RSA, DH, and ECC keys with less than 112 bits of security. SSLContext defaults to minimum protocol version TLS 1.2. Settings are based on Hynek Schlawack’s research. (Contributed by Christian Heimes in bpo-43998.)

The deprecated protocols SSL 3.0, TLS 1.0, and TLS 1.1 are no longer officially supported. Python does not block them actively. However OpenSSL build options, distro configurations, vendor patches, and cipher suites may prevent a successful handshake.

Add a timeout parameter to the ssl.get_server_certificate() function. (Contributed by Zackery Spytz in bpo-31870.)

The ssl module uses heap-types and multi-phase initialization. (Contributed by Christian Heimes in bpo-42333.)

A new verify flag VERIFY_X509_PARTIAL_CHAIN has been added. (Contributed by l0x in bpo-40849.)

sqlite3
Add audit events for connect/handle(), enable_load_extension(), and load_extension(). (Contributed by Erlend E. Aasland in bpo-43762.)

sys
Add sys.orig_argv attribute: the list of the original command line arguments passed to the Python executable. (Contributed by Victor Stinner in bpo-23427.)

Add sys.stdlib_module_names, containing the list of the standard library module names. (Contributed by Victor Stinner in bpo-42955.)

_thread
_thread.interrupt_main() now takes an optional signal number to simulate (the default is still signal.SIGINT). (Contributed by Antoine Pitrou in bpo-43356.)

threading
Add threading.gettrace() and threading.getprofile() to retrieve the functions set by threading.settrace() and threading.setprofile() respectively. (Contributed by Mario Corchero in bpo-42251.)

Add threading.__excepthook__ to allow retrieving the original value of threading.excepthook() in case it is set to a broken or a different value. (Contributed by Mario Corchero in bpo-42308.)

traceback
The format_exception(), format_exception_only(), and print_exception() functions can now take an exception object as a positional-only argument. (Contributed by Zackery Spytz and Matthias Bussonnier in bpo-26389.)

types
Reintroduce the types.EllipsisType, types.NoneType and types.NotImplementedType classes, providing a new set of types readily interpretable by type checkers. (Contributed by Bas van Beek in bpo-41810.)

typing
For major changes, see New Features Related to Type Hints.

The behavior of typing.Literal was changed to conform with PEP 586 and to match the behavior of static type checkers specified in the PEP.

Literal now de-duplicates parameters.

Equality comparisons between Literal objects are now order independent.

Literal comparisons now respect types. For example, Literal[0] == Literal[False] previously evaluated to True. It is now False. To support this change, the internally used type cache now supports differentiating types.

Literal objects will now raise a TypeError exception during equality comparisons if any of their parameters are not hashable. Note that declaring Literal with unhashable parameters will not throw an error:

>>>
>>> from typing import Literal
>>> Literal[{0}]
>>> Literal[{0}] == Literal[{False}]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: unhashable type: 'set'
(Contributed by Yurii Karabas in bpo-42345.)

Add new function typing.is_typeddict() to introspect if an annotation is a typing.TypedDict. (Contributed by Patrick Reader in bpo-41792.)

Subclasses of typing.Protocol which only have data variables declared will now raise a TypeError when checked with isinstance unless they are decorated with runtime_checkable(). Previously, these checks passed silently. Users should decorate their subclasses with the runtime_checkable() decorator if they want runtime protocols. (Contributed by Yurii Karabas in bpo-38908.)

Importing from the typing.io and typing.re submodules will now emit DeprecationWarning. These submodules have been deprecated since Python 3.8 and will be removed in a future version of Python. Anything belonging to those submodules should be imported directly from typing instead. (Contributed by Sebastian Rittau in bpo-38291.)

unittest
Add new method assertNoLogs() to complement the existing assertLogs(). (Contributed by Kit Yan Choi in bpo-39385.)

urllib.parse
Python versions earlier than Python 3.10 allowed using both ; and & as query parameter separators in urllib.parse.parse_qs() and urllib.parse.parse_qsl(). Due to security concerns, and to conform with newer W3C recommendations, this has been changed to allow only a single separator key, with & as the default. This change also affects cgi.parse() and cgi.parse_multipart() as they use the affected functions internally. For more details, please see their respective documentation. (Contributed by Adam Goldschmidt, Senthil Kumaran and Ken Jin in bpo-42967.)

The presence of newline or tab characters in parts of a URL allows for some forms of attacks. Following the WHATWG specification that updates RFC 3986, ASCII newline \n, \r and tab \t characters are stripped from the URL by the parser in urllib.parse preventing such attacks. The removal characters are controlled by a new module level variable urllib.parse._UNSAFE_URL_BYTES_TO_REMOVE. (See bpo-43882)

xml
Add a LexicalHandler class to the xml.sax.handler module. (Contributed by Jonathan Gossage and Zackery Spytz in bpo-35018.)

zipimport
Add methods related to PEP 451: find_spec(), zipimport.zipimporter.create_module(), and zipimport.zipimporter.exec_module(). (Contributed by Brett Cannon in bpo-42131.)

Add invalidate_caches() method. (Contributed by Desmond Cheong in bpo-14678.)

Optimizations
Constructors str(), bytes() and bytearray() are now faster (around 30–40% for small objects). (Contributed by Serhiy Storchaka in bpo-41334.)

The runpy module now imports fewer modules. The python3 -m module-name command startup time is 1.4x faster in average. On Linux, python3 -I -m module-name imports 69 modules on Python 3.9, whereas it only imports 51 modules (-18) on Python 3.10. (Contributed by Victor Stinner in bpo-41006 and bpo-41718.)

The LOAD_ATTR instruction now uses new “per opcode cache” mechanism. It is about 36% faster now for regular attributes and 44% faster for slots. (Contributed by Pablo Galindo and Yury Selivanov in bpo-42093 and Guido van Rossum in bpo-42927, based on ideas implemented originally in PyPy and MicroPython.)

When building Python with --enable-optimizations now -fno-semantic-interposition is added to both the compile and link line. This speeds builds of the Python interpreter created with --enable-shared with gcc by up to 30%. See this article for more details. (Contributed by Victor Stinner and Pablo Galindo in bpo-38980.)

Use a new output buffer management code for bz2 / lzma / zlib modules, and add .readall() function to _compression.DecompressReader class. bz2 decompression is now 1.09x ~ 1.17x faster, lzma decompression 1.20x ~ 1.32x faster, GzipFile.read(-1) 1.11x ~ 1.18x faster. (Contributed by Ma Lin, reviewed by Gregory P. Smith, in bpo-41486)

When using stringized annotations, annotations dicts for functions are no longer created when the function is created. Instead, they are stored as a tuple of strings, and the function object lazily converts this into the annotations dict on demand. This optimization cuts the CPU time needed to define an annotated function by half. (Contributed by Yurii Karabas and Inada Naoki in bpo-42202.)

Substring search functions such as str1 in str2 and str2.find(str1) now sometimes use Crochemore & Perrin’s “Two-Way” string searching algorithm to avoid quadratic behavior on long strings. (Contributed by Dennis Sweeney in bpo-41972)

Add micro-optimizations to _PyType_Lookup() to improve type attribute cache lookup performance in the common case of cache hits. This makes the interpreter 1.04 times faster on average. (Contributed by Dino Viehland in bpo-43452.)

The following built-in functions now support the faster PEP 590 vectorcall calling convention: map(), filter(), reversed(), bool() and float(). (Contributed by Dong-hee Na and Jeroen Demeyer in bpo-43575, bpo-43287, bpo-41922, bpo-41873 and bpo-41870.)

BZ2File performance is improved by removing internal RLock. This makes BZ2File thread unsafe in the face of multiple simultaneous readers or writers, just like its equivalent classes in gzip and lzma have always been. (Contributed by Inada Naoki in bpo-43785.)

Deprecated
Currently Python accepts numeric literals immediately followed by keywords, for example 0in x, 1or x, 0if 1else 2. It allows confusing and ambiguous expressions like [0x1for x in y] (which can be interpreted as [0x1 for x in y] or [0x1f or x in y]). Starting in this release, a deprecation warning is raised if the numeric literal is immediately followed by one of keywords and, else, for, if, in, is and or. In future releases it will be changed to syntax warning, and finally to syntax error. (Contributed by Serhiy Storchaka in bpo-43833.)

Starting in this release, there will be a concerted effort to begin cleaning up old import semantics that were kept for Python 2.7 compatibility. Specifically, find_loader()/find_module() (superseded by find_spec()), load_module() (superseded by exec_module()), module_repr() (which the import system takes care of for you), the __package__ attribute (superseded by __spec__.parent), the __loader__ attribute (superseded by __spec__.loader), and the __cached__ attribute (superseded by __spec__.cached) will slowly be removed (as well as other classes and methods in importlib). ImportWarning and/or DeprecationWarning will be raised as appropriate to help identify code which needs updating during this transition.

The entire distutils namespace is deprecated, to be removed in Python 3.12. Refer to the module changes section for more information.

Non-integer arguments to random.randrange() are deprecated. The ValueError is deprecated in favor of a TypeError. (Contributed by Serhiy Storchaka and Raymond Hettinger in bpo-37319.)

The various load_module() methods of importlib have been documented as deprecated since Python 3.6, but will now also trigger a DeprecationWarning. Use exec_module() instead. (Contributed by Brett Cannon in bpo-26131.)

zimport.zipimporter.load_module() has been deprecated in preference for exec_module(). (Contributed by Brett Cannon in bpo-26131.)

The use of load_module() by the import system now triggers an ImportWarning as exec_module() is preferred. (Contributed by Brett Cannon in bpo-26131.)

The use of importlib.abc.MetaPathFinder.find_module() and importlib.abc.PathEntryFinder.find_module() by the import system now trigger an ImportWarning as importlib.abc.MetaPathFinder.find_spec() and importlib.abc.PathEntryFinder.find_spec() are preferred, respectively. You can use importlib.util.spec_from_loader() to help in porting. (Contributed by Brett Cannon in bpo-42134.)

The use of importlib.abc.PathEntryFinder.find_loader() by the import system now triggers an ImportWarning as importlib.abc.PathEntryFinder.find_spec() is preferred. You can use importlib.util.spec_from_loader() to help in porting. (Contributed by Brett Cannon in bpo-43672.)

The various implementations of importlib.abc.MetaPathFinder.find_module() ( importlib.machinery.BuiltinImporter.find_module(), importlib.machinery.FrozenImporter.find_module(), importlib.machinery.WindowsRegistryFinder.find_module(), importlib.machinery.PathFinder.find_module(), importlib.abc.MetaPathFinder.find_module() ), importlib.abc.PathEntryFinder.find_module() ( importlib.machinery.FileFinder.find_module() ), and importlib.abc.PathEntryFinder.find_loader() ( importlib.machinery.FileFinder.find_loader() ) now raise DeprecationWarning and are slated for removal in Python 3.12 (previously they were documented as deprecated in Python 3.4). (Contributed by Brett Cannon in bpo-42135.)

importlib.abc.Finder is deprecated (including its sole method, find_module()). Both importlib.abc.MetaPathFinder and importlib.abc.PathEntryFinder no longer inherit from the class. Users should inherit from one of these two classes as appropriate instead. (Contributed by Brett Cannon in bpo-42135.)

The deprecations of imp, importlib.find_loader(), importlib.util.set_package_wrapper(), importlib.util.set_loader_wrapper(), importlib.util.module_for_loader(), pkgutil.ImpImporter, and pkgutil.ImpLoader have all been updated to list Python 3.12 as the slated version of removal (they began raising DeprecationWarning in previous versions of Python). (Contributed by Brett Cannon in bpo-43720.)

The import system now uses the __spec__ attribute on modules before falling back on module_repr() for a module’s __repr__() method. Removal of the use of module_repr() is scheduled for Python 3.12. (Contributed by Brett Cannon in bpo-42137.)

importlib.abc.Loader.module_repr(), importlib.machinery.FrozenLoader.module_repr(), and importlib.machinery.BuiltinLoader.module_repr() are deprecated and slated for removal in Python 3.12. (Contributed by Brett Cannon in bpo-42136.)

sqlite3.OptimizedUnicode has been undocumented and obsolete since Python 3.3, when it was made an alias to str. It is now deprecated, scheduled for removal in Python 3.12. (Contributed by Erlend E. Aasland in bpo-42264.)

asyncio.get_event_loop() now emits a deprecation warning if there is no running event loop. In the future it will be an alias of get_running_loop(). asyncio functions which implicitly create Future or Task objects now emit a deprecation warning if there is no running event loop and no explicit loop argument is passed: ensure_future(), wrap_future(), gather(), shield(), as_completed() and constructors of Future, Task, StreamReader, StreamReaderProtocol. (Contributed by Serhiy Storchaka in bpo-39529.)

The undocumented built-in function sqlite3.enable_shared_cache is now deprecated, scheduled for removal in Python 3.12. Its use is strongly discouraged by the SQLite3 documentation. See the SQLite3 docs for more details. If a shared cache must be used, open the database in URI mode using the cache=shared query parameter. (Contributed by Erlend E. Aasland in bpo-24464.)

The following threading methods are now deprecated:

threading.currentThread => threading.current_thread()

threading.activeCount => threading.active_count()

threading.Condition.notifyAll => threading.Condition.notify_all()

threading.Event.isSet => threading.Event.is_set()

threading.Thread.setName => threading.Thread.name

threading.thread.getName => threading.Thread.name

threading.Thread.isDaemon => threading.Thread.daemon

threading.Thread.setDaemon => threading.Thread.daemon

(Contributed by Jelle Zijlstra in gh-87889.)

pathlib.Path.link_to() is deprecated and slated for removal in Python 3.12. Use pathlib.Path.hardlink_to() instead. (Contributed by Barney Gale in bpo-39950.)

cgi.log() is deprecated and slated for removal in Python 3.12. (Contributed by Inada Naoki in bpo-41139.)

The following ssl features have been deprecated since Python 3.6, Python 3.7, or OpenSSL 1.1.0 and will be removed in 3.11:

OP_NO_SSLv2, OP_NO_SSLv3, OP_NO_TLSv1, OP_NO_TLSv1_1, OP_NO_TLSv1_2, and OP_NO_TLSv1_3 are replaced by sslSSLContext.minimum_version and sslSSLContext.maximum_version.

PROTOCOL_SSLv2, PROTOCOL_SSLv3, PROTOCOL_SSLv23, PROTOCOL_TLSv1, PROTOCOL_TLSv1_1, PROTOCOL_TLSv1_2, and PROTOCOL_TLS are deprecated in favor of PROTOCOL_TLS_CLIENT and PROTOCOL_TLS_SERVER

wrap_socket() is replaced by ssl.SSLContext.wrap_socket()

match_hostname()

RAND_pseudo_bytes(), RAND_egd()

NPN features like ssl.SSLSocket.selected_npn_protocol() and ssl.SSLContext.set_npn_protocols() are replaced by ALPN.

The threading debug (PYTHONTHREADDEBUG environment variable) is deprecated in Python 3.10 and will be removed in Python 3.12. This feature requires a debug build of Python. (Contributed by Victor Stinner in bpo-44584.)

Importing from the typing.io and typing.re submodules will now emit DeprecationWarning. These submodules will be removed in a future version of Python. Anything belonging to these submodules should be imported directly from typing instead. (Contributed by Sebastian Rittau in bpo-38291.)

Removed
Removed special methods __int__, __float__, __floordiv__, __mod__, __divmod__, __rfloordiv__, __rmod__ and __rdivmod__ of the complex class. They always raised a TypeError. (Contributed by Serhiy Storchaka in bpo-41974.)

The ParserBase.error() method from the private and undocumented _markupbase module has been removed. html.parser.HTMLParser is the only subclass of ParserBase and its error() implementation was already removed in Python 3.5. (Contributed by Berker Peksag in bpo-31844.)

Removed the unicodedata.ucnhash_CAPI attribute which was an internal PyCapsule object. The related private _PyUnicode_Name_CAPI structure was moved to the internal C API. (Contributed by Victor Stinner in bpo-42157.)

Removed the parser module, which was deprecated in 3.9 due to the switch to the new PEG parser, as well as all the C source and header files that were only being used by the old parser, including node.h, parser.h, graminit.h and grammar.h.

Removed the Public C API functions PyParser_SimpleParseStringFlags, PyParser_SimpleParseStringFlagsFilename, PyParser_SimpleParseFileFlags and PyNode_Compile that were deprecated in 3.9 due to the switch to the new PEG parser.

Removed the formatter module, which was deprecated in Python 3.4. It is somewhat obsolete, little used, and not tested. It was originally scheduled to be removed in Python 3.6, but such removals were delayed until after Python 2.7 EOL. Existing users should copy whatever classes they use into their code. (Contributed by Dong-hee Na and Terry J. Reedy in bpo-42299.)

Removed the PyModule_GetWarningsModule() function that was useless now due to the _warnings module was converted to a builtin module in 2.6. (Contributed by Hai Shi in bpo-42599.)

Remove deprecated aliases to Collections Abstract Base Classes from the collections module. (Contributed by Victor Stinner in bpo-37324.)

The loop parameter has been removed from most of asyncio‘s high-level API following deprecation in Python 3.8. The motivation behind this change is multifold:

This simplifies the high-level API.

The functions in the high-level API have been implicitly getting the current thread’s running event loop since Python 3.7. There isn’t a need to pass the event loop to the API in most normal use cases.

Event loop passing is error-prone especially when dealing with loops running in different threads.

Note that the low-level API will still accept loop. See Changes in the Python API for examples of how to replace existing code.

(Contributed by Yurii Karabas, Andrew Svetlov, Yury Selivanov and Kyle Stanley in bpo-42392.)

Porting to Python 3.10
This section lists previously described changes and other bugfixes that may require changes to your code.

Changes in the Python syntax
Deprecation warning is now emitted when compiling previously valid syntax if the numeric literal is immediately followed by a keyword (like in 0in x). In future releases it will be changed to syntax warning, and finally to a syntax error. To get rid of the warning and make the code compatible with future releases just add a space between the numeric literal and the following keyword. (Contributed by Serhiy Storchaka in bpo-43833.)

Changes in the Python API
The etype parameters of the format_exception(), format_exception_only(), and print_exception() functions in the traceback module have been renamed to exc. (Contributed by Zackery Spytz and Matthias Bussonnier in bpo-26389.)

atexit: At Python exit, if a callback registered with atexit.register() fails, its exception is now logged. Previously, only some exceptions were logged, and the last exception was always silently ignored. (Contributed by Victor Stinner in bpo-42639.)

collections.abc.Callable generic now flattens type parameters, similar to what typing.Callable currently does. This means that collections.abc.Callable[[int, str], str] will have __args__ of (int, str, str); previously this was ([int, str], str). Code which accesses the arguments via typing.get_args() or __args__ need to account for this change. Furthermore, TypeError may be raised for invalid forms of parameterizing collections.abc.Callable which may have passed silently in Python 3.9. (Contributed by Ken Jin in bpo-42195.)

socket.htons() and socket.ntohs() now raise OverflowError instead of DeprecationWarning if the given parameter will not fit in a 16-bit unsigned integer. (Contributed by Erlend E. Aasland in bpo-42393.)

The loop parameter has been removed from most of asyncio‘s high-level API following deprecation in Python 3.8.

A coroutine that currently looks like this:

async def foo(loop):
    await asyncio.sleep(1, loop=loop)
Should be replaced with this:

async def foo():
    await asyncio.sleep(1)
If foo() was specifically designed not to run in the current thread’s running event loop (e.g. running in another thread’s event loop), consider using asyncio.run_coroutine_threadsafe() instead.

(Contributed by Yurii Karabas, Andrew Svetlov, Yury Selivanov and Kyle Stanley in bpo-42392.)

The types.FunctionType constructor now inherits the current builtins if the globals dictionary has no "__builtins__" key, rather than using {"None": None} as builtins: same behavior as eval() and exec() functions. Defining a function with def function(...): ... in Python is not affected, globals cannot be overridden with this syntax: it also inherits the current builtins. (Contributed by Victor Stinner in bpo-42990.)

Changes in the C API
The C API functions PyParser_SimpleParseStringFlags, PyParser_SimpleParseStringFlagsFilename, PyParser_SimpleParseFileFlags, PyNode_Compile and the type used by these functions, struct _node, were removed due to the switch to the new PEG parser.

Source should be now be compiled directly to a code object using, for example, Py_CompileString(). The resulting code object can then be evaluated using, for example, PyEval_EvalCode().

Specifically:

A call to PyParser_SimpleParseStringFlags followed by PyNode_Compile can be replaced by calling Py_CompileString().

There is no direct replacement for PyParser_SimpleParseFileFlags. To compile code from a FILE * argument, you will need to read the file in C and pass the resulting buffer to Py_CompileString().

To compile a file given a char * filename, explicitly open the file, read it and compile the result. One way to do this is using the io module with PyImport_ImportModule(), PyObject_CallMethod(), PyBytes_AsString() and Py_CompileString(), as sketched below. (Declarations and error handling are omitted.)

io_module = Import_ImportModule("io");
fileobject = PyObject_CallMethod(io_module, "open", "ss", filename, "rb");
source_bytes_object = PyObject_CallMethod(fileobject, "read", "");
result = PyObject_CallMethod(fileobject, "close", "");
source_buf = PyBytes_AsString(source_bytes_object);
code = Py_CompileString(source_buf, filename, Py_file_input);
For FrameObject objects, the f_lasti member now represents a wordcode offset instead of a simple offset into the bytecode string. This means that this number needs to be multiplied by 2 to be used with APIs that expect a byte offset instead (like PyCode_Addr2Line() for example). Notice as well that the f_lasti member of FrameObject objects is not considered stable: please use PyFrame_GetLineNumber() instead.

CPython bytecode changes
The MAKE_FUNCTION instruction now accepts either a dict or a tuple of strings as the function’s annotations. (Contributed by Yurii Karabas and Inada Naoki in bpo-42202.)

Build Changes
PEP 644: Python now requires OpenSSL 1.1.1 or newer. OpenSSL 1.0.2 is no longer supported. (Contributed by Christian Heimes in bpo-43669.)

The C99 functions snprintf() and vsnprintf() are now required to build Python. (Contributed by Victor Stinner in bpo-36020.)

sqlite3 requires SQLite 3.7.15 or higher. (Contributed by Sergey Fedoseev and Erlend E. Aasland in bpo-40744 and bpo-40810.)

The atexit module must now always be built as a built-in module. (Contributed by Victor Stinner in bpo-42639.)

Add --disable-test-modules option to the configure script: don’t build nor install test modules. (Contributed by Xavier de Gaye, Thomas Petazzoni and Peixing Xin in bpo-27640.)

Add --with-wheel-pkg-dir=PATH option to the ./configure script. If specified, the ensurepip module looks for setuptools and pip wheel packages in this directory: if both are present, these wheel packages are used instead of ensurepip bundled wheel packages.

Some Linux distribution packaging policies recommend against bundling dependencies. For example, Fedora installs wheel packages in the /usr/share/python-wheels/ directory and don’t install the ensurepip._bundled package.

(Contributed by Victor Stinner in bpo-42856.)

Add a new configure --without-static-libpython option to not build the libpythonMAJOR.MINOR.a static library and not install the python.o object file.

(Contributed by Victor Stinner in bpo-43103.)

The configure script now uses the pkg-config utility, if available, to detect the location of Tcl/Tk headers and libraries. As before, those locations can be explicitly specified with the --with-tcltk-includes and --with-tcltk-libs configuration options. (Contributed by Manolis Stamatogiannakis in bpo-42603.)

Add --with-openssl-rpath option to configure script. The option simplifies building Python with a custom OpenSSL installation, e.g. ./configure --with-openssl=/path/to/openssl --with-openssl-rpath=auto. (Contributed by Christian Heimes in bpo-43466.)

C API Changes
PEP 652: Maintaining the Stable ABI
The Stable ABI (Application Binary Interface) for extension modules or embedding Python is now explicitly defined. C API Stability describes C API and ABI stability guarantees along with best practices for using the Stable ABI.

(Contributed by Petr Viktorin in PEP 652 and bpo-43795.)

New Features
The result of PyNumber_Index() now always has exact type int. Previously, the result could have been an instance of a subclass of int. (Contributed by Serhiy Storchaka in bpo-40792.)

Add a new orig_argv member to the PyConfig structure: the list of the original command line arguments passed to the Python executable. (Contributed by Victor Stinner in bpo-23427.)

The PyDateTime_DATE_GET_TZINFO() and PyDateTime_TIME_GET_TZINFO() macros have been added for accessing the tzinfo attributes of datetime.datetime and datetime.time objects. (Contributed by Zackery Spytz in bpo-30155.)

Add a PyCodec_Unregister() function to unregister a codec search function. (Contributed by Hai Shi in bpo-41842.)

The PyIter_Send() function was added to allow sending value into iterator without raising StopIteration exception. (Contributed by Vladimir Matveev in bpo-41756.)

Add PyUnicode_AsUTF8AndSize() to the limited C API. (Contributed by Alex Gaynor in bpo-41784.)

Add PyModule_AddObjectRef() function: similar to PyModule_AddObject() but don’t steal a reference to the value on success. (Contributed by Victor Stinner in bpo-1635741.)

Add Py_NewRef() and Py_XNewRef() functions to increment the reference count of an object and return the object. (Contributed by Victor Stinner in bpo-42262.)

The PyType_FromSpecWithBases() and PyType_FromModuleAndSpec() functions now accept a single class as the bases argument. (Contributed by Serhiy Storchaka in bpo-42423.)

The PyType_FromModuleAndSpec() function now accepts NULL tp_doc slot. (Contributed by Hai Shi in bpo-41832.)

The PyType_GetSlot() function can accept static types. (Contributed by Hai Shi and Petr Viktorin in bpo-41073.)

Add a new PySet_CheckExact() function to the C-API to check if an object is an instance of set but not an instance of a subtype. (Contributed by Pablo Galindo in bpo-43277.)

Add PyErr_SetInterruptEx() which allows passing a signal number to simulate. (Contributed by Antoine Pitrou in bpo-43356.)

The limited C API is now supported if Python is built in debug mode (if the Py_DEBUG macro is defined). In the limited C API, the Py_INCREF() and Py_DECREF() functions are now implemented as opaque function calls, rather than accessing directly the PyObject.ob_refcnt member, if Python is built in debug mode and the Py_LIMITED_API macro targets Python 3.10 or newer. It became possible to support the limited C API in debug mode because the PyObject structure is the same in release and debug mode since Python 3.8 (see bpo-36465).

The limited C API is still not supported in the --with-trace-refs special build (Py_TRACE_REFS macro). (Contributed by Victor Stinner in bpo-43688.)

Add the Py_Is(x, y) function to test if the x object is the y object, the same as x is y in Python. Add also the Py_IsNone(), Py_IsTrue(), Py_IsFalse() functions to test if an object is, respectively, the None singleton, the True singleton or the False singleton. (Contributed by Victor Stinner in bpo-43753.)

Add new functions to control the garbage collector from C code: PyGC_Enable(), PyGC_Disable(), PyGC_IsEnabled(). These functions allow to activate, deactivate and query the state of the garbage collector from C code without having to import the gc module.

Add a new Py_TPFLAGS_DISALLOW_INSTANTIATION type flag to disallow creating type instances. (Contributed by Victor Stinner in bpo-43916.)

Add a new Py_TPFLAGS_IMMUTABLETYPE type flag for creating immutable type objects: type attributes cannot be set nor deleted. (Contributed by Victor Stinner and Erlend E. Aasland in bpo-43908.)

Porting to Python 3.10
The PY_SSIZE_T_CLEAN macro must now be defined to use PyArg_ParseTuple() and Py_BuildValue() formats which use #: es#, et#, s#, u#, y#, z#, U# and Z#. See Parsing arguments and building values and PEP 353. (Contributed by Victor Stinner in bpo-40943.)

Since Py_REFCNT() is changed to the inline static function, Py_REFCNT(obj) = new_refcnt must be replaced with Py_SET_REFCNT(obj, new_refcnt): see Py_SET_REFCNT() (available since Python 3.9). For backward compatibility, this macro can be used:

#if PY_VERSION_HEX < 0x030900A4
#  define Py_SET_REFCNT(obj, refcnt) ((Py_REFCNT(obj) = (refcnt)), (void)0)
#endif
(Contributed by Victor Stinner in bpo-39573.)

Calling PyDict_GetItem() without GIL held had been allowed for historical reason. It is no longer allowed. (Contributed by Victor Stinner in bpo-40839.)

PyUnicode_FromUnicode(NULL, size) and PyUnicode_FromStringAndSize(NULL, size) raise DeprecationWarning now. Use PyUnicode_New() to allocate Unicode object without initial data. (Contributed by Inada Naoki in bpo-36346.)

The private _PyUnicode_Name_CAPI structure of the PyCapsule API unicodedata.ucnhash_CAPI has been moved to the internal C API. (Contributed by Victor Stinner in bpo-42157.)

Py_GetPath(), Py_GetPrefix(), Py_GetExecPrefix(), Py_GetProgramFullPath(), Py_GetPythonHome() and Py_GetProgramName() functions now return NULL if called before Py_Initialize() (before Python is initialized). Use the new Python Initialization Configuration API to get the Python Path Configuration. (Contributed by Victor Stinner in bpo-42260.)

PyList_SET_ITEM(), PyTuple_SET_ITEM() and PyCell_SET() macros can no longer be used as l-value or r-value. For example, x = PyList_SET_ITEM(a, b, c) and PyList_SET_ITEM(a, b, c) = x now fail with a compiler error. It prevents bugs like if (PyList_SET_ITEM (a, b, c) < 0) ... test. (Contributed by Zackery Spytz and Victor Stinner in bpo-30459.)

The non-limited API files odictobject.h, parser_interface.h, picklebufobject.h, pyarena.h, pyctype.h, pydebug.h, pyfpe.h, and pytime.h have been moved to the Include/cpython directory. These files must not be included directly, as they are already included in Python.h; see Include Files. If they have been included directly, consider including Python.h instead. (Contributed by Nicholas Sim in bpo-35134.)

Use the Py_TPFLAGS_IMMUTABLETYPE type flag to create immutable type objects. Do not rely on Py_TPFLAGS_HEAPTYPE to decide if a type object is mutable or not; check if Py_TPFLAGS_IMMUTABLETYPE is set instead. (Contributed by Victor Stinner and Erlend E. Aasland in bpo-43908.)

The undocumented function Py_FrozenMain has been removed from the limited API. The function is mainly useful for custom builds of Python. (Contributed by Petr Viktorin in bpo-26241.)

Deprecated
The PyUnicode_InternImmortal() function is now deprecated and will be removed in Python 3.12: use PyUnicode_InternInPlace() instead. (Contributed by Victor Stinner in bpo-41692.)

Removed
Removed Py_UNICODE_str* functions manipulating Py_UNICODE* strings. (Contributed by Inada Naoki in bpo-41123.)

Py_UNICODE_strlen: use PyUnicode_GetLength() or PyUnicode_GET_LENGTH

Py_UNICODE_strcat: use PyUnicode_CopyCharacters() or PyUnicode_FromFormat()

Py_UNICODE_strcpy, Py_UNICODE_strncpy: use PyUnicode_CopyCharacters() or PyUnicode_Substring()

Py_UNICODE_strcmp: use PyUnicode_Compare()

Py_UNICODE_strncmp: use PyUnicode_Tailmatch()

Py_UNICODE_strchr, Py_UNICODE_strrchr: use PyUnicode_FindChar()

Removed PyUnicode_GetMax(). Please migrate to new (PEP 393) APIs. (Contributed by Inada Naoki in bpo-41103.)

Removed PyLong_FromUnicode(). Please migrate to PyLong_FromUnicodeObject(). (Contributed by Inada Naoki in bpo-41103.)

Removed PyUnicode_AsUnicodeCopy(). Please use PyUnicode_AsUCS4Copy() or PyUnicode_AsWideCharString() (Contributed by Inada Naoki in bpo-41103.)

Removed _Py_CheckRecursionLimit variable: it has been replaced by ceval.recursion_limit of the PyInterpreterState structure. (Contributed by Victor Stinner in bpo-41834.)

Removed undocumented macros Py_ALLOW_RECURSION and Py_END_ALLOW_RECURSION and the recursion_critical field of the PyInterpreterState structure. (Contributed by Serhiy Storchaka in bpo-41936.)

Removed the undocumented PyOS_InitInterrupts() function. Initializing Python already implicitly installs signal handlers: see PyConfig.install_signal_handlers. (Contributed by Victor Stinner in bpo-41713.)

Remove the PyAST_Validate() function. It is no longer possible to build a AST object (mod_ty type) with the public C API. The function was already excluded from the limited C API (PEP 384). (Contributed by Victor Stinner in bpo-43244.)

Remove the symtable.h header file and the undocumented functions:

PyST_GetScope()

PySymtable_Build()

PySymtable_BuildObject()

PySymtable_Free()

Py_SymtableString()

Py_SymtableStringObject()

The Py_SymtableString() function was part the stable ABI by mistake but it could not be used, because the symtable.h header file was excluded from the limited C API.

Use Python symtable module instead. (Contributed by Victor Stinner in bpo-43244.)

Remove PyOS_ReadlineFunctionPointer() from the limited C API headers and from python3.dll, the library that provides the stable ABI on Windows. Since the function takes a FILE* argument, its ABI stability cannot be guaranteed. (Contributed by Petr Viktorin in bpo-43868.)

Remove ast.h, asdl.h, and Python-ast.h header files. These functions were undocumented and excluded from the limited C API. Most names defined by these header files were not prefixed by Py and so could create names conflicts. For example, Python-ast.h defined a Yield macro which was conflict with the Yield name used by the Windows <winbase.h> header. Use the Python ast module instead. (Contributed by Victor Stinner in bpo-43244.)

Remove the compiler and parser functions using struct _mod type, because the public AST C API was removed:

PyAST_Compile()

PyAST_CompileEx()

PyAST_CompileObject()

PyFuture_FromAST()

PyFuture_FromASTObject()

PyParser_ASTFromFile()

PyParser_ASTFromFileObject()

PyParser_ASTFromFilename()

PyParser_ASTFromString()

PyParser_ASTFromStringObject()

These functions were undocumented and excluded from the limited C API. (Contributed by Victor Stinner in bpo-43244.)

Remove the pyarena.h header file with functions:

PyArena_New()

PyArena_Free()

PyArena_Malloc()

PyArena_AddPyObject()

These functions were undocumented, excluded from the limited C API, and were only used internally by the compiler. (Contributed by Victor Stinner in bpo-43244.)

The PyThreadState.use_tracing member has been removed to optimize Python. (Contributed by Mark Shannon in bpo-43760.)

Notable security feature in 3.10.7
Converting between int and str in bases other than 2 (binary), 4, 8 (octal), 16 (hexadecimal), or 32 such as base 10 (decimal) now raises a ValueError if the number of digits in string form is above a limit to avoid potential denial of service attacks due to the algorithmic complexity. This is a mitigation for CVE-2020-10735. This limit can be configured or disabled by environment variable, command line flag, or sys APIs. See the integer string conversion length limitation documentation. The default limit is 4300 digits in string form.

Notable security feature in 3.10.8
The deprecated mailcap module now refuses to inject unsafe text (filenames, MIME types, parameters) into shell commands. Instead of using such text, it will warn and act as if a match was not found (or for test commands, as if the test failed). (Contributed by Petr Viktorin in gh-98966.)

Table of Contents
What’s New In Python 3.10
Summary – Release highlights
New Features
Parenthesized context managers
Better error messages
SyntaxErrors
IndentationErrors
AttributeErrors
NameErrors
PEP 626: Precise line numbers for debugging and other tools
PEP 634: Structural Pattern Matching
Syntax and operations
Declarative approach
Simple pattern: match to a literal
Behavior without the wildcard
Patterns with a literal and variable
Patterns and classes
Patterns with positional parameters
Nested patterns
Complex patterns and the wildcard
Guard
Other Key Features
Optional EncodingWarning and encoding="locale" option
New Features Related to Type Hints
PEP 604: New Type Union Operator
PEP 612: Parameter Specification Variables
PEP 613: TypeAlias
PEP 647: User-Defined Type Guards
Other Language Changes
New Modules
Improved Modules
asyncio
argparse
array
asynchat, asyncore, smtpd
base64
bdb
bisect
codecs
collections.abc
contextlib
curses
dataclasses
__slots__
Keyword-only fields
distutils
doctest
encodings
fileinput
faulthandler
gc
glob
hashlib
hmac
IDLE and idlelib
importlib.metadata
inspect
itertools
linecache
os
os.path
pathlib
platform
pprint
py_compile
pyclbr
shelve
statistics
site
socket
ssl
sqlite3
sys
_thread
threading
traceback
types
typing
unittest
urllib.parse
xml
zipimport
Optimizations
Deprecated
Removed
Porting to Python 3.10
Changes in the Python syntax
Changes in the Python API
Changes in the C API
CPython bytecode changes
Build Changes
C API Changes
PEP 652: Maintaining the Stable ABI
New Features
Porting to Python 3.10
Deprecated
Removed
Notable security feature in 3.10.7
Notable security feature in 3.10.8
Previous topic
What’s New in Python

Next topic
What’s New In Python 3.9

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » What’s New in Python » What’s New In Python 3.10
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » The Python Tutorial
Quick search
  |
The Python Tutorial
Python is an easy to learn, powerful programming language. It has efficient high-level data structures and a simple but effective approach to object-oriented programming. Python’s elegant syntax and dynamic typing, together with its interpreted nature, make it an ideal language for scripting and rapid application development in many areas on most platforms.

The Python interpreter and the extensive standard library are freely available in source or binary form for all major platforms from the Python web site, https://www.python.org/, and may be freely distributed. The same site also contains distributions of and pointers to many free third party Python modules, programs and tools, and additional documentation.

The Python interpreter is easily extended with new functions and data types implemented in C or C++ (or other languages callable from C). Python is also suitable as an extension language for customizable applications.

This tutorial introduces the reader informally to the basic concepts and features of the Python language and system. It helps to have a Python interpreter handy for hands-on experience, but all examples are self-contained, so the tutorial can be read off-line as well.

For a description of standard objects and modules, see The Python Standard Library. The Python Language Reference gives a more formal definition of the language. To write extensions in C or C++, read Extending and Embedding the Python Interpreter and Python/C API Reference Manual. There are also several books covering Python in depth.

This tutorial does not attempt to be comprehensive and cover every single feature, or even every commonly used feature. Instead, it introduces many of Python’s most noteworthy features, and will give you a good idea of the language’s flavor and style. After reading it, you will be able to read and write Python modules and programs, and you will be ready to learn more about the various Python library modules described in The Python Standard Library.

The Glossary is also worth going through.

1. Whetting Your Appetite
2. Using the Python Interpreter
2.1. Invoking the Interpreter
2.1.1. Argument Passing
2.1.2. Interactive Mode
2.2. The Interpreter and Its Environment
2.2.1. Source Code Encoding
3. An Informal Introduction to Python
3.1. Using Python as a Calculator
3.1.1. Numbers
3.1.2. Strings
3.1.3. Lists
3.2. First Steps Towards Programming
4. More Control Flow Tools
4.1. if Statements
4.2. for Statements
4.3. The range() Function
4.4. break and continue Statements, and else Clauses on Loops
4.5. pass Statements
4.6. match Statements
4.7. Defining Functions
4.8. More on Defining Functions
4.8.1. Default Argument Values
4.8.2. Keyword Arguments
4.8.3. Special parameters
4.8.3.1. Positional-or-Keyword Arguments
4.8.3.2. Positional-Only Parameters
4.8.3.3. Keyword-Only Arguments
4.8.3.4. Function Examples
4.8.3.5. Recap
4.8.4. Arbitrary Argument Lists
4.8.5. Unpacking Argument Lists
4.8.6. Lambda Expressions
4.8.7. Documentation Strings
4.8.8. Function Annotations
4.9. Intermezzo: Coding Style
5. Data Structures
5.1. More on Lists
5.1.1. Using Lists as Stacks
5.1.2. Using Lists as Queues
5.1.3. List Comprehensions
5.1.4. Nested List Comprehensions
5.2. The del statement
5.3. Tuples and Sequences
5.4. Sets
5.5. Dictionaries
5.6. Looping Techniques
5.7. More on Conditions
5.8. Comparing Sequences and Other Types
6. Modules
6.1. More on Modules
6.1.1. Executing modules as scripts
6.1.2. The Module Search Path
6.1.3. “Compiled” Python files
6.2. Standard Modules
6.3. The dir() Function
6.4. Packages
6.4.1. Importing * From a Package
6.4.2. Intra-package References
6.4.3. Packages in Multiple Directories
7. Input and Output
7.1. Fancier Output Formatting
7.1.1. Formatted String Literals
7.1.2. The String format() Method
7.1.3. Manual String Formatting
7.1.4. Old string formatting
7.2. Reading and Writing Files
7.2.1. Methods of File Objects
7.2.2. Saving structured data with json
8. Errors and Exceptions
8.1. Syntax Errors
8.2. Exceptions
8.3. Handling Exceptions
8.4. Raising Exceptions
8.5. Exception Chaining
8.6. User-defined Exceptions
8.7. Defining Clean-up Actions
8.8. Predefined Clean-up Actions
9. Classes
9.1. A Word About Names and Objects
9.2. Python Scopes and Namespaces
9.2.1. Scopes and Namespaces Example
9.3. A First Look at Classes
9.3.1. Class Definition Syntax
9.3.2. Class Objects
9.3.3. Instance Objects
9.3.4. Method Objects
9.3.5. Class and Instance Variables
9.4. Random Remarks
9.5. Inheritance
9.5.1. Multiple Inheritance
9.6. Private Variables
9.7. Odds and Ends
9.8. Iterators
9.9. Generators
9.10. Generator Expressions
10. Brief Tour of the Standard Library
10.1. Operating System Interface
10.2. File Wildcards
10.3. Command Line Arguments
10.4. Error Output Redirection and Program Termination
10.5. String Pattern Matching
10.6. Mathematics
10.7. Internet Access
10.8. Dates and Times
10.9. Data Compression
10.10. Performance Measurement
10.11. Quality Control
10.12. Batteries Included
11. Brief Tour of the Standard Library — Part II
11.1. Output Formatting
11.2. Templating
11.3. Working with Binary Data Record Layouts
11.4. Multi-threading
11.5. Logging
11.6. Weak References
11.7. Tools for Working with Lists
11.8. Decimal Floating Point Arithmetic
12. Virtual Environments and Packages
12.1. Introduction
12.2. Creating Virtual Environments
12.3. Managing Packages with pip
13. What Now?
14. Interactive Input Editing and History Substitution
14.1. Tab Completion and History Editing
14.2. Alternatives to the Interactive Interpreter
15. Floating Point Arithmetic: Issues and Limitations
15.1. Representation Error
16. Appendix
16.1. Interactive Mode
16.1.1. Error Handling
16.1.2. Executable Python Scripts
16.1.3. The Interactive Startup File
16.1.4. The Customization Modules
Previous topic
Changelog

Next topic
1. Whetting Your Appetite

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » The Python Tutorial
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » The Python Standard Library
Quick search
  |
The Python Standard Library
While The Python Language Reference describes the exact syntax and semantics of the Python language, this library reference manual describes the standard library that is distributed with Python. It also describes some of the optional components that are commonly included in Python distributions.

Python’s standard library is very extensive, offering a wide range of facilities as indicated by the long table of contents listed below. The library contains built-in modules (written in C) that provide access to system functionality such as file I/O that would otherwise be inaccessible to Python programmers, as well as modules written in Python that provide standardized solutions for many problems that occur in everyday programming. Some of these modules are explicitly designed to encourage and enhance the portability of Python programs by abstracting away platform-specifics into platform-neutral APIs.

The Python installers for the Windows platform usually include the entire standard library and often also include many additional components. For Unix-like operating systems Python is normally provided as a collection of packages, so it may be necessary to use the packaging tools provided with the operating system to obtain some or all of the optional components.

In addition to the standard library, there is a growing collection of several thousand components (from individual programs and modules to packages and entire application development frameworks), available from the Python Package Index.

Introduction
Notes on availability
Built-in Functions
Built-in Constants
Constants added by the site module
Built-in Types
Truth Value Testing
Boolean Operations — and, or, not
Comparisons
Numeric Types — int, float, complex
Iterator Types
Sequence Types — list, tuple, range
Text Sequence Type — str
Binary Sequence Types — bytes, bytearray, memoryview
Set Types — set, frozenset
Mapping Types — dict
Context Manager Types
Type Annotation Types — Generic Alias, Union
Other Built-in Types
Special Attributes
Integer string conversion length limitation
Built-in Exceptions
Exception context
Inheriting from built-in exceptions
Base classes
Concrete exceptions
Warnings
Exception hierarchy
Text Processing Services
string — Common string operations
re — Regular expression operations
difflib — Helpers for computing deltas
textwrap — Text wrapping and filling
unicodedata — Unicode Database
stringprep — Internet String Preparation
readline — GNU readline interface
rlcompleter — Completion function for GNU readline
Binary Data Services
struct — Interpret bytes as packed binary data
codecs — Codec registry and base classes
Data Types
datetime — Basic date and time types
zoneinfo — IANA time zone support
calendar — General calendar-related functions
collections — Container datatypes
collections.abc — Abstract Base Classes for Containers
heapq — Heap queue algorithm
bisect — Array bisection algorithm
array — Efficient arrays of numeric values
weakref — Weak references
types — Dynamic type creation and names for built-in types
copy — Shallow and deep copy operations
pprint — Data pretty printer
reprlib — Alternate repr() implementation
enum — Support for enumerations
graphlib — Functionality to operate with graph-like structures
Numeric and Mathematical Modules
numbers — Numeric abstract base classes
math — Mathematical functions
cmath — Mathematical functions for complex numbers
decimal — Decimal fixed point and floating point arithmetic
fractions — Rational numbers
random — Generate pseudo-random numbers
statistics — Mathematical statistics functions
Functional Programming Modules
itertools — Functions creating iterators for efficient looping
functools — Higher-order functions and operations on callable objects
operator — Standard operators as functions
File and Directory Access
pathlib — Object-oriented filesystem paths
os.path — Common pathname manipulations
fileinput — Iterate over lines from multiple input streams
stat — Interpreting stat() results
filecmp — File and Directory Comparisons
tempfile — Generate temporary files and directories
glob — Unix style pathname pattern expansion
fnmatch — Unix filename pattern matching
linecache — Random access to text lines
shutil — High-level file operations
Data Persistence
pickle — Python object serialization
copyreg — Register pickle support functions
shelve — Python object persistence
marshal — Internal Python object serialization
dbm — Interfaces to Unix “databases”
sqlite3 — DB-API 2.0 interface for SQLite databases
Data Compression and Archiving
zlib — Compression compatible with gzip
gzip — Support for gzip files
bz2 — Support for bzip2 compression
lzma — Compression using the LZMA algorithm
zipfile — Work with ZIP archives
tarfile — Read and write tar archive files
File Formats
csv — CSV File Reading and Writing
configparser — Configuration file parser
netrc — netrc file processing
plistlib — Generate and parse Apple .plist files
Cryptographic Services
hashlib — Secure hashes and message digests
hmac — Keyed-Hashing for Message Authentication
secrets — Generate secure random numbers for managing secrets
Generic Operating System Services
os — Miscellaneous operating system interfaces
io — Core tools for working with streams
time — Time access and conversions
argparse — Parser for command-line options, arguments and sub-commands
getopt — C-style parser for command line options
logging — Logging facility for Python
logging.config — Logging configuration
logging.handlers — Logging handlers
getpass — Portable password input
curses — Terminal handling for character-cell displays
curses.textpad — Text input widget for curses programs
curses.ascii — Utilities for ASCII characters
curses.panel — A panel stack extension for curses
platform — Access to underlying platform’s identifying data
errno — Standard errno system symbols
ctypes — A foreign function library for Python
Concurrent Execution
threading — Thread-based parallelism
multiprocessing — Process-based parallelism
multiprocessing.shared_memory — Shared memory for direct access across processes
The concurrent package
concurrent.futures — Launching parallel tasks
subprocess — Subprocess management
sched — Event scheduler
queue — A synchronized queue class
contextvars — Context Variables
_thread — Low-level threading API
Networking and Interprocess Communication
asyncio — Asynchronous I/O
socket — Low-level networking interface
ssl — TLS/SSL wrapper for socket objects
select — Waiting for I/O completion
selectors — High-level I/O multiplexing
signal — Set handlers for asynchronous events
mmap — Memory-mapped file support
Internet Data Handling
email — An email and MIME handling package
json — JSON encoder and decoder
mailbox — Manipulate mailboxes in various formats
mimetypes — Map filenames to MIME types
base64 — Base16, Base32, Base64, Base85 Data Encodings
binhex — Encode and decode binhex4 files
binascii — Convert between binary and ASCII
quopri — Encode and decode MIME quoted-printable data
Structured Markup Processing Tools
html — HyperText Markup Language support
html.parser — Simple HTML and XHTML parser
html.entities — Definitions of HTML general entities
XML Processing Modules
xml.etree.ElementTree — The ElementTree XML API
xml.dom — The Document Object Model API
xml.dom.minidom — Minimal DOM implementation
xml.dom.pulldom — Support for building partial DOM trees
xml.sax — Support for SAX2 parsers
xml.sax.handler — Base classes for SAX handlers
xml.sax.saxutils — SAX Utilities
xml.sax.xmlreader — Interface for XML parsers
xml.parsers.expat — Fast XML parsing using Expat
Internet Protocols and Support
webbrowser — Convenient web-browser controller
wsgiref — WSGI Utilities and Reference Implementation
urllib — URL handling modules
urllib.request — Extensible library for opening URLs
urllib.response — Response classes used by urllib
urllib.parse — Parse URLs into components
urllib.error — Exception classes raised by urllib.request
urllib.robotparser — Parser for robots.txt
http — HTTP modules
http.client — HTTP protocol client
ftplib — FTP protocol client
poplib — POP3 protocol client
imaplib — IMAP4 protocol client
smtplib — SMTP protocol client
uuid — UUID objects according to RFC 4122
socketserver — A framework for network servers
http.server — HTTP servers
http.cookies — HTTP state management
http.cookiejar — Cookie handling for HTTP clients
xmlrpc — XMLRPC server and client modules
xmlrpc.client — XML-RPC client access
xmlrpc.server — Basic XML-RPC servers
ipaddress — IPv4/IPv6 manipulation library
Multimedia Services
wave — Read and write WAV files
colorsys — Conversions between color systems
Internationalization
gettext — Multilingual internationalization services
locale — Internationalization services
Program Frameworks
turtle — Turtle graphics
cmd — Support for line-oriented command interpreters
shlex — Simple lexical analysis
Graphical User Interfaces with Tk
tkinter — Python interface to Tcl/Tk
tkinter.colorchooser — Color choosing dialog
tkinter.font — Tkinter font wrapper
Tkinter Dialogs
tkinter.messagebox — Tkinter message prompts
tkinter.scrolledtext — Scrolled Text Widget
tkinter.dnd — Drag and drop support
tkinter.ttk — Tk themed widgets
tkinter.tix — Extension widgets for Tk
IDLE
Development Tools
typing — Support for type hints
pydoc — Documentation generator and online help system
Python Development Mode
Effects of the Python Development Mode
ResourceWarning Example
Bad file descriptor error example
doctest — Test interactive Python examples
unittest — Unit testing framework
unittest.mock — mock object library
unittest.mock — getting started
2to3 — Automated Python 2 to 3 code translation
test — Regression tests package for Python
test.support — Utilities for the Python test suite
test.support.socket_helper — Utilities for socket tests
test.support.script_helper — Utilities for the Python execution tests
test.support.bytecode_helper — Support tools for testing correct bytecode generation
test.support.threading_helper — Utilities for threading tests
test.support.os_helper — Utilities for os tests
test.support.import_helper — Utilities for import tests
test.support.warnings_helper — Utilities for warnings tests
Debugging and Profiling
Audit events table
bdb — Debugger framework
faulthandler — Dump the Python traceback
pdb — The Python Debugger
The Python Profilers
timeit — Measure execution time of small code snippets
trace — Trace or track Python statement execution
tracemalloc — Trace memory allocations
Software Packaging and Distribution
distutils — Building and installing Python modules
ensurepip — Bootstrapping the pip installer
venv — Creation of virtual environments
zipapp — Manage executable Python zip archives
Python Runtime Services
sys — System-specific parameters and functions
sysconfig — Provide access to Python’s configuration information
builtins — Built-in objects
__main__ — Top-level code environment
warnings — Warning control
dataclasses — Data Classes
contextlib — Utilities for with-statement contexts
abc — Abstract Base Classes
atexit — Exit handlers
traceback — Print or retrieve a stack traceback
__future__ — Future statement definitions
gc — Garbage Collector interface
inspect — Inspect live objects
site — Site-specific configuration hook
Custom Python Interpreters
code — Interpreter base classes
codeop — Compile Python code
Importing Modules
zipimport — Import modules from Zip archives
pkgutil — Package extension utility
modulefinder — Find modules used by a script
runpy — Locating and executing Python modules
importlib — The implementation of import
Using importlib.metadata
Python Language Services
ast — Abstract Syntax Trees
symtable — Access to the compiler’s symbol tables
token — Constants used with Python parse trees
keyword — Testing for Python keywords
tokenize — Tokenizer for Python source
tabnanny — Detection of ambiguous indentation
pyclbr — Python module browser support
py_compile — Compile Python source files
compileall — Byte-compile Python libraries
dis — Disassembler for Python bytecode
pickletools — Tools for pickle developers
MS Windows Specific Services
msvcrt — Useful routines from the MS VC++ runtime
winreg — Windows registry access
winsound — Sound-playing interface for Windows
Unix Specific Services
posix — The most common POSIX system calls
pwd — The password database
grp — The group database
termios — POSIX style tty control
tty — Terminal control functions
pty — Pseudo-terminal utilities
fcntl — The fcntl and ioctl system calls
resource — Resource usage information
syslog — Unix syslog library routines
Superseded Modules
aifc — Read and write AIFF and AIFC files
asynchat — Asynchronous socket command/response handler
asyncore — Asynchronous socket handler
audioop — Manipulate raw audio data
cgi — Common Gateway Interface support
cgitb — Traceback manager for CGI scripts
chunk — Read IFF chunked data
crypt — Function to check Unix passwords
imghdr — Determine the type of an image
imp — Access the import internals
mailcap — Mailcap file handling
msilib — Read and write Microsoft Installer files
nis — Interface to Sun’s NIS (Yellow Pages)
nntplib — NNTP protocol client
optparse — Parser for command line options
ossaudiodev — Access to OSS-compatible audio devices
pipes — Interface to shell pipelines
smtpd — SMTP Server
sndhdr — Determine type of sound file
spwd — The shadow password database
sunau — Read and write Sun AU files
telnetlib — Telnet client
uu — Encode and decode uuencode files
xdrlib — Encode and decode XDR data
Security Considerations
Previous topic
10. Full Grammar specification

Next topic
Introduction

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » The Python Standard Library
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » The Python Language Reference
Quick search
  |
The Python Language Reference
This reference manual describes the syntax and “core semantics” of the language. It is terse, but attempts to be exact and complete. The semantics of non-essential built-in object types and of the built-in functions and modules are described in The Python Standard Library. For an informal introduction to the language, see The Python Tutorial. For C or C++ programmers, two additional manuals exist: Extending and Embedding the Python Interpreter describes the high-level picture of how to write a Python extension module, and the Python/C API Reference Manual describes the interfaces available to C/C++ programmers in detail.

1. Introduction
1.1. Alternate Implementations
1.2. Notation
2. Lexical analysis
2.1. Line structure
2.2. Other tokens
2.3. Identifiers and keywords
2.4. Literals
2.5. Operators
2.6. Delimiters
3. Data model
3.1. Objects, values and types
3.2. The standard type hierarchy
3.3. Special method names
3.4. Coroutines
4. Execution model
4.1. Structure of a program
4.2. Naming and binding
4.3. Exceptions
5. The import system
5.1. importlib
5.2. Packages
5.3. Searching
5.4. Loading
5.5. The Path Based Finder
5.6. Replacing the standard import system
5.7. Package Relative Imports
5.8. Special considerations for __main__
5.9. References
6. Expressions
6.1. Arithmetic conversions
6.2. Atoms
6.3. Primaries
6.4. Await expression
6.5. The power operator
6.6. Unary arithmetic and bitwise operations
6.7. Binary arithmetic operations
6.8. Shifting operations
6.9. Binary bitwise operations
6.10. Comparisons
6.11. Boolean operations
6.12. Assignment expressions
6.13. Conditional expressions
6.14. Lambdas
6.15. Expression lists
6.16. Evaluation order
6.17. Operator precedence
7. Simple statements
7.1. Expression statements
7.2. Assignment statements
7.3. The assert statement
7.4. The pass statement
7.5. The del statement
7.6. The return statement
7.7. The yield statement
7.8. The raise statement
7.9. The break statement
7.10. The continue statement
7.11. The import statement
7.12. The global statement
7.13. The nonlocal statement
8. Compound statements
8.1. The if statement
8.2. The while statement
8.3. The for statement
8.4. The try statement
8.5. The with statement
8.6. The match statement
8.7. Function definitions
8.8. Class definitions
8.9. Coroutines
9. Top-level components
9.1. Complete Python programs
9.2. File input
9.3. Interactive input
9.4. Expression input
10. Full Grammar specification
Previous topic
6. Editors and IDEs

Next topic
1. Introduction

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » The Python Language Reference
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python Setup and Usage
Quick search
  |
Python Setup and Usage
This part of the documentation is devoted to general information on the setup of the Python environment on different platforms, the invocation of the interpreter and things that make working with Python easier.

1. Command line and environment
1.1. Command line
1.1.1. Interface options
1.1.2. Generic options
1.1.3. Miscellaneous options
1.1.4. Options you shouldn’t use
1.2. Environment variables
1.2.1. Debug-mode variables
2. Using Python on Unix platforms
2.1. Getting and installing the latest version of Python
2.1.1. On Linux
2.1.2. On FreeBSD and OpenBSD
2.1.3. On OpenSolaris
2.2. Building Python
2.3. Python-related paths and files
2.4. Miscellaneous
2.5. Custom OpenSSL
3. Configure Python
3.1. Configure Options
3.1.1. General Options
3.1.2. Install Options
3.1.3. Performance options
3.1.4. Python Debug Build
3.1.5. Debug options
3.1.6. Linker options
3.1.7. Libraries options
3.1.8. Security Options
3.1.9. macOS Options
3.2. Python Build System
3.2.1. Main files of the build system
3.2.2. Main build steps
3.2.3. Main Makefile targets
3.2.4. C extensions
3.3. Compiler and linker flags
3.3.1. Preprocessor flags
3.3.2. Compiler flags
3.3.3. Linker flags
4. Using Python on Windows
4.1. The full installer
4.1.1. Installation steps
4.1.2. Removing the MAX_PATH Limitation
4.1.3. Installing Without UI
4.1.4. Installing Without Downloading
4.1.5. Modifying an install
4.2. The Microsoft Store package
4.2.1. Known issues
4.2.1.1. Redirection of local data, registry, and temporary paths
4.3. The nuget.org packages
4.4. The embeddable package
4.4.1. Python Application
4.4.2. Embedding Python
4.5. Alternative bundles
4.6. Configuring Python
4.6.1. Excursus: Setting environment variables
4.6.2. Finding the Python executable
4.7. UTF-8 mode
4.8. Python Launcher for Windows
4.8.1. Getting started
4.8.1.1. From the command-line
4.8.1.2. Virtual environments
4.8.1.3. From a script
4.8.1.4. From file associations
4.8.2. Shebang Lines
4.8.3. Arguments in shebang lines
4.8.4. Customization
4.8.4.1. Customization via INI files
4.8.4.2. Customizing default Python versions
4.8.5. Diagnostics
4.9. Finding modules
4.10. Additional modules
4.10.1. PyWin32
4.10.2. cx_Freeze
4.11. Compiling Python on Windows
4.12. Other Platforms
5. Using Python on a Mac
5.1. Getting and Installing MacPython
5.1.1. How to run a Python script
5.1.2. Running scripts with a GUI
5.1.3. Configuration
5.2. The IDE
5.3. Installing Additional Python Packages
5.4. GUI Programming on the Mac
5.5. Distributing Python Applications on the Mac
5.6. Other Resources
6. Editors and IDEs
Previous topic
16. Appendix

Next topic
1. Command line and environment

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python Setup and Usage
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs
Quick search
  |
Python HOWTOs
Python HOWTOs are documents that cover a single, specific topic, and attempt to cover it fairly completely. Modelled on the Linux Documentation Project’s HOWTO collection, this collection is an effort to foster documentation that’s more detailed than the Python Library Reference.

Currently, the HOWTOs are:

Porting Python 2 Code to Python 3
Porting Extension Modules to Python 3
Curses Programming with Python
Descriptor HowTo Guide
Functional Programming HOWTO
Logging HOWTO
Logging Cookbook
Regular Expression HOWTO
Socket Programming HOWTO
Sorting HOW TO
Unicode HOWTO
HOWTO Fetch Internet Resources Using The urllib Package
Argparse Tutorial
An introduction to the ipaddress module
Argument Clinic How-To
Instrumenting CPython with DTrace and SystemTap
Annotations Best Practices
Previous topic
Installing Python Modules

Next topic
Porting Python 2 Code to Python 3

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Porting Python 2 Code to Python 3
Quick search
  |
Porting Python 2 Code to Python 3
author
Brett Cannon

Abstract

With Python 3 being the future of Python while Python 2 is still in active use, it is good to have your project available for both major releases of Python. This guide is meant to help you figure out how best to support both Python 2 & 3 simultaneously.

If you are looking to port an extension module instead of pure Python code, please see Porting Extension Modules to Python 3.

If you would like to read one core Python developer’s take on why Python 3 came into existence, you can read Nick Coghlan’s Python 3 Q & A or Brett Cannon’s Why Python 3 exists.

For help with porting, you can view the archived python-porting mailing list.

The Short Explanation
To make your project be single-source Python 2/3 compatible, the basic steps are:

Only worry about supporting Python 2.7

Make sure you have good test coverage (coverage.py can help; python -m pip install coverage)

Learn the differences between Python 2 & 3

Use Futurize (or Modernize) to update your code (e.g. python -m pip install future)

Use Pylint to help make sure you don’t regress on your Python 3 support (python -m pip install pylint)

Use caniusepython3 to find out which of your dependencies are blocking your use of Python 3 (python -m pip install caniusepython3)

Once your dependencies are no longer blocking you, use continuous integration to make sure you stay compatible with Python 2 & 3 (tox can help test against multiple versions of Python; python -m pip install tox)

Consider using optional static type checking to make sure your type usage works in both Python 2 & 3 (e.g. use mypy to check your typing under both Python 2 & Python 3; python -m pip install mypy).

Note Note: Using python -m pip install guarantees that the pip you invoke is the one installed for the Python currently in use, whether it be a system-wide pip or one installed within a virtual environment.
Details
A key point about supporting Python 2 & 3 simultaneously is that you can start today! Even if your dependencies are not supporting Python 3 yet that does not mean you can’t modernize your code now to support Python 3. Most changes required to support Python 3 lead to cleaner code using newer practices even in Python 2 code.

Another key point is that modernizing your Python 2 code to also support Python 3 is largely automated for you. While you might have to make some API decisions thanks to Python 3 clarifying text data versus binary data, the lower-level work is now mostly done for you and thus can at least benefit from the automated changes immediately.

Keep those key points in mind while you read on about the details of porting your code to support Python 2 & 3 simultaneously.

Drop support for Python 2.6 and older
While you can make Python 2.5 work with Python 3, it is much easier if you only have to work with Python 2.7. If dropping Python 2.5 is not an option then the six project can help you support Python 2.5 & 3 simultaneously (python -m pip install six). Do realize, though, that nearly all the projects listed in this HOWTO will not be available to you.

If you are able to skip Python 2.5 and older, then the required changes to your code should continue to look and feel like idiomatic Python code. At worst you will have to use a function instead of a method in some instances or have to import a function instead of using a built-in one, but otherwise the overall transformation should not feel foreign to you.

But you should aim for only supporting Python 2.7. Python 2.6 is no longer freely supported and thus is not receiving bugfixes. This means you will have to work around any issues you come across with Python 2.6. There are also some tools mentioned in this HOWTO which do not support Python 2.6 (e.g., Pylint), and this will become more commonplace as time goes on. It will simply be easier for you if you only support the versions of Python that you have to support.

Make sure you specify the proper version support in your setup.py file
In your setup.py file you should have the proper trove classifier specifying what versions of Python you support. As your project does not support Python 3 yet you should at least have Programming Language :: Python :: 2 :: Only specified. Ideally you should also specify each major/minor version of Python that you do support, e.g. Programming Language :: Python :: 2.7.

Have good test coverage
Once you have your code supporting the oldest version of Python 2 you want it to, you will want to make sure your test suite has good coverage. A good rule of thumb is that if you want to be confident enough in your test suite that any failures that appear after having tools rewrite your code are actual bugs in the tools and not in your code. If you want a number to aim for, try to get over 80% coverage (and don’t feel bad if you find it hard to get better than 90% coverage). If you don’t already have a tool to measure test coverage then coverage.py is recommended.

Learn the differences between Python 2 & 3
Once you have your code well-tested you are ready to begin porting your code to Python 3! But to fully understand how your code is going to change and what you want to look out for while you code, you will want to learn what changes Python 3 makes in terms of Python 2. Typically the two best ways of doing that is reading the “What’s New” doc for each release of Python 3 and the Porting to Python 3 book (which is free online). There is also a handy cheat sheet from the Python-Future project.

Update your code
Once you feel like you know what is different in Python 3 compared to Python 2, it’s time to update your code! You have a choice between two tools in porting your code automatically: Futurize and Modernize. Which tool you choose will depend on how much like Python 3 you want your code to be. Futurize does its best to make Python 3 idioms and practices exist in Python 2, e.g. backporting the bytes type from Python 3 so that you have semantic parity between the major versions of Python. Modernize, on the other hand, is more conservative and targets a Python 2/3 subset of Python, directly relying on six to help provide compatibility. As Python 3 is the future, it might be best to consider Futurize to begin adjusting to any new practices that Python 3 introduces which you are not accustomed to yet.

Regardless of which tool you choose, they will update your code to run under Python 3 while staying compatible with the version of Python 2 you started with. Depending on how conservative you want to be, you may want to run the tool over your test suite first and visually inspect the diff to make sure the transformation is accurate. After you have transformed your test suite and verified that all the tests still pass as expected, then you can transform your application code knowing that any tests which fail is a translation failure.

Unfortunately the tools can’t automate everything to make your code work under Python 3 and so there are a handful of things you will need to update manually to get full Python 3 support (which of these steps are necessary vary between the tools). Read the documentation for the tool you choose to use to see what it fixes by default and what it can do optionally to know what will (not) be fixed for you and what you may have to fix on your own (e.g. using io.open() over the built-in open() function is off by default in Modernize). Luckily, though, there are only a couple of things to watch out for which can be considered large issues that may be hard to debug if not watched for.

Division
In Python 3, 5 / 2 == 2.5 and not 2; all division between int values result in a float. This change has actually been planned since Python 2.2 which was released in 2002. Since then users have been encouraged to add from __future__ import division to any and all files which use the / and // operators or to be running the interpreter with the -Q flag. If you have not been doing this then you will need to go through your code and do two things:

Add from __future__ import division to your files

Update any division operator as necessary to either use // to use floor division or continue using / and expect a float

The reason that / isn’t simply translated to // automatically is that if an object defines a __truediv__ method but not __floordiv__ then your code would begin to fail (e.g. a user-defined class that uses / to signify some operation but not // for the same thing or at all).

Text versus binary data
In Python 2 you could use the str type for both text and binary data. Unfortunately this confluence of two different concepts could lead to brittle code which sometimes worked for either kind of data, sometimes not. It also could lead to confusing APIs if people didn’t explicitly state that something that accepted str accepted either text or binary data instead of one specific type. This complicated the situation especially for anyone supporting multiple languages as APIs wouldn’t bother explicitly supporting unicode when they claimed text data support.

To make the distinction between text and binary data clearer and more pronounced, Python 3 did what most languages created in the age of the internet have done and made text and binary data distinct types that cannot blindly be mixed together (Python predates widespread access to the internet). For any code that deals only with text or only binary data, this separation doesn’t pose an issue. But for code that has to deal with both, it does mean you might have to now care about when you are using text compared to binary data, which is why this cannot be entirely automated.

To start, you will need to decide which APIs take text and which take binary (it is highly recommended you don’t design APIs that can take both due to the difficulty of keeping the code working; as stated earlier it is difficult to do well). In Python 2 this means making sure the APIs that take text can work with unicode and those that work with binary data work with the bytes type from Python 3 (which is a subset of str in Python 2 and acts as an alias for bytes type in Python 2). Usually the biggest issue is realizing which methods exist on which types in Python 2 & 3 simultaneously (for text that’s unicode in Python 2 and str in Python 3, for binary that’s str/bytes in Python 2 and bytes in Python 3). The following table lists the unique methods of each data type across Python 2 & 3 (e.g., the decode() method is usable on the equivalent binary data type in either Python 2 or 3, but it can’t be used by the textual data type consistently between Python 2 and 3 because str in Python 3 doesn’t have the method). Do note that as of Python 3.5 the __mod__ method was added to the bytes type.

Text data

Binary data

decode

encode

format

isdecimal

isnumeric

Making the distinction easier to handle can be accomplished by encoding and decoding between binary data and text at the edge of your code. This means that when you receive text in binary data, you should immediately decode it. And if your code needs to send text as binary data then encode it as late as possible. This allows your code to work with only text internally and thus eliminates having to keep track of what type of data you are working with.

The next issue is making sure you know whether the string literals in your code represent text or binary data. You should add a b prefix to any literal that presents binary data. For text you should add a u prefix to the text literal. (there is a __future__ import to force all unspecified literals to be Unicode, but usage has shown it isn’t as effective as adding a b or u prefix to all literals explicitly)

As part of this dichotomy you also need to be careful about opening files. Unless you have been working on Windows, there is a chance you have not always bothered to add the b mode when opening a binary file (e.g., rb for binary reading). Under Python 3, binary files and text files are clearly distinct and mutually incompatible; see the io module for details. Therefore, you must make a decision of whether a file will be used for binary access (allowing binary data to be read and/or written) or textual access (allowing text data to be read and/or written). You should also use io.open() for opening files instead of the built-in open() function as the io module is consistent from Python 2 to 3 while the built-in open() function is not (in Python 3 it’s actually io.open()). Do not bother with the outdated practice of using codecs.open() as that’s only necessary for keeping compatibility with Python 2.5.

The constructors of both str and bytes have different semantics for the same arguments between Python 2 & 3. Passing an integer to bytes in Python 2 will give you the string representation of the integer: bytes(3) == '3'. But in Python 3, an integer argument to bytes will give you a bytes object as long as the integer specified, filled with null bytes: bytes(3) == b'\x00\x00\x00'. A similar worry is necessary when passing a bytes object to str. In Python 2 you just get the bytes object back: str(b'3') == b'3'. But in Python 3 you get the string representation of the bytes object: str(b'3') == "b'3'".

Finally, the indexing of binary data requires careful handling (slicing does not require any special handling). In Python 2, b'123'[1] == b'2' while in Python 3 b'123'[1] == 50. Because binary data is simply a collection of binary numbers, Python 3 returns the integer value for the byte you index on. But in Python 2 because bytes == str, indexing returns a one-item slice of bytes. The six project has a function named six.indexbytes() which will return an integer like in Python 3: six.indexbytes(b'123', 1).

To summarize:

Decide which of your APIs take text and which take binary data

Make sure that your code that works with text also works with unicode and code for binary data works with bytes in Python 2 (see the table above for what methods you cannot use for each type)

Mark all binary literals with a b prefix, textual literals with a u prefix

Decode binary data to text as soon as possible, encode text as binary data as late as possible

Open files using io.open() and make sure to specify the b mode when appropriate

Be careful when indexing into binary data

Use feature detection instead of version detection
Inevitably you will have code that has to choose what to do based on what version of Python is running. The best way to do this is with feature detection of whether the version of Python you’re running under supports what you need. If for some reason that doesn’t work then you should make the version check be against Python 2 and not Python 3. To help explain this, let’s look at an example.

Let’s pretend that you need access to a feature of importlib that is available in Python’s standard library since Python 3.3 and available for Python 2 through importlib2 on PyPI. You might be tempted to write code to access e.g. the importlib.abc module by doing the following:

import sys

if sys.version_info[0] == 3:
    from importlib import abc
else:
    from importlib2 import abc
The problem with this code is what happens when Python 4 comes out? It would be better to treat Python 2 as the exceptional case instead of Python 3 and assume that future Python versions will be more compatible with Python 3 than Python 2:

import sys

if sys.version_info[0] > 2:
    from importlib import abc
else:
    from importlib2 import abc
The best solution, though, is to do no version detection at all and instead rely on feature detection. That avoids any potential issues of getting the version detection wrong and helps keep you future-compatible:

try:
    from importlib import abc
except ImportError:
    from importlib2 import abc
Prevent compatibility regressions
Once you have fully translated your code to be compatible with Python 3, you will want to make sure your code doesn’t regress and stop working under Python 3. This is especially true if you have a dependency which is blocking you from actually running under Python 3 at the moment.

To help with staying compatible, any new modules you create should have at least the following block of code at the top of it:

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
You can also run Python 2 with the -3 flag to be warned about various compatibility issues your code triggers during execution. If you turn warnings into errors with -Werror then you can make sure that you don’t accidentally miss a warning.

You can also use the Pylint project and its --py3k flag to lint your code to receive warnings when your code begins to deviate from Python 3 compatibility. This also prevents you from having to run Modernize or Futurize over your code regularly to catch compatibility regressions. This does require you only support Python 2.7 and Python 3.4 or newer as that is Pylint’s minimum Python version support.

Check which dependencies block your transition
After you have made your code compatible with Python 3 you should begin to care about whether your dependencies have also been ported. The caniusepython3 project was created to help you determine which projects – directly or indirectly – are blocking you from supporting Python 3. There is both a command-line tool as well as a web interface at https://caniusepython3.com.

The project also provides code which you can integrate into your test suite so that you will have a failing test when you no longer have dependencies blocking you from using Python 3. This allows you to avoid having to manually check your dependencies and to be notified quickly when you can start running on Python 3.

Update your setup.py file to denote Python 3 compatibility
Once your code works under Python 3, you should update the classifiers in your setup.py to contain Programming Language :: Python :: 3 and to not specify sole Python 2 support. This will tell anyone using your code that you support Python 2 and 3. Ideally you will also want to add classifiers for each major/minor version of Python you now support.

Use continuous integration to stay compatible
Once you are able to fully run under Python 3 you will want to make sure your code always works under both Python 2 & 3. Probably the best tool for running your tests under multiple Python interpreters is tox. You can then integrate tox with your continuous integration system so that you never accidentally break Python 2 or 3 support.

You may also want to use the -bb flag with the Python 3 interpreter to trigger an exception when you are comparing bytes to strings or bytes to an int (the latter is available starting in Python 3.5). By default type-differing comparisons simply return False, but if you made a mistake in your separation of text/binary data handling or indexing on bytes you wouldn’t easily find the mistake. This flag will raise an exception when these kinds of comparisons occur, making the mistake much easier to track down.

And that’s mostly it! At this point your code base is compatible with both Python 2 and 3 simultaneously. Your testing will also be set up so that you don’t accidentally break Python 2 or 3 compatibility regardless of which version you typically run your tests under while developing.

Consider using optional static type checking
Another way to help port your code is to use a static type checker like mypy or pytype on your code. These tools can be used to analyze your code as if it’s being run under Python 2, then you can run the tool a second time as if your code is running under Python 3. By running a static type checker twice like this you can discover if you’re e.g. misusing binary data type in one version of Python compared to another. If you add optional type hints to your code you can also explicitly state whether your APIs use textual or binary data, helping to make sure everything functions as expected in both versions of Python.

Table of Contents
Porting Python 2 Code to Python 3
The Short Explanation
Details
Drop support for Python 2.6 and older
Make sure you specify the proper version support in your setup.py file
Have good test coverage
Learn the differences between Python 2 & 3
Update your code
Division
Text versus binary data
Use feature detection instead of version detection
Prevent compatibility regressions
Check which dependencies block your transition
Update your setup.py file to denote Python 3 compatibility
Use continuous integration to stay compatible
Consider using optional static type checking
Previous topic
Python HOWTOs

Next topic
Porting Extension Modules to Python 3

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Porting Python 2 Code to Python 3
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Porting Extension Modules to Python 3
Quick search
  |
Porting Extension Modules to Python 3
We recommend the following resources for porting extension modules to Python 3:

The Migrating C extensions chapter from Supporting Python 3: An in-depth guide, a book on moving from Python 2 to Python 3 in general, guides the reader through porting an extension module.

The Porting guide from the py3c project provides opinionated suggestions with supporting code.

The Cython and CFFI libraries offer abstractions over Python’s C API. Extensions generally need to be re-written to use one of them, but the library then handles differences between various Python versions and implementations.

Previous topic
Porting Python 2 Code to Python 3

Next topic
Curses Programming with Python

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Porting Extension Modules to Python 3
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Curses Programming with Python
Quick search
  |
Curses Programming with Python
Author
A.M. Kuchling, Eric S. Raymond

Release
2.04

Abstract

This document describes how to use the curses extension module to control text-mode displays.

What is curses?¶
The curses library supplies a terminal-independent screen-painting and keyboard-handling facility for text-based terminals; such terminals include VT100s, the Linux console, and the simulated terminal provided by various programs. Display terminals support various control codes to perform common operations such as moving the cursor, scrolling the screen, and erasing areas. Different terminals use widely differing codes, and often have their own minor quirks.

In a world of graphical displays, one might ask “why bother”? It’s true that character-cell display terminals are an obsolete technology, but there are niches in which being able to do fancy things with them are still valuable. One niche is on small-footprint or embedded Unixes that don’t run an X server. Another is tools such as OS installers and kernel configurators that may have to run before any graphical support is available.

The curses library provides fairly basic functionality, providing the programmer with an abstraction of a display containing multiple non-overlapping windows of text. The contents of a window can be changed in various ways—adding text, erasing it, changing its appearance—and the curses library will figure out what control codes need to be sent to the terminal to produce the right output. curses doesn’t provide many user-interface concepts such as buttons, checkboxes, or dialogs; if you need such features, consider a user interface library such as Urwid.

The curses library was originally written for BSD Unix; the later System V versions of Unix from AT&T added many enhancements and new functions. BSD curses is no longer maintained, having been replaced by ncurses, which is an open-source implementation of the AT&T interface. If you’re using an open-source Unix such as Linux or FreeBSD, your system almost certainly uses ncurses. Since most current commercial Unix versions are based on System V code, all the functions described here will probably be available. The older versions of curses carried by some proprietary Unixes may not support everything, though.

The Windows version of Python doesn’t include the curses module. A ported version called UniCurses is available.

The Python curses module
The Python module is a fairly simple wrapper over the C functions provided by curses; if you’re already familiar with curses programming in C, it’s really easy to transfer that knowledge to Python. The biggest difference is that the Python interface makes things simpler by merging different C functions such as addstr(), mvaddstr(), and mvwaddstr() into a single addstr() method. You’ll see this covered in more detail later.

This HOWTO is an introduction to writing text-mode programs with curses and Python. It doesn’t attempt to be a complete guide to the curses API; for that, see the Python library guide’s section on ncurses, and the C manual pages for ncurses. It will, however, give you the basic ideas.

Starting and ending a curses application
Before doing anything, curses must be initialized. This is done by calling the initscr() function, which will determine the terminal type, send any required setup codes to the terminal, and create various internal data structures. If successful, initscr() returns a window object representing the entire screen; this is usually called stdscr after the name of the corresponding C variable.

import curses
stdscr = curses.initscr()
Usually curses applications turn off automatic echoing of keys to the screen, in order to be able to read keys and only display them under certain circumstances. This requires calling the noecho() function.

curses.noecho()
Applications will also commonly need to react to keys instantly, without requiring the Enter key to be pressed; this is called cbreak mode, as opposed to the usual buffered input mode.

curses.cbreak()
Terminals usually return special keys, such as the cursor keys or navigation keys such as Page Up and Home, as a multibyte escape sequence. While you could write your application to expect such sequences and process them accordingly, curses can do it for you, returning a special value such as curses.KEY_LEFT. To get curses to do the job, you’ll have to enable keypad mode.

stdscr.keypad(True)
Terminating a curses application is much easier than starting one. You’ll need to call:

curses.nocbreak()
stdscr.keypad(False)
curses.echo()
to reverse the curses-friendly terminal settings. Then call the endwin() function to restore the terminal to its original operating mode.

curses.endwin()
A common problem when debugging a curses application is to get your terminal messed up when the application dies without restoring the terminal to its previous state. In Python this commonly happens when your code is buggy and raises an uncaught exception. Keys are no longer echoed to the screen when you type them, for example, which makes using the shell difficult.

In Python you can avoid these complications and make debugging much easier by importing the curses.wrapper() function and using it like this:

from curses import wrapper

def main(stdscr):
    # Clear screen
    stdscr.clear()

    # This raises ZeroDivisionError when i == 10.
    for i in range(0, 11):
        v = i-10
        stdscr.addstr(i, 0, '10 divided by {} is {}'.format(v, 10/v))

    stdscr.refresh()
    stdscr.getkey()

wrapper(main)
The wrapper() function takes a callable object and does the initializations described above, also initializing colors if color support is present. wrapper() then runs your provided callable. Once the callable returns, wrapper() will restore the original state of the terminal. The callable is called inside a try…except that catches exceptions, restores the state of the terminal, and then re-raises the exception. Therefore your terminal won’t be left in a funny state on exception and you’ll be able to read the exception’s message and traceback.

Windows and Pads
Windows are the basic abstraction in curses. A window object represents a rectangular area of the screen, and supports methods to display text, erase it, allow the user to input strings, and so forth.

The stdscr object returned by the initscr() function is a window object that covers the entire screen. Many programs may need only this single window, but you might wish to divide the screen into smaller windows, in order to redraw or clear them separately. The newwin() function creates a new window of a given size, returning the new window object.

begin_x = 20; begin_y = 7
height = 5; width = 40
win = curses.newwin(height, width, begin_y, begin_x)
Note that the coordinate system used in curses is unusual. Coordinates are always passed in the order y,x, and the top-left corner of a window is coordinate (0,0). This breaks the normal convention for handling coordinates where the x coordinate comes first. This is an unfortunate difference from most other computer applications, but it’s been part of curses since it was first written, and it’s too late to change things now.

Your application can determine the size of the screen by using the curses.LINES and curses.COLS variables to obtain the y and x sizes. Legal coordinates will then extend from (0,0) to (curses.LINES - 1, curses.COLS - 1).

When you call a method to display or erase text, the effect doesn’t immediately show up on the display. Instead you must call the refresh() method of window objects to update the screen.

This is because curses was originally written with slow 300-baud terminal connections in mind; with these terminals, minimizing the time required to redraw the screen was very important. Instead curses accumulates changes to the screen and displays them in the most efficient manner when you call refresh(). For example, if your program displays some text in a window and then clears the window, there’s no need to send the original text because they’re never visible.

In practice, explicitly telling curses to redraw a window doesn’t really complicate programming with curses much. Most programs go into a flurry of activity, and then pause waiting for a keypress or some other action on the part of the user. All you have to do is to be sure that the screen has been redrawn before pausing to wait for user input, by first calling stdscr.refresh() or the refresh() method of some other relevant window.

A pad is a special case of a window; it can be larger than the actual display screen, and only a portion of the pad displayed at a time. Creating a pad requires the pad’s height and width, while refreshing a pad requires giving the coordinates of the on-screen area where a subsection of the pad will be displayed.

pad = curses.newpad(100, 100)
# These loops fill the pad with letters; addch() is
# explained in the next section
for y in range(0, 99):
    for x in range(0, 99):
        pad.addch(y,x, ord('a') + (x*x+y*y) % 26)

# Displays a section of the pad in the middle of the screen.
# (0,0) : coordinate of upper-left corner of pad area to display.
# (5,5) : coordinate of upper-left corner of window area to be filled
#         with pad content.
# (20, 75) : coordinate of lower-right corner of window area to be
#          : filled with pad content.
pad.refresh( 0,0, 5,5, 20,75)
The refresh() call displays a section of the pad in the rectangle extending from coordinate (5,5) to coordinate (20,75) on the screen; the upper left corner of the displayed section is coordinate (0,0) on the pad. Beyond that difference, pads are exactly like ordinary windows and support the same methods.

If you have multiple windows and pads on screen there is a more efficient way to update the screen and prevent annoying screen flicker as each part of the screen gets updated. refresh() actually does two things:

Calls the noutrefresh() method of each window to update an underlying data structure representing the desired state of the screen.

Calls the function doupdate() function to change the physical screen to match the desired state recorded in the data structure.

Instead you can call noutrefresh() on a number of windows to update the data structure, and then call doupdate() to update the screen.

Displaying Text
From a C programmer’s point of view, curses may sometimes look like a twisty maze of functions, all subtly different. For example, addstr() displays a string at the current cursor location in the stdscr window, while mvaddstr() moves to a given y,x coordinate first before displaying the string. waddstr() is just like addstr(), but allows specifying a window to use instead of using stdscr by default. mvwaddstr() allows specifying both a window and a coordinate.

Fortunately the Python interface hides all these details. stdscr is a window object like any other, and methods such as addstr() accept multiple argument forms. Usually there are four different forms.

Form

Description

str or ch

Display the string str or character ch at the current position

str or ch, attr

Display the string str or character ch, using attribute attr at the current position

y, x, str or ch

Move to position y,x within the window, and display str or ch

y, x, str or ch, attr

Move to position y,x within the window, and display str or ch, using attribute attr

Attributes allow displaying text in highlighted forms such as boldface, underline, reverse code, or in color. They’ll be explained in more detail in the next subsection.

The addstr() method takes a Python string or bytestring as the value to be displayed. The contents of bytestrings are sent to the terminal as-is. Strings are encoded to bytes using the value of the window’s encoding attribute; this defaults to the default system encoding as returned by locale.getpreferredencoding().

The addch() methods take a character, which can be either a string of length 1, a bytestring of length 1, or an integer.

Constants are provided for extension characters; these constants are integers greater than 255. For example, ACS_PLMINUS is a +/- symbol, and ACS_ULCORNER is the upper left corner of a box (handy for drawing borders). You can also use the appropriate Unicode character.

Windows remember where the cursor was left after the last operation, so if you leave out the y,x coordinates, the string or character will be displayed wherever the last operation left off. You can also move the cursor with the move(y,x) method. Because some terminals always display a flashing cursor, you may want to ensure that the cursor is positioned in some location where it won’t be distracting; it can be confusing to have the cursor blinking at some apparently random location.

If your application doesn’t need a blinking cursor at all, you can call curs_set(False) to make it invisible. For compatibility with older curses versions, there’s a leaveok(bool) function that’s a synonym for curs_set(). When bool is true, the curses library will attempt to suppress the flashing cursor, and you won’t need to worry about leaving it in odd locations.

Attributes and Color
Characters can be displayed in different ways. Status lines in a text-based application are commonly shown in reverse video, or a text viewer may need to highlight certain words. curses supports this by allowing you to specify an attribute for each cell on the screen.

An attribute is an integer, each bit representing a different attribute. You can try to display text with multiple attribute bits set, but curses doesn’t guarantee that all the possible combinations are available, or that they’re all visually distinct. That depends on the ability of the terminal being used, so it’s safest to stick to the most commonly available attributes, listed here.

Attribute

Description

A_BLINK

Blinking text

A_BOLD

Extra bright or bold text

A_DIM

Half bright text

A_REVERSE

Reverse-video text

A_STANDOUT

The best highlighting mode available

A_UNDERLINE

Underlined text

So, to display a reverse-video status line on the top line of the screen, you could code:

stdscr.addstr(0, 0, "Current mode: Typing mode",
              curses.A_REVERSE)
stdscr.refresh()
The curses library also supports color on those terminals that provide it. The most common such terminal is probably the Linux console, followed by color xterms.

To use color, you must call the start_color() function soon after calling initscr(), to initialize the default color set (the curses.wrapper() function does this automatically). Once that’s done, the has_colors() function returns TRUE if the terminal in use can actually display color. (Note: curses uses the American spelling ‘color’, instead of the Canadian/British spelling ‘colour’. If you’re used to the British spelling, you’ll have to resign yourself to misspelling it for the sake of these functions.)

The curses library maintains a finite number of color pairs, containing a foreground (or text) color and a background color. You can get the attribute value corresponding to a color pair with the color_pair() function; this can be bitwise-OR’ed with other attributes such as A_REVERSE, but again, such combinations are not guaranteed to work on all terminals.

An example, which displays a line of text using color pair 1:

stdscr.addstr("Pretty text", curses.color_pair(1))
stdscr.refresh()
As I said before, a color pair consists of a foreground and background color. The init_pair(n, f, b) function changes the definition of color pair n, to foreground color f and background color b. Color pair 0 is hard-wired to white on black, and cannot be changed.

Colors are numbered, and start_color() initializes 8 basic colors when it activates color mode. They are: 0:black, 1:red, 2:green, 3:yellow, 4:blue, 5:magenta, 6:cyan, and 7:white. The curses module defines named constants for each of these colors: curses.COLOR_BLACK, curses.COLOR_RED, and so forth.

Let’s put all this together. To change color 1 to red text on a white background, you would call:

curses.init_pair(1, curses.COLOR_RED, curses.COLOR_WHITE)
When you change a color pair, any text already displayed using that color pair will change to the new colors. You can also display new text in this color with:

stdscr.addstr(0,0, "RED ALERT!", curses.color_pair(1))
Very fancy terminals can change the definitions of the actual colors to a given RGB value. This lets you change color 1, which is usually red, to purple or blue or any other color you like. Unfortunately, the Linux console doesn’t support this, so I’m unable to try it out, and can’t provide any examples. You can check if your terminal can do this by calling can_change_color(), which returns True if the capability is there. If you’re lucky enough to have such a talented terminal, consult your system’s man pages for more information.

User Input
The C curses library offers only very simple input mechanisms. Python’s curses module adds a basic text-input widget. (Other libraries such as Urwid have more extensive collections of widgets.)

There are two methods for getting input from a window:

getch() refreshes the screen and then waits for the user to hit a key, displaying the key if echo() has been called earlier. You can optionally specify a coordinate to which the cursor should be moved before pausing.

getkey() does the same thing but converts the integer to a string. Individual characters are returned as 1-character strings, and special keys such as function keys return longer strings containing a key name such as KEY_UP or ^G.

It’s possible to not wait for the user using the nodelay() window method. After nodelay(True), getch() and getkey() for the window become non-blocking. To signal that no input is ready, getch() returns curses.ERR (a value of -1) and getkey() raises an exception. There’s also a halfdelay() function, which can be used to (in effect) set a timer on each getch(); if no input becomes available within a specified delay (measured in tenths of a second), curses raises an exception.

The getch() method returns an integer; if it’s between 0 and 255, it represents the ASCII code of the key pressed. Values greater than 255 are special keys such as Page Up, Home, or the cursor keys. You can compare the value returned to constants such as curses.KEY_PPAGE, curses.KEY_HOME, or curses.KEY_LEFT. The main loop of your program may look something like this:

while True:
    c = stdscr.getch()
    if c == ord('p'):
        PrintDocument()
    elif c == ord('q'):
        break  # Exit the while loop
    elif c == curses.KEY_HOME:
        x = y = 0
The curses.ascii module supplies ASCII class membership functions that take either integer or 1-character string arguments; these may be useful in writing more readable tests for such loops. It also supplies conversion functions that take either integer or 1-character-string arguments and return the same type. For example, curses.ascii.ctrl() returns the control character corresponding to its argument.

There’s also a method to retrieve an entire string, getstr(). It isn’t used very often, because its functionality is quite limited; the only editing keys available are the backspace key and the Enter key, which terminates the string. It can optionally be limited to a fixed number of characters.

curses.echo()            # Enable echoing of characters

# Get a 15-character string, with the cursor on the top line
s = stdscr.getstr(0,0, 15)
The curses.textpad module supplies a text box that supports an Emacs-like set of keybindings. Various methods of the Textbox class support editing with input validation and gathering the edit results either with or without trailing spaces. Here’s an example:

import curses
from curses.textpad import Textbox, rectangle

def main(stdscr):
    stdscr.addstr(0, 0, "Enter IM message: (hit Ctrl-G to send)")

    editwin = curses.newwin(5,30, 2,1)
    rectangle(stdscr, 1,0, 1+5+1, 1+30+1)
    stdscr.refresh()

    box = Textbox(editwin)

    # Let the user edit until Ctrl-G is struck.
    box.edit()

    # Get resulting contents
    message = box.gather()
See the library documentation on curses.textpad for more details.

For More Information
This HOWTO doesn’t cover some advanced topics, such as reading the contents of the screen or capturing mouse events from an xterm instance, but the Python library page for the curses module is now reasonably complete. You should browse it next.

If you’re in doubt about the detailed behavior of the curses functions, consult the manual pages for your curses implementation, whether it’s ncurses or a proprietary Unix vendor’s. The manual pages will document any quirks, and provide complete lists of all the functions, attributes, and ACS_* characters available to you.

Because the curses API is so large, some functions aren’t supported in the Python interface. Often this isn’t because they’re difficult to implement, but because no one has needed them yet. Also, Python doesn’t yet support the menu library associated with ncurses. Patches adding support for these would be welcome; see the Python Developer’s Guide to learn more about submitting patches to Python.

Writing Programs with NCURSES: a lengthy tutorial for C programmers.

The ncurses man page

The ncurses FAQ

“Use curses… don’t swear”: video of a PyCon 2013 talk on controlling terminals using curses or Urwid.

“Console Applications with Urwid”: video of a PyCon CA 2012 talk demonstrating some applications written using Urwid.

Table of Contents
Curses Programming with Python
What is curses?
The Python curses module
Starting and ending a curses application
Windows and Pads
Displaying Text
Attributes and Color
User Input
For More Information
Previous topic
Porting Extension Modules to Python 3

Next topic
Descriptor HowTo Guide

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Curses Programming with Python
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Descriptor HowTo Guide
Quick search
  |
Descriptor HowTo Guide
Author
Raymond Hettinger

Contact
<python at rcn dot com>

Contents

Descriptor HowTo Guide

Primer

Simple example: A descriptor that returns a constant

Dynamic lookups

Managed attributes

Customized names

Closing thoughts

Complete Practical Example

Validator class

Custom validators

Practical application

Technical Tutorial

Abstract

Definition and introduction

Descriptor protocol

Overview of descriptor invocation

Invocation from an instance

Invocation from a class

Invocation from super

Summary of invocation logic

Automatic name notification

ORM example

Pure Python Equivalents

Properties

Functions and methods

Kinds of methods

Static methods

Class methods

Member objects and __slots__

Descriptors let objects customize attribute lookup, storage, and deletion.

This guide has four major sections:

The “primer” gives a basic overview, moving gently from simple examples, adding one feature at a time. Start here if you’re new to descriptors.

The second section shows a complete, practical descriptor example. If you already know the basics, start there.

The third section provides a more technical tutorial that goes into the detailed mechanics of how descriptors work. Most people don’t need this level of detail.

The last section has pure Python equivalents for built-in descriptors that are written in C. Read this if you’re curious about how functions turn into bound methods or about the implementation of common tools like classmethod(), staticmethod(), property(), and __slots__.

Primer
In this primer, we start with the most basic possible example and then we’ll add new capabilities one by one.

Simple example: A descriptor that returns a constant
The Ten class is a descriptor whose __get__() method always returns the constant 10:

class Ten:
    def __get__(self, obj, objtype=None):
        return 10
To use the descriptor, it must be stored as a class variable in another class:

class A:
    x = 5                       # Regular class attribute
    y = Ten()                   # Descriptor instance
An interactive session shows the difference between normal attribute lookup and descriptor lookup:

>>>
>>> a = A()                     # Make an instance of class A
>>> a.x                         # Normal attribute lookup
5
>>> a.y                         # Descriptor lookup
10
In the a.x attribute lookup, the dot operator finds 'x': 5 in the class dictionary. In the a.y lookup, the dot operator finds a descriptor instance, recognized by its __get__ method. Calling that method returns 10.

Note that the value 10 is not stored in either the class dictionary or the instance dictionary. Instead, the value 10 is computed on demand.

This example shows how a simple descriptor works, but it isn’t very useful. For retrieving constants, normal attribute lookup would be better.

In the next section, we’ll create something more useful, a dynamic lookup.

Dynamic lookups
Interesting descriptors typically run computations instead of returning constants:

import os

class DirectorySize:

    def __get__(self, obj, objtype=None):
        return len(os.listdir(obj.dirname))

class Directory:

    size = DirectorySize()              # Descriptor instance

    def __init__(self, dirname):
        self.dirname = dirname          # Regular instance attribute
An interactive session shows that the lookup is dynamic — it computes different, updated answers each time:

>>>
>>> s = Directory('songs')
>>> g = Directory('games')
>>> s.size                              # The songs directory has twenty files
20
>>> g.size                              # The games directory has three files
3
>>> os.remove('games/chess')            # Delete a game
>>> g.size                              # File count is automatically updated
2
Besides showing how descriptors can run computations, this example also reveals the purpose of the parameters to __get__(). The self parameter is size, an instance of DirectorySize. The obj parameter is either g or s, an instance of Directory. It is the obj parameter that lets the __get__() method learn the target directory. The objtype parameter is the class Directory.

Managed attributes
A popular use for descriptors is managing access to instance data. The descriptor is assigned to a public attribute in the class dictionary while the actual data is stored as a private attribute in the instance dictionary. The descriptor’s __get__() and __set__() methods are triggered when the public attribute is accessed.

In the following example, age is the public attribute and _age is the private attribute. When the public attribute is accessed, the descriptor logs the lookup or update:

import logging

logging.basicConfig(level=logging.INFO)

class LoggedAgeAccess:

    def __get__(self, obj, objtype=None):
        value = obj._age
        logging.info('Accessing %r giving %r', 'age', value)
        return value

    def __set__(self, obj, value):
        logging.info('Updating %r to %r', 'age', value)
        obj._age = value

class Person:

    age = LoggedAgeAccess()             # Descriptor instance

    def __init__(self, name, age):
        self.name = name                # Regular instance attribute
        self.age = age                  # Calls __set__()

    def birthday(self):
        self.age += 1                   # Calls both __get__() and __set__()
An interactive session shows that all access to the managed attribute age is logged, but that the regular attribute name is not logged:

>>>
>>> mary = Person('Mary M', 30)         # The initial age update is logged
INFO:root:Updating 'age' to 30
>>> dave = Person('David D', 40)
INFO:root:Updating 'age' to 40

>>> vars(mary)                          # The actual data is in a private attribute
{'name': 'Mary M', '_age': 30}
>>> vars(dave)
{'name': 'David D', '_age': 40}

>>> mary.age                            # Access the data and log the lookup
INFO:root:Accessing 'age' giving 30
30
>>> mary.birthday()                     # Updates are logged as well
INFO:root:Accessing 'age' giving 30
INFO:root:Updating 'age' to 31

>>> dave.name                           # Regular attribute lookup isn't logged
'David D'
>>> dave.age                            # Only the managed attribute is logged
INFO:root:Accessing 'age' giving 40
40
One major issue with this example is that the private name _age is hardwired in the LoggedAgeAccess class. That means that each instance can only have one logged attribute and that its name is unchangeable. In the next example, we’ll fix that problem.

Customized names
When a class uses descriptors, it can inform each descriptor about which variable name was used.

In this example, the Person class has two descriptor instances, name and age. When the Person class is defined, it makes a callback to __set_name__() in LoggedAccess so that the field names can be recorded, giving each descriptor its own public_name and private_name:

import logging

logging.basicConfig(level=logging.INFO)

class LoggedAccess:

    def __set_name__(self, owner, name):
        self.public_name = name
        self.private_name = '_' + name

    def __get__(self, obj, objtype=None):
        value = getattr(obj, self.private_name)
        logging.info('Accessing %r giving %r', self.public_name, value)
        return value

    def __set__(self, obj, value):
        logging.info('Updating %r to %r', self.public_name, value)
        setattr(obj, self.private_name, value)

class Person:

    name = LoggedAccess()                # First descriptor instance
    age = LoggedAccess()                 # Second descriptor instance

    def __init__(self, name, age):
        self.name = name                 # Calls the first descriptor
        self.age = age                   # Calls the second descriptor

    def birthday(self):
        self.age += 1
An interactive session shows that the Person class has called __set_name__() so that the field names would be recorded. Here we call vars() to look up the descriptor without triggering it:

>>>
>>> vars(vars(Person)['name'])
{'public_name': 'name', 'private_name': '_name'}
>>> vars(vars(Person)['age'])
{'public_name': 'age', 'private_name': '_age'}
The new class now logs access to both name and age:

>>>
>>> pete = Person('Peter P', 10)
INFO:root:Updating 'name' to 'Peter P'
INFO:root:Updating 'age' to 10
>>> kate = Person('Catherine C', 20)
INFO:root:Updating 'name' to 'Catherine C'
INFO:root:Updating 'age' to 20
The two Person instances contain only the private names:

>>>
>>> vars(pete)
{'_name': 'Peter P', '_age': 10}
>>> vars(kate)
{'_name': 'Catherine C', '_age': 20}
Closing thoughts
A descriptor is what we call any object that defines __get__(), __set__(), or __delete__().

Optionally, descriptors can have a __set_name__() method. This is only used in cases where a descriptor needs to know either the class where it was created or the name of class variable it was assigned to. (This method, if present, is called even if the class is not a descriptor.)

Descriptors get invoked by the dot operator during attribute lookup. If a descriptor is accessed indirectly with vars(some_class)[descriptor_name], the descriptor instance is returned without invoking it.

Descriptors only work when used as class variables. When put in instances, they have no effect.

The main motivation for descriptors is to provide a hook allowing objects stored in class variables to control what happens during attribute lookup.

Traditionally, the calling class controls what happens during lookup. Descriptors invert that relationship and allow the data being looked-up to have a say in the matter.

Descriptors are used throughout the language. It is how functions turn into bound methods. Common tools like classmethod(), staticmethod(), property(), and functools.cached_property() are all implemented as descriptors.

Complete Practical Example
In this example, we create a practical and powerful tool for locating notoriously hard to find data corruption bugs.

Validator class
A validator is a descriptor for managed attribute access. Prior to storing any data, it verifies that the new value meets various type and range restrictions. If those restrictions aren’t met, it raises an exception to prevent data corruption at its source.

This Validator class is both an abstract base class and a managed attribute descriptor:

from abc import ABC, abstractmethod

class Validator(ABC):

    def __set_name__(self, owner, name):
        self.private_name = '_' + name

    def __get__(self, obj, objtype=None):
        return getattr(obj, self.private_name)

    def __set__(self, obj, value):
        self.validate(value)
        setattr(obj, self.private_name, value)

    @abstractmethod
    def validate(self, value):
        pass
Custom validators need to inherit from Validator and must supply a validate() method to test various restrictions as needed.

Custom validators
Here are three practical data validation utilities:

OneOf verifies that a value is one of a restricted set of options.

Number verifies that a value is either an int or float. Optionally, it verifies that a value is between a given minimum or maximum.

String verifies that a value is a str. Optionally, it validates a given minimum or maximum length. It can validate a user-defined predicate as well.

class OneOf(Validator):

    def __init__(self, *options):
        self.options = set(options)

    def validate(self, value):
        if value not in self.options:
            raise ValueError(f'Expected {value!r} to be one of {self.options!r}')

class Number(Validator):

    def __init__(self, minvalue=None, maxvalue=None):
        self.minvalue = minvalue
        self.maxvalue = maxvalue

    def validate(self, value):
        if not isinstance(value, (int, float)):
            raise TypeError(f'Expected {value!r} to be an int or float')
        if self.minvalue is not None and value < self.minvalue:
            raise ValueError(
                f'Expected {value!r} to be at least {self.minvalue!r}'
            )
        if self.maxvalue is not None and value > self.maxvalue:
            raise ValueError(
                f'Expected {value!r} to be no more than {self.maxvalue!r}'
            )

class String(Validator):

    def __init__(self, minsize=None, maxsize=None, predicate=None):
        self.minsize = minsize
        self.maxsize = maxsize
        self.predicate = predicate

    def validate(self, value):
        if not isinstance(value, str):
            raise TypeError(f'Expected {value!r} to be an str')
        if self.minsize is not None and len(value) < self.minsize:
            raise ValueError(
                f'Expected {value!r} to be no smaller than {self.minsize!r}'
            )
        if self.maxsize is not None and len(value) > self.maxsize:
            raise ValueError(
                f'Expected {value!r} to be no bigger than {self.maxsize!r}'
            )
        if self.predicate is not None and not self.predicate(value):
            raise ValueError(
                f'Expected {self.predicate} to be true for {value!r}'
            )
Practical application
Here’s how the data validators can be used in a real class:

class Component:

    name = String(minsize=3, maxsize=10, predicate=str.isupper)
    kind = OneOf('wood', 'metal', 'plastic')
    quantity = Number(minvalue=0)

    def __init__(self, name, kind, quantity):
        self.name = name
        self.kind = kind
        self.quantity = quantity
The descriptors prevent invalid instances from being created:

>>>
>>> Component('Widget', 'metal', 5)      # Blocked: 'Widget' is not all uppercase
Traceback (most recent call last):
    ...
ValueError: Expected <method 'isupper' of 'str' objects> to be true for 'Widget'

>>> Component('WIDGET', 'metle', 5)      # Blocked: 'metle' is misspelled
Traceback (most recent call last):
    ...
ValueError: Expected 'metle' to be one of {'metal', 'plastic', 'wood'}

>>> Component('WIDGET', 'metal', -5)     # Blocked: -5 is negative
Traceback (most recent call last):
    ...
ValueError: Expected -5 to be at least 0
>>> Component('WIDGET', 'metal', 'V')    # Blocked: 'V' isn't a number
Traceback (most recent call last):
    ...
TypeError: Expected 'V' to be an int or float

>>> c = Component('WIDGET', 'metal', 5)  # Allowed:  The inputs are valid
Technical Tutorial
What follows is a more technical tutorial for the mechanics and details of how descriptors work.

Abstract
Defines descriptors, summarizes the protocol, and shows how descriptors are called. Provides an example showing how object relational mappings work.

Learning about descriptors not only provides access to a larger toolset, it creates a deeper understanding of how Python works.

Definition and introduction
In general, a descriptor is an attribute value that has one of the methods in the descriptor protocol. Those methods are __get__(), __set__(), and __delete__(). If any of those methods are defined for an attribute, it is said to be a descriptor.

The default behavior for attribute access is to get, set, or delete the attribute from an object’s dictionary. For instance, a.x has a lookup chain starting with a.__dict__['x'], then type(a).__dict__['x'], and continuing through the method resolution order of type(a). If the looked-up value is an object defining one of the descriptor methods, then Python may override the default behavior and invoke the descriptor method instead. Where this occurs in the precedence chain depends on which descriptor methods were defined.

Descriptors are a powerful, general purpose protocol. They are the mechanism behind properties, methods, static methods, class methods, and super(). They are used throughout Python itself. Descriptors simplify the underlying C code and offer a flexible set of new tools for everyday Python programs.

Descriptor protocol
descr.__get__(self, obj, type=None) -> value

descr.__set__(self, obj, value) -> None

descr.__delete__(self, obj) -> None

That is all there is to it. Define any of these methods and an object is considered a descriptor and can override default behavior upon being looked up as an attribute.

If an object defines __set__() or __delete__(), it is considered a data descriptor. Descriptors that only define __get__() are called non-data descriptors (they are often used for methods but other uses are possible).

Data and non-data descriptors differ in how overrides are calculated with respect to entries in an instance’s dictionary. If an instance’s dictionary has an entry with the same name as a data descriptor, the data descriptor takes precedence. If an instance’s dictionary has an entry with the same name as a non-data descriptor, the dictionary entry takes precedence.

To make a read-only data descriptor, define both __get__() and __set__() with the __set__() raising an AttributeError when called. Defining the __set__() method with an exception raising placeholder is enough to make it a data descriptor.

Overview of descriptor invocation
A descriptor can be called directly with desc.__get__(obj) or desc.__get__(None, cls).

But it is more common for a descriptor to be invoked automatically from attribute access.

The expression obj.x looks up the attribute x in the chain of namespaces for obj. If the search finds a descriptor outside of the instance __dict__, its __get__() method is invoked according to the precedence rules listed below.

The details of invocation depend on whether obj is an object, class, or instance of super.

Invocation from an instance
Instance lookup scans through a chain of namespaces giving data descriptors the highest priority, followed by instance variables, then non-data descriptors, then class variables, and lastly __getattr__() if it is provided.

If a descriptor is found for a.x, then it is invoked with: desc.__get__(a, type(a)).

The logic for a dotted lookup is in object.__getattribute__(). Here is a pure Python equivalent:

def find_name_in_mro(cls, name, default):
    "Emulate _PyType_Lookup() in Objects/typeobject.c"
    for base in cls.__mro__:
        if name in vars(base):
            return vars(base)[name]
    return default

def object_getattribute(obj, name):
    "Emulate PyObject_GenericGetAttr() in Objects/object.c"
    null = object()
    objtype = type(obj)
    cls_var = find_name_in_mro(objtype, name, null)
    descr_get = getattr(type(cls_var), '__get__', null)
    if descr_get is not null:
        if (hasattr(type(cls_var), '__set__')
            or hasattr(type(cls_var), '__delete__')):
            return descr_get(cls_var, obj, objtype)     # data descriptor
    if hasattr(obj, '__dict__') and name in vars(obj):
        return vars(obj)[name]                          # instance variable
    if descr_get is not null:
        return descr_get(cls_var, obj, objtype)         # non-data descriptor
    if cls_var is not null:
        return cls_var                                  # class variable
    raise AttributeError(name)
Note, there is no __getattr__() hook in the __getattribute__() code. That is why calling __getattribute__() directly or with super().__getattribute__ will bypass __getattr__() entirely.

Instead, it is the dot operator and the getattr() function that are responsible for invoking __getattr__() whenever __getattribute__() raises an AttributeError. Their logic is encapsulated in a helper function:

def getattr_hook(obj, name):
    "Emulate slot_tp_getattr_hook() in Objects/typeobject.c"
    try:
        return obj.__getattribute__(name)
    except AttributeError:
        if not hasattr(type(obj), '__getattr__'):
            raise
    return type(obj).__getattr__(obj, name)             # __getattr__
Invocation from a class
The logic for a dotted lookup such as A.x is in type.__getattribute__(). The steps are similar to those for object.__getattribute__() but the instance dictionary lookup is replaced by a search through the class’s method resolution order.

If a descriptor is found, it is invoked with desc.__get__(None, A).

The full C implementation can be found in type_getattro() and _PyType_Lookup() in Objects/typeobject.c.

Invocation from super
The logic for super’s dotted lookup is in the __getattribute__() method for object returned by super().

A dotted lookup such as super(A, obj).m searches obj.__class__.__mro__ for the base class B immediately following A and then returns B.__dict__['m'].__get__(obj, A). If not a descriptor, m is returned unchanged.

The full C implementation can be found in super_getattro() in Objects/typeobject.c. A pure Python equivalent can be found in Guido’s Tutorial.

Summary of invocation logic
The mechanism for descriptors is embedded in the __getattribute__() methods for object, type, and super().

The important points to remember are:

Descriptors are invoked by the __getattribute__() method.

Classes inherit this machinery from object, type, or super().

Overriding __getattribute__() prevents automatic descriptor calls because all the descriptor logic is in that method.

object.__getattribute__() and type.__getattribute__() make different calls to __get__(). The first includes the instance and may include the class. The second puts in None for the instance and always includes the class.

Data descriptors always override instance dictionaries.

Non-data descriptors may be overridden by instance dictionaries.

Automatic name notification
Sometimes it is desirable for a descriptor to know what class variable name it was assigned to. When a new class is created, the type metaclass scans the dictionary of the new class. If any of the entries are descriptors and if they define __set_name__(), that method is called with two arguments. The owner is the class where the descriptor is used, and the name is the class variable the descriptor was assigned to.

The implementation details are in type_new() and set_names() in Objects/typeobject.c.

Since the update logic is in type.__new__(), notifications only take place at the time of class creation. If descriptors are added to the class afterwards, __set_name__() will need to be called manually.

ORM example
The following code is a simplified skeleton showing how data descriptors could be used to implement an object relational mapping.

The essential idea is that the data is stored in an external database. The Python instances only hold keys to the database’s tables. Descriptors take care of lookups or updates:

class Field:

    def __set_name__(self, owner, name):
        self.fetch = f'SELECT {name} FROM {owner.table} WHERE {owner.key}=?;'
        self.store = f'UPDATE {owner.table} SET {name}=? WHERE {owner.key}=?;'

    def __get__(self, obj, objtype=None):
        return conn.execute(self.fetch, [obj.key]).fetchone()[0]

    def __set__(self, obj, value):
        conn.execute(self.store, [value, obj.key])
        conn.commit()
We can use the Field class to define models that describe the schema for each table in a database:

class Movie:
    table = 'Movies'                    # Table name
    key = 'title'                       # Primary key
    director = Field()
    year = Field()

    def __init__(self, key):
        self.key = key

class Song:
    table = 'Music'
    key = 'title'
    artist = Field()
    year = Field()
    genre = Field()

    def __init__(self, key):
        self.key = key
To use the models, first connect to the database:

>>>
>>> import sqlite3
>>> conn = sqlite3.connect('entertainment.db')
An interactive session shows how data is retrieved from the database and how it can be updated:

>>>
>>> Movie('Star Wars').director
'George Lucas'
>>> jaws = Movie('Jaws')
>>> f'Released in {jaws.year} by {jaws.director}'
'Released in 1975 by Steven Spielberg'

>>> Song('Country Roads').artist
'John Denver'

>>> Movie('Star Wars').director = 'J.J. Abrams'
>>> Movie('Star Wars').director
'J.J. Abrams'
Pure Python Equivalents
The descriptor protocol is simple and offers exciting possibilities. Several use cases are so common that they have been prepackaged into built-in tools. Properties, bound methods, static methods, class methods, and __slots__ are all based on the descriptor protocol.

Properties
Calling property() is a succinct way of building a data descriptor that triggers a function call upon access to an attribute. Its signature is:

property(fget=None, fset=None, fdel=None, doc=None) -> property
The documentation shows a typical use to define a managed attribute x:

class C:
    def getx(self): return self.__x
    def setx(self, value): self.__x = value
    def delx(self): del self.__x
    x = property(getx, setx, delx, "I'm the 'x' property.")
To see how property() is implemented in terms of the descriptor protocol, here is a pure Python equivalent:

class Property:
    "Emulate PyProperty_Type() in Objects/descrobject.c"

    def __init__(self, fget=None, fset=None, fdel=None, doc=None):
        self.fget = fget
        self.fset = fset
        self.fdel = fdel
        if doc is None and fget is not None:
            doc = fget.__doc__
        self.__doc__ = doc
        self._name = ''

    def __set_name__(self, owner, name):
        self._name = name

    def __get__(self, obj, objtype=None):
        if obj is None:
            return self
        if self.fget is None:
            raise AttributeError(f'unreadable attribute {self._name}')
        return self.fget(obj)

    def __set__(self, obj, value):
        if self.fset is None:
            raise AttributeError(f"can't set attribute {self._name}")
        self.fset(obj, value)

    def __delete__(self, obj):
        if self.fdel is None:
            raise AttributeError(f"can't delete attribute {self._name}")
        self.fdel(obj)

    def getter(self, fget):
        prop = type(self)(fget, self.fset, self.fdel, self.__doc__)
        prop._name = self._name
        return prop

    def setter(self, fset):
        prop = type(self)(self.fget, fset, self.fdel, self.__doc__)
        prop._name = self._name
        return prop

    def deleter(self, fdel):
        prop = type(self)(self.fget, self.fset, fdel, self.__doc__)
        prop._name = self._name
        return prop
The property() builtin helps whenever a user interface has granted attribute access and then subsequent changes require the intervention of a method.

For instance, a spreadsheet class may grant access to a cell value through Cell('b10').value. Subsequent improvements to the program require the cell to be recalculated on every access; however, the programmer does not want to affect existing client code accessing the attribute directly. The solution is to wrap access to the value attribute in a property data descriptor:

class Cell:
    ...

    @property
    def value(self):
        "Recalculate the cell before returning value"
        self.recalc()
        return self._value
Either the built-in property() or our Property() equivalent would work in this example.

Functions and methods
Python’s object oriented features are built upon a function based environment. Using non-data descriptors, the two are merged seamlessly.

Functions stored in class dictionaries get turned into methods when invoked. Methods only differ from regular functions in that the object instance is prepended to the other arguments. By convention, the instance is called self but could be called this or any other variable name.

Methods can be created manually with types.MethodType which is roughly equivalent to:

class MethodType:
    "Emulate PyMethod_Type in Objects/classobject.c"

    def __init__(self, func, obj):
        self.__func__ = func
        self.__self__ = obj

    def __call__(self, *args, **kwargs):
        func = self.__func__
        obj = self.__self__
        return func(obj, *args, **kwargs)
To support automatic creation of methods, functions include the __get__() method for binding methods during attribute access. This means that functions are non-data descriptors that return bound methods during dotted lookup from an instance. Here’s how it works:

class Function:
    ...

    def __get__(self, obj, objtype=None):
        "Simulate func_descr_get() in Objects/funcobject.c"
        if obj is None:
            return self
        return MethodType(self, obj)
Running the following class in the interpreter shows how the function descriptor works in practice:

class D:
    def f(self, x):
         return x
The function has a qualified name attribute to support introspection:

>>>
>>> D.f.__qualname__
'D.f'
Accessing the function through the class dictionary does not invoke __get__(). Instead, it just returns the underlying function object:

>>>
>>> D.__dict__['f']
<function D.f at 0x00C45070>
Dotted access from a class calls __get__() which just returns the underlying function unchanged:

>>>
>>> D.f
<function D.f at 0x00C45070>
The interesting behavior occurs during dotted access from an instance. The dotted lookup calls __get__() which returns a bound method object:

>>>
>>> d = D()
>>> d.f
<bound method D.f of <__main__.D object at 0x00B18C90>>
Internally, the bound method stores the underlying function and the bound instance:

>>>
>>> d.f.__func__
<function D.f at 0x00C45070>

>>> d.f.__self__
<__main__.D object at 0x1012e1f98>
If you have ever wondered where self comes from in regular methods or where cls comes from in class methods, this is it!

Kinds of methods
Non-data descriptors provide a simple mechanism for variations on the usual patterns of binding functions into methods.

To recap, functions have a __get__() method so that they can be converted to a method when accessed as attributes. The non-data descriptor transforms an obj.f(*args) call into f(obj, *args). Calling cls.f(*args) becomes f(*args).

This chart summarizes the binding and its two most useful variants:

Transformation

Called from an object

Called from a class

function

f(obj, *args)

f(*args)

staticmethod

f(*args)

f(*args)

classmethod

f(type(obj), *args)

f(cls, *args)

Static methods
Static methods return the underlying function without changes. Calling either c.f or C.f is the equivalent of a direct lookup into object.__getattribute__(c, "f") or object.__getattribute__(C, "f"). As a result, the function becomes identically accessible from either an object or a class.

Good candidates for static methods are methods that do not reference the self variable.

For instance, a statistics package may include a container class for experimental data. The class provides normal methods for computing the average, mean, median, and other descriptive statistics that depend on the data. However, there may be useful functions which are conceptually related but do not depend on the data. For instance, erf(x) is handy conversion routine that comes up in statistical work but does not directly depend on a particular dataset. It can be called either from an object or the class: s.erf(1.5) --> .9332 or Sample.erf(1.5) --> .9332.

Since static methods return the underlying function with no changes, the example calls are unexciting:

class E:
    @staticmethod
    def f(x):
        return x * 10
>>>
>>> E.f(3)
30
>>> E().f(3)
30
Using the non-data descriptor protocol, a pure Python version of staticmethod() would look like this:

class StaticMethod:
    "Emulate PyStaticMethod_Type() in Objects/funcobject.c"

    def __init__(self, f):
        self.f = f

    def __get__(self, obj, objtype=None):
        return self.f

    def __call__(self, *args, **kwds):
        return self.f(*args, **kwds)
Class methods
Unlike static methods, class methods prepend the class reference to the argument list before calling the function. This format is the same for whether the caller is an object or a class:

class F:
    @classmethod
    def f(cls, x):
        return cls.__name__, x
>>>
>>> F.f(3)
('F', 3)
>>> F().f(3)
('F', 3)
This behavior is useful whenever the method only needs to have a class reference and does not rely on data stored in a specific instance. One use for class methods is to create alternate class constructors. For example, the classmethod dict.fromkeys() creates a new dictionary from a list of keys. The pure Python equivalent is:

class Dict(dict):
    @classmethod
    def fromkeys(cls, iterable, value=None):
        "Emulate dict_fromkeys() in Objects/dictobject.c"
        d = cls()
        for key in iterable:
            d[key] = value
        return d
Now a new dictionary of unique keys can be constructed like this:

>>>
>>> d = Dict.fromkeys('abracadabra')
>>> type(d) is Dict
True
>>> d
{'a': None, 'b': None, 'r': None, 'c': None, 'd': None}
Using the non-data descriptor protocol, a pure Python version of classmethod() would look like this:

class ClassMethod:
    "Emulate PyClassMethod_Type() in Objects/funcobject.c"

    def __init__(self, f):
        self.f = f

    def __get__(self, obj, cls=None):
        if cls is None:
            cls = type(obj)
        if hasattr(type(self.f), '__get__'):
            return self.f.__get__(cls, cls)
        return MethodType(self.f, cls)
The code path for hasattr(type(self.f), '__get__') was added in Python 3.9 and makes it possible for classmethod() to support chained decorators. For example, a classmethod and property could be chained together:

class G:
    @classmethod
    @property
    def __doc__(cls):
        return f'A doc for {cls.__name__!r}'
>>>
>>> G.__doc__
"A doc for 'G'"
Member objects and __slots__
When a class defines __slots__, it replaces instance dictionaries with a fixed-length array of slot values. From a user point of view that has several effects:

1. Provides immediate detection of bugs due to misspelled attribute assignments. Only attribute names specified in __slots__ are allowed:

class Vehicle:
    __slots__ = ('id_number', 'make', 'model')
>>>
>>> auto = Vehicle()
>>> auto.id_nubmer = 'VYE483814LQEX'
Traceback (most recent call last):
    ...
AttributeError: 'Vehicle' object has no attribute 'id_nubmer'
2. Helps create immutable objects where descriptors manage access to private attributes stored in __slots__:

class Immutable:

    __slots__ = ('_dept', '_name')          # Replace the instance dictionary

    def __init__(self, dept, name):
        self._dept = dept                   # Store to private attribute
        self._name = name                   # Store to private attribute

    @property                               # Read-only descriptor
    def dept(self):
        return self._dept

    @property
    def name(self):                         # Read-only descriptor
        return self._name
>>>
>>> mark = Immutable('Botany', 'Mark Watney')
>>> mark.dept
'Botany'
>>> mark.dept = 'Space Pirate'
Traceback (most recent call last):
    ...
AttributeError: can't set attribute
>>> mark.location = 'Mars'
Traceback (most recent call last):
    ...
AttributeError: 'Immutable' object has no attribute 'location'
3. Saves memory. On a 64-bit Linux build, an instance with two attributes takes 48 bytes with __slots__ and 152 bytes without. This flyweight design pattern likely only matters when a large number of instances are going to be created.

4. Improves speed. Reading instance variables is 35% faster with __slots__ (as measured with Python 3.10 on an Apple M1 processor).

5. Blocks tools like functools.cached_property() which require an instance dictionary to function correctly:

from functools import cached_property

class CP:
    __slots__ = ()                          # Eliminates the instance dict

    @cached_property                        # Requires an instance dict
    def pi(self):
        return 4 * sum((-1.0)**n / (2.0*n + 1.0)
                       for n in reversed(range(100_000)))
>>>
>>> CP().pi
Traceback (most recent call last):
  ...
TypeError: No '__dict__' attribute on 'CP' instance to cache 'pi' property.
It is not possible to create an exact drop-in pure Python version of __slots__ because it requires direct access to C structures and control over object memory allocation. However, we can build a mostly faithful simulation where the actual C structure for slots is emulated by a private _slotvalues list. Reads and writes to that private structure are managed by member descriptors:

null = object()

class Member:

    def __init__(self, name, clsname, offset):
        'Emulate PyMemberDef in Include/structmember.h'
        # Also see descr_new() in Objects/descrobject.c
        self.name = name
        self.clsname = clsname
        self.offset = offset

    def __get__(self, obj, objtype=None):
        'Emulate member_get() in Objects/descrobject.c'
        # Also see PyMember_GetOne() in Python/structmember.c
        if obj is None:
            return self
        value = obj._slotvalues[self.offset]
        if value is null:
            raise AttributeError(self.name)
        return value

    def __set__(self, obj, value):
        'Emulate member_set() in Objects/descrobject.c'
        obj._slotvalues[self.offset] = value

    def __delete__(self, obj):
        'Emulate member_delete() in Objects/descrobject.c'
        value = obj._slotvalues[self.offset]
        if value is null:
            raise AttributeError(self.name)
        obj._slotvalues[self.offset] = null

    def __repr__(self):
        'Emulate member_repr() in Objects/descrobject.c'
        return f'<Member {self.name!r} of {self.clsname!r}>'
The type.__new__() method takes care of adding member objects to class variables:

class Type(type):
    'Simulate how the type metaclass adds member objects for slots'

    def __new__(mcls, clsname, bases, mapping, **kwargs):
        'Emulate type_new() in Objects/typeobject.c'
        # type_new() calls PyTypeReady() which calls add_methods()
        slot_names = mapping.get('slot_names', [])
        for offset, name in enumerate(slot_names):
            mapping[name] = Member(name, clsname, offset)
        return type.__new__(mcls, clsname, bases, mapping, **kwargs)
The object.__new__() method takes care of creating instances that have slots instead of an instance dictionary. Here is a rough simulation in pure Python:

class Object:
    'Simulate how object.__new__() allocates memory for __slots__'

    def __new__(cls, *args, **kwargs):
        'Emulate object_new() in Objects/typeobject.c'
        inst = super().__new__(cls)
        if hasattr(cls, 'slot_names'):
            empty_slots = [null] * len(cls.slot_names)
            object.__setattr__(inst, '_slotvalues', empty_slots)
        return inst

    def __setattr__(self, name, value):
        'Emulate _PyObject_GenericSetAttrWithDict() Objects/object.c'
        cls = type(self)
        if hasattr(cls, 'slot_names') and name not in cls.slot_names:
            raise AttributeError(
                f'{cls.__name__!r} object has no attribute {name!r}'
            )
        super().__setattr__(name, value)

    def __delattr__(self, name):
        'Emulate _PyObject_GenericSetAttrWithDict() Objects/object.c'
        cls = type(self)
        if hasattr(cls, 'slot_names') and name not in cls.slot_names:
            raise AttributeError(
                f'{cls.__name__!r} object has no attribute {name!r}'
            )
        super().__delattr__(name)
To use the simulation in a real class, just inherit from Object and set the metaclass to Type:

class H(Object, metaclass=Type):
    'Instance variables stored in slots'

    slot_names = ['x', 'y']

    def __init__(self, x, y):
        self.x = x
        self.y = y
At this point, the metaclass has loaded member objects for x and y:

>>>
>>> from pprint import pp
>>> pp(dict(vars(H)))
{'__module__': '__main__',
 '__doc__': 'Instance variables stored in slots',
 'slot_names': ['x', 'y'],
 '__init__': <function H.__init__ at 0x7fb5d302f9d0>,
 'x': <Member 'x' of 'H'>,
 'y': <Member 'y' of 'H'>}
When instances are created, they have a slot_values list where the attributes are stored:

>>>
>>> h = H(10, 20)
>>> vars(h)
{'_slotvalues': [10, 20]}
>>> h.x = 55
>>> vars(h)
{'_slotvalues': [55, 20]}
Misspelled or unassigned attributes will raise an exception:

>>>
>>> h.xz
Traceback (most recent call last):
    ...
AttributeError: 'H' object has no attribute 'xz'
Table of Contents
Descriptor HowTo Guide
Primer
Simple example: A descriptor that returns a constant
Dynamic lookups
Managed attributes
Customized names
Closing thoughts
Complete Practical Example
Validator class
Custom validators
Practical application
Technical Tutorial
Abstract
Definition and introduction
Descriptor protocol
Overview of descriptor invocation
Invocation from an instance
Invocation from a class
Invocation from super
Summary of invocation logic
Automatic name notification
ORM example
Pure Python Equivalents
Properties
Functions and methods
Kinds of methods
Static methods
Class methods
Member objects and __slots__
Previous topic
Curses Programming with Python

Next topic
Functional Programming HOWTO

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Descriptor HowTo Guide
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Functional Programming HOWTO
Quick search
  |
Functional Programming HOWTO
Author
A. M. Kuchling

Release
0.32

In this document, we’ll take a tour of Python’s features suitable for implementing programs in a functional style. After an introduction to the concepts of functional programming, we’ll look at language features such as iterators and generators and relevant library modules such as itertools and functools.

Introduction
This section explains the basic concept of functional programming; if you’re just interested in learning about Python language features, skip to the next section on Iterators.

Programming languages support decomposing problems in several different ways:

Most programming languages are procedural: programs are lists of instructions that tell the computer what to do with the program’s input. C, Pascal, and even Unix shells are procedural languages.

In declarative languages, you write a specification that describes the problem to be solved, and the language implementation figures out how to perform the computation efficiently. SQL is the declarative language you’re most likely to be familiar with; a SQL query describes the data set you want to retrieve, and the SQL engine decides whether to scan tables or use indexes, which subclauses should be performed first, etc.

Object-oriented programs manipulate collections of objects. Objects have internal state and support methods that query or modify this internal state in some way. Smalltalk and Java are object-oriented languages. C++ and Python are languages that support object-oriented programming, but don’t force the use of object-oriented features.

Functional programming decomposes a problem into a set of functions. Ideally, functions only take inputs and produce outputs, and don’t have any internal state that affects the output produced for a given input. Well-known functional languages include the ML family (Standard ML, OCaml, and other variants) and Haskell.

The designers of some computer languages choose to emphasize one particular approach to programming. This often makes it difficult to write programs that use a different approach. Other languages are multi-paradigm languages that support several different approaches. Lisp, C++, and Python are multi-paradigm; you can write programs or libraries that are largely procedural, object-oriented, or functional in all of these languages. In a large program, different sections might be written using different approaches; the GUI might be object-oriented while the processing logic is procedural or functional, for example.

In a functional program, input flows through a set of functions. Each function operates on its input and produces some output. Functional style discourages functions with side effects that modify internal state or make other changes that aren’t visible in the function’s return value. Functions that have no side effects at all are called purely functional. Avoiding side effects means not using data structures that get updated as a program runs; every function’s output must only depend on its input.

Some languages are very strict about purity and don’t even have assignment statements such as a=3 or c = a + b, but it’s difficult to avoid all side effects, such as printing to the screen or writing to a disk file. Another example is a call to the print() or time.sleep() function, neither of which returns a useful value. Both are called only for their side effects of sending some text to the screen or pausing execution for a second.

Python programs written in functional style usually won’t go to the extreme of avoiding all I/O or all assignments; instead, they’ll provide a functional-appearing interface but will use non-functional features internally. For example, the implementation of a function will still use assignments to local variables, but won’t modify global variables or have other side effects.

Functional programming can be considered the opposite of object-oriented programming. Objects are little capsules containing some internal state along with a collection of method calls that let you modify this state, and programs consist of making the right set of state changes. Functional programming wants to avoid state changes as much as possible and works with data flowing between functions. In Python you might combine the two approaches by writing functions that take and return instances representing objects in your application (e-mail messages, transactions, etc.).

Functional design may seem like an odd constraint to work under. Why should you avoid objects and side effects? There are theoretical and practical advantages to the functional style:

Formal provability.

Modularity.

Composability.

Ease of debugging and testing.

Formal provability
A theoretical benefit is that it’s easier to construct a mathematical proof that a functional program is correct.

For a long time researchers have been interested in finding ways to mathematically prove programs correct. This is different from testing a program on numerous inputs and concluding that its output is usually correct, or reading a program’s source code and concluding that the code looks right; the goal is instead a rigorous proof that a program produces the right result for all possible inputs.

The technique used to prove programs correct is to write down invariants, properties of the input data and of the program’s variables that are always true. For each line of code, you then show that if invariants X and Y are true before the line is executed, the slightly different invariants X’ and Y’ are true after the line is executed. This continues until you reach the end of the program, at which point the invariants should match the desired conditions on the program’s output.

Functional programming’s avoidance of assignments arose because assignments are difficult to handle with this technique; assignments can break invariants that were true before the assignment without producing any new invariants that can be propagated onward.

Unfortunately, proving programs correct is largely impractical and not relevant to Python software. Even trivial programs require proofs that are several pages long; the proof of correctness for a moderately complicated program would be enormous, and few or none of the programs you use daily (the Python interpreter, your XML parser, your web browser) could be proven correct. Even if you wrote down or generated a proof, there would then be the question of verifying the proof; maybe there’s an error in it, and you wrongly believe you’ve proved the program correct.

Modularity
A more practical benefit of functional programming is that it forces you to break apart your problem into small pieces. Programs are more modular as a result. It’s easier to specify and write a small function that does one thing than a large function that performs a complicated transformation. Small functions are also easier to read and to check for errors.

Ease of debugging and testing
Testing and debugging a functional-style program is easier.

Debugging is simplified because functions are generally small and clearly specified. When a program doesn’t work, each function is an interface point where you can check that the data are correct. You can look at the intermediate inputs and outputs to quickly isolate the function that’s responsible for a bug.

Testing is easier because each function is a potential subject for a unit test. Functions don’t depend on system state that needs to be replicated before running a test; instead you only have to synthesize the right input and then check that the output matches expectations.

Composability
As you work on a functional-style program, you’ll write a number of functions with varying inputs and outputs. Some of these functions will be unavoidably specialized to a particular application, but others will be useful in a wide variety of programs. For example, a function that takes a directory path and returns all the XML files in the directory, or a function that takes a filename and returns its contents, can be applied to many different situations.

Over time you’ll form a personal library of utilities. Often you’ll assemble new programs by arranging existing functions in a new configuration and writing a few functions specialized for the current task.

Iterators
I’ll start by looking at a Python language feature that’s an important foundation for writing functional-style programs: iterators.

An iterator is an object representing a stream of data; this object returns the data one element at a time. A Python iterator must support a method called __next__() that takes no arguments and always returns the next element of the stream. If there are no more elements in the stream, __next__() must raise the StopIteration exception. Iterators don’t have to be finite, though; it’s perfectly reasonable to write an iterator that produces an infinite stream of data.

The built-in iter() function takes an arbitrary object and tries to return an iterator that will return the object’s contents or elements, raising TypeError if the object doesn’t support iteration. Several of Python’s built-in data types support iteration, the most common being lists and dictionaries. An object is called iterable if you can get an iterator for it.

You can experiment with the iteration interface manually:

>>>
L = [1, 2, 3]
it = iter(L)
it  
<...iterator object at ...>
it.__next__()  # same as next(it)
1
next(it)
2
next(it)
3
next(it)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
>>>
Python expects iterable objects in several different contexts, the most important being the for statement. In the statement for X in Y, Y must be an iterator or some object for which iter() can create an iterator. These two statements are equivalent:

for i in iter(obj):
    print(i)

for i in obj:
    print(i)
Iterators can be materialized as lists or tuples by using the list() or tuple() constructor functions:

>>>
L = [1, 2, 3]
iterator = iter(L)
t = tuple(iterator)
t
(1, 2, 3)
Sequence unpacking also supports iterators: if you know an iterator will return N elements, you can unpack them into an N-tuple:

>>>
L = [1, 2, 3]
iterator = iter(L)
a, b, c = iterator
a, b, c
(1, 2, 3)
Built-in functions such as max() and min() can take a single iterator argument and will return the largest or smallest element. The "in" and "not in" operators also support iterators: X in iterator is true if X is found in the stream returned by the iterator. You’ll run into obvious problems if the iterator is infinite; max(), min() will never return, and if the element X never appears in the stream, the "in" and "not in" operators won’t return either.

Note that you can only go forward in an iterator; there’s no way to get the previous element, reset the iterator, or make a copy of it. Iterator objects can optionally provide these additional capabilities, but the iterator protocol only specifies the __next__() method. Functions may therefore consume all of the iterator’s output, and if you need to do something different with the same stream, you’ll have to create a new iterator.

Data Types That Support Iterators
We’ve already seen how lists and tuples support iterators. In fact, any Python sequence type, such as strings, will automatically support creation of an iterator.

Calling iter() on a dictionary returns an iterator that will loop over the dictionary’s keys:

>>>
>>> m = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,
...      'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}
>>> for key in m:
...     print(key, m[key])
Jan 1
Feb 2
Mar 3
Apr 4
May 5
Jun 6
Jul 7
Aug 8
Sep 9
Oct 10
Nov 11
Dec 12
Note that starting with Python 3.7, dictionary iteration order is guaranteed to be the same as the insertion order. In earlier versions, the behaviour was unspecified and could vary between implementations.

Applying iter() to a dictionary always loops over the keys, but dictionaries have methods that return other iterators. If you want to iterate over values or key/value pairs, you can explicitly call the values() or items() methods to get an appropriate iterator.

The dict() constructor can accept an iterator that returns a finite stream of (key, value) tuples:

>>>
L = [('Italy', 'Rome'), ('France', 'Paris'), ('US', 'Washington DC')]
dict(iter(L))
{'Italy': 'Rome', 'France': 'Paris', 'US': 'Washington DC'}
Files also support iteration by calling the readline() method until there are no more lines in the file. This means you can read each line of a file like this:

for line in file:
    # do something for each line
    ...
Sets can take their contents from an iterable and let you iterate over the set’s elements:

>>>
>>> S = {2, 3, 5, 7, 11, 13}
>>> for i in S:
...     print(i)
2
3
5
7
11
13
Generator expressions and list comprehensions
Two common operations on an iterator’s output are 1) performing some operation for every element, 2) selecting a subset of elements that meet some condition. For example, given a list of strings, you might want to strip off trailing whitespace from each line or extract all the strings containing a given substring.

List comprehensions and generator expressions (short form: “listcomps” and “genexps”) are a concise notation for such operations, borrowed from the functional programming language Haskell (https://www.haskell.org/). You can strip all the whitespace from a stream of strings with the following code:

>>>
>>> line_list = ['  line 1\n', 'line 2  \n', ' \n', '']

>>> # Generator expression -- returns iterator
>>> stripped_iter = (line.strip() for line in line_list)

>>> # List comprehension -- returns list
>>> stripped_list = [line.strip() for line in line_list]
You can select only certain elements by adding an "if" condition:

>>>
>>> stripped_list = [line.strip() for line in line_list
...                  if line != ""]
With a list comprehension, you get back a Python list; stripped_list is a list containing the resulting lines, not an iterator. Generator expressions return an iterator that computes the values as necessary, not needing to materialize all the values at once. This means that list comprehensions aren’t useful if you’re working with iterators that return an infinite stream or a very large amount of data. Generator expressions are preferable in these situations.

Generator expressions are surrounded by parentheses (“()”) and list comprehensions are surrounded by square brackets (“[]”). Generator expressions have the form:

( expression for expr in sequence1
             if condition1
             for expr2 in sequence2
             if condition2
             for expr3 in sequence3
             ...
             if condition3
             for exprN in sequenceN
             if conditionN )
Again, for a list comprehension only the outside brackets are different (square brackets instead of parentheses).

The elements of the generated output will be the successive values of expression. The if clauses are all optional; if present, expression is only evaluated and added to the result when condition is true.

Generator expressions always have to be written inside parentheses, but the parentheses signalling a function call also count. If you want to create an iterator that will be immediately passed to a function you can write:

obj_total = sum(obj.count for obj in list_all_objects())
The for...in clauses contain the sequences to be iterated over. The sequences do not have to be the same length, because they are iterated over from left to right, not in parallel. For each element in sequence1, sequence2 is looped over from the beginning. sequence3 is then looped over for each resulting pair of elements from sequence1 and sequence2.

To put it another way, a list comprehension or generator expression is equivalent to the following Python code:

for expr1 in sequence1:
    if not (condition1):
        continue   # Skip this element
    for expr2 in sequence2:
        if not (condition2):
            continue   # Skip this element
        ...
        for exprN in sequenceN:
            if not (conditionN):
                continue   # Skip this element

            # Output the value of
            # the expression.
This means that when there are multiple for...in clauses but no if clauses, the length of the resulting output will be equal to the product of the lengths of all the sequences. If you have two lists of length 3, the output list is 9 elements long:

>>>
seq1 = 'abc'
seq2 = (1, 2, 3)
[(x, y) for x in seq1 for y in seq2]  
[('a', 1), ('a', 2), ('a', 3),
 ('b', 1), ('b', 2), ('b', 3),
 ('c', 1), ('c', 2), ('c', 3)]
To avoid introducing an ambiguity into Python’s grammar, if expression is creating a tuple, it must be surrounded with parentheses. The first list comprehension below is a syntax error, while the second one is correct:

# Syntax error
[x, y for x in seq1 for y in seq2]
# Correct
[(x, y) for x in seq1 for y in seq2]
Generators
Generators are a special class of functions that simplify the task of writing iterators. Regular functions compute a value and return it, but generators return an iterator that returns a stream of values.

You’re doubtless familiar with how regular function calls work in Python or C. When you call a function, it gets a private namespace where its local variables are created. When the function reaches a return statement, the local variables are destroyed and the value is returned to the caller. A later call to the same function creates a new private namespace and a fresh set of local variables. But, what if the local variables weren’t thrown away on exiting a function? What if you could later resume the function where it left off? This is what generators provide; they can be thought of as resumable functions.

Here’s the simplest example of a generator function:

>>>
def generate_ints(N):
   for i in range(N):
       yield i
Any function containing a yield keyword is a generator function; this is detected by Python’s bytecode compiler which compiles the function specially as a result.

When you call a generator function, it doesn’t return a single value; instead it returns a generator object that supports the iterator protocol. On executing the yield expression, the generator outputs the value of i, similar to a return statement. The big difference between yield and a return statement is that on reaching a yield the generator’s state of execution is suspended and local variables are preserved. On the next call to the generator’s __next__() method, the function will resume executing.

Here’s a sample usage of the generate_ints() generator:

>>>
gen = generate_ints(3)
gen  
<generator object generate_ints at ...>
next(gen)
0
next(gen)
1
next(gen)
2
next(gen)
Traceback (most recent call last):
  File "stdin", line 1, in <module>
  File "stdin", line 2, in generate_ints
StopIteration
You could equally write for i in generate_ints(5), or a, b, c = generate_ints(3).

Inside a generator function, return value causes StopIteration(value) to be raised from the __next__() method. Once this happens, or the bottom of the function is reached, the procession of values ends and the generator cannot yield any further values.

You could achieve the effect of generators manually by writing your own class and storing all the local variables of the generator as instance variables. For example, returning a list of integers could be done by setting self.count to 0, and having the __next__() method increment self.count and return it. However, for a moderately complicated generator, writing a corresponding class can be much messier.

The test suite included with Python’s library, Lib/test/test_generators.py, contains a number of more interesting examples. Here’s one generator that implements an in-order traversal of a tree using generators recursively.

# A recursive generator that generates Tree leaves in in-order.
def inorder(t):
    if t:
        for x in inorder(t.left):
            yield x

        yield t.label

        for x in inorder(t.right):
            yield x
Two other examples in test_generators.py produce solutions for the N-Queens problem (placing N queens on an NxN chess board so that no queen threatens another) and the Knight’s Tour (finding a route that takes a knight to every square of an NxN chessboard without visiting any square twice).

Passing values into a generator
In Python 2.4 and earlier, generators only produced output. Once a generator’s code was invoked to create an iterator, there was no way to pass any new information into the function when its execution is resumed. You could hack together this ability by making the generator look at a global variable or by passing in some mutable object that callers then modify, but these approaches are messy.

In Python 2.5 there’s a simple way to pass values into a generator. yield became an expression, returning a value that can be assigned to a variable or otherwise operated on:

val = (yield i)
I recommend that you always put parentheses around a yield expression when you’re doing something with the returned value, as in the above example. The parentheses aren’t always necessary, but it’s easier to always add them instead of having to remember when they’re needed.

(PEP 342 explains the exact rules, which are that a yield-expression must always be parenthesized except when it occurs at the top-level expression on the right-hand side of an assignment. This means you can write val = yield i but have to use parentheses when there’s an operation, as in val = (yield i) + 12.)

Values are sent into a generator by calling its send(value) method. This method resumes the generator’s code and the yield expression returns the specified value. If the regular __next__() method is called, the yield returns None.

Here’s a simple counter that increments by 1 and allows changing the value of the internal counter.

def counter(maximum):
    i = 0
    while i < maximum:
        val = (yield i)
        # If value provided, change counter
        if val is not None:
            i = val
        else:
            i += 1
And here’s an example of changing the counter:

>>>
it = counter(10)  
next(it)  
0
next(it)  
1
it.send(8)  
8
next(it)  
9
next(it)  
Traceback (most recent call last):
  File "t.py", line 15, in <module>
    it.next()
StopIteration
Because yield will often be returning None, you should always check for this case. Don’t just use its value in expressions unless you’re sure that the send() method will be the only method used to resume your generator function.

In addition to send(), there are two other methods on generators:

throw(value) is used to raise an exception inside the generator; the exception is raised by the yield expression where the generator’s execution is paused.

close() raises a GeneratorExit exception inside the generator to terminate the iteration. On receiving this exception, the generator’s code must either raise GeneratorExit or StopIteration; catching the exception and doing anything else is illegal and will trigger a RuntimeError. close() will also be called by Python’s garbage collector when the generator is garbage-collected.

If you need to run cleanup code when a GeneratorExit occurs, I suggest using a try: ... finally: suite instead of catching GeneratorExit.

The cumulative effect of these changes is to turn generators from one-way producers of information into both producers and consumers.

Generators also become coroutines, a more generalized form of subroutines. Subroutines are entered at one point and exited at another point (the top of the function, and a return statement), but coroutines can be entered, exited, and resumed at many different points (the yield statements).

Built-in functions
Let’s look in more detail at built-in functions often used with iterators.

Two of Python’s built-in functions, map() and filter() duplicate the features of generator expressions:

map(f, iterA, iterB, ...) returns an iterator over the sequence
f(iterA[0], iterB[0]), f(iterA[1], iterB[1]), f(iterA[2], iterB[2]), ....

>>>
def upper(s):
    return s.upper()
>>>
list(map(upper, ['sentence', 'fragment']))
['SENTENCE', 'FRAGMENT']
[upper(s) for s in ['sentence', 'fragment']]
['SENTENCE', 'FRAGMENT']
You can of course achieve the same effect with a list comprehension.

filter(predicate, iter) returns an iterator over all the sequence elements that meet a certain condition, and is similarly duplicated by list comprehensions. A predicate is a function that returns the truth value of some condition; for use with filter(), the predicate must take a single value.

>>>
def is_even(x):
    return (x % 2) == 0
>>>
list(filter(is_even, range(10)))
[0, 2, 4, 6, 8]
This can also be written as a list comprehension:

>>>
list(x for x in range(10) if is_even(x))
[0, 2, 4, 6, 8]
enumerate(iter, start=0) counts off the elements in the iterable returning 2-tuples containing the count (from start) and each element.

>>>
>>> for item in enumerate(['subject', 'verb', 'object']):
...     print(item)
(0, 'subject')
(1, 'verb')
(2, 'object')
enumerate() is often used when looping through a list and recording the indexes at which certain conditions are met:

f = open('data.txt', 'r')
for i, line in enumerate(f):
    if line.strip() == '':
        print('Blank line at line #%i' % i)
sorted(iterable, key=None, reverse=False) collects all the elements of the iterable into a list, sorts the list, and returns the sorted result. The key and reverse arguments are passed through to the constructed list’s sort() method.

>>>
>>> import random
>>> # Generate 8 random numbers between [0, 10000)
>>> rand_list = random.sample(range(10000), 8)
>>> rand_list  
[769, 7953, 9828, 6431, 8442, 9878, 6213, 2207]
>>> sorted(rand_list)  
[769, 2207, 6213, 6431, 7953, 8442, 9828, 9878]
>>> sorted(rand_list, reverse=True)  
[9878, 9828, 8442, 7953, 6431, 6213, 2207, 769]
(For a more detailed discussion of sorting, see the Sorting HOW TO.)

The any(iter) and all(iter) built-ins look at the truth values of an iterable’s contents. any() returns True if any element in the iterable is a true value, and all() returns True if all of the elements are true values:

>>>
any([0, 1, 0])
True
any([0, 0, 0])
False
any([1, 1, 1])
True
all([0, 1, 0])
False
all([0, 0, 0])
False
all([1, 1, 1])
True
zip(iterA, iterB, ...) takes one element from each iterable and returns them in a tuple:

zip(['a', 'b', 'c'], (1, 2, 3)) =>
  ('a', 1), ('b', 2), ('c', 3)
It doesn’t construct an in-memory list and exhaust all the input iterators before returning; instead tuples are constructed and returned only if they’re requested. (The technical term for this behaviour is lazy evaluation.)

This iterator is intended to be used with iterables that are all of the same length. If the iterables are of different lengths, the resulting stream will be the same length as the shortest iterable.

zip(['a', 'b'], (1, 2, 3)) =>
  ('a', 1), ('b', 2)
You should avoid doing this, though, because an element may be taken from the longer iterators and discarded. This means you can’t go on to use the iterators further because you risk skipping a discarded element.

The itertools module
The itertools module contains a number of commonly used iterators as well as functions for combining several iterators. This section will introduce the module’s contents by showing small examples.

The module’s functions fall into a few broad classes:

Functions that create a new iterator based on an existing iterator.

Functions for treating an iterator’s elements as function arguments.

Functions for selecting portions of an iterator’s output.

A function for grouping an iterator’s output.

Creating new iterators
itertools.count(start, step) returns an infinite stream of evenly spaced values. You can optionally supply the starting number, which defaults to 0, and the interval between numbers, which defaults to 1:

itertools.count() =>
  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...
itertools.count(10) =>
  10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...
itertools.count(10, 5) =>
  10, 15, 20, 25, 30, 35, 40, 45, 50, 55, ...
itertools.cycle(iter) saves a copy of the contents of a provided iterable and returns a new iterator that returns its elements from first to last. The new iterator will repeat these elements infinitely.

itertools.cycle([1, 2, 3, 4, 5]) =>
  1, 2, 3, 4, 5, 1, 2, 3, 4, 5, ...
itertools.repeat(elem, [n]) returns the provided element n times, or returns the element endlessly if n is not provided.

itertools.repeat('abc') =>
  abc, abc, abc, abc, abc, abc, abc, abc, abc, abc, ...
itertools.repeat('abc', 5) =>
  abc, abc, abc, abc, abc
itertools.chain(iterA, iterB, ...) takes an arbitrary number of iterables as input, and returns all the elements of the first iterator, then all the elements of the second, and so on, until all of the iterables have been exhausted.

itertools.chain(['a', 'b', 'c'], (1, 2, 3)) =>
  a, b, c, 1, 2, 3
itertools.islice(iter, [start], stop, [step]) returns a stream that’s a slice of the iterator. With a single stop argument, it will return the first stop elements. If you supply a starting index, you’ll get stop-start elements, and if you supply a value for step, elements will be skipped accordingly. Unlike Python’s string and list slicing, you can’t use negative values for start, stop, or step.

itertools.islice(range(10), 8) =>
  0, 1, 2, 3, 4, 5, 6, 7
itertools.islice(range(10), 2, 8) =>
  2, 3, 4, 5, 6, 7
itertools.islice(range(10), 2, 8, 2) =>
  2, 4, 6
itertools.tee(iter, [n]) replicates an iterator; it returns n independent iterators that will all return the contents of the source iterator. If you don’t supply a value for n, the default is 2. Replicating iterators requires saving some of the contents of the source iterator, so this can consume significant memory if the iterator is large and one of the new iterators is consumed more than the others.

itertools.tee( itertools.count() ) =>
   iterA, iterB

where iterA ->
   0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...

and   iterB ->
   0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...
Calling functions on elements
The operator module contains a set of functions corresponding to Python’s operators. Some examples are operator.add(a, b) (adds two values), operator.ne(a, b) (same as a != b), and operator.attrgetter('id') (returns a callable that fetches the .id attribute).

itertools.starmap(func, iter) assumes that the iterable will return a stream of tuples, and calls func using these tuples as the arguments:

itertools.starmap(os.path.join,
                  [('/bin', 'python'), ('/usr', 'bin', 'java'),
                   ('/usr', 'bin', 'perl'), ('/usr', 'bin', 'ruby')])
=>
  /bin/python, /usr/bin/java, /usr/bin/perl, /usr/bin/ruby
Selecting elements
Another group of functions chooses a subset of an iterator’s elements based on a predicate.

itertools.filterfalse(predicate, iter) is the opposite of filter(), returning all elements for which the predicate returns false:

itertools.filterfalse(is_even, itertools.count()) =>
  1, 3, 5, 7, 9, 11, 13, 15, ...
itertools.takewhile(predicate, iter) returns elements for as long as the predicate returns true. Once the predicate returns false, the iterator will signal the end of its results.

def less_than_10(x):
    return x < 10

itertools.takewhile(less_than_10, itertools.count()) =>
  0, 1, 2, 3, 4, 5, 6, 7, 8, 9

itertools.takewhile(is_even, itertools.count()) =>
  0
itertools.dropwhile(predicate, iter) discards elements while the predicate returns true, and then returns the rest of the iterable’s results.

itertools.dropwhile(less_than_10, itertools.count()) =>
  10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...

itertools.dropwhile(is_even, itertools.count()) =>
  1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...
itertools.compress(data, selectors) takes two iterators and returns only those elements of data for which the corresponding element of selectors is true, stopping whenever either one is exhausted:

itertools.compress([1, 2, 3, 4, 5], [True, True, False, False, True]) =>
   1, 2, 5
Combinatoric functions
The itertools.combinations(iterable, r) returns an iterator giving all possible r-tuple combinations of the elements contained in iterable.

itertools.combinations([1, 2, 3, 4, 5], 2) =>
  (1, 2), (1, 3), (1, 4), (1, 5),
  (2, 3), (2, 4), (2, 5),
  (3, 4), (3, 5),
  (4, 5)

itertools.combinations([1, 2, 3, 4, 5], 3) =>
  (1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5),
  (2, 3, 4), (2, 3, 5), (2, 4, 5),
  (3, 4, 5)
The elements within each tuple remain in the same order as iterable returned them. For example, the number 1 is always before 2, 3, 4, or 5 in the examples above. A similar function, itertools.permutations(iterable, r=None), removes this constraint on the order, returning all possible arrangements of length r:

itertools.permutations([1, 2, 3, 4, 5], 2) =>
  (1, 2), (1, 3), (1, 4), (1, 5),
  (2, 1), (2, 3), (2, 4), (2, 5),
  (3, 1), (3, 2), (3, 4), (3, 5),
  (4, 1), (4, 2), (4, 3), (4, 5),
  (5, 1), (5, 2), (5, 3), (5, 4)

itertools.permutations([1, 2, 3, 4, 5]) =>
  (1, 2, 3, 4, 5), (1, 2, 3, 5, 4), (1, 2, 4, 3, 5),
  ...
  (5, 4, 3, 2, 1)
If you don’t supply a value for r the length of the iterable is used, meaning that all the elements are permuted.

Note that these functions produce all of the possible combinations by position and don’t require that the contents of iterable are unique:

itertools.permutations('aba', 3) =>
  ('a', 'b', 'a'), ('a', 'a', 'b'), ('b', 'a', 'a'),
  ('b', 'a', 'a'), ('a', 'a', 'b'), ('a', 'b', 'a')
The identical tuple ('a', 'a', 'b') occurs twice, but the two ‘a’ strings came from different positions.

The itertools.combinations_with_replacement(iterable, r) function relaxes a different constraint: elements can be repeated within a single tuple. Conceptually an element is selected for the first position of each tuple and then is replaced before the second element is selected.

itertools.combinations_with_replacement([1, 2, 3, 4, 5], 2) =>
  (1, 1), (1, 2), (1, 3), (1, 4), (1, 5),
  (2, 2), (2, 3), (2, 4), (2, 5),
  (3, 3), (3, 4), (3, 5),
  (4, 4), (4, 5),
  (5, 5)
Grouping elements
The last function I’ll discuss, itertools.groupby(iter, key_func=None), is the most complicated. key_func(elem) is a function that can compute a key value for each element returned by the iterable. If you don’t supply a key function, the key is simply each element itself.

groupby() collects all the consecutive elements from the underlying iterable that have the same key value, and returns a stream of 2-tuples containing a key value and an iterator for the elements with that key.

city_list = [('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL'),
             ('Anchorage', 'AK'), ('Nome', 'AK'),
             ('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ'),
             ...
            ]

def get_state(city_state):
    return city_state[1]

itertools.groupby(city_list, get_state) =>
  ('AL', iterator-1),
  ('AK', iterator-2),
  ('AZ', iterator-3), ...

where
iterator-1 =>
  ('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL')
iterator-2 =>
  ('Anchorage', 'AK'), ('Nome', 'AK')
iterator-3 =>
  ('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ')
groupby() assumes that the underlying iterable’s contents will already be sorted based on the key. Note that the returned iterators also use the underlying iterable, so you have to consume the results of iterator-1 before requesting iterator-2 and its corresponding key.

The functools module
The functools module in Python 2.5 contains some higher-order functions. A higher-order function takes one or more functions as input and returns a new function. The most useful tool in this module is the functools.partial() function.

For programs written in a functional style, you’ll sometimes want to construct variants of existing functions that have some of the parameters filled in. Consider a Python function f(a, b, c); you may wish to create a new function g(b, c) that’s equivalent to f(1, b, c); you’re filling in a value for one of f()’s parameters. This is called “partial function application”.

The constructor for partial() takes the arguments (function, arg1, arg2, ..., kwarg1=value1, kwarg2=value2). The resulting object is callable, so you can just call it to invoke function with the filled-in arguments.

Here’s a small but realistic example:

import functools

def log(message, subsystem):
    """Write the contents of 'message' to the specified subsystem."""
    print('%s: %s' % (subsystem, message))
    ...

server_log = functools.partial(log, subsystem='server')
server_log('Unable to open socket')
functools.reduce(func, iter, [initial_value]) cumulatively performs an operation on all the iterable’s elements and, therefore, can’t be applied to infinite iterables. func must be a function that takes two elements and returns a single value. functools.reduce() takes the first two elements A and B returned by the iterator and calculates func(A, B). It then requests the third element, C, calculates func(func(A, B), C), combines this result with the fourth element returned, and continues until the iterable is exhausted. If the iterable returns no values at all, a TypeError exception is raised. If the initial value is supplied, it’s used as a starting point and func(initial_value, A) is the first calculation.

>>>
>>> import operator, functools
>>> functools.reduce(operator.concat, ['A', 'BB', 'C'])
'ABBC'
>>> functools.reduce(operator.concat, [])
Traceback (most recent call last):
  ...
TypeError: reduce() of empty sequence with no initial value
>>> functools.reduce(operator.mul, [1, 2, 3], 1)
6
>>> functools.reduce(operator.mul, [], 1)
1
If you use operator.add() with functools.reduce(), you’ll add up all the elements of the iterable. This case is so common that there’s a special built-in called sum() to compute it:

>>>
import functools, operator
functools.reduce(operator.add, [1, 2, 3, 4], 0)
10
sum([1, 2, 3, 4])
10
sum([])
0
For many uses of functools.reduce(), though, it can be clearer to just write the obvious for loop:

import functools
# Instead of:
product = functools.reduce(operator.mul, [1, 2, 3], 1)

# You can write:
product = 1
for i in [1, 2, 3]:
    product *= i
A related function is itertools.accumulate(iterable, func=operator.add). It performs the same calculation, but instead of returning only the final result, accumulate() returns an iterator that also yields each partial result:

itertools.accumulate([1, 2, 3, 4, 5]) =>
  1, 3, 6, 10, 15

itertools.accumulate([1, 2, 3, 4, 5], operator.mul) =>
  1, 2, 6, 24, 120
The operator module
The operator module was mentioned earlier. It contains a set of functions corresponding to Python’s operators. These functions are often useful in functional-style code because they save you from writing trivial functions that perform a single operation.

Some of the functions in this module are:

Math operations: add(), sub(), mul(), floordiv(), abs(), …

Logical operations: not_(), truth().

Bitwise operations: and_(), or_(), invert().

Comparisons: eq(), ne(), lt(), le(), gt(), and ge().

Object identity: is_(), is_not().

Consult the operator module’s documentation for a complete list.

Small functions and the lambda expression
When writing functional-style programs, you’ll often need little functions that act as predicates or that combine elements in some way.

If there’s a Python built-in or a module function that’s suitable, you don’t need to define a new function at all:

stripped_lines = [line.strip() for line in lines]
existing_files = filter(os.path.exists, file_list)
If the function you need doesn’t exist, you need to write it. One way to write small functions is to use the lambda expression. lambda takes a number of parameters and an expression combining these parameters, and creates an anonymous function that returns the value of the expression:

adder = lambda x, y: x+y

print_assign = lambda name, value: name + '=' + str(value)
An alternative is to just use the def statement and define a function in the usual way:

def adder(x, y):
    return x + y

def print_assign(name, value):
    return name + '=' + str(value)
Which alternative is preferable? That’s a style question; my usual course is to avoid using lambda.

One reason for my preference is that lambda is quite limited in the functions it can define. The result has to be computable as a single expression, which means you can’t have multiway if... elif... else comparisons or try... except statements. If you try to do too much in a lambda statement, you’ll end up with an overly complicated expression that’s hard to read. Quick, what’s the following code doing?

import functools
total = functools.reduce(lambda a, b: (0, a[1] + b[1]), items)[1]
You can figure it out, but it takes time to disentangle the expression to figure out what’s going on. Using a short nested def statements makes things a little bit better:

import functools
def combine(a, b):
    return 0, a[1] + b[1]

total = functools.reduce(combine, items)[1]
But it would be best of all if I had simply used a for loop:

total = 0
for a, b in items:
    total += b
Or the sum() built-in and a generator expression:

total = sum(b for a, b in items)
Many uses of functools.reduce() are clearer when written as for loops.

Fredrik Lundh once suggested the following set of rules for refactoring uses of lambda:

Write a lambda function.

Write a comment explaining what the heck that lambda does.

Study the comment for a while, and think of a name that captures the essence of the comment.

Convert the lambda to a def statement, using that name.

Remove the comment.

I really like these rules, but you’re free to disagree about whether this lambda-free style is better.

Revision History and Acknowledgements
The author would like to thank the following people for offering suggestions, corrections and assistance with various drafts of this article: Ian Bicking, Nick Coghlan, Nick Efford, Raymond Hettinger, Jim Jewett, Mike Krell, Leandro Lameiro, Jussi Salmela, Collin Winter, Blake Winton.

Version 0.1: posted June 30 2006.

Version 0.11: posted July 1 2006. Typo fixes.

Version 0.2: posted July 10 2006. Merged genexp and listcomp sections into one. Typo fixes.

Version 0.21: Added more references suggested on the tutor mailing list.

Version 0.30: Adds a section on the functional module written by Collin Winter; adds short section on the operator module; a few other edits.

References
General
Structure and Interpretation of Computer Programs, by Harold Abelson and Gerald Jay Sussman with Julie Sussman. Full text at https://mitpress.mit.edu/sicp/. In this classic textbook of computer science, chapters 2 and 3 discuss the use of sequences and streams to organize the data flow inside a program. The book uses Scheme for its examples, but many of the design approaches described in these chapters are applicable to functional-style Python code.

https://www.defmacro.org/ramblings/fp.html: A general introduction to functional programming that uses Java examples and has a lengthy historical introduction.

https://en.wikipedia.org/wiki/Functional_programming: General Wikipedia entry describing functional programming.

https://en.wikipedia.org/wiki/Coroutine: Entry for coroutines.

https://en.wikipedia.org/wiki/Currying: Entry for the concept of currying.

Python-specific
https://gnosis.cx/TPiP/: The first chapter of David Mertz’s book Text Processing in Python discusses functional programming for text processing, in the section titled “Utilizing Higher-Order Functions in Text Processing”.

Mertz also wrote a 3-part series of articles on functional programming for IBM’s DeveloperWorks site; see part 1, part 2, and part 3,

Python documentation
Documentation for the itertools module.

Documentation for the functools module.

Documentation for the operator module.

PEP 289: “Generator Expressions”

PEP 342: “Coroutines via Enhanced Generators” describes the new generator features in Python 2.5.

Table of Contents
Functional Programming HOWTO
Introduction
Formal provability
Modularity
Ease of debugging and testing
Composability
Iterators
Data Types That Support Iterators
Generator expressions and list comprehensions
Generators
Passing values into a generator
Built-in functions
The itertools module
Creating new iterators
Calling functions on elements
Selecting elements
Combinatoric functions
Grouping elements
The functools module
The operator module
Small functions and the lambda expression
Revision History and Acknowledgements
References
General
Python-specific
Python documentation
Previous topic
Descriptor HowTo Guide

Next topic
Logging HOWTO

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Functional Programming HOWTO
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Logging HOWTO
Quick search
  |
Logging HOWTO
Author
Vinay Sajip <vinay_sajip at red-dove dot com>

Basic Logging Tutorial
Logging is a means of tracking events that happen when some software runs. The software’s developer adds logging calls to their code to indicate that certain events have occurred. An event is described by a descriptive message which can optionally contain variable data (i.e. data that is potentially different for each occurrence of the event). Events also have an importance which the developer ascribes to the event; the importance can also be called the level or severity.

When to use logging
Logging provides a set of convenience functions for simple logging usage. These are debug(), info(), warning(), error() and critical(). To determine when to use logging, see the table below, which states, for each of a set of common tasks, the best tool to use for it.

Task you want to perform

The best tool for the task

Display console output for ordinary usage of a command line script or program

print()

Report events that occur during normal operation of a program (e.g. for status monitoring or fault investigation)

logging.info() (or logging.debug() for very detailed output for diagnostic purposes)

Issue a warning regarding a particular runtime event

warnings.warn() in library code if the issue is avoidable and the client application should be modified to eliminate the warning

logging.warning() if there is nothing the client application can do about the situation, but the event should still be noted

Report an error regarding a particular runtime event

Raise an exception

Report suppression of an error without raising an exception (e.g. error handler in a long-running server process)

logging.error(), logging.exception() or logging.critical() as appropriate for the specific error and application domain

The logging functions are named after the level or severity of the events they are used to track. The standard levels and their applicability are described below (in increasing order of severity):

Level

When it’s used

DEBUG

Detailed information, typically of interest only when diagnosing problems.

INFO

Confirmation that things are working as expected.

WARNING

An indication that something unexpected happened, or indicative of some problem in the near future (e.g. ‘disk space low’). The software is still working as expected.

ERROR

Due to a more serious problem, the software has not been able to perform some function.

CRITICAL

A serious error, indicating that the program itself may be unable to continue running.

The default level is WARNING, which means that only events of this level and above will be tracked, unless the logging package is configured to do otherwise.

Events that are tracked can be handled in different ways. The simplest way of handling tracked events is to print them to the console. Another common way is to write them to a disk file.

A simple example
A very simple example is:

import logging
logging.warning('Watch out!')  # will print a message to the console
logging.info('I told you so')  # will not print anything
If you type these lines into a script and run it, you’ll see:

WARNING:root:Watch out!
printed out on the console. The INFO message doesn’t appear because the default level is WARNING. The printed message includes the indication of the level and the description of the event provided in the logging call, i.e. ‘Watch out!’. Don’t worry about the ‘root’ part for now: it will be explained later. The actual output can be formatted quite flexibly if you need that; formatting options will also be explained later.

Logging to a file
A very common situation is that of recording logging events in a file, so let’s look at that next. Be sure to try the following in a newly started Python interpreter, and don’t just continue from the session described above:

import logging
logging.basicConfig(filename='example.log', encoding='utf-8', level=logging.DEBUG)
logging.debug('This message should go to the log file')
logging.info('So should this')
logging.warning('And this, too')
logging.error('And non-ASCII stuff, too, like Øresund and Malmö')
Changed in version 3.9: The encoding argument was added. In earlier Python versions, or if not specified, the encoding used is the default value used by open(). While not shown in the above example, an errors argument can also now be passed, which determines how encoding errors are handled. For available values and the default, see the documentation for open().

And now if we open the file and look at what we have, we should find the log messages:

DEBUG:root:This message should go to the log file
INFO:root:So should this
WARNING:root:And this, too
ERROR:root:And non-ASCII stuff, too, like Øresund and Malmö
This example also shows how you can set the logging level which acts as the threshold for tracking. In this case, because we set the threshold to DEBUG, all of the messages were printed.

If you want to set the logging level from a command-line option such as:

--log=INFO
and you have the value of the parameter passed for --log in some variable loglevel, you can use:

getattr(logging, loglevel.upper())
to get the value which you’ll pass to basicConfig() via the level argument. You may want to error check any user input value, perhaps as in the following example:

# assuming loglevel is bound to the string value obtained from the
# command line argument. Convert to upper case to allow the user to
# specify --log=DEBUG or --log=debug
numeric_level = getattr(logging, loglevel.upper(), None)
if not isinstance(numeric_level, int):
    raise ValueError('Invalid log level: %s' % loglevel)
logging.basicConfig(level=numeric_level, ...)
The call to basicConfig() should come before any calls to debug(), info(), etc. Otherwise, those functions will call basicConfig() for you with the default options. As it’s intended as a one-off simple configuration facility, only the first call will actually do anything: subsequent calls are effectively no-ops.

If you run the above script several times, the messages from successive runs are appended to the file example.log. If you want each run to start afresh, not remembering the messages from earlier runs, you can specify the filemode argument, by changing the call in the above example to:

logging.basicConfig(filename='example.log', filemode='w', level=logging.DEBUG)
The output will be the same as before, but the log file is no longer appended to, so the messages from earlier runs are lost.

Logging from multiple modules
If your program consists of multiple modules, here’s an example of how you could organize logging in it:

# myapp.py
import logging
import mylib

def main():
    logging.basicConfig(filename='myapp.log', level=logging.INFO)
    logging.info('Started')
    mylib.do_something()
    logging.info('Finished')

if __name__ == '__main__':
    main()
# mylib.py
import logging

def do_something():
    logging.info('Doing something')
If you run myapp.py, you should see this in myapp.log:

INFO:root:Started
INFO:root:Doing something
INFO:root:Finished
which is hopefully what you were expecting to see. You can generalize this to multiple modules, using the pattern in mylib.py. Note that for this simple usage pattern, you won’t know, by looking in the log file, where in your application your messages came from, apart from looking at the event description. If you want to track the location of your messages, you’ll need to refer to the documentation beyond the tutorial level – see Advanced Logging Tutorial.

Logging variable data
To log variable data, use a format string for the event description message and append the variable data as arguments. For example:

import logging
logging.warning('%s before you %s', 'Look', 'leap!')
will display:

WARNING:root:Look before you leap!
As you can see, merging of variable data into the event description message uses the old, %-style of string formatting. This is for backwards compatibility: the logging package pre-dates newer formatting options such as str.format() and string.Template. These newer formatting options are supported, but exploring them is outside the scope of this tutorial: see Using particular formatting styles throughout your application for more information.

Changing the format of displayed messages
To change the format which is used to display messages, you need to specify the format you want to use:

import logging
logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)
logging.debug('This message should appear on the console')
logging.info('So should this')
logging.warning('And this, too')
which would print:

DEBUG:This message should appear on the console
INFO:So should this
WARNING:And this, too
Notice that the ‘root’ which appeared in earlier examples has disappeared. For a full set of things that can appear in format strings, you can refer to the documentation for LogRecord attributes, but for simple usage, you just need the levelname (severity), message (event description, including variable data) and perhaps to display when the event occurred. This is described in the next section.

Displaying the date/time in messages
To display the date and time of an event, you would place ‘%(asctime)s’ in your format string:

import logging
logging.basicConfig(format='%(asctime)s %(message)s')
logging.warning('is when this event was logged.')
which should print something like this:

2010-12-12 11:41:42,612 is when this event was logged.
The default format for date/time display (shown above) is like ISO8601 or RFC 3339. If you need more control over the formatting of the date/time, provide a datefmt argument to basicConfig, as in this example:

import logging
logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')
logging.warning('is when this event was logged.')
which would display something like this:

12/12/2010 11:46:36 AM is when this event was logged.
The format of the datefmt argument is the same as supported by time.strftime().

Next Steps
That concludes the basic tutorial. It should be enough to get you up and running with logging. There’s a lot more that the logging package offers, but to get the best out of it, you’ll need to invest a little more of your time in reading the following sections. If you’re ready for that, grab some of your favourite beverage and carry on.

If your logging needs are simple, then use the above examples to incorporate logging into your own scripts, and if you run into problems or don’t understand something, please post a question on the comp.lang.python Usenet group (available at https://groups.google.com/forum/#!forum/comp.lang.python) and you should receive help before too long.

Still here? You can carry on reading the next few sections, which provide a slightly more advanced/in-depth tutorial than the basic one above. After that, you can take a look at the Logging Cookbook.

Advanced Logging Tutorial
The logging library takes a modular approach and offers several categories of components: loggers, handlers, filters, and formatters.

Loggers expose the interface that application code directly uses.

Handlers send the log records (created by loggers) to the appropriate destination.

Filters provide a finer grained facility for determining which log records to output.

Formatters specify the layout of log records in the final output.

Log event information is passed between loggers, handlers, filters and formatters in a LogRecord instance.

Logging is performed by calling methods on instances of the Logger class (hereafter called loggers). Each instance has a name, and they are conceptually arranged in a namespace hierarchy using dots (periods) as separators. For example, a logger named ‘scan’ is the parent of loggers ‘scan.text’, ‘scan.html’ and ‘scan.pdf’. Logger names can be anything you want, and indicate the area of an application in which a logged message originates.

A good convention to use when naming loggers is to use a module-level logger, in each module which uses logging, named as follows:

logger = logging.getLogger(__name__)
This means that logger names track the package/module hierarchy, and it’s intuitively obvious where events are logged just from the logger name.

The root of the hierarchy of loggers is called the root logger. That’s the logger used by the functions debug(), info(), warning(), error() and critical(), which just call the same-named method of the root logger. The functions and the methods have the same signatures. The root logger’s name is printed as ‘root’ in the logged output.

It is, of course, possible to log messages to different destinations. Support is included in the package for writing log messages to files, HTTP GET/POST locations, email via SMTP, generic sockets, queues, or OS-specific logging mechanisms such as syslog or the Windows NT event log. Destinations are served by handler classes. You can create your own log destination class if you have special requirements not met by any of the built-in handler classes.

By default, no destination is set for any logging messages. You can specify a destination (such as console or file) by using basicConfig() as in the tutorial examples. If you call the functions debug(), info(), warning(), error() and critical(), they will check to see if no destination is set; and if one is not set, they will set a destination of the console (sys.stderr) and a default format for the displayed message before delegating to the root logger to do the actual message output.

The default format set by basicConfig() for messages is:

severity:logger name:message
You can change this by passing a format string to basicConfig() with the format keyword argument. For all options regarding how a format string is constructed, see Formatter Objects.

Logging Flow
The flow of log event information in loggers and handlers is illustrated in the following diagram.

../_images/logging_flow.png
Loggers
Logger objects have a threefold job. First, they expose several methods to application code so that applications can log messages at runtime. Second, logger objects determine which log messages to act upon based upon severity (the default filtering facility) or filter objects. Third, logger objects pass along relevant log messages to all interested log handlers.

The most widely used methods on logger objects fall into two categories: configuration and message sending.

These are the most common configuration methods:

Logger.setLevel() specifies the lowest-severity log message a logger will handle, where debug is the lowest built-in severity level and critical is the highest built-in severity. For example, if the severity level is INFO, the logger will handle only INFO, WARNING, ERROR, and CRITICAL messages and will ignore DEBUG messages.

Logger.addHandler() and Logger.removeHandler() add and remove handler objects from the logger object. Handlers are covered in more detail in Handlers.

Logger.addFilter() and Logger.removeFilter() add and remove filter objects from the logger object. Filters are covered in more detail in Filter Objects.

You don’t need to always call these methods on every logger you create. See the last two paragraphs in this section.

With the logger object configured, the following methods create log messages:

Logger.debug(), Logger.info(), Logger.warning(), Logger.error(), and Logger.critical() all create log records with a message and a level that corresponds to their respective method names. The message is actually a format string, which may contain the standard string substitution syntax of %s, %d, %f, and so on. The rest of their arguments is a list of objects that correspond with the substitution fields in the message. With regard to **kwargs, the logging methods care only about a keyword of exc_info and use it to determine whether to log exception information.

Logger.exception() creates a log message similar to Logger.error(). The difference is that Logger.exception() dumps a stack trace along with it. Call this method only from an exception handler.

Logger.log() takes a log level as an explicit argument. This is a little more verbose for logging messages than using the log level convenience methods listed above, but this is how to log at custom log levels.

getLogger() returns a reference to a logger instance with the specified name if it is provided, or root if not. The names are period-separated hierarchical structures. Multiple calls to getLogger() with the same name will return a reference to the same logger object. Loggers that are further down in the hierarchical list are children of loggers higher up in the list. For example, given a logger with a name of foo, loggers with names of foo.bar, foo.bar.baz, and foo.bam are all descendants of foo.

Loggers have a concept of effective level. If a level is not explicitly set on a logger, the level of its parent is used instead as its effective level. If the parent has no explicit level set, its parent is examined, and so on - all ancestors are searched until an explicitly set level is found. The root logger always has an explicit level set (WARNING by default). When deciding whether to process an event, the effective level of the logger is used to determine whether the event is passed to the logger’s handlers.

Child loggers propagate messages up to the handlers associated with their ancestor loggers. Because of this, it is unnecessary to define and configure handlers for all the loggers an application uses. It is sufficient to configure handlers for a top-level logger and create child loggers as needed. (You can, however, turn off propagation by setting the propagate attribute of a logger to False.)

Handlers
Handler objects are responsible for dispatching the appropriate log messages (based on the log messages’ severity) to the handler’s specified destination. Logger objects can add zero or more handler objects to themselves with an addHandler() method. As an example scenario, an application may want to send all log messages to a log file, all log messages of error or higher to stdout, and all messages of critical to an email address. This scenario requires three individual handlers where each handler is responsible for sending messages of a specific severity to a specific location.

The standard library includes quite a few handler types (see Useful Handlers); the tutorials use mainly StreamHandler and FileHandler in its examples.

There are very few methods in a handler for application developers to concern themselves with. The only handler methods that seem relevant for application developers who are using the built-in handler objects (that is, not creating custom handlers) are the following configuration methods:

The setLevel() method, just as in logger objects, specifies the lowest severity that will be dispatched to the appropriate destination. Why are there two setLevel() methods? The level set in the logger determines which severity of messages it will pass to its handlers. The level set in each handler determines which messages that handler will send on.

setFormatter() selects a Formatter object for this handler to use.

addFilter() and removeFilter() respectively configure and deconfigure filter objects on handlers.

Application code should not directly instantiate and use instances of Handler. Instead, the Handler class is a base class that defines the interface that all handlers should have and establishes some default behavior that child classes can use (or override).

Formatters
Formatter objects configure the final order, structure, and contents of the log message. Unlike the base logging.Handler class, application code may instantiate formatter classes, although you could likely subclass the formatter if your application needs special behavior. The constructor takes three optional arguments – a message format string, a date format string and a style indicator.

logging.Formatter.__init__(fmt=None, datefmt=None, style='%')
If there is no message format string, the default is to use the raw message. If there is no date format string, the default date format is:

%Y-%m-%d %H:%M:%S
with the milliseconds tacked on at the end. The style is one of '%', '{', or '$'. If one of these is not specified, then '%' will be used.

If the style is '%', the message format string uses %(<dictionary key>)s styled string substitution; the possible keys are documented in LogRecord attributes. If the style is '{', the message format string is assumed to be compatible with str.format() (using keyword arguments), while if the style is '$' then the message format string should conform to what is expected by string.Template.substitute().

Changed in version 3.2: Added the style parameter.

The following message format string will log the time in a human-readable format, the severity of the message, and the contents of the message, in that order:

'%(asctime)s - %(levelname)s - %(message)s'
Formatters use a user-configurable function to convert the creation time of a record to a tuple. By default, time.localtime() is used; to change this for a particular formatter instance, set the converter attribute of the instance to a function with the same signature as time.localtime() or time.gmtime(). To change it for all formatters, for example if you want all logging times to be shown in GMT, set the converter attribute in the Formatter class (to time.gmtime for GMT display).

Configuring Logging
Programmers can configure logging in three ways:

Creating loggers, handlers, and formatters explicitly using Python code that calls the configuration methods listed above.

Creating a logging config file and reading it using the fileConfig() function.

Creating a dictionary of configuration information and passing it to the dictConfig() function.

For the reference documentation on the last two options, see Configuration functions. The following example configures a very simple logger, a console handler, and a simple formatter using Python code:

import logging

# create logger
logger = logging.getLogger('simple_example')
logger.setLevel(logging.DEBUG)

# create console handler and set level to debug
ch = logging.StreamHandler()
ch.setLevel(logging.DEBUG)

# create formatter
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# add formatter to ch
ch.setFormatter(formatter)

# add ch to logger
logger.addHandler(ch)

# 'application' code
logger.debug('debug message')
logger.info('info message')
logger.warning('warn message')
logger.error('error message')
logger.critical('critical message')
Running this module from the command line produces the following output:

$ python simple_logging_module.py
2005-03-19 15:10:26,618 - simple_example - DEBUG - debug message
2005-03-19 15:10:26,620 - simple_example - INFO - info message
2005-03-19 15:10:26,695 - simple_example - WARNING - warn message
2005-03-19 15:10:26,697 - simple_example - ERROR - error message
2005-03-19 15:10:26,773 - simple_example - CRITICAL - critical message
The following Python module creates a logger, handler, and formatter nearly identical to those in the example listed above, with the only difference being the names of the objects:

import logging
import logging.config

logging.config.fileConfig('logging.conf')

# create logger
logger = logging.getLogger('simpleExample')

# 'application' code
logger.debug('debug message')
logger.info('info message')
logger.warning('warn message')
logger.error('error message')
logger.critical('critical message')
Here is the logging.conf file:

[loggers]
keys=root,simpleExample

[handlers]
keys=consoleHandler

[formatters]
keys=simpleFormatter

[logger_root]
level=DEBUG
handlers=consoleHandler

[logger_simpleExample]
level=DEBUG
handlers=consoleHandler
qualname=simpleExample
propagate=0

[handler_consoleHandler]
class=StreamHandler
level=DEBUG
formatter=simpleFormatter
args=(sys.stdout,)

[formatter_simpleFormatter]
format=%(asctime)s - %(name)s - %(levelname)s - %(message)s
The output is nearly identical to that of the non-config-file-based example:

$ python simple_logging_config.py
2005-03-19 15:38:55,977 - simpleExample - DEBUG - debug message
2005-03-19 15:38:55,979 - simpleExample - INFO - info message
2005-03-19 15:38:56,054 - simpleExample - WARNING - warn message
2005-03-19 15:38:56,055 - simpleExample - ERROR - error message
2005-03-19 15:38:56,130 - simpleExample - CRITICAL - critical message
You can see that the config file approach has a few advantages over the Python code approach, mainly separation of configuration and code and the ability of noncoders to easily modify the logging properties.

Warning The fileConfig() function takes a default parameter, disable_existing_loggers, which defaults to True for reasons of backward compatibility. This may or may not be what you want, since it will cause any non-root loggers existing before the fileConfig() call to be disabled unless they (or an ancestor) are explicitly named in the configuration. Please refer to the reference documentation for more information, and specify False for this parameter if you wish.
The dictionary passed to dictConfig() can also specify a Boolean value with key disable_existing_loggers, which if not specified explicitly in the dictionary also defaults to being interpreted as True. This leads to the logger-disabling behaviour described above, which may not be what you want - in which case, provide the key explicitly with a value of False.

Note that the class names referenced in config files need to be either relative to the logging module, or absolute values which can be resolved using normal import mechanisms. Thus, you could use either WatchedFileHandler (relative to the logging module) or mypackage.mymodule.MyHandler (for a class defined in package mypackage and module mymodule, where mypackage is available on the Python import path).

In Python 3.2, a new means of configuring logging has been introduced, using dictionaries to hold configuration information. This provides a superset of the functionality of the config-file-based approach outlined above, and is the recommended configuration method for new applications and deployments. Because a Python dictionary is used to hold configuration information, and since you can populate that dictionary using different means, you have more options for configuration. For example, you can use a configuration file in JSON format, or, if you have access to YAML processing functionality, a file in YAML format, to populate the configuration dictionary. Or, of course, you can construct the dictionary in Python code, receive it in pickled form over a socket, or use whatever approach makes sense for your application.

Here’s an example of the same configuration as above, in YAML format for the new dictionary-based approach:

version: 1
formatters:
  simple:
    format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
handlers:
  console:
    class: logging.StreamHandler
    level: DEBUG
    formatter: simple
    stream: ext://sys.stdout
loggers:
  simpleExample:
    level: DEBUG
    handlers: [console]
    propagate: no
root:
  level: DEBUG
  handlers: [console]
For more information about logging using a dictionary, see Configuration functions.

What happens if no configuration is provided
If no logging configuration is provided, it is possible to have a situation where a logging event needs to be output, but no handlers can be found to output the event. The behaviour of the logging package in these circumstances is dependent on the Python version.

For versions of Python prior to 3.2, the behaviour is as follows:

If logging.raiseExceptions is False (production mode), the event is silently dropped.

If logging.raiseExceptions is True (development mode), a message ‘No handlers could be found for logger X.Y.Z’ is printed once.

In Python 3.2 and later, the behaviour is as follows:

The event is output using a ‘handler of last resort’, stored in logging.lastResort. This internal handler is not associated with any logger, and acts like a StreamHandler which writes the event description message to the current value of sys.stderr (therefore respecting any redirections which may be in effect). No formatting is done on the message - just the bare event description message is printed. The handler’s level is set to WARNING, so all events at this and greater severities will be output.

To obtain the pre-3.2 behaviour, logging.lastResort can be set to None.

Configuring Logging for a Library
When developing a library which uses logging, you should take care to document how the library uses logging - for example, the names of loggers used. Some consideration also needs to be given to its logging configuration. If the using application does not use logging, and library code makes logging calls, then (as described in the previous section) events of severity WARNING and greater will be printed to sys.stderr. This is regarded as the best default behaviour.

If for some reason you don’t want these messages printed in the absence of any logging configuration, you can attach a do-nothing handler to the top-level logger for your library. This avoids the message being printed, since a handler will always be found for the library’s events: it just doesn’t produce any output. If the library user configures logging for application use, presumably that configuration will add some handlers, and if levels are suitably configured then logging calls made in library code will send output to those handlers, as normal.

A do-nothing handler is included in the logging package: NullHandler (since Python 3.1). An instance of this handler could be added to the top-level logger of the logging namespace used by the library (if you want to prevent your library’s logged events being output to sys.stderr in the absence of logging configuration). If all logging by a library foo is done using loggers with names matching ‘foo.x’, ‘foo.x.y’, etc. then the code:

import logging
logging.getLogger('foo').addHandler(logging.NullHandler())
should have the desired effect. If an organisation produces a number of libraries, then the logger name specified can be ‘orgname.foo’ rather than just ‘foo’.

Note It is strongly advised that you do not add any handlers other than NullHandler to your library’s loggers. This is because the configuration of handlers is the prerogative of the application developer who uses your library. The application developer knows their target audience and what handlers are most appropriate for their application: if you add handlers ‘under the hood’, you might well interfere with their ability to carry out unit tests and deliver logs which suit their requirements.
Logging Levels
The numeric values of logging levels are given in the following table. These are primarily of interest if you want to define your own levels, and need them to have specific values relative to the predefined levels. If you define a level with the same numeric value, it overwrites the predefined value; the predefined name is lost.

Level

Numeric value

CRITICAL

50

ERROR

40

WARNING

30

INFO

20

DEBUG

10

NOTSET

0

Levels can also be associated with loggers, being set either by the developer or through loading a saved logging configuration. When a logging method is called on a logger, the logger compares its own level with the level associated with the method call. If the logger’s level is higher than the method call’s, no logging message is actually generated. This is the basic mechanism controlling the verbosity of logging output.

Logging messages are encoded as instances of the LogRecord class. When a logger decides to actually log an event, a LogRecord instance is created from the logging message.

Logging messages are subjected to a dispatch mechanism through the use of handlers, which are instances of subclasses of the Handler class. Handlers are responsible for ensuring that a logged message (in the form of a LogRecord) ends up in a particular location (or set of locations) which is useful for the target audience for that message (such as end users, support desk staff, system administrators, developers). Handlers are passed LogRecord instances intended for particular destinations. Each logger can have zero, one or more handlers associated with it (via the addHandler() method of Logger). In addition to any handlers directly associated with a logger, all handlers associated with all ancestors of the logger are called to dispatch the message (unless the propagate flag for a logger is set to a false value, at which point the passing to ancestor handlers stops).

Just as for loggers, handlers can have levels associated with them. A handler’s level acts as a filter in the same way as a logger’s level does. If a handler decides to actually dispatch an event, the emit() method is used to send the message to its destination. Most user-defined subclasses of Handler will need to override this emit().

Custom Levels
Defining your own levels is possible, but should not be necessary, as the existing levels have been chosen on the basis of practical experience. However, if you are convinced that you need custom levels, great care should be exercised when doing this, and it is possibly a very bad idea to define custom levels if you are developing a library. That’s because if multiple library authors all define their own custom levels, there is a chance that the logging output from such multiple libraries used together will be difficult for the using developer to control and/or interpret, because a given numeric value might mean different things for different libraries.

Useful Handlers
In addition to the base Handler class, many useful subclasses are provided:

StreamHandler instances send messages to streams (file-like objects).

FileHandler instances send messages to disk files.

BaseRotatingHandler is the base class for handlers that rotate log files at a certain point. It is not meant to be instantiated directly. Instead, use RotatingFileHandler or TimedRotatingFileHandler.

RotatingFileHandler instances send messages to disk files, with support for maximum log file sizes and log file rotation.

TimedRotatingFileHandler instances send messages to disk files, rotating the log file at certain timed intervals.

SocketHandler instances send messages to TCP/IP sockets. Since 3.4, Unix domain sockets are also supported.

DatagramHandler instances send messages to UDP sockets. Since 3.4, Unix domain sockets are also supported.

SMTPHandler instances send messages to a designated email address.

SysLogHandler instances send messages to a Unix syslog daemon, possibly on a remote machine.

NTEventLogHandler instances send messages to a Windows NT/2000/XP event log.

MemoryHandler instances send messages to a buffer in memory, which is flushed whenever specific criteria are met.

HTTPHandler instances send messages to an HTTP server using either GET or POST semantics.

WatchedFileHandler instances watch the file they are logging to. If the file changes, it is closed and reopened using the file name. This handler is only useful on Unix-like systems; Windows does not support the underlying mechanism used.

QueueHandler instances send messages to a queue, such as those implemented in the queue or multiprocessing modules.

NullHandler instances do nothing with error messages. They are used by library developers who want to use logging, but want to avoid the ‘No handlers could be found for logger XXX’ message which can be displayed if the library user has not configured logging. See Configuring Logging for a Library for more information.

New in version 3.1: The NullHandler class.

New in version 3.2: The QueueHandler class.

The NullHandler, StreamHandler and FileHandler classes are defined in the core logging package. The other handlers are defined in a sub-module, logging.handlers. (There is also another sub-module, logging.config, for configuration functionality.)

Logged messages are formatted for presentation through instances of the Formatter class. They are initialized with a format string suitable for use with the % operator and a dictionary.

For formatting multiple messages in a batch, instances of BufferingFormatter can be used. In addition to the format string (which is applied to each message in the batch), there is provision for header and trailer format strings.

When filtering based on logger level and/or handler level is not enough, instances of Filter can be added to both Logger and Handler instances (through their addFilter() method). Before deciding to process a message further, both loggers and handlers consult all their filters for permission. If any filter returns a false value, the message is not processed further.

The basic Filter functionality allows filtering by specific logger name. If this feature is used, messages sent to the named logger and its children are allowed through the filter, and all others dropped.

Exceptions raised during logging
The logging package is designed to swallow exceptions which occur while logging in production. This is so that errors which occur while handling logging events - such as logging misconfiguration, network or other similar errors - do not cause the application using logging to terminate prematurely.

SystemExit and KeyboardInterrupt exceptions are never swallowed. Other exceptions which occur during the emit() method of a Handler subclass are passed to its handleError() method.

The default implementation of handleError() in Handler checks to see if a module-level variable, raiseExceptions, is set. If set, a traceback is printed to sys.stderr. If not set, the exception is swallowed.

Note The default value of raiseExceptions is True. This is because during development, you typically want to be notified of any exceptions that occur. It’s advised that you set raiseExceptions to False for production usage.
Using arbitrary objects as messages
In the preceding sections and examples, it has been assumed that the message passed when logging the event is a string. However, this is not the only possibility. You can pass an arbitrary object as a message, and its __str__() method will be called when the logging system needs to convert it to a string representation. In fact, if you want to, you can avoid computing a string representation altogether - for example, the SocketHandler emits an event by pickling it and sending it over the wire.

Optimization
Formatting of message arguments is deferred until it cannot be avoided. However, computing the arguments passed to the logging method can also be expensive, and you may want to avoid doing it if the logger will just throw away your event. To decide what to do, you can call the isEnabledFor() method which takes a level argument and returns true if the event would be created by the Logger for that level of call. You can write code like this:

if logger.isEnabledFor(logging.DEBUG):
    logger.debug('Message with %s, %s', expensive_func1(),
                                        expensive_func2())
so that if the logger’s threshold is set above DEBUG, the calls to expensive_func1() and expensive_func2() are never made.

Note In some cases, isEnabledFor() can itself be more expensive than you’d like (e.g. for deeply nested loggers where an explicit level is only set high up in the logger hierarchy). In such cases (or if you want to avoid calling a method in tight loops), you can cache the result of a call to isEnabledFor() in a local or instance variable, and use that instead of calling the method each time. Such a cached value would only need to be recomputed when the logging configuration changes dynamically while the application is running (which is not all that common).
There are other optimizations which can be made for specific applications which need more precise control over what logging information is collected. Here’s a list of things you can do to avoid processing during logging which you don’t need:

What you don’t want to collect

How to avoid collecting it

Information about where calls were made from.

Set logging._srcfile to None. This avoids calling sys._getframe(), which may help to speed up your code in environments like PyPy (which can’t speed up code that uses sys._getframe()).

Threading information.

Set logging.logThreads to False.

Current process ID (os.getpid())

Set logging.logProcesses to False.

Current process name when using multiprocessing to manage multiple processes.

Set logging.logMultiprocessing to False.

Also note that the core logging module only includes the basic handlers. If you don’t import logging.handlers and logging.config, they won’t take up any memory.

See also
Module logging
API reference for the logging module.

Module logging.config
Configuration API for the logging module.

Module logging.handlers
Useful handlers included with the logging module.

A logging cookbook

Table of Contents
Logging HOWTO
Basic Logging Tutorial
When to use logging
A simple example
Logging to a file
Logging from multiple modules
Logging variable data
Changing the format of displayed messages
Displaying the date/time in messages
Next Steps
Advanced Logging Tutorial
Logging Flow
Loggers
Handlers
Formatters
Configuring Logging
What happens if no configuration is provided
Configuring Logging for a Library
Logging Levels
Custom Levels
Useful Handlers
Exceptions raised during logging
Using arbitrary objects as messages
Optimization
Previous topic
Functional Programming HOWTO

Next topic
Logging Cookbook

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Logging HOWTO
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Logging Cookbook
Quick search
  |
Logging Cookbook
Author
Vinay Sajip <vinay_sajip at red-dove dot com>

This page contains a number of recipes related to logging, which have been found useful in the past. For links to tutorial and reference information, please see Other resources.

Using logging in multiple modules
Multiple calls to logging.getLogger('someLogger') return a reference to the same logger object. This is true not only within the same module, but also across modules as long as it is in the same Python interpreter process. It is true for references to the same object; additionally, application code can define and configure a parent logger in one module and create (but not configure) a child logger in a separate module, and all logger calls to the child will pass up to the parent. Here is a main module:

import logging
import auxiliary_module

# create logger with 'spam_application'
logger = logging.getLogger('spam_application')
logger.setLevel(logging.DEBUG)
# create file handler which logs even debug messages
fh = logging.FileHandler('spam.log')
fh.setLevel(logging.DEBUG)
# create console handler with a higher log level
ch = logging.StreamHandler()
ch.setLevel(logging.ERROR)
# create formatter and add it to the handlers
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
fh.setFormatter(formatter)
ch.setFormatter(formatter)
# add the handlers to the logger
logger.addHandler(fh)
logger.addHandler(ch)

logger.info('creating an instance of auxiliary_module.Auxiliary')
a = auxiliary_module.Auxiliary()
logger.info('created an instance of auxiliary_module.Auxiliary')
logger.info('calling auxiliary_module.Auxiliary.do_something')
a.do_something()
logger.info('finished auxiliary_module.Auxiliary.do_something')
logger.info('calling auxiliary_module.some_function()')
auxiliary_module.some_function()
logger.info('done with auxiliary_module.some_function()')
Here is the auxiliary module:

import logging

# create logger
module_logger = logging.getLogger('spam_application.auxiliary')

class Auxiliary:
    def __init__(self):
        self.logger = logging.getLogger('spam_application.auxiliary.Auxiliary')
        self.logger.info('creating an instance of Auxiliary')

    def do_something(self):
        self.logger.info('doing something')
        a = 1 + 1
        self.logger.info('done doing something')

def some_function():
    module_logger.info('received a call to "some_function"')
The output looks like this:

2005-03-23 23:47:11,663 - spam_application - INFO -
   creating an instance of auxiliary_module.Auxiliary
2005-03-23 23:47:11,665 - spam_application.auxiliary.Auxiliary - INFO -
   creating an instance of Auxiliary
2005-03-23 23:47:11,665 - spam_application - INFO -
   created an instance of auxiliary_module.Auxiliary
2005-03-23 23:47:11,668 - spam_application - INFO -
   calling auxiliary_module.Auxiliary.do_something
2005-03-23 23:47:11,668 - spam_application.auxiliary.Auxiliary - INFO -
   doing something
2005-03-23 23:47:11,669 - spam_application.auxiliary.Auxiliary - INFO -
   done doing something
2005-03-23 23:47:11,670 - spam_application - INFO -
   finished auxiliary_module.Auxiliary.do_something
2005-03-23 23:47:11,671 - spam_application - INFO -
   calling auxiliary_module.some_function()
2005-03-23 23:47:11,672 - spam_application.auxiliary - INFO -
   received a call to 'some_function'
2005-03-23 23:47:11,673 - spam_application - INFO -
   done with auxiliary_module.some_function()
Logging from multiple threads
Logging from multiple threads requires no special effort. The following example shows logging from the main (initial) thread and another thread:

import logging
import threading
import time

def worker(arg):
    while not arg['stop']:
        logging.debug('Hi from myfunc')
        time.sleep(0.5)

def main():
    logging.basicConfig(level=logging.DEBUG, format='%(relativeCreated)6d %(threadName)s %(message)s')
    info = {'stop': False}
    thread = threading.Thread(target=worker, args=(info,))
    thread.start()
    while True:
        try:
            logging.debug('Hello from main')
            time.sleep(0.75)
        except KeyboardInterrupt:
            info['stop'] = True
            break
    thread.join()

if __name__ == '__main__':
    main()
When run, the script should print something like the following:

   0 Thread-1 Hi from myfunc
   3 MainThread Hello from main
 505 Thread-1 Hi from myfunc
 755 MainThread Hello from main
1007 Thread-1 Hi from myfunc
1507 MainThread Hello from main
1508 Thread-1 Hi from myfunc
2010 Thread-1 Hi from myfunc
2258 MainThread Hello from main
2512 Thread-1 Hi from myfunc
3009 MainThread Hello from main
3013 Thread-1 Hi from myfunc
3515 Thread-1 Hi from myfunc
3761 MainThread Hello from main
4017 Thread-1 Hi from myfunc
4513 MainThread Hello from main
4518 Thread-1 Hi from myfunc
This shows the logging output interspersed as one might expect. This approach works for more threads than shown here, of course.

Multiple handlers and formatters
Loggers are plain Python objects. The addHandler() method has no minimum or maximum quota for the number of handlers you may add. Sometimes it will be beneficial for an application to log all messages of all severities to a text file while simultaneously logging errors or above to the console. To set this up, simply configure the appropriate handlers. The logging calls in the application code will remain unchanged. Here is a slight modification to the previous simple module-based configuration example:

import logging

logger = logging.getLogger('simple_example')
logger.setLevel(logging.DEBUG)
# create file handler which logs even debug messages
fh = logging.FileHandler('spam.log')
fh.setLevel(logging.DEBUG)
# create console handler with a higher log level
ch = logging.StreamHandler()
ch.setLevel(logging.ERROR)
# create formatter and add it to the handlers
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
ch.setFormatter(formatter)
fh.setFormatter(formatter)
# add the handlers to logger
logger.addHandler(ch)
logger.addHandler(fh)

# 'application' code
logger.debug('debug message')
logger.info('info message')
logger.warning('warn message')
logger.error('error message')
logger.critical('critical message')
Notice that the ‘application’ code does not care about multiple handlers. All that changed was the addition and configuration of a new handler named fh.

The ability to create new handlers with higher- or lower-severity filters can be very helpful when writing and testing an application. Instead of using many print statements for debugging, use logger.debug: Unlike the print statements, which you will have to delete or comment out later, the logger.debug statements can remain intact in the source code and remain dormant until you need them again. At that time, the only change that needs to happen is to modify the severity level of the logger and/or handler to debug.

Logging to multiple destinations
Let’s say you want to log to console and file with different message formats and in differing circumstances. Say you want to log messages with levels of DEBUG and higher to file, and those messages at level INFO and higher to the console. Let’s also assume that the file should contain timestamps, but the console messages should not. Here’s how you can achieve this:

import logging

# set up logging to file - see previous section for more details
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',
                    datefmt='%m-%d %H:%M',
                    filename='/tmp/myapp.log',
                    filemode='w')
# define a Handler which writes INFO messages or higher to the sys.stderr
console = logging.StreamHandler()
console.setLevel(logging.INFO)
# set a format which is simpler for console use
formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')
# tell the handler to use this format
console.setFormatter(formatter)
# add the handler to the root logger
logging.getLogger('').addHandler(console)

# Now, we can log to the root logger, or any other logger. First the root...
logging.info('Jackdaws love my big sphinx of quartz.')

# Now, define a couple of other loggers which might represent areas in your
# application:

logger1 = logging.getLogger('myapp.area1')
logger2 = logging.getLogger('myapp.area2')

logger1.debug('Quick zephyrs blow, vexing daft Jim.')
logger1.info('How quickly daft jumping zebras vex.')
logger2.warning('Jail zesty vixen who grabbed pay from quack.')
logger2.error('The five boxing wizards jump quickly.')
When you run this, on the console you will see

root        : INFO     Jackdaws love my big sphinx of quartz.
myapp.area1 : INFO     How quickly daft jumping zebras vex.
myapp.area2 : WARNING  Jail zesty vixen who grabbed pay from quack.
myapp.area2 : ERROR    The five boxing wizards jump quickly.
and in the file you will see something like

10-22 22:19 root         INFO     Jackdaws love my big sphinx of quartz.
10-22 22:19 myapp.area1  DEBUG    Quick zephyrs blow, vexing daft Jim.
10-22 22:19 myapp.area1  INFO     How quickly daft jumping zebras vex.
10-22 22:19 myapp.area2  WARNING  Jail zesty vixen who grabbed pay from quack.
10-22 22:19 myapp.area2  ERROR    The five boxing wizards jump quickly.
As you can see, the DEBUG message only shows up in the file. The other messages are sent to both destinations.

This example uses console and file handlers, but you can use any number and combination of handlers you choose.

Note that the above choice of log filename /tmp/myapp.log implies use of a standard location for temporary files on POSIX systems. On Windows, you may need to choose a different directory name for the log - just ensure that the directory exists and that you have the permissions to create and update files in it.

Custom handling of levels
Sometimes, you might want to do something slightly different from the standard handling of levels in handlers, where all levels above a threshold get processed by a handler. To do this, you need to use filters. Let’s look at a scenario where you want to arrange things as follows:

Send messages of severity INFO and WARNING to sys.stdout

Send messages of severity ERROR and above to sys.stderr

Send messages of severity DEBUG and above to file app.log

Suppose you configure logging with the following JSON:

{
    "version": 1,
    "disable_existing_loggers": false,
    "formatters": {
        "simple": {
            "format": "%(levelname)-8s - %(message)s"
        }
    },
    "handlers": {
        "stdout": {
            "class": "logging.StreamHandler",
            "level": "INFO",
            "formatter": "simple",
            "stream": "ext://sys.stdout",
        },
        "stderr": {
            "class": "logging.StreamHandler",
            "level": "ERROR",
            "formatter": "simple",
            "stream": "ext://sys.stderr"
        },
        "file": {
            "class": "logging.FileHandler",
            "formatter": "simple",
            "filename": "app.log",
            "mode": "w"
        }
    },
    "root": {
        "level": "DEBUG",
        "handlers": [
            "stderr",
            "stdout",
            "file"
        ]
    }
}
This configuration does almost what we want, except that sys.stdout would show messages of severity ERROR and above as well as INFO and WARNING messages. To prevent this, we can set up a filter which excludes those messages and add it to the relevant handler. This can be configured by adding a filters section parallel to formatters and handlers:

"filters": {
    "warnings_and_below": {
        "()" : "__main__.filter_maker",
        "level": "WARNING"
    }
}
and changing the section on the stdout handler to add it:

"stdout": {
    "class": "logging.StreamHandler",
    "level": "INFO",
    "formatter": "simple",
    "stream": "ext://sys.stdout",
    "filters": ["warnings_and_below"]
}
A filter is just a function, so we can define the filter_maker (a factory function) as follows:

def filter_maker(level):
    level = getattr(logging, level)

    def filter(record):
        return record.levelno <= level

    return filter
This converts the string argument passed in to a numeric level, and returns a function which only returns True if the level of the passed in record is at or below the specified level. Note that in this example I have defined the filter_maker in a test script main.py that I run from the command line, so its module will be __main__ - hence the __main__.filter_maker in the filter configuration. You will need to change that if you define it in a different module.

With the filter added, we can run main.py, which in full is:

import json
import logging
import logging.config

CONFIG = '''
{
    "version": 1,
    "disable_existing_loggers": false,
    "formatters": {
        "simple": {
            "format": "%(levelname)-8s - %(message)s"
        }
    },
    "filters": {
        "warnings_and_below": {
            "()" : "__main__.filter_maker",
            "level": "WARNING"
        }
    },
    "handlers": {
        "stdout": {
            "class": "logging.StreamHandler",
            "level": "INFO",
            "formatter": "simple",
            "stream": "ext://sys.stdout",
            "filters": ["warnings_and_below"]
        },
        "stderr": {
            "class": "logging.StreamHandler",
            "level": "ERROR",
            "formatter": "simple",
            "stream": "ext://sys.stderr"
        },
        "file": {
            "class": "logging.FileHandler",
            "formatter": "simple",
            "filename": "app.log",
            "mode": "w"
        }
    },
    "root": {
        "level": "DEBUG",
        "handlers": [
            "stderr",
            "stdout",
            "file"
        ]
    }
}
'''

def filter_maker(level):
    level = getattr(logging, level)

    def filter(record):
        return record.levelno <= level

    return filter

logging.config.dictConfig(json.loads(CONFIG))
logging.debug('A DEBUG message')
logging.info('An INFO message')
logging.warning('A WARNING message')
logging.error('An ERROR message')
logging.critical('A CRITICAL message')
And after running it like this:

python main.py 2>stderr.log >stdout.log
We can see the results are as expected:

$ more *.log
::::::::::::::
app.log
::::::::::::::
DEBUG    - A DEBUG message
INFO     - An INFO message
WARNING  - A WARNING message
ERROR    - An ERROR message
CRITICAL - A CRITICAL message
::::::::::::::
stderr.log
::::::::::::::
ERROR    - An ERROR message
CRITICAL - A CRITICAL message
::::::::::::::
stdout.log
::::::::::::::
INFO     - An INFO message
WARNING  - A WARNING message
Configuration server example
Here is an example of a module using the logging configuration server:

import logging
import logging.config
import time
import os

# read initial config file
logging.config.fileConfig('logging.conf')

# create and start listener on port 9999
t = logging.config.listen(9999)
t.start()

logger = logging.getLogger('simpleExample')

try:
    # loop through logging calls to see the difference
    # new configurations make, until Ctrl+C is pressed
    while True:
        logger.debug('debug message')
        logger.info('info message')
        logger.warning('warn message')
        logger.error('error message')
        logger.critical('critical message')
        time.sleep(5)
except KeyboardInterrupt:
    # cleanup
    logging.config.stopListening()
    t.join()
And here is a script that takes a filename and sends that file to the server, properly preceded with the binary-encoded length, as the new logging configuration:

#!/usr/bin/env python
import socket, sys, struct

with open(sys.argv[1], 'rb') as f:
    data_to_send = f.read()

HOST = 'localhost'
PORT = 9999
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print('connecting...')
s.connect((HOST, PORT))
print('sending config...')
s.send(struct.pack('>L', len(data_to_send)))
s.send(data_to_send)
s.close()
print('complete')
Dealing with handlers that block
Sometimes you have to get your logging handlers to do their work without blocking the thread you’re logging from. This is common in web applications, though of course it also occurs in other scenarios.

A common culprit which demonstrates sluggish behaviour is the SMTPHandler: sending emails can take a long time, for a number of reasons outside the developer’s control (for example, a poorly performing mail or network infrastructure). But almost any network-based handler can block: Even a SocketHandler operation may do a DNS query under the hood which is too slow (and this query can be deep in the socket library code, below the Python layer, and outside your control).

One solution is to use a two-part approach. For the first part, attach only a QueueHandler to those loggers which are accessed from performance-critical threads. They simply write to their queue, which can be sized to a large enough capacity or initialized with no upper bound to their size. The write to the queue will typically be accepted quickly, though you will probably need to catch the queue.Full exception as a precaution in your code. If you are a library developer who has performance-critical threads in their code, be sure to document this (together with a suggestion to attach only QueueHandlers to your loggers) for the benefit of other developers who will use your code.

The second part of the solution is QueueListener, which has been designed as the counterpart to QueueHandler. A QueueListener is very simple: it’s passed a queue and some handlers, and it fires up an internal thread which listens to its queue for LogRecords sent from QueueHandlers (or any other source of LogRecords, for that matter). The LogRecords are removed from the queue and passed to the handlers for processing.

The advantage of having a separate QueueListener class is that you can use the same instance to service multiple QueueHandlers. This is more resource-friendly than, say, having threaded versions of the existing handler classes, which would eat up one thread per handler for no particular benefit.

An example of using these two classes follows (imports omitted):

que = queue.Queue(-1)  # no limit on size
queue_handler = QueueHandler(que)
handler = logging.StreamHandler()
listener = QueueListener(que, handler)
root = logging.getLogger()
root.addHandler(queue_handler)
formatter = logging.Formatter('%(threadName)s: %(message)s')
handler.setFormatter(formatter)
listener.start()
# The log output will display the thread which generated
# the event (the main thread) rather than the internal
# thread which monitors the internal queue. This is what
# you want to happen.
root.warning('Look out!')
listener.stop()
which, when run, will produce:

MainThread: Look out!
Note Although the earlier discussion wasn’t specifically talking about async code, but rather about slow logging handlers, it should be noted that when logging from async code, network and even file handlers could lead to problems (blocking the event loop) because some logging is done from asyncio internals. It might be best, if any async code is used in an application, to use the above approach for logging, so that any blocking code runs only in the QueueListener thread.
Changed in version 3.5: Prior to Python 3.5, the QueueListener always passed every message received from the queue to every handler it was initialized with. (This was because it was assumed that level filtering was all done on the other side, where the queue is filled.) From 3.5 onwards, this behaviour can be changed by passing a keyword argument respect_handler_level=True to the listener’s constructor. When this is done, the listener compares the level of each message with the handler’s level, and only passes a message to a handler if it’s appropriate to do so.

Sending and receiving logging events across a network
Let’s say you want to send logging events across a network, and handle them at the receiving end. A simple way of doing this is attaching a SocketHandler instance to the root logger at the sending end:

import logging, logging.handlers

rootLogger = logging.getLogger('')
rootLogger.setLevel(logging.DEBUG)
socketHandler = logging.handlers.SocketHandler('localhost',
                    logging.handlers.DEFAULT_TCP_LOGGING_PORT)
# don't bother with a formatter, since a socket handler sends the event as
# an unformatted pickle
rootLogger.addHandler(socketHandler)

# Now, we can log to the root logger, or any other logger. First the root...
logging.info('Jackdaws love my big sphinx of quartz.')

# Now, define a couple of other loggers which might represent areas in your
# application:

logger1 = logging.getLogger('myapp.area1')
logger2 = logging.getLogger('myapp.area2')

logger1.debug('Quick zephyrs blow, vexing daft Jim.')
logger1.info('How quickly daft jumping zebras vex.')
logger2.warning('Jail zesty vixen who grabbed pay from quack.')
logger2.error('The five boxing wizards jump quickly.')
At the receiving end, you can set up a receiver using the socketserver module. Here is a basic working example:

import pickle
import logging
import logging.handlers
import socketserver
import struct


class LogRecordStreamHandler(socketserver.StreamRequestHandler):
    """Handler for a streaming logging request.

    This basically logs the record using whatever logging policy is
    configured locally.
    """

    def handle(self):
        """
        Handle multiple requests - each expected to be a 4-byte length,
        followed by the LogRecord in pickle format. Logs the record
        according to whatever policy is configured locally.
        """
        while True:
            chunk = self.connection.recv(4)
            if len(chunk) < 4:
                break
            slen = struct.unpack('>L', chunk)[0]
            chunk = self.connection.recv(slen)
            while len(chunk) < slen:
                chunk = chunk + self.connection.recv(slen - len(chunk))
            obj = self.unPickle(chunk)
            record = logging.makeLogRecord(obj)
            self.handleLogRecord(record)

    def unPickle(self, data):
        return pickle.loads(data)

    def handleLogRecord(self, record):
        # if a name is specified, we use the named logger rather than the one
        # implied by the record.
        if self.server.logname is not None:
            name = self.server.logname
        else:
            name = record.name
        logger = logging.getLogger(name)
        # N.B. EVERY record gets logged. This is because Logger.handle
        # is normally called AFTER logger-level filtering. If you want
        # to do filtering, do it at the client end to save wasting
        # cycles and network bandwidth!
        logger.handle(record)

class LogRecordSocketReceiver(socketserver.ThreadingTCPServer):
    """
    Simple TCP socket-based logging receiver suitable for testing.
    """

    allow_reuse_address = True

    def __init__(self, host='localhost',
                 port=logging.handlers.DEFAULT_TCP_LOGGING_PORT,
                 handler=LogRecordStreamHandler):
        socketserver.ThreadingTCPServer.__init__(self, (host, port), handler)
        self.abort = 0
        self.timeout = 1
        self.logname = None

    def serve_until_stopped(self):
        import select
        abort = 0
        while not abort:
            rd, wr, ex = select.select([self.socket.fileno()],
                                       [], [],
                                       self.timeout)
            if rd:
                self.handle_request()
            abort = self.abort

def main():
    logging.basicConfig(
        format='%(relativeCreated)5d %(name)-15s %(levelname)-8s %(message)s')
    tcpserver = LogRecordSocketReceiver()
    print('About to start TCP server...')
    tcpserver.serve_until_stopped()

if __name__ == '__main__':
    main()
First run the server, and then the client. On the client side, nothing is printed on the console; on the server side, you should see something like:

About to start TCP server...
   59 root            INFO     Jackdaws love my big sphinx of quartz.
   59 myapp.area1     DEBUG    Quick zephyrs blow, vexing daft Jim.
   69 myapp.area1     INFO     How quickly daft jumping zebras vex.
   69 myapp.area2     WARNING  Jail zesty vixen who grabbed pay from quack.
   69 myapp.area2     ERROR    The five boxing wizards jump quickly.
Note that there are some security issues with pickle in some scenarios. If these affect you, you can use an alternative serialization scheme by overriding the makePickle() method and implementing your alternative there, as well as adapting the above script to use your alternative serialization.

Running a logging socket listener in production
To run a logging listener in production, you may need to use a process-management tool such as Supervisor. Here is a Gist which provides the bare-bones files to run the above functionality using Supervisor: you will need to change the /path/to/ parts in the Gist to reflect the actual paths you want to use.

Adding contextual information to your logging output
Sometimes you want logging output to contain contextual information in addition to the parameters passed to the logging call. For example, in a networked application, it may be desirable to log client-specific information in the log (e.g. remote client’s username, or IP address). Although you could use the extra parameter to achieve this, it’s not always convenient to pass the information in this way. While it might be tempting to create Logger instances on a per-connection basis, this is not a good idea because these instances are not garbage collected. While this is not a problem in practice, when the number of Logger instances is dependent on the level of granularity you want to use in logging an application, it could be hard to manage if the number of Logger instances becomes effectively unbounded.

Using LoggerAdapters to impart contextual information
An easy way in which you can pass contextual information to be output along with logging event information is to use the LoggerAdapter class. This class is designed to look like a Logger, so that you can call debug(), info(), warning(), error(), exception(), critical() and log(). These methods have the same signatures as their counterparts in Logger, so you can use the two types of instances interchangeably.

When you create an instance of LoggerAdapter, you pass it a Logger instance and a dict-like object which contains your contextual information. When you call one of the logging methods on an instance of LoggerAdapter, it delegates the call to the underlying instance of Logger passed to its constructor, and arranges to pass the contextual information in the delegated call. Here’s a snippet from the code of LoggerAdapter:

def debug(self, msg, /, *args, **kwargs):
    """
    Delegate a debug call to the underlying logger, after adding
    contextual information from this adapter instance.
    """
    msg, kwargs = self.process(msg, kwargs)
    self.logger.debug(msg, *args, **kwargs)
The process() method of LoggerAdapter is where the contextual information is added to the logging output. It’s passed the message and keyword arguments of the logging call, and it passes back (potentially) modified versions of these to use in the call to the underlying logger. The default implementation of this method leaves the message alone, but inserts an ‘extra’ key in the keyword argument whose value is the dict-like object passed to the constructor. Of course, if you had passed an ‘extra’ keyword argument in the call to the adapter, it will be silently overwritten.

The advantage of using ‘extra’ is that the values in the dict-like object are merged into the LogRecord instance’s __dict__, allowing you to use customized strings with your Formatter instances which know about the keys of the dict-like object. If you need a different method, e.g. if you want to prepend or append the contextual information to the message string, you just need to subclass LoggerAdapter and override process() to do what you need. Here is a simple example:

class CustomAdapter(logging.LoggerAdapter):
    """
    This example adapter expects the passed in dict-like object to have a
    'connid' key, whose value in brackets is prepended to the log message.
    """
    def process(self, msg, kwargs):
        return '[%s] %s' % (self.extra['connid'], msg), kwargs
which you can use like this:

logger = logging.getLogger(__name__)
adapter = CustomAdapter(logger, {'connid': some_conn_id})
Then any events that you log to the adapter will have the value of some_conn_id prepended to the log messages.

Using objects other than dicts to pass contextual information
You don’t need to pass an actual dict to a LoggerAdapter - you could pass an instance of a class which implements __getitem__ and __iter__ so that it looks like a dict to logging. This would be useful if you want to generate values dynamically (whereas the values in a dict would be constant).

Using Filters to impart contextual information
You can also add contextual information to log output using a user-defined Filter. Filter instances are allowed to modify the LogRecords passed to them, including adding additional attributes which can then be output using a suitable format string, or if needed a custom Formatter.

For example in a web application, the request being processed (or at least, the interesting parts of it) can be stored in a threadlocal (threading.local) variable, and then accessed from a Filter to add, say, information from the request - say, the remote IP address and remote user’s username - to the LogRecord, using the attribute names ‘ip’ and ‘user’ as in the LoggerAdapter example above. In that case, the same format string can be used to get similar output to that shown above. Here’s an example script:

import logging
from random import choice

class ContextFilter(logging.Filter):
    """
    This is a filter which injects contextual information into the log.

    Rather than use actual contextual information, we just use random
    data in this demo.
    """

    USERS = ['jim', 'fred', 'sheila']
    IPS = ['123.231.231.123', '127.0.0.1', '192.168.0.1']

    def filter(self, record):

        record.ip = choice(ContextFilter.IPS)
        record.user = choice(ContextFilter.USERS)
        return True

if __name__ == '__main__':
    levels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL)
    logging.basicConfig(level=logging.DEBUG,
                        format='%(asctime)-15s %(name)-5s %(levelname)-8s IP: %(ip)-15s User: %(user)-8s %(message)s')
    a1 = logging.getLogger('a.b.c')
    a2 = logging.getLogger('d.e.f')

    f = ContextFilter()
    a1.addFilter(f)
    a2.addFilter(f)
    a1.debug('A debug message')
    a1.info('An info message with %s', 'some parameters')
    for x in range(10):
        lvl = choice(levels)
        lvlname = logging.getLevelName(lvl)
        a2.log(lvl, 'A message at %s level with %d %s', lvlname, 2, 'parameters')
which, when run, produces something like:

2010-09-06 22:38:15,292 a.b.c DEBUG    IP: 123.231.231.123 User: fred     A debug message
2010-09-06 22:38:15,300 a.b.c INFO     IP: 192.168.0.1     User: sheila   An info message with some parameters
2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1       User: sheila   A message at CRITICAL level with 2 parameters
2010-09-06 22:38:15,300 d.e.f ERROR    IP: 127.0.0.1       User: jim      A message at ERROR level with 2 parameters
2010-09-06 22:38:15,300 d.e.f DEBUG    IP: 127.0.0.1       User: sheila   A message at DEBUG level with 2 parameters
2010-09-06 22:38:15,300 d.e.f ERROR    IP: 123.231.231.123 User: fred     A message at ERROR level with 2 parameters
2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 192.168.0.1     User: jim      A message at CRITICAL level with 2 parameters
2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1       User: sheila   A message at CRITICAL level with 2 parameters
2010-09-06 22:38:15,300 d.e.f DEBUG    IP: 192.168.0.1     User: jim      A message at DEBUG level with 2 parameters
2010-09-06 22:38:15,301 d.e.f ERROR    IP: 127.0.0.1       User: sheila   A message at ERROR level with 2 parameters
2010-09-06 22:38:15,301 d.e.f DEBUG    IP: 123.231.231.123 User: fred     A message at DEBUG level with 2 parameters
2010-09-06 22:38:15,301 d.e.f INFO     IP: 123.231.231.123 User: fred     A message at INFO level with 2 parameters
Use of contextvars
Since Python 3.7, the contextvars module has provided context-local storage which works for both threading and asyncio processing needs. This type of storage may thus be generally preferable to thread-locals. The following example shows how, in a multi-threaded environment, logs can populated with contextual information such as, for example, request attributes handled by web applications.

For the purposes of illustration, say that you have different web applications, each independent of the other but running in the same Python process and using a library common to them. How can each of these applications have their own log, where all logging messages from the library (and other request processing code) are directed to the appropriate application’s log file, while including in the log additional contextual information such as client IP, HTTP request method and client username?

Let’s assume that the library can be simulated by the following code:

# webapplib.py
import logging
import time

logger = logging.getLogger(__name__)

def useful():
    # Just a representative event logged from the library
    logger.debug('Hello from webapplib!')
    # Just sleep for a bit so other threads get to run
    time.sleep(0.01)
We can simulate the multiple web applications by means of two simple classes, Request and WebApp. These simulate how real threaded web applications work - each request is handled by a thread:

# main.py
import argparse
from contextvars import ContextVar
import logging
import os
from random import choice
import threading
import webapplib

logger = logging.getLogger(__name__)
root = logging.getLogger()
root.setLevel(logging.DEBUG)

class Request:
    """
    A simple dummy request class which just holds dummy HTTP request method,
    client IP address and client username
    """
    def __init__(self, method, ip, user):
        self.method = method
        self.ip = ip
        self.user = user

# A dummy set of requests which will be used in the simulation - we'll just pick
# from this list randomly. Note that all GET requests are from 192.168.2.XXX
# addresses, whereas POST requests are from 192.16.3.XXX addresses. Three users
# are represented in the sample requests.

REQUESTS = [
    Request('GET', '192.168.2.20', 'jim'),
    Request('POST', '192.168.3.20', 'fred'),
    Request('GET', '192.168.2.21', 'sheila'),
    Request('POST', '192.168.3.21', 'jim'),
    Request('GET', '192.168.2.22', 'fred'),
    Request('POST', '192.168.3.22', 'sheila'),
]

# Note that the format string includes references to request context information
# such as HTTP method, client IP and username

formatter = logging.Formatter('%(threadName)-11s %(appName)s %(name)-9s %(user)-6s %(ip)s %(method)-4s %(message)s')

# Create our context variables. These will be filled at the start of request
# processing, and used in the logging that happens during that processing

ctx_request = ContextVar('request')
ctx_appname = ContextVar('appname')

class InjectingFilter(logging.Filter):
    """
    A filter which injects context-specific information into logs and ensures
    that only information for a specific webapp is included in its log
    """
    def __init__(self, app):
        self.app = app

    def filter(self, record):
        request = ctx_request.get()
        record.method = request.method
        record.ip = request.ip
        record.user = request.user
        record.appName = appName = ctx_appname.get()
        return appName == self.app.name

class WebApp:
    """
    A dummy web application class which has its own handler and filter for a
    webapp-specific log.
    """
    def __init__(self, name):
        self.name = name
        handler = logging.FileHandler(name + '.log', 'w')
        f = InjectingFilter(self)
        handler.setFormatter(formatter)
        handler.addFilter(f)
        root.addHandler(handler)
        self.num_requests = 0

    def process_request(self, request):
        """
        This is the dummy method for processing a request. It's called on a
        different thread for every request. We store the context information into
        the context vars before doing anything else.
        """
        ctx_request.set(request)
        ctx_appname.set(self.name)
        self.num_requests += 1
        logger.debug('Request processing started')
        webapplib.useful()
        logger.debug('Request processing finished')

def main():
    fn = os.path.splitext(os.path.basename(__file__))[0]
    adhf = argparse.ArgumentDefaultsHelpFormatter
    ap = argparse.ArgumentParser(formatter_class=adhf, prog=fn,
                                 description='Simulate a couple of web '
                                             'applications handling some '
                                             'requests, showing how request '
                                             'context can be used to '
                                             'populate logs')
    aa = ap.add_argument
    aa('--count', '-c', default=100, help='How many requests to simulate')
    options = ap.parse_args()

    # Create the dummy webapps and put them in a list which we can use to select
    # from randomly
    app1 = WebApp('app1')
    app2 = WebApp('app2')
    apps = [app1, app2]
    threads = []
    # Add a common handler which will capture all events
    handler = logging.FileHandler('app.log', 'w')
    handler.setFormatter(formatter)
    root.addHandler(handler)

    # Generate calls to process requests
    for i in range(options.count):
        try:
            # Pick an app at random and a request for it to process
            app = choice(apps)
            request = choice(REQUESTS)
            # Process the request in its own thread
            t = threading.Thread(target=app.process_request, args=(request,))
            threads.append(t)
            t.start()
        except KeyboardInterrupt:
            break

    # Wait for the threads to terminate
    for t in threads:
        t.join()

    for app in apps:
        print('%s processed %s requests' % (app.name, app.num_requests))

if __name__ == '__main__':
    main()
If you run the above, you should find that roughly half the requests go into app1.log and the rest into app2.log, and the all the requests are logged to app.log. Each webapp-specific log will contain only log entries for only that webapp, and the request information will be displayed consistently in the log (i.e. the information in each dummy request will always appear together in a log line). This is illustrated by the following shell output:

~/logging-contextual-webapp$ python main.py
app1 processed 51 requests
app2 processed 49 requests
~/logging-contextual-webapp$ wc -l *.log
  153 app1.log
  147 app2.log
  300 app.log
  600 total
~/logging-contextual-webapp$ head -3 app1.log
Thread-3 (process_request) app1 __main__  jim    192.168.3.21 POST Request processing started
Thread-3 (process_request) app1 webapplib jim    192.168.3.21 POST Hello from webapplib!
Thread-5 (process_request) app1 __main__  jim    192.168.3.21 POST Request processing started
~/logging-contextual-webapp$ head -3 app2.log
Thread-1 (process_request) app2 __main__  sheila 192.168.2.21 GET  Request processing started
Thread-1 (process_request) app2 webapplib sheila 192.168.2.21 GET  Hello from webapplib!
Thread-2 (process_request) app2 __main__  jim    192.168.2.20 GET  Request processing started
~/logging-contextual-webapp$ head app.log
Thread-1 (process_request) app2 __main__  sheila 192.168.2.21 GET  Request processing started
Thread-1 (process_request) app2 webapplib sheila 192.168.2.21 GET  Hello from webapplib!
Thread-2 (process_request) app2 __main__  jim    192.168.2.20 GET  Request processing started
Thread-3 (process_request) app1 __main__  jim    192.168.3.21 POST Request processing started
Thread-2 (process_request) app2 webapplib jim    192.168.2.20 GET  Hello from webapplib!
Thread-3 (process_request) app1 webapplib jim    192.168.3.21 POST Hello from webapplib!
Thread-4 (process_request) app2 __main__  fred   192.168.2.22 GET  Request processing started
Thread-5 (process_request) app1 __main__  jim    192.168.3.21 POST Request processing started
Thread-4 (process_request) app2 webapplib fred   192.168.2.22 GET  Hello from webapplib!
Thread-6 (process_request) app1 __main__  jim    192.168.3.21 POST Request processing started
~/logging-contextual-webapp$ grep app1 app1.log | wc -l
153
~/logging-contextual-webapp$ grep app2 app2.log | wc -l
147
~/logging-contextual-webapp$ grep app1 app.log | wc -l
153
~/logging-contextual-webapp$ grep app2 app.log | wc -l
147
Imparting contextual information in handlers
Each Handler has its own chain of filters. If you want to add contextual information to a LogRecord without leaking it to other handlers, you can use a filter that returns a new LogRecord instead of modifying it in-place, as shown in the following script:

import copy
import logging

def filter(record: logging.LogRecord):
    record = copy.copy(record)
    record.user = 'jim'
    return record

if __name__ == '__main__':
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(message)s from %(user)-8s')
    handler.setFormatter(formatter)
    handler.addFilter(filter)
    logger.addHandler(handler)

    logger.info('A log message')
Logging to a single file from multiple processes
Although logging is thread-safe, and logging to a single file from multiple threads in a single process is supported, logging to a single file from multiple processes is not supported, because there is no standard way to serialize access to a single file across multiple processes in Python. If you need to log to a single file from multiple processes, one way of doing this is to have all the processes log to a SocketHandler, and have a separate process which implements a socket server which reads from the socket and logs to file. (If you prefer, you can dedicate one thread in one of the existing processes to perform this function.) This section documents this approach in more detail and includes a working socket receiver which can be used as a starting point for you to adapt in your own applications.

You could also write your own handler which uses the Lock class from the multiprocessing module to serialize access to the file from your processes. The existing FileHandler and subclasses do not make use of multiprocessing at present, though they may do so in the future. Note that at present, the multiprocessing module does not provide working lock functionality on all platforms (see https://bugs.python.org/issue3770).

Alternatively, you can use a Queue and a QueueHandler to send all logging events to one of the processes in your multi-process application. The following example script demonstrates how you can do this; in the example a separate listener process listens for events sent by other processes and logs them according to its own logging configuration. Although the example only demonstrates one way of doing it (for example, you may want to use a listener thread rather than a separate listener process – the implementation would be analogous) it does allow for completely different logging configurations for the listener and the other processes in your application, and can be used as the basis for code meeting your own specific requirements:

# You'll need these imports in your own code
import logging
import logging.handlers
import multiprocessing

# Next two import lines for this demo only
from random import choice, random
import time

#
# Because you'll want to define the logging configurations for listener and workers, the
# listener and worker process functions take a configurer parameter which is a callable
# for configuring logging for that process. These functions are also passed the queue,
# which they use for communication.
#
# In practice, you can configure the listener however you want, but note that in this
# simple example, the listener does not apply level or filter logic to received records.
# In practice, you would probably want to do this logic in the worker processes, to avoid
# sending events which would be filtered out between processes.
#
# The size of the rotated files is made small so you can see the results easily.
def listener_configurer():
    root = logging.getLogger()
    h = logging.handlers.RotatingFileHandler('mptest.log', 'a', 300, 10)
    f = logging.Formatter('%(asctime)s %(processName)-10s %(name)s %(levelname)-8s %(message)s')
    h.setFormatter(f)
    root.addHandler(h)

# This is the listener process top-level loop: wait for logging events
# (LogRecords)on the queue and handle them, quit when you get a None for a
# LogRecord.
def listener_process(queue, configurer):
    configurer()
    while True:
        try:
            record = queue.get()
            if record is None:  # We send this as a sentinel to tell the listener to quit.
                break
            logger = logging.getLogger(record.name)
            logger.handle(record)  # No level or filter logic applied - just do it!
        except Exception:
            import sys, traceback
            print('Whoops! Problem:', file=sys.stderr)
            traceback.print_exc(file=sys.stderr)

# Arrays used for random selections in this demo

LEVELS = [logging.DEBUG, logging.INFO, logging.WARNING,
          logging.ERROR, logging.CRITICAL]

LOGGERS = ['a.b.c', 'd.e.f']

MESSAGES = [
    'Random message #1',
    'Random message #2',
    'Random message #3',
]

# The worker configuration is done at the start of the worker process run.
# Note that on Windows you can't rely on fork semantics, so each process
# will run the logging configuration code when it starts.
def worker_configurer(queue):
    h = logging.handlers.QueueHandler(queue)  # Just the one handler needed
    root = logging.getLogger()
    root.addHandler(h)
    # send all messages, for demo; no other level or filter logic applied.
    root.setLevel(logging.DEBUG)

# This is the worker process top-level loop, which just logs ten events with
# random intervening delays before terminating.
# The print messages are just so you know it's doing something!
def worker_process(queue, configurer):
    configurer(queue)
    name = multiprocessing.current_process().name
    print('Worker started: %s' % name)
    for i in range(10):
        time.sleep(random())
        logger = logging.getLogger(choice(LOGGERS))
        level = choice(LEVELS)
        message = choice(MESSAGES)
        logger.log(level, message)
    print('Worker finished: %s' % name)

# Here's where the demo gets orchestrated. Create the queue, create and start
# the listener, create ten workers and start them, wait for them to finish,
# then send a None to the queue to tell the listener to finish.
def main():
    queue = multiprocessing.Queue(-1)
    listener = multiprocessing.Process(target=listener_process,
                                       args=(queue, listener_configurer))
    listener.start()
    workers = []
    for i in range(10):
        worker = multiprocessing.Process(target=worker_process,
                                         args=(queue, worker_configurer))
        workers.append(worker)
        worker.start()
    for w in workers:
        w.join()
    queue.put_nowait(None)
    listener.join()

if __name__ == '__main__':
    main()
A variant of the above script keeps the logging in the main process, in a separate thread:

import logging
import logging.config
import logging.handlers
from multiprocessing import Process, Queue
import random
import threading
import time

def logger_thread(q):
    while True:
        record = q.get()
        if record is None:
            break
        logger = logging.getLogger(record.name)
        logger.handle(record)


def worker_process(q):
    qh = logging.handlers.QueueHandler(q)
    root = logging.getLogger()
    root.setLevel(logging.DEBUG)
    root.addHandler(qh)
    levels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,
              logging.CRITICAL]
    loggers = ['foo', 'foo.bar', 'foo.bar.baz',
               'spam', 'spam.ham', 'spam.ham.eggs']
    for i in range(100):
        lvl = random.choice(levels)
        logger = logging.getLogger(random.choice(loggers))
        logger.log(lvl, 'Message no. %d', i)

if __name__ == '__main__':
    q = Queue()
    d = {
        'version': 1,
        'formatters': {
            'detailed': {
                'class': 'logging.Formatter',
                'format': '%(asctime)s %(name)-15s %(levelname)-8s %(processName)-10s %(message)s'
            }
        },
        'handlers': {
            'console': {
                'class': 'logging.StreamHandler',
                'level': 'INFO',
            },
            'file': {
                'class': 'logging.FileHandler',
                'filename': 'mplog.log',
                'mode': 'w',
                'formatter': 'detailed',
            },
            'foofile': {
                'class': 'logging.FileHandler',
                'filename': 'mplog-foo.log',
                'mode': 'w',
                'formatter': 'detailed',
            },
            'errors': {
                'class': 'logging.FileHandler',
                'filename': 'mplog-errors.log',
                'mode': 'w',
                'level': 'ERROR',
                'formatter': 'detailed',
            },
        },
        'loggers': {
            'foo': {
                'handlers': ['foofile']
            }
        },
        'root': {
            'level': 'DEBUG',
            'handlers': ['console', 'file', 'errors']
        },
    }
    workers = []
    for i in range(5):
        wp = Process(target=worker_process, name='worker %d' % (i + 1), args=(q,))
        workers.append(wp)
        wp.start()
    logging.config.dictConfig(d)
    lp = threading.Thread(target=logger_thread, args=(q,))
    lp.start()
    # At this point, the main process could do some useful work of its own
    # Once it's done that, it can wait for the workers to terminate...
    for wp in workers:
        wp.join()
    # And now tell the logging thread to finish up, too
    q.put(None)
    lp.join()
This variant shows how you can e.g. apply configuration for particular loggers - e.g. the foo logger has a special handler which stores all events in the foo subsystem in a file mplog-foo.log. This will be used by the logging machinery in the main process (even though the logging events are generated in the worker processes) to direct the messages to the appropriate destinations.

Using concurrent.futures.ProcessPoolExecutor
If you want to use concurrent.futures.ProcessPoolExecutor to start your worker processes, you need to create the queue slightly differently. Instead of

queue = multiprocessing.Queue(-1)
you should use

queue = multiprocessing.Manager().Queue(-1)  # also works with the examples above
and you can then replace the worker creation from this:

workers = []
for i in range(10):
    worker = multiprocessing.Process(target=worker_process,
                                     args=(queue, worker_configurer))
    workers.append(worker)
    worker.start()
for w in workers:
    w.join()
to this (remembering to first import concurrent.futures):

with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:
    for i in range(10):
        executor.submit(worker_process, queue, worker_configurer)
Deploying Web applications using Gunicorn and uWSGI
When deploying Web applications using Gunicorn or uWSGI (or similar), multiple worker processes are created to handle client requests. In such environments, avoid creating file-based handlers directly in your web application. Instead, use a SocketHandler to log from the web application to a listener in a separate process. This can be set up using a process management tool such as Supervisor - see Running a logging socket listener in production for more details.

Using file rotation
Sometimes you want to let a log file grow to a certain size, then open a new file and log to that. You may want to keep a certain number of these files, and when that many files have been created, rotate the files so that the number of files and the size of the files both remain bounded. For this usage pattern, the logging package provides a RotatingFileHandler:

import glob
import logging
import logging.handlers

LOG_FILENAME = 'logging_rotatingfile_example.out'

# Set up a specific logger with our desired output level
my_logger = logging.getLogger('MyLogger')
my_logger.setLevel(logging.DEBUG)

# Add the log message handler to the logger
handler = logging.handlers.RotatingFileHandler(
              LOG_FILENAME, maxBytes=20, backupCount=5)

my_logger.addHandler(handler)

# Log some messages
for i in range(20):
    my_logger.debug('i = %d' % i)

# See what files are created
logfiles = glob.glob('%s*' % LOG_FILENAME)

for filename in logfiles:
    print(filename)
The result should be 6 separate files, each with part of the log history for the application:

logging_rotatingfile_example.out
logging_rotatingfile_example.out.1
logging_rotatingfile_example.out.2
logging_rotatingfile_example.out.3
logging_rotatingfile_example.out.4
logging_rotatingfile_example.out.5
The most current file is always logging_rotatingfile_example.out, and each time it reaches the size limit it is renamed with the suffix .1. Each of the existing backup files is renamed to increment the suffix (.1 becomes .2, etc.) and the .6 file is erased.

Obviously this example sets the log length much too small as an extreme example. You would want to set maxBytes to an appropriate value.

Use of alternative formatting styles
When logging was added to the Python standard library, the only way of formatting messages with variable content was to use the %-formatting method. Since then, Python has gained two new formatting approaches: string.Template (added in Python 2.4) and str.format() (added in Python 2.6).

Logging (as of 3.2) provides improved support for these two additional formatting styles. The Formatter class been enhanced to take an additional, optional keyword parameter named style. This defaults to '%', but other possible values are '{' and '$', which correspond to the other two formatting styles. Backwards compatibility is maintained by default (as you would expect), but by explicitly specifying a style parameter, you get the ability to specify format strings which work with str.format() or string.Template. Here’s an example console session to show the possibilities:

>>>
>>> import logging
>>> root = logging.getLogger()
>>> root.setLevel(logging.DEBUG)
>>> handler = logging.StreamHandler()
>>> bf = logging.Formatter('{asctime} {name} {levelname:8s} {message}',
...                        style='{')
>>> handler.setFormatter(bf)
>>> root.addHandler(handler)
>>> logger = logging.getLogger('foo.bar')
>>> logger.debug('This is a DEBUG message')
2010-10-28 15:11:55,341 foo.bar DEBUG    This is a DEBUG message
>>> logger.critical('This is a CRITICAL message')
2010-10-28 15:12:11,526 foo.bar CRITICAL This is a CRITICAL message
>>> df = logging.Formatter('$asctime $name ${levelname} $message',
...                        style='$')
>>> handler.setFormatter(df)
>>> logger.debug('This is a DEBUG message')
2010-10-28 15:13:06,924 foo.bar DEBUG This is a DEBUG message
>>> logger.critical('This is a CRITICAL message')
2010-10-28 15:13:11,494 foo.bar CRITICAL This is a CRITICAL message
>>>
Note that the formatting of logging messages for final output to logs is completely independent of how an individual logging message is constructed. That can still use %-formatting, as shown here:

>>>
>>> logger.error('This is an%s %s %s', 'other,', 'ERROR,', 'message')
2010-10-28 15:19:29,833 foo.bar ERROR This is another, ERROR, message
>>>
Logging calls (logger.debug(), logger.info() etc.) only take positional parameters for the actual logging message itself, with keyword parameters used only for determining options for how to handle the actual logging call (e.g. the exc_info keyword parameter to indicate that traceback information should be logged, or the extra keyword parameter to indicate additional contextual information to be added to the log). So you cannot directly make logging calls using str.format() or string.Template syntax, because internally the logging package uses %-formatting to merge the format string and the variable arguments. There would be no changing this while preserving backward compatibility, since all logging calls which are out there in existing code will be using %-format strings.

There is, however, a way that you can use {}- and $- formatting to construct your individual log messages. Recall that for a message you can use an arbitrary object as a message format string, and that the logging package will call str() on that object to get the actual format string. Consider the following two classes:

class BraceMessage:
    def __init__(self, fmt, /, *args, **kwargs):
        self.fmt = fmt
        self.args = args
        self.kwargs = kwargs

    def __str__(self):
        return self.fmt.format(*self.args, **self.kwargs)

class DollarMessage:
    def __init__(self, fmt, /, **kwargs):
        self.fmt = fmt
        self.kwargs = kwargs

    def __str__(self):
        from string import Template
        return Template(self.fmt).substitute(**self.kwargs)
Either of these can be used in place of a format string, to allow {}- or $-formatting to be used to build the actual “message” part which appears in the formatted log output in place of “%(message)s” or “{message}” or “$message”. It’s a little unwieldy to use the class names whenever you want to log something, but it’s quite palatable if you use an alias such as __ (double underscore — not to be confused with _, the single underscore used as a synonym/alias for gettext.gettext() or its brethren).

The above classes are not included in Python, though they’re easy enough to copy and paste into your own code. They can be used as follows (assuming that they’re declared in a module called wherever):

>>>
>>> from wherever import BraceMessage as __
>>> print(__('Message with {0} {name}', 2, name='placeholders'))
Message with 2 placeholders
>>> class Point: pass
...
>>> p = Point()
>>> p.x = 0.5
>>> p.y = 0.5
>>> print(__('Message with coordinates: ({point.x:.2f}, {point.y:.2f})',
...       point=p))
Message with coordinates: (0.50, 0.50)
>>> from wherever import DollarMessage as __
>>> print(__('Message with $num $what', num=2, what='placeholders'))
Message with 2 placeholders
>>>
While the above examples use print() to show how the formatting works, you would of course use logger.debug() or similar to actually log using this approach.

One thing to note is that you pay no significant performance penalty with this approach: the actual formatting happens not when you make the logging call, but when (and if) the logged message is actually about to be output to a log by a handler. So the only slightly unusual thing which might trip you up is that the parentheses go around the format string and the arguments, not just the format string. That’s because the __ notation is just syntax sugar for a constructor call to one of the XXXMessage classes.

If you prefer, you can use a LoggerAdapter to achieve a similar effect to the above, as in the following example:

import logging

class Message:
    def __init__(self, fmt, args):
        self.fmt = fmt
        self.args = args

    def __str__(self):
        return self.fmt.format(*self.args)

class StyleAdapter(logging.LoggerAdapter):
    def __init__(self, logger, extra=None):
        super().__init__(logger, extra or {})

    def log(self, level, msg, /, *args, **kwargs):
        if self.isEnabledFor(level):
            msg, kwargs = self.process(msg, kwargs)
            self.logger._log(level, Message(msg, args), (), **kwargs)

logger = StyleAdapter(logging.getLogger(__name__))

def main():
    logger.debug('Hello, {}', 'world!')

if __name__ == '__main__':
    logging.basicConfig(level=logging.DEBUG)
    main()
The above script should log the message Hello, world! when run with Python 3.2 or later.

Customizing LogRecord
Every logging event is represented by a LogRecord instance. When an event is logged and not filtered out by a logger’s level, a LogRecord is created, populated with information about the event and then passed to the handlers for that logger (and its ancestors, up to and including the logger where further propagation up the hierarchy is disabled). Before Python 3.2, there were only two places where this creation was done:

Logger.makeRecord(), which is called in the normal process of logging an event. This invoked LogRecord directly to create an instance.

makeLogRecord(), which is called with a dictionary containing attributes to be added to the LogRecord. This is typically invoked when a suitable dictionary has been received over the network (e.g. in pickle form via a SocketHandler, or in JSON form via an HTTPHandler).

This has usually meant that if you need to do anything special with a LogRecord, you’ve had to do one of the following.

Create your own Logger subclass, which overrides Logger.makeRecord(), and set it using setLoggerClass() before any loggers that you care about are instantiated.

Add a Filter to a logger or handler, which does the necessary special manipulation you need when its filter() method is called.

The first approach would be a little unwieldy in the scenario where (say) several different libraries wanted to do different things. Each would attempt to set its own Logger subclass, and the one which did this last would win.

The second approach works reasonably well for many cases, but does not allow you to e.g. use a specialized subclass of LogRecord. Library developers can set a suitable filter on their loggers, but they would have to remember to do this every time they introduced a new logger (which they would do simply by adding new packages or modules and doing

logger = logging.getLogger(__name__)
at module level). It’s probably one too many things to think about. Developers could also add the filter to a NullHandler attached to their top-level logger, but this would not be invoked if an application developer attached a handler to a lower-level library logger — so output from that handler would not reflect the intentions of the library developer.

In Python 3.2 and later, LogRecord creation is done through a factory, which you can specify. The factory is just a callable you can set with setLogRecordFactory(), and interrogate with getLogRecordFactory(). The factory is invoked with the same signature as the LogRecord constructor, as LogRecord is the default setting for the factory.

This approach allows a custom factory to control all aspects of LogRecord creation. For example, you could return a subclass, or just add some additional attributes to the record once created, using a pattern similar to this:

old_factory = logging.getLogRecordFactory()

def record_factory(*args, **kwargs):
    record = old_factory(*args, **kwargs)
    record.custom_attribute = 0xdecafbad
    return record

logging.setLogRecordFactory(record_factory)
This pattern allows different libraries to chain factories together, and as long as they don’t overwrite each other’s attributes or unintentionally overwrite the attributes provided as standard, there should be no surprises. However, it should be borne in mind that each link in the chain adds run-time overhead to all logging operations, and the technique should only be used when the use of a Filter does not provide the desired result.

Subclassing QueueHandler - a ZeroMQ example
You can use a QueueHandler subclass to send messages to other kinds of queues, for example a ZeroMQ ‘publish’ socket. In the example below,the socket is created separately and passed to the handler (as its ‘queue’):

import zmq   # using pyzmq, the Python binding for ZeroMQ
import json  # for serializing records portably

ctx = zmq.Context()
sock = zmq.Socket(ctx, zmq.PUB)  # or zmq.PUSH, or other suitable value
sock.bind('tcp://*:5556')        # or wherever

class ZeroMQSocketHandler(QueueHandler):
    def enqueue(self, record):
        self.queue.send_json(record.__dict__)


handler = ZeroMQSocketHandler(sock)
Of course there are other ways of organizing this, for example passing in the data needed by the handler to create the socket:

class ZeroMQSocketHandler(QueueHandler):
    def __init__(self, uri, socktype=zmq.PUB, ctx=None):
        self.ctx = ctx or zmq.Context()
        socket = zmq.Socket(self.ctx, socktype)
        socket.bind(uri)
        super().__init__(socket)

    def enqueue(self, record):
        self.queue.send_json(record.__dict__)

    def close(self):
        self.queue.close()
Subclassing QueueListener - a ZeroMQ example
You can also subclass QueueListener to get messages from other kinds of queues, for example a ZeroMQ ‘subscribe’ socket. Here’s an example:

class ZeroMQSocketListener(QueueListener):
    def __init__(self, uri, /, *handlers, **kwargs):
        self.ctx = kwargs.get('ctx') or zmq.Context()
        socket = zmq.Socket(self.ctx, zmq.SUB)
        socket.setsockopt_string(zmq.SUBSCRIBE, '')  # subscribe to everything
        socket.connect(uri)
        super().__init__(socket, *handlers, **kwargs)

    def dequeue(self):
        msg = self.queue.recv_json()
        return logging.makeLogRecord(msg)
See also
Module logging
API reference for the logging module.

Module logging.config
Configuration API for the logging module.

Module logging.handlers
Useful handlers included with the logging module.

A basic logging tutorial

A more advanced logging tutorial

An example dictionary-based configuration
Below is an example of a logging configuration dictionary - it’s taken from the documentation on the Django project. This dictionary is passed to dictConfig() to put the configuration into effect:

LOGGING = {
    'version': 1,
    'disable_existing_loggers': True,
    'formatters': {
        'verbose': {
            'format': '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s'
        },
        'simple': {
            'format': '%(levelname)s %(message)s'
        },
    },
    'filters': {
        'special': {
            '()': 'project.logging.SpecialFilter',
            'foo': 'bar',
        }
    },
    'handlers': {
        'null': {
            'level':'DEBUG',
            'class':'django.utils.log.NullHandler',
        },
        'console':{
            'level':'DEBUG',
            'class':'logging.StreamHandler',
            'formatter': 'simple'
        },
        'mail_admins': {
            'level': 'ERROR',
            'class': 'django.utils.log.AdminEmailHandler',
            'filters': ['special']
        }
    },
    'loggers': {
        'django': {
            'handlers':['null'],
            'propagate': True,
            'level':'INFO',
        },
        'django.request': {
            'handlers': ['mail_admins'],
            'level': 'ERROR',
            'propagate': False,
        },
        'myproject.custom': {
            'handlers': ['console', 'mail_admins'],
            'level': 'INFO',
            'filters': ['special']
        }
    }
}
For more information about this configuration, you can see the relevant section of the Django documentation.

Using a rotator and namer to customize log rotation processing
An example of how you can define a namer and rotator is given in the following snippet, which shows zlib-based compression of the log file:

def namer(name):
    return name + ".gz"

def rotator(source, dest):
    with open(source, "rb") as sf:
        data = sf.read()
        compressed = zlib.compress(data, 9)
        with open(dest, "wb") as df:
            df.write(compressed)
    os.remove(source)

rh = logging.handlers.RotatingFileHandler(...)
rh.rotator = rotator
rh.namer = namer
These are not “true” .gz files, as they are bare compressed data, with no “container” such as you’d find in an actual gzip file. This snippet is just for illustration purposes.

A more elaborate multiprocessing example
The following working example shows how logging can be used with multiprocessing using configuration files. The configurations are fairly simple, but serve to illustrate how more complex ones could be implemented in a real multiprocessing scenario.

In the example, the main process spawns a listener process and some worker processes. Each of the main process, the listener and the workers have three separate configurations (the workers all share the same configuration). We can see logging in the main process, how the workers log to a QueueHandler and how the listener implements a QueueListener and a more complex logging configuration, and arranges to dispatch events received via the queue to the handlers specified in the configuration. Note that these configurations are purely illustrative, but you should be able to adapt this example to your own scenario.

Here’s the script - the docstrings and the comments hopefully explain how it works:

import logging
import logging.config
import logging.handlers
from multiprocessing import Process, Queue, Event, current_process
import os
import random
import time

class MyHandler:
    """
    A simple handler for logging events. It runs in the listener process and
    dispatches events to loggers based on the name in the received record,
    which then get dispatched, by the logging system, to the handlers
    configured for those loggers.
    """

    def handle(self, record):
        if record.name == "root":
            logger = logging.getLogger()
        else:
            logger = logging.getLogger(record.name)

        if logger.isEnabledFor(record.levelno):
            # The process name is transformed just to show that it's the listener
            # doing the logging to files and console
            record.processName = '%s (for %s)' % (current_process().name, record.processName)
            logger.handle(record)

def listener_process(q, stop_event, config):
    """
    This could be done in the main process, but is just done in a separate
    process for illustrative purposes.

    This initialises logging according to the specified configuration,
    starts the listener and waits for the main process to signal completion
    via the event. The listener is then stopped, and the process exits.
    """
    logging.config.dictConfig(config)
    listener = logging.handlers.QueueListener(q, MyHandler())
    listener.start()
    if os.name == 'posix':
        # On POSIX, the setup logger will have been configured in the
        # parent process, but should have been disabled following the
        # dictConfig call.
        # On Windows, since fork isn't used, the setup logger won't
        # exist in the child, so it would be created and the message
        # would appear - hence the "if posix" clause.
        logger = logging.getLogger('setup')
        logger.critical('Should not appear, because of disabled logger ...')
    stop_event.wait()
    listener.stop()

def worker_process(config):
    """
    A number of these are spawned for the purpose of illustration. In
    practice, they could be a heterogeneous bunch of processes rather than
    ones which are identical to each other.

    This initialises logging according to the specified configuration,
    and logs a hundred messages with random levels to randomly selected
    loggers.

    A small sleep is added to allow other processes a chance to run. This
    is not strictly needed, but it mixes the output from the different
    processes a bit more than if it's left out.
    """
    logging.config.dictConfig(config)
    levels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,
              logging.CRITICAL]
    loggers = ['foo', 'foo.bar', 'foo.bar.baz',
               'spam', 'spam.ham', 'spam.ham.eggs']
    if os.name == 'posix':
        # On POSIX, the setup logger will have been configured in the
        # parent process, but should have been disabled following the
        # dictConfig call.
        # On Windows, since fork isn't used, the setup logger won't
        # exist in the child, so it would be created and the message
        # would appear - hence the "if posix" clause.
        logger = logging.getLogger('setup')
        logger.critical('Should not appear, because of disabled logger ...')
    for i in range(100):
        lvl = random.choice(levels)
        logger = logging.getLogger(random.choice(loggers))
        logger.log(lvl, 'Message no. %d', i)
        time.sleep(0.01)

def main():
    q = Queue()
    # The main process gets a simple configuration which prints to the console.
    config_initial = {
        'version': 1,
        'handlers': {
            'console': {
                'class': 'logging.StreamHandler',
                'level': 'INFO'
            }
        },
        'root': {
            'handlers': ['console'],
            'level': 'DEBUG'
        }
    }
    # The worker process configuration is just a QueueHandler attached to the
    # root logger, which allows all messages to be sent to the queue.
    # We disable existing loggers to disable the "setup" logger used in the
    # parent process. This is needed on POSIX because the logger will
    # be there in the child following a fork().
    config_worker = {
        'version': 1,
        'disable_existing_loggers': True,
        'handlers': {
            'queue': {
                'class': 'logging.handlers.QueueHandler',
                'queue': q
            }
        },
        'root': {
            'handlers': ['queue'],
            'level': 'DEBUG'
        }
    }
    # The listener process configuration shows that the full flexibility of
    # logging configuration is available to dispatch events to handlers however
    # you want.
    # We disable existing loggers to disable the "setup" logger used in the
    # parent process. This is needed on POSIX because the logger will
    # be there in the child following a fork().
    config_listener = {
        'version': 1,
        'disable_existing_loggers': True,
        'formatters': {
            'detailed': {
                'class': 'logging.Formatter',
                'format': '%(asctime)s %(name)-15s %(levelname)-8s %(processName)-10s %(message)s'
            },
            'simple': {
                'class': 'logging.Formatter',
                'format': '%(name)-15s %(levelname)-8s %(processName)-10s %(message)s'
            }
        },
        'handlers': {
            'console': {
                'class': 'logging.StreamHandler',
                'formatter': 'simple',
                'level': 'INFO'
            },
            'file': {
                'class': 'logging.FileHandler',
                'filename': 'mplog.log',
                'mode': 'w',
                'formatter': 'detailed'
            },
            'foofile': {
                'class': 'logging.FileHandler',
                'filename': 'mplog-foo.log',
                'mode': 'w',
                'formatter': 'detailed'
            },
            'errors': {
                'class': 'logging.FileHandler',
                'filename': 'mplog-errors.log',
                'mode': 'w',
                'formatter': 'detailed',
                'level': 'ERROR'
            }
        },
        'loggers': {
            'foo': {
                'handlers': ['foofile']
            }
        },
        'root': {
            'handlers': ['console', 'file', 'errors'],
            'level': 'DEBUG'
        }
    }
    # Log some initial events, just to show that logging in the parent works
    # normally.
    logging.config.dictConfig(config_initial)
    logger = logging.getLogger('setup')
    logger.info('About to create workers ...')
    workers = []
    for i in range(5):
        wp = Process(target=worker_process, name='worker %d' % (i + 1),
                     args=(config_worker,))
        workers.append(wp)
        wp.start()
        logger.info('Started worker: %s', wp.name)
    logger.info('About to create listener ...')
    stop_event = Event()
    lp = Process(target=listener_process, name='listener',
                 args=(q, stop_event, config_listener))
    lp.start()
    logger.info('Started listener')
    # We now hang around for the workers to finish their work.
    for wp in workers:
        wp.join()
    # Workers all done, listening can now stop.
    # Logging in the parent still works normally.
    logger.info('Telling listener to stop ...')
    stop_event.set()
    lp.join()
    logger.info('All done.')

if __name__ == '__main__':
    main()
Inserting a BOM into messages sent to a SysLogHandler
RFC 5424 requires that a Unicode message be sent to a syslog daemon as a set of bytes which have the following structure: an optional pure-ASCII component, followed by a UTF-8 Byte Order Mark (BOM), followed by Unicode encoded using UTF-8. (See the relevant section of the specification.)

In Python 3.1, code was added to SysLogHandler to insert a BOM into the message, but unfortunately, it was implemented incorrectly, with the BOM appearing at the beginning of the message and hence not allowing any pure-ASCII component to appear before it.

As this behaviour is broken, the incorrect BOM insertion code is being removed from Python 3.2.4 and later. However, it is not being replaced, and if you want to produce RFC 5424-compliant messages which include a BOM, an optional pure-ASCII sequence before it and arbitrary Unicode after it, encoded using UTF-8, then you need to do the following:

Attach a Formatter instance to your SysLogHandler instance, with a format string such as:

'ASCII section\ufeffUnicode section'
The Unicode code point U+FEFF, when encoded using UTF-8, will be encoded as a UTF-8 BOM – the byte-string b'\xef\xbb\xbf'.

Replace the ASCII section with whatever placeholders you like, but make sure that the data that appears in there after substitution is always ASCII (that way, it will remain unchanged after UTF-8 encoding).

Replace the Unicode section with whatever placeholders you like; if the data which appears there after substitution contains characters outside the ASCII range, that’s fine – it will be encoded using UTF-8.

The formatted message will be encoded using UTF-8 encoding by SysLogHandler. If you follow the above rules, you should be able to produce RFC 5424-compliant messages. If you don’t, logging may not complain, but your messages will not be RFC 5424-compliant, and your syslog daemon may complain.

Implementing structured logging
Although most logging messages are intended for reading by humans, and thus not readily machine-parseable, there might be circumstances where you want to output messages in a structured format which is capable of being parsed by a program (without needing complex regular expressions to parse the log message). This is straightforward to achieve using the logging package. There are a number of ways in which this could be achieved, but the following is a simple approach which uses JSON to serialise the event in a machine-parseable manner:

import json
import logging

class StructuredMessage:
    def __init__(self, message, /, **kwargs):
        self.message = message
        self.kwargs = kwargs

    def __str__(self):
        return '%s >>> %s' % (self.message, json.dumps(self.kwargs))

_ = StructuredMessage   # optional, to improve readability

logging.basicConfig(level=logging.INFO, format='%(message)s')
logging.info(_('message 1', foo='bar', bar='baz', num=123, fnum=123.456))
If the above script is run, it prints:

message 1 >>> {"fnum": 123.456, "num": 123, "bar": "baz", "foo": "bar"}
Note that the order of items might be different according to the version of Python used.

If you need more specialised processing, you can use a custom JSON encoder, as in the following complete example:

import json
import logging


class Encoder(json.JSONEncoder):
    def default(self, o):
        if isinstance(o, set):
            return tuple(o)
        elif isinstance(o, str):
            return o.encode('unicode_escape').decode('ascii')
        return super().default(o)

class StructuredMessage:
    def __init__(self, message, /, **kwargs):
        self.message = message
        self.kwargs = kwargs

    def __str__(self):
        s = Encoder().encode(self.kwargs)
        return '%s >>> %s' % (self.message, s)

_ = StructuredMessage   # optional, to improve readability

def main():
    logging.basicConfig(level=logging.INFO, format='%(message)s')
    logging.info(_('message 1', set_value={1, 2, 3}, snowman='\u2603'))

if __name__ == '__main__':
    main()
When the above script is run, it prints:

message 1 >>> {"snowman": "\u2603", "set_value": [1, 2, 3]}
Note that the order of items might be different according to the version of Python used.

Customizing handlers with dictConfig()
There are times when you want to customize logging handlers in particular ways, and if you use dictConfig() you may be able to do this without subclassing. As an example, consider that you may want to set the ownership of a log file. On POSIX, this is easily done using shutil.chown(), but the file handlers in the stdlib don’t offer built-in support. You can customize handler creation using a plain function such as:

def owned_file_handler(filename, mode='a', encoding=None, owner=None):
    if owner:
        if not os.path.exists(filename):
            open(filename, 'a').close()
        shutil.chown(filename, *owner)
    return logging.FileHandler(filename, mode, encoding)
You can then specify, in a logging configuration passed to dictConfig(), that a logging handler be created by calling this function:

LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'default': {
            'format': '%(asctime)s %(levelname)s %(name)s %(message)s'
        },
    },
    'handlers': {
        'file':{
            # The values below are popped from this dictionary and
            # used to create the handler, set the handler's level and
            # its formatter.
            '()': owned_file_handler,
            'level':'DEBUG',
            'formatter': 'default',
            # The values below are passed to the handler creator callable
            # as keyword arguments.
            'owner': ['pulse', 'pulse'],
            'filename': 'chowntest.log',
            'mode': 'w',
            'encoding': 'utf-8',
        },
    },
    'root': {
        'handlers': ['file'],
        'level': 'DEBUG',
    },
}
In this example I am setting the ownership using the pulse user and group, just for the purposes of illustration. Putting it together into a working script, chowntest.py:

import logging, logging.config, os, shutil

def owned_file_handler(filename, mode='a', encoding=None, owner=None):
    if owner:
        if not os.path.exists(filename):
            open(filename, 'a').close()
        shutil.chown(filename, *owner)
    return logging.FileHandler(filename, mode, encoding)

LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'default': {
            'format': '%(asctime)s %(levelname)s %(name)s %(message)s'
        },
    },
    'handlers': {
        'file':{
            # The values below are popped from this dictionary and
            # used to create the handler, set the handler's level and
            # its formatter.
            '()': owned_file_handler,
            'level':'DEBUG',
            'formatter': 'default',
            # The values below are passed to the handler creator callable
            # as keyword arguments.
            'owner': ['pulse', 'pulse'],
            'filename': 'chowntest.log',
            'mode': 'w',
            'encoding': 'utf-8',
        },
    },
    'root': {
        'handlers': ['file'],
        'level': 'DEBUG',
    },
}

logging.config.dictConfig(LOGGING)
logger = logging.getLogger('mylogger')
logger.debug('A debug message')
To run this, you will probably need to run as root:

$ sudo python3.3 chowntest.py
$ cat chowntest.log
2013-11-05 09:34:51,128 DEBUG mylogger A debug message
$ ls -l chowntest.log
-rw-r--r-- 1 pulse pulse 55 2013-11-05 09:34 chowntest.log
Note that this example uses Python 3.3 because that’s where shutil.chown() makes an appearance. This approach should work with any Python version that supports dictConfig() - namely, Python 2.7, 3.2 or later. With pre-3.3 versions, you would need to implement the actual ownership change using e.g. os.chown().

In practice, the handler-creating function may be in a utility module somewhere in your project. Instead of the line in the configuration:

'()': owned_file_handler,
you could use e.g.:

'()': 'ext://project.util.owned_file_handler',
where project.util can be replaced with the actual name of the package where the function resides. In the above working script, using 'ext://__main__.owned_file_handler' should work. Here, the actual callable is resolved by dictConfig() from the ext:// specification.

This example hopefully also points the way to how you could implement other types of file change - e.g. setting specific POSIX permission bits - in the same way, using os.chmod().

Of course, the approach could also be extended to types of handler other than a FileHandler - for example, one of the rotating file handlers, or a different type of handler altogether.

Using particular formatting styles throughout your application
In Python 3.2, the Formatter gained a style keyword parameter which, while defaulting to % for backward compatibility, allowed the specification of { or $ to support the formatting approaches supported by str.format() and string.Template. Note that this governs the formatting of logging messages for final output to logs, and is completely orthogonal to how an individual logging message is constructed.

Logging calls (debug(), info() etc.) only take positional parameters for the actual logging message itself, with keyword parameters used only for determining options for how to handle the logging call (e.g. the exc_info keyword parameter to indicate that traceback information should be logged, or the extra keyword parameter to indicate additional contextual information to be added to the log). So you cannot directly make logging calls using str.format() or string.Template syntax, because internally the logging package uses %-formatting to merge the format string and the variable arguments. There would no changing this while preserving backward compatibility, since all logging calls which are out there in existing code will be using %-format strings.

There have been suggestions to associate format styles with specific loggers, but that approach also runs into backward compatibility problems because any existing code could be using a given logger name and using %-formatting.

For logging to work interoperably between any third-party libraries and your code, decisions about formatting need to be made at the level of the individual logging call. This opens up a couple of ways in which alternative formatting styles can be accommodated.

Using LogRecord factories
In Python 3.2, along with the Formatter changes mentioned above, the logging package gained the ability to allow users to set their own LogRecord subclasses, using the setLogRecordFactory() function. You can use this to set your own subclass of LogRecord, which does the Right Thing by overriding the getMessage() method. The base class implementation of this method is where the msg % args formatting happens, and where you can substitute your alternate formatting; however, you should be careful to support all formatting styles and allow %-formatting as the default, to ensure interoperability with other code. Care should also be taken to call str(self.msg), just as the base implementation does.

Refer to the reference documentation on setLogRecordFactory() and LogRecord for more information.

Using custom message objects
There is another, perhaps simpler way that you can use {}- and $- formatting to construct your individual log messages. You may recall (from Using arbitrary objects as messages) that when logging you can use an arbitrary object as a message format string, and that the logging package will call str() on that object to get the actual format string. Consider the following two classes:

class BraceMessage:
    def __init__(self, fmt, /, *args, **kwargs):
        self.fmt = fmt
        self.args = args
        self.kwargs = kwargs

    def __str__(self):
        return self.fmt.format(*self.args, **self.kwargs)

class DollarMessage:
    def __init__(self, fmt, /, **kwargs):
        self.fmt = fmt
        self.kwargs = kwargs

    def __str__(self):
        from string import Template
        return Template(self.fmt).substitute(**self.kwargs)
Either of these can be used in place of a format string, to allow {}- or $-formatting to be used to build the actual “message” part which appears in the formatted log output in place of “%(message)s” or “{message}” or “$message”. If you find it a little unwieldy to use the class names whenever you want to log something, you can make it more palatable if you use an alias such as M or _ for the message (or perhaps __, if you are using _ for localization).

Examples of this approach are given below. Firstly, formatting with str.format():

>>>
>>> __ = BraceMessage
>>> print(__('Message with {0} {1}', 2, 'placeholders'))
Message with 2 placeholders
>>> class Point: pass
...
>>> p = Point()
>>> p.x = 0.5
>>> p.y = 0.5
>>> print(__('Message with coordinates: ({point.x:.2f}, {point.y:.2f})', point=p))
Message with coordinates: (0.50, 0.50)
Secondly, formatting with string.Template:

>>>
>>> __ = DollarMessage
>>> print(__('Message with $num $what', num=2, what='placeholders'))
Message with 2 placeholders
>>>
One thing to note is that you pay no significant performance penalty with this approach: the actual formatting happens not when you make the logging call, but when (and if) the logged message is actually about to be output to a log by a handler. So the only slightly unusual thing which might trip you up is that the parentheses go around the format string and the arguments, not just the format string. That’s because the __ notation is just syntax sugar for a constructor call to one of the XXXMessage classes shown above.

Configuring filters with dictConfig()
You can configure filters using dictConfig(), though it might not be obvious at first glance how to do it (hence this recipe). Since Filter is the only filter class included in the standard library, and it is unlikely to cater to many requirements (it’s only there as a base class), you will typically need to define your own Filter subclass with an overridden filter() method. To do this, specify the () key in the configuration dictionary for the filter, specifying a callable which will be used to create the filter (a class is the most obvious, but you can provide any callable which returns a Filter instance). Here is a complete example:

import logging
import logging.config
import sys

class MyFilter(logging.Filter):
    def __init__(self, param=None):
        self.param = param

    def filter(self, record):
        if self.param is None:
            allow = True
        else:
            allow = self.param not in record.msg
        if allow:
            record.msg = 'changed: ' + record.msg
        return allow

LOGGING = {
    'version': 1,
    'filters': {
        'myfilter': {
            '()': MyFilter,
            'param': 'noshow',
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'filters': ['myfilter']
        }
    },
    'root': {
        'level': 'DEBUG',
        'handlers': ['console']
    },
}

if __name__ == '__main__':
    logging.config.dictConfig(LOGGING)
    logging.debug('hello')
    logging.debug('hello - noshow')
This example shows how you can pass configuration data to the callable which constructs the instance, in the form of keyword parameters. When run, the above script will print:

changed: hello
which shows that the filter is working as configured.

A couple of extra points to note:

If you can’t refer to the callable directly in the configuration (e.g. if it lives in a different module, and you can’t import it directly where the configuration dictionary is), you can use the form ext://... as described in Access to external objects. For example, you could have used the text 'ext://__main__.MyFilter' instead of MyFilter in the above example.

As well as for filters, this technique can also be used to configure custom handlers and formatters. See User-defined objects for more information on how logging supports using user-defined objects in its configuration, and see the other cookbook recipe Customizing handlers with dictConfig() above.

Customized exception formatting
There might be times when you want to do customized exception formatting - for argument’s sake, let’s say you want exactly one line per logged event, even when exception information is present. You can do this with a custom formatter class, as shown in the following example:

import logging

class OneLineExceptionFormatter(logging.Formatter):
    def formatException(self, exc_info):
        """
        Format an exception so that it prints on a single line.
        """
        result = super().formatException(exc_info)
        return repr(result)  # or format into one line however you want to

    def format(self, record):
        s = super().format(record)
        if record.exc_text:
            s = s.replace('\n', '') + '|'
        return s

def configure_logging():
    fh = logging.FileHandler('output.txt', 'w')
    f = OneLineExceptionFormatter('%(asctime)s|%(levelname)s|%(message)s|',
                                  '%d/%m/%Y %H:%M:%S')
    fh.setFormatter(f)
    root = logging.getLogger()
    root.setLevel(logging.DEBUG)
    root.addHandler(fh)

def main():
    configure_logging()
    logging.info('Sample message')
    try:
        x = 1 / 0
    except ZeroDivisionError as e:
        logging.exception('ZeroDivisionError: %s', e)

if __name__ == '__main__':
    main()
When run, this produces a file with exactly two lines:

28/01/2015 07:21:23|INFO|Sample message|
28/01/2015 07:21:23|ERROR|ZeroDivisionError: integer division or modulo by zero|'Traceback (most recent call last):\n  File "logtest7.py", line 30, in main\n    x = 1 / 0\nZeroDivisionError: integer division or modulo by zero'|
While the above treatment is simplistic, it points the way to how exception information can be formatted to your liking. The traceback module may be helpful for more specialized needs.

Speaking logging messages
There might be situations when it is desirable to have logging messages rendered in an audible rather than a visible format. This is easy to do if you have text-to-speech (TTS) functionality available in your system, even if it doesn’t have a Python binding. Most TTS systems have a command line program you can run, and this can be invoked from a handler using subprocess. It’s assumed here that TTS command line programs won’t expect to interact with users or take a long time to complete, and that the frequency of logged messages will be not so high as to swamp the user with messages, and that it’s acceptable to have the messages spoken one at a time rather than concurrently, The example implementation below waits for one message to be spoken before the next is processed, and this might cause other handlers to be kept waiting. Here is a short example showing the approach, which assumes that the espeak TTS package is available:

import logging
import subprocess
import sys

class TTSHandler(logging.Handler):
    def emit(self, record):
        msg = self.format(record)
        # Speak slowly in a female English voice
        cmd = ['espeak', '-s150', '-ven+f3', msg]
        p = subprocess.Popen(cmd, stdout=subprocess.PIPE,
                             stderr=subprocess.STDOUT)
        # wait for the program to finish
        p.communicate()

def configure_logging():
    h = TTSHandler()
    root = logging.getLogger()
    root.addHandler(h)
    # the default formatter just returns the message
    root.setLevel(logging.DEBUG)

def main():
    logging.info('Hello')
    logging.debug('Goodbye')

if __name__ == '__main__':
    configure_logging()
    sys.exit(main())
When run, this script should say “Hello” and then “Goodbye” in a female voice.

The above approach can, of course, be adapted to other TTS systems and even other systems altogether which can process messages via external programs run from a command line.

Buffering logging messages and outputting them conditionally
There might be situations where you want to log messages in a temporary area and only output them if a certain condition occurs. For example, you may want to start logging debug events in a function, and if the function completes without errors, you don’t want to clutter the log with the collected debug information, but if there is an error, you want all the debug information to be output as well as the error.

Here is an example which shows how you could do this using a decorator for your functions where you want logging to behave this way. It makes use of the logging.handlers.MemoryHandler, which allows buffering of logged events until some condition occurs, at which point the buffered events are flushed - passed to another handler (the target handler) for processing. By default, the MemoryHandler flushed when its buffer gets filled up or an event whose level is greater than or equal to a specified threshold is seen. You can use this recipe with a more specialised subclass of MemoryHandler if you want custom flushing behavior.

The example script has a simple function, foo, which just cycles through all the logging levels, writing to sys.stderr to say what level it’s about to log at, and then actually logging a message at that level. You can pass a parameter to foo which, if true, will log at ERROR and CRITICAL levels - otherwise, it only logs at DEBUG, INFO and WARNING levels.

The script just arranges to decorate foo with a decorator which will do the conditional logging that’s required. The decorator takes a logger as a parameter and attaches a memory handler for the duration of the call to the decorated function. The decorator can be additionally parameterised using a target handler, a level at which flushing should occur, and a capacity for the buffer (number of records buffered). These default to a StreamHandler which writes to sys.stderr, logging.ERROR and 100 respectively.

Here’s the script:

import logging
from logging.handlers import MemoryHandler
import sys

logger = logging.getLogger(__name__)
logger.addHandler(logging.NullHandler())

def log_if_errors(logger, target_handler=None, flush_level=None, capacity=None):
    if target_handler is None:
        target_handler = logging.StreamHandler()
    if flush_level is None:
        flush_level = logging.ERROR
    if capacity is None:
        capacity = 100
    handler = MemoryHandler(capacity, flushLevel=flush_level, target=target_handler)

    def decorator(fn):
        def wrapper(*args, **kwargs):
            logger.addHandler(handler)
            try:
                return fn(*args, **kwargs)
            except Exception:
                logger.exception('call failed')
                raise
            finally:
                super(MemoryHandler, handler).flush()
                logger.removeHandler(handler)
        return wrapper

    return decorator

def write_line(s):
    sys.stderr.write('%s\n' % s)

def foo(fail=False):
    write_line('about to log at DEBUG ...')
    logger.debug('Actually logged at DEBUG')
    write_line('about to log at INFO ...')
    logger.info('Actually logged at INFO')
    write_line('about to log at WARNING ...')
    logger.warning('Actually logged at WARNING')
    if fail:
        write_line('about to log at ERROR ...')
        logger.error('Actually logged at ERROR')
        write_line('about to log at CRITICAL ...')
        logger.critical('Actually logged at CRITICAL')
    return fail

decorated_foo = log_if_errors(logger)(foo)

if __name__ == '__main__':
    logger.setLevel(logging.DEBUG)
    write_line('Calling undecorated foo with False')
    assert not foo(False)
    write_line('Calling undecorated foo with True')
    assert foo(True)
    write_line('Calling decorated foo with False')
    assert not decorated_foo(False)
    write_line('Calling decorated foo with True')
    assert decorated_foo(True)
When this script is run, the following output should be observed:

Calling undecorated foo with False
about to log at DEBUG ...
about to log at INFO ...
about to log at WARNING ...
Calling undecorated foo with True
about to log at DEBUG ...
about to log at INFO ...
about to log at WARNING ...
about to log at ERROR ...
about to log at CRITICAL ...
Calling decorated foo with False
about to log at DEBUG ...
about to log at INFO ...
about to log at WARNING ...
Calling decorated foo with True
about to log at DEBUG ...
about to log at INFO ...
about to log at WARNING ...
about to log at ERROR ...
Actually logged at DEBUG
Actually logged at INFO
Actually logged at WARNING
Actually logged at ERROR
about to log at CRITICAL ...
Actually logged at CRITICAL
As you can see, actual logging output only occurs when an event is logged whose severity is ERROR or greater, but in that case, any previous events at lower severities are also logged.

You can of course use the conventional means of decoration:

@log_if_errors(logger)
def foo(fail=False):
    ...
Sending logging messages to email, with buffering
To illustrate how you can send log messages via email, so that a set number of messages are sent per email, you can subclass BufferingHandler. In the following example, which you can adapt to suit your specific needs, a simple test harness is provided which allows you to run the script with command line arguments specifying what you typically need to send things via SMTP. (Run the downloaded script with the -h argument to see the required and optional arguments.)

import logging
import logging.handlers
import smtplib

class BufferingSMTPHandler(logging.handlers.BufferingHandler):
    def __init__(self, mailhost, port, username, password, fromaddr, toaddrs,
                 subject, capacity):
        logging.handlers.BufferingHandler.__init__(self, capacity)
        self.mailhost = mailhost
        self.mailport = port
        self.username = username
        self.password = password
        self.fromaddr = fromaddr
        if isinstance(toaddrs, str):
            toaddrs = [toaddrs]
        self.toaddrs = toaddrs
        self.subject = subject
        self.setFormatter(logging.Formatter("%(asctime)s %(levelname)-5s %(message)s"))

    def flush(self):
        if len(self.buffer) > 0:
            try:
                smtp = smtplib.SMTP(self.mailhost, self.mailport)
                smtp.starttls()
                smtp.login(self.username, self.password)
                msg = "From: %s\r\nTo: %s\r\nSubject: %s\r\n\r\n" % (self.fromaddr, ','.join(self.toaddrs), self.subject)
                for record in self.buffer:
                    s = self.format(record)
                    msg = msg + s + "\r\n"
                smtp.sendmail(self.fromaddr, self.toaddrs, msg)
                smtp.quit()
            except Exception:
                if logging.raiseExceptions:
                    raise
            self.buffer = []

if __name__ == '__main__':
    import argparse

    ap = argparse.ArgumentParser()
    aa = ap.add_argument
    aa('host', metavar='HOST', help='SMTP server')
    aa('--port', '-p', type=int, default=587, help='SMTP port')
    aa('user', metavar='USER', help='SMTP username')
    aa('password', metavar='PASSWORD', help='SMTP password')
    aa('to', metavar='TO', help='Addressee for emails')
    aa('sender', metavar='SENDER', help='Sender email address')
    aa('--subject', '-s',
       default='Test Logging email from Python logging module (buffering)',
       help='Subject of email')
    options = ap.parse_args()
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    h = BufferingSMTPHandler(options.host, options.port, options.user,
                             options.password, options.sender,
                             options.to, options.subject, 10)
    logger.addHandler(h)
    for i in range(102):
        logger.info("Info index = %d", i)
    h.flush()
    h.close()
If you run this script and your SMTP server is correctly set up, you should find that it sends eleven emails to the addressee you specify. The first ten emails will each have ten log messages, and the eleventh will have two messages. That makes up 102 messages as specified in the script.

Formatting times using UTC (GMT) via configuration
Sometimes you want to format times using UTC, which can be done using a class such as UTCFormatter, shown below:

import logging
import time

class UTCFormatter(logging.Formatter):
    converter = time.gmtime
and you can then use the UTCFormatter in your code instead of Formatter. If you want to do that via configuration, you can use the dictConfig() API with an approach illustrated by the following complete example:

import logging
import logging.config
import time

class UTCFormatter(logging.Formatter):
    converter = time.gmtime

LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'utc': {
            '()': UTCFormatter,
            'format': '%(asctime)s %(message)s',
        },
        'local': {
            'format': '%(asctime)s %(message)s',
        }
    },
    'handlers': {
        'console1': {
            'class': 'logging.StreamHandler',
            'formatter': 'utc',
        },
        'console2': {
            'class': 'logging.StreamHandler',
            'formatter': 'local',
        },
    },
    'root': {
        'handlers': ['console1', 'console2'],
   }
}

if __name__ == '__main__':
    logging.config.dictConfig(LOGGING)
    logging.warning('The local time is %s', time.asctime())
When this script is run, it should print something like:

2015-10-17 12:53:29,501 The local time is Sat Oct 17 13:53:29 2015
2015-10-17 13:53:29,501 The local time is Sat Oct 17 13:53:29 2015
showing how the time is formatted both as local time and UTC, one for each handler.

Using a context manager for selective logging
There are times when it would be useful to temporarily change the logging configuration and revert it back after doing something. For this, a context manager is the most obvious way of saving and restoring the logging context. Here is a simple example of such a context manager, which allows you to optionally change the logging level and add a logging handler purely in the scope of the context manager:

import logging
import sys

class LoggingContext:
    def __init__(self, logger, level=None, handler=None, close=True):
        self.logger = logger
        self.level = level
        self.handler = handler
        self.close = close

    def __enter__(self):
        if self.level is not None:
            self.old_level = self.logger.level
            self.logger.setLevel(self.level)
        if self.handler:
            self.logger.addHandler(self.handler)

    def __exit__(self, et, ev, tb):
        if self.level is not None:
            self.logger.setLevel(self.old_level)
        if self.handler:
            self.logger.removeHandler(self.handler)
        if self.handler and self.close:
            self.handler.close()
        # implicit return of None => don't swallow exceptions
If you specify a level value, the logger’s level is set to that value in the scope of the with block covered by the context manager. If you specify a handler, it is added to the logger on entry to the block and removed on exit from the block. You can also ask the manager to close the handler for you on block exit - you could do this if you don’t need the handler any more.

To illustrate how it works, we can add the following block of code to the above:

if __name__ == '__main__':
    logger = logging.getLogger('foo')
    logger.addHandler(logging.StreamHandler())
    logger.setLevel(logging.INFO)
    logger.info('1. This should appear just once on stderr.')
    logger.debug('2. This should not appear.')
    with LoggingContext(logger, level=logging.DEBUG):
        logger.debug('3. This should appear once on stderr.')
    logger.debug('4. This should not appear.')
    h = logging.StreamHandler(sys.stdout)
    with LoggingContext(logger, level=logging.DEBUG, handler=h, close=True):
        logger.debug('5. This should appear twice - once on stderr and once on stdout.')
    logger.info('6. This should appear just once on stderr.')
    logger.debug('7. This should not appear.')
We initially set the logger’s level to INFO, so message #1 appears and message #2 doesn’t. We then change the level to DEBUG temporarily in the following with block, and so message #3 appears. After the block exits, the logger’s level is restored to INFO and so message #4 doesn’t appear. In the next with block, we set the level to DEBUG again but also add a handler writing to sys.stdout. Thus, message #5 appears twice on the console (once via stderr and once via stdout). After the with statement’s completion, the status is as it was before so message #6 appears (like message #1) whereas message #7 doesn’t (just like message #2).

If we run the resulting script, the result is as follows:

$ python logctx.py
1. This should appear just once on stderr.
3. This should appear once on stderr.
5. This should appear twice - once on stderr and once on stdout.
5. This should appear twice - once on stderr and once on stdout.
6. This should appear just once on stderr.
If we run it again, but pipe stderr to /dev/null, we see the following, which is the only message written to stdout:

$ python logctx.py 2>/dev/null
5. This should appear twice - once on stderr and once on stdout.
Once again, but piping stdout to /dev/null, we get:

$ python logctx.py >/dev/null
1. This should appear just once on stderr.
3. This should appear once on stderr.
5. This should appear twice - once on stderr and once on stdout.
6. This should appear just once on stderr.
In this case, the message #5 printed to stdout doesn’t appear, as expected.

Of course, the approach described here can be generalised, for example to attach logging filters temporarily. Note that the above code works in Python 2 as well as Python 3.

A CLI application starter template
Here’s an example which shows how you can:

Use a logging level based on command-line arguments

Dispatch to multiple subcommands in separate files, all logging at the same level in a consistent way

Make use of simple, minimal configuration

Suppose we have a command-line application whose job is to stop, start or restart some services. This could be organised for the purposes of illustration as a file app.py that is the main script for the application, with individual commands implemented in start.py, stop.py and restart.py. Suppose further that we want to control the verbosity of the application via a command-line argument, defaulting to logging.INFO. Here’s one way that app.py could be written:

import argparse
import importlib
import logging
import os
import sys

def main(args=None):
    scriptname = os.path.basename(__file__)
    parser = argparse.ArgumentParser(scriptname)
    levels = ('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL')
    parser.add_argument('--log-level', default='INFO', choices=levels)
    subparsers = parser.add_subparsers(dest='command',
                                       help='Available commands:')
    start_cmd = subparsers.add_parser('start', help='Start a service')
    start_cmd.add_argument('name', metavar='NAME',
                           help='Name of service to start')
    stop_cmd = subparsers.add_parser('stop',
                                     help='Stop one or more services')
    stop_cmd.add_argument('names', metavar='NAME', nargs='+',
                          help='Name of service to stop')
    restart_cmd = subparsers.add_parser('restart',
                                        help='Restart one or more services')
    restart_cmd.add_argument('names', metavar='NAME', nargs='+',
                             help='Name of service to restart')
    options = parser.parse_args()
    # the code to dispatch commands could all be in this file. For the purposes
    # of illustration only, we implement each command in a separate module.
    try:
        mod = importlib.import_module(options.command)
        cmd = getattr(mod, 'command')
    except (ImportError, AttributeError):
        print('Unable to find the code for command \'%s\'' % options.command)
        return 1
    # Could get fancy here and load configuration from file or dictionary
    logging.basicConfig(level=options.log_level,
                        format='%(levelname)s %(name)s %(message)s')
    cmd(options)

if __name__ == '__main__':
    sys.exit(main())
And the start, stop and restart commands can be implemented in separate modules, like so for starting:

# start.py
import logging

logger = logging.getLogger(__name__)

def command(options):
    logger.debug('About to start %s', options.name)
    # actually do the command processing here ...
    logger.info('Started the \'%s\' service.', options.name)
and thus for stopping:

# stop.py
import logging

logger = logging.getLogger(__name__)

def command(options):
    n = len(options.names)
    if n == 1:
        plural = ''
        services = '\'%s\'' % options.names[0]
    else:
        plural = 's'
        services = ', '.join('\'%s\'' % name for name in options.names)
        i = services.rfind(', ')
        services = services[:i] + ' and ' + services[i + 2:]
    logger.debug('About to stop %s', services)
    # actually do the command processing here ...
    logger.info('Stopped the %s service%s.', services, plural)
and similarly for restarting:

# restart.py
import logging

logger = logging.getLogger(__name__)

def command(options):
    n = len(options.names)
    if n == 1:
        plural = ''
        services = '\'%s\'' % options.names[0]
    else:
        plural = 's'
        services = ', '.join('\'%s\'' % name for name in options.names)
        i = services.rfind(', ')
        services = services[:i] + ' and ' + services[i + 2:]
    logger.debug('About to restart %s', services)
    # actually do the command processing here ...
    logger.info('Restarted the %s service%s.', services, plural)
If we run this application with the default log level, we get output like this:

$ python app.py start foo
INFO start Started the 'foo' service.

$ python app.py stop foo bar
INFO stop Stopped the 'foo' and 'bar' services.

$ python app.py restart foo bar baz
INFO restart Restarted the 'foo', 'bar' and 'baz' services.
The first word is the logging level, and the second word is the module or package name of the place where the event was logged.

If we change the logging level, then we can change the information sent to the log. For example, if we want more information:

$ python app.py --log-level DEBUG start foo
DEBUG start About to start foo
INFO start Started the 'foo' service.

$ python app.py --log-level DEBUG stop foo bar
DEBUG stop About to stop 'foo' and 'bar'
INFO stop Stopped the 'foo' and 'bar' services.

$ python app.py --log-level DEBUG restart foo bar baz
DEBUG restart About to restart 'foo', 'bar' and 'baz'
INFO restart Restarted the 'foo', 'bar' and 'baz' services.
And if we want less:

$ python app.py --log-level WARNING start foo
$ python app.py --log-level WARNING stop foo bar
$ python app.py --log-level WARNING restart foo bar baz
In this case, the commands don’t print anything to the console, since nothing at WARNING level or above is logged by them.

A Qt GUI for logging
A question that comes up from time to time is about how to log to a GUI application. The Qt framework is a popular cross-platform UI framework with Python bindings using PySide2 or PyQt5 libraries.

The following example shows how to log to a Qt GUI. This introduces a simple QtHandler class which takes a callable, which should be a slot in the main thread that does GUI updates. A worker thread is also created to show how you can log to the GUI from both the UI itself (via a button for manual logging) as well as a worker thread doing work in the background (here, just logging messages at random levels with random short delays in between).

The worker thread is implemented using Qt’s QThread class rather than the threading module, as there are circumstances where one has to use QThread, which offers better integration with other Qt components.

The code should work with recent releases of either PySide2 or PyQt5. You should be able to adapt the approach to earlier versions of Qt. Please refer to the comments in the code snippet for more detailed information.

import datetime
import logging
import random
import sys
import time

# Deal with minor differences between PySide2 and PyQt5
try:
    from PySide2 import QtCore, QtGui, QtWidgets
    Signal = QtCore.Signal
    Slot = QtCore.Slot
except ImportError:
    from PyQt5 import QtCore, QtGui, QtWidgets
    Signal = QtCore.pyqtSignal
    Slot = QtCore.pyqtSlot


logger = logging.getLogger(__name__)


#
# Signals need to be contained in a QObject or subclass in order to be correctly
# initialized.
#
class Signaller(QtCore.QObject):
    signal = Signal(str, logging.LogRecord)

#
# Output to a Qt GUI is only supposed to happen on the main thread. So, this
# handler is designed to take a slot function which is set up to run in the main
# thread. In this example, the function takes a string argument which is a
# formatted log message, and the log record which generated it. The formatted
# string is just a convenience - you could format a string for output any way
# you like in the slot function itself.
#
# You specify the slot function to do whatever GUI updates you want. The handler
# doesn't know or care about specific UI elements.
#
class QtHandler(logging.Handler):
    def __init__(self, slotfunc, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.signaller = Signaller()
        self.signaller.signal.connect(slotfunc)

    def emit(self, record):
        s = self.format(record)
        self.signaller.signal.emit(s, record)

#
# This example uses QThreads, which means that the threads at the Python level
# are named something like "Dummy-1". The function below gets the Qt name of the
# current thread.
#
def ctname():
    return QtCore.QThread.currentThread().objectName()


#
# Used to generate random levels for logging.
#
LEVELS = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,
          logging.CRITICAL)

#
# This worker class represents work that is done in a thread separate to the
# main thread. The way the thread is kicked off to do work is via a button press
# that connects to a slot in the worker.
#
# Because the default threadName value in the LogRecord isn't much use, we add
# a qThreadName which contains the QThread name as computed above, and pass that
# value in an "extra" dictionary which is used to update the LogRecord with the
# QThread name.
#
# This example worker just outputs messages sequentially, interspersed with
# random delays of the order of a few seconds.
#
class Worker(QtCore.QObject):
    @Slot()
    def start(self):
        extra = {'qThreadName': ctname() }
        logger.debug('Started work', extra=extra)
        i = 1
        # Let the thread run until interrupted. This allows reasonably clean
        # thread termination.
        while not QtCore.QThread.currentThread().isInterruptionRequested():
            delay = 0.5 + random.random() * 2
            time.sleep(delay)
            level = random.choice(LEVELS)
            logger.log(level, 'Message after delay of %3.1f: %d', delay, i, extra=extra)
            i += 1

#
# Implement a simple UI for this cookbook example. This contains:
#
# * A read-only text edit window which holds formatted log messages
# * A button to start work and log stuff in a separate thread
# * A button to log something from the main thread
# * A button to clear the log window
#
class Window(QtWidgets.QWidget):

    COLORS = {
        logging.DEBUG: 'black',
        logging.INFO: 'blue',
        logging.WARNING: 'orange',
        logging.ERROR: 'red',
        logging.CRITICAL: 'purple',
    }

    def __init__(self, app):
        super().__init__()
        self.app = app
        self.textedit = te = QtWidgets.QPlainTextEdit(self)
        # Set whatever the default monospace font is for the platform
        f = QtGui.QFont('nosuchfont')
        f.setStyleHint(f.Monospace)
        te.setFont(f)
        te.setReadOnly(True)
        PB = QtWidgets.QPushButton
        self.work_button = PB('Start background work', self)
        self.log_button = PB('Log a message at a random level', self)
        self.clear_button = PB('Clear log window', self)
        self.handler = h = QtHandler(self.update_status)
        # Remember to use qThreadName rather than threadName in the format string.
        fs = '%(asctime)s %(qThreadName)-12s %(levelname)-8s %(message)s'
        formatter = logging.Formatter(fs)
        h.setFormatter(formatter)
        logger.addHandler(h)
        # Set up to terminate the QThread when we exit
        app.aboutToQuit.connect(self.force_quit)

        # Lay out all the widgets
        layout = QtWidgets.QVBoxLayout(self)
        layout.addWidget(te)
        layout.addWidget(self.work_button)
        layout.addWidget(self.log_button)
        layout.addWidget(self.clear_button)
        self.setFixedSize(900, 400)

        # Connect the non-worker slots and signals
        self.log_button.clicked.connect(self.manual_update)
        self.clear_button.clicked.connect(self.clear_display)

        # Start a new worker thread and connect the slots for the worker
        self.start_thread()
        self.work_button.clicked.connect(self.worker.start)
        # Once started, the button should be disabled
        self.work_button.clicked.connect(lambda : self.work_button.setEnabled(False))

    def start_thread(self):
        self.worker = Worker()
        self.worker_thread = QtCore.QThread()
        self.worker.setObjectName('Worker')
        self.worker_thread.setObjectName('WorkerThread')  # for qThreadName
        self.worker.moveToThread(self.worker_thread)
        # This will start an event loop in the worker thread
        self.worker_thread.start()

    def kill_thread(self):
        # Just tell the worker to stop, then tell it to quit and wait for that
        # to happen
        self.worker_thread.requestInterruption()
        if self.worker_thread.isRunning():
            self.worker_thread.quit()
            self.worker_thread.wait()
        else:
            print('worker has already exited.')

    def force_quit(self):
        # For use when the window is closed
        if self.worker_thread.isRunning():
            self.kill_thread()

    # The functions below update the UI and run in the main thread because
    # that's where the slots are set up

    @Slot(str, logging.LogRecord)
    def update_status(self, status, record):
        color = self.COLORS.get(record.levelno, 'black')
        s = '<pre><font color="%s">%s</font></pre>' % (color, status)
        self.textedit.appendHtml(s)

    @Slot()
    def manual_update(self):
        # This function uses the formatted message passed in, but also uses
        # information from the record to format the message in an appropriate
        # color according to its severity (level).
        level = random.choice(LEVELS)
        extra = {'qThreadName': ctname() }
        logger.log(level, 'Manually logged!', extra=extra)

    @Slot()
    def clear_display(self):
        self.textedit.clear()


def main():
    QtCore.QThread.currentThread().setObjectName('MainThread')
    logging.getLogger().setLevel(logging.DEBUG)
    app = QtWidgets.QApplication(sys.argv)
    example = Window(app)
    example.show()
    sys.exit(app.exec_())

if __name__=='__main__':
    main()
Logging to syslog with RFC5424 support
Although RFC 5424 dates from 2009, most syslog servers are configured by detault to use the older RFC 3164, which hails from 2001. When logging was added to Python in 2003, it supported the earlier (and only existing) protocol at the time. Since RFC5424 came out, as there has not been widespread deployment of it in syslog servers, the SysLogHandler functionality has not been updated.

RFC 5424 contains some useful features such as support for structured data, and if you need to be able to log to a syslog server with support for it, you can do so with a subclassed handler which looks something like this:

import datetime
import logging.handlers
import re
import socket
import time

class SysLogHandler5424(logging.handlers.SysLogHandler):

    tz_offset = re.compile(r'([+-]\d{2})(\d{2})$')
    escaped = re.compile(r'([\]"\\])')

    def __init__(self, *args, **kwargs):
        self.msgid = kwargs.pop('msgid', None)
        self.appname = kwargs.pop('appname', None)
        super().__init__(*args, **kwargs)

    def format(self, record):
        version = 1
        asctime = datetime.datetime.fromtimestamp(record.created).isoformat()
        m = self.tz_offset.match(time.strftime('%z'))
        has_offset = False
        if m and time.timezone:
            hrs, mins = m.groups()
            if int(hrs) or int(mins):
                has_offset = True
        if not has_offset:
            asctime += 'Z'
        else:
            asctime += f'{hrs}:{mins}'
        try:
            hostname = socket.gethostname()
        except Exception:
            hostname = '-'
        appname = self.appname or '-'
        procid = record.process
        msgid = '-'
        msg = super().format(record)
        sdata = '-'
        if hasattr(record, 'structured_data'):
            sd = record.structured_data
            # This should be a dict where the keys are SD-ID and the value is a
            # dict mapping PARAM-NAME to PARAM-VALUE (refer to the RFC for what these
            # mean)
            # There's no error checking here - it's purely for illustration, and you
            # can adapt this code for use in production environments
            parts = []

            def replacer(m):
                g = m.groups()
                return '\\' + g[0]

            for sdid, dv in sd.items():
                part = f'[{sdid}'
                for k, v in dv.items():
                    s = str(v)
                    s = self.escaped.sub(replacer, s)
                    part += f' {k}="{s}"'
                part += ']'
                parts.append(part)
            sdata = ''.join(parts)
        return f'{version} {asctime} {hostname} {appname} {procid} {msgid} {sdata} {msg}'
You’ll need to be familiar with RFC 5424 to fully understand the above code, and it may be that you have slightly different needs (e.g. for how you pass structural data to the log). Nevertheless, the above should be adaptable to your speciric needs. With the above handler, you’d pass structured data using something like this:

sd = {
    'foo@12345': {'bar': 'baz', 'baz': 'bozz', 'fizz': r'buzz'},
    'foo@54321': {'rab': 'baz', 'zab': 'bozz', 'zzif': r'buzz'}
}
extra = {'structured_data': sd}
i = 1
logger.debug('Message %d', i, extra=extra)
How to treat a logger like an output stream
Sometimes, you need to interface to a third-party API which expects a file-like object to write to, but you want to direct the API’s output to a logger. You can do this using a class which wraps a logger with a file-like API. Here’s a short script illustrating such a class:

import logging

class LoggerWriter:
    def __init__(self, logger, level):
        self.logger = logger
        self.level = level

    def write(self, message):
        if message != '\n':  # avoid printing bare newlines, if you like
            self.logger.log(self.level, message)

    def flush(self):
        # doesn't actually do anything, but might be expected of a file-like
        # object - so optional depending on your situation
        pass

    def close(self):
        # doesn't actually do anything, but might be expected of a file-like
        # object - so optional depending on your situation. You might want
        # to set a flag so that later calls to write raise an exception
        pass

def main():
    logging.basicConfig(level=logging.DEBUG)
    logger = logging.getLogger('demo')
    info_fp = LoggerWriter(logger, logging.INFO)
    debug_fp = LoggerWriter(logger, logging.DEBUG)
    print('An INFO message', file=info_fp)
    print('A DEBUG message', file=debug_fp)

if __name__ == "__main__":
    main()
When this script is run, it prints

INFO:demo:An INFO message
DEBUG:demo:A DEBUG message
You could also use LoggerWriter to redirect sys.stdout and sys.stderr by doing something like this:

import sys

sys.stdout = LoggerWriter(logger, logging.INFO)
sys.stderr = LoggerWriter(logger, logging.WARNING)
You should do this after configuring logging for your needs. In the above example, the basicConfig() call does this (using the sys.stderr value before it is overwritten by a LoggerWriter instance). Then, you’d get this kind of result:

>>>
>>> print('Foo')
INFO:demo:Foo
>>> print('Bar', file=sys.stderr)
WARNING:demo:Bar
>>>
Of course, these above examples show output according to the format used by basicConfig(), but you can use a different formatter when you configure logging.

Note that with the above scheme, you are somewhat at the mercy of buffering and the sequence of write calls which you are intercepting. For example, with the definition of LoggerWriter above, if you have the snippet

sys.stderr = LoggerWriter(logger, logging.WARNING)
1 / 0
then running the script results in

WARNING:demo:Traceback (most recent call last):

WARNING:demo:  File "/home/runner/cookbook-loggerwriter/test.py", line 53, in <module>

WARNING:demo:
WARNING:demo:main()
WARNING:demo:  File "/home/runner/cookbook-loggerwriter/test.py", line 49, in main

WARNING:demo:
WARNING:demo:1 / 0
WARNING:demo:ZeroDivisionError
WARNING:demo::
WARNING:demo:division by zero
As you can see, this output isn’t ideal. That’s because the underlying code which writes to sys.stderr makes mutiple writes, each of which results in a separate logged line (for example, the last three lines above). To get around this problem, you need to buffer things and only output log lines when newlines are seen. Let’s use a slghtly better implementation of LoggerWriter:

class BufferingLoggerWriter(LoggerWriter):
    def __init__(self, logger, level):
        super().__init__(logger, level)
        self.buffer = ''

    def write(self, message):
        if '\n' not in message:
            self.buffer += message
        else:
            parts = message.split('\n')
            if self.buffer:
                s = self.buffer + parts.pop(0)
                self.logger.log(self.level, s)
            self.buffer = parts.pop()
            for part in parts:
                self.logger.log(self.level, part)
This just buffers up stuff until a newline is seen, and then logs complete lines. With this approach, you get better output:

WARNING:demo:Traceback (most recent call last):
WARNING:demo:  File "/home/runner/cookbook-loggerwriter/main.py", line 55, in <module>
WARNING:demo:    main()
WARNING:demo:  File "/home/runner/cookbook-loggerwriter/main.py", line 52, in main
WARNING:demo:    1/0
WARNING:demo:ZeroDivisionError: division by zero
Patterns to avoid
Although the preceding sections have described ways of doing things you might need to do or deal with, it is worth mentioning some usage patterns which are unhelpful, and which should therefore be avoided in most cases. The following sections are in no particular order.

Opening the same log file multiple times
On Windows, you will generally not be able to open the same file multiple times as this will lead to a “file is in use by another process” error. However, on POSIX platforms you’ll not get any errors if you open the same file multiple times. This could be done accidentally, for example by:

Adding a file handler more than once which references the same file (e.g. by a copy/paste/forget-to-change error).

Opening two files that look different, as they have different names, but are the same because one is a symbolic link to the other.

Forking a process, following which both parent and child have a reference to the same file. This might be through use of the multiprocessing module, for example.

Opening a file multiple times might appear to work most of the time, but can lead to a number of problems in practice:

Logging output can be garbled because multiple threads or processes try to write to the same file. Although logging guards against concurrent use of the same handler instance by multiple threads, there is no such protection if concurrent writes are attempted by two different threads using two different handler instances which happen to point to the same file.

An attempt to delete a file (e.g. during file rotation) silently fails, because there is another reference pointing to it. This can lead to confusion and wasted debugging time - log entries end up in unexpected places, or are lost altogether. Or a file that was supposed to be moved remains in place, and grows in size unexpectedly despite size-based rotation being supposedly in place.

Use the techniques outlined in Logging to a single file from multiple processes to circumvent such issues.

Using loggers as attributes in a class or passing them as parameters
While there might be unusual cases where you’ll need to do this, in general there is no point because loggers are singletons. Code can always access a given logger instance by name using logging.getLogger(name), so passing instances around and holding them as instance attributes is pointless. Note that in other languages such as Java and C#, loggers are often static class attributes. However, this pattern doesn’t make sense in Python, where the module (and not the class) is the unit of software decomposition.

Adding handlers other than NullHandler to a logger in a library
Configuring logging by adding handlers, formatters and filters is the responsibility of the application developer, not the library developer. If you are maintaining a library, ensure that you don’t add handlers to any of your loggers other than a NullHandler instance.

Creating a lot of loggers
Loggers are singletons that are never freed during a script execution, and so creating lots of loggers will use up memory which can’t then be freed. Rather than create a logger per e.g. file processed or network connection made, use the existing mechanisms for passing contextual information into your logs and restrict the loggers created to those describing areas within your application (generally modules, but occasionally slightly more fine-grained than that).

Other resources
See also
Module logging
API reference for the logging module.

Module logging.config
Configuration API for the logging module.

Module logging.handlers
Useful handlers included with the logging module.

Basic Tutorial

Advanced Tutorial

Table of Contents
Logging Cookbook
Using logging in multiple modules
Logging from multiple threads
Multiple handlers and formatters
Logging to multiple destinations
Custom handling of levels
Configuration server example
Dealing with handlers that block
Sending and receiving logging events across a network
Running a logging socket listener in production
Adding contextual information to your logging output
Using LoggerAdapters to impart contextual information
Using objects other than dicts to pass contextual information
Using Filters to impart contextual information
Use of contextvars
Imparting contextual information in handlers
Logging to a single file from multiple processes
Using concurrent.futures.ProcessPoolExecutor
Deploying Web applications using Gunicorn and uWSGI
Using file rotation
Use of alternative formatting styles
Customizing LogRecord
Subclassing QueueHandler - a ZeroMQ example
Subclassing QueueListener - a ZeroMQ example
An example dictionary-based configuration
Using a rotator and namer to customize log rotation processing
A more elaborate multiprocessing example
Inserting a BOM into messages sent to a SysLogHandler
Implementing structured logging
Customizing handlers with dictConfig()
Using particular formatting styles throughout your application
Using LogRecord factories
Using custom message objects
Configuring filters with dictConfig()
Customized exception formatting
Speaking logging messages
Buffering logging messages and outputting them conditionally
Sending logging messages to email, with buffering
Formatting times using UTC (GMT) via configuration
Using a context manager for selective logging
A CLI application starter template
A Qt GUI for logging
Logging to syslog with RFC5424 support
How to treat a logger like an output stream
Patterns to avoid
Opening the same log file multiple times
Using loggers as attributes in a class or passing them as parameters
Adding handlers other than NullHandler to a logger in a library
Creating a lot of loggers
Other resources
Previous topic
Logging HOWTO

Next topic
Regular Expression HOWTO

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Logging Cookbook
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Regular Expression HOWTO
Quick search
  |
Regular Expression HOWTO
Author
A.M. Kuchling <amk@amk.ca>

Abstract

This document is an introductory tutorial to using regular expressions in Python with the re module. It provides a gentler introduction than the corresponding section in the Library Reference.

Introduction
Regular expressions (called REs, or regexes, or regex patterns) are essentially a tiny, highly specialized programming language embedded inside Python and made available through the re module. Using this little language, you specify the rules for the set of possible strings that you want to match; this set might contain English sentences, or e-mail addresses, or TeX commands, or anything you like. You can then ask questions such as “Does this string match the pattern?”, or “Is there a match for the pattern anywhere in this string?”. You can also use REs to modify a string or to split it apart in various ways.

Regular expression patterns are compiled into a series of bytecodes which are then executed by a matching engine written in C. For advanced use, it may be necessary to pay careful attention to how the engine will execute a given RE, and write the RE in a certain way in order to produce bytecode that runs faster. Optimization isn’t covered in this document, because it requires that you have a good understanding of the matching engine’s internals.

The regular expression language is relatively small and restricted, so not all possible string processing tasks can be done using regular expressions. There are also tasks that can be done with regular expressions, but the expressions turn out to be very complicated. In these cases, you may be better off writing Python code to do the processing; while Python code will be slower than an elaborate regular expression, it will also probably be more understandable.

Simple Patterns
We’ll start by learning about the simplest possible regular expressions. Since regular expressions are used to operate on strings, we’ll begin with the most common task: matching characters.

For a detailed explanation of the computer science underlying regular expressions (deterministic and non-deterministic finite automata), you can refer to almost any textbook on writing compilers.

Matching Characters
Most letters and characters will simply match themselves. For example, the regular expression test will match the string test exactly. (You can enable a case-insensitive mode that would let this RE match Test or TEST as well; more about this later.)

There are exceptions to this rule; some characters are special metacharacters, and don’t match themselves. Instead, they signal that some out-of-the-ordinary thing should be matched, or they affect other portions of the RE by repeating them or changing their meaning. Much of this document is devoted to discussing various metacharacters and what they do.

Here’s a complete list of the metacharacters; their meanings will be discussed in the rest of this HOWTO.

. ^ $ * + ? { } [ ] \ | ( )
The first metacharacters we’ll look at are [ and ]. They’re used for specifying a character class, which is a set of characters that you wish to match. Characters can be listed individually, or a range of characters can be indicated by giving two characters and separating them by a '-'. For example, [abc] will match any of the characters a, b, or c; this is the same as [a-c], which uses a range to express the same set of characters. If you wanted to match only lowercase letters, your RE would be [a-z].

Metacharacters (except \) are not active inside classes. For example, [akm$] will match any of the characters 'a', 'k', 'm', or '$'; '$' is usually a metacharacter, but inside a character class it’s stripped of its special nature.

You can match the characters not listed within the class by complementing the set. This is indicated by including a '^' as the first character of the class. For example, [^5] will match any character except '5'. If the caret appears elsewhere in a character class, it does not have special meaning. For example: [5^] will match either a '5' or a '^'.

Perhaps the most important metacharacter is the backslash, \. As in Python string literals, the backslash can be followed by various characters to signal various special sequences. It’s also used to escape all the metacharacters so you can still match them in patterns; for example, if you need to match a [ or \, you can precede them with a backslash to remove their special meaning: \[ or \\.

Some of the special sequences beginning with '\' represent predefined sets of characters that are often useful, such as the set of digits, the set of letters, or the set of anything that isn’t whitespace.

Let’s take an example: \w matches any alphanumeric character. If the regex pattern is expressed in bytes, this is equivalent to the class [a-zA-Z0-9_]. If the regex pattern is a string, \w will match all the characters marked as letters in the Unicode database provided by the unicodedata module. You can use the more restricted definition of \w in a string pattern by supplying the re.ASCII flag when compiling the regular expression.

The following list of special sequences isn’t complete. For a complete list of sequences and expanded class definitions for Unicode string patterns, see the last part of Regular Expression Syntax in the Standard Library reference. In general, the Unicode versions match any character that’s in the appropriate category in the Unicode database.

\d
Matches any decimal digit; this is equivalent to the class [0-9].

\D
Matches any non-digit character; this is equivalent to the class [^0-9].

\s
Matches any whitespace character; this is equivalent to the class [ \t\n\r\f\v].

\S
Matches any non-whitespace character; this is equivalent to the class [^ \t\n\r\f\v].

\w
Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].

\W
Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].

These sequences can be included inside a character class. For example, [\s,.] is a character class that will match any whitespace character, or ',' or '.'.

The final metacharacter in this section is .. It matches anything except a newline character, and there’s an alternate mode (re.DOTALL) where it will match even a newline. . is often used where you want to match “any character”.

Repeating Things
Being able to match varying sets of characters is the first thing regular expressions can do that isn’t already possible with the methods available on strings. However, if that was the only additional capability of regexes, they wouldn’t be much of an advance. Another capability is that you can specify that portions of the RE must be repeated a certain number of times.

The first metacharacter for repeating things that we’ll look at is *. * doesn’t match the literal character '*'; instead, it specifies that the previous character can be matched zero or more times, instead of exactly once.

For example, ca*t will match 'ct' (0 'a' characters), 'cat' (1 'a'), 'caaat' (3 'a' characters), and so forth.

Repetitions such as * are greedy; when repeating a RE, the matching engine will try to repeat it as many times as possible. If later portions of the pattern don’t match, the matching engine will then back up and try again with fewer repetitions.

A step-by-step example will make this more obvious. Let’s consider the expression a[bcd]*b. This matches the letter 'a', zero or more letters from the class [bcd], and finally ends with a 'b'. Now imagine matching this RE against the string 'abcbd'.

Step

Matched

Explanation

1

a

The a in the RE matches.

2

abcbd

The engine matches [bcd]*, going as far as it can, which is to the end of the string.

3

Failure

The engine tries to match b, but the current position is at the end of the string, so it fails.

4

abcb

Back up, so that [bcd]* matches one less character.

5

Failure

Try b again, but the current position is at the last character, which is a 'd'.

6

abc

Back up again, so that [bcd]* is only matching bc.

6

abcb

Try b again. This time the character at the current position is 'b', so it succeeds.

The end of the RE has now been reached, and it has matched 'abcb'. This demonstrates how the matching engine goes as far as it can at first, and if no match is found it will then progressively back up and retry the rest of the RE again and again. It will back up until it has tried zero matches for [bcd]*, and if that subsequently fails, the engine will conclude that the string doesn’t match the RE at all.

Another repeating metacharacter is +, which matches one or more times. Pay careful attention to the difference between * and +; * matches zero or more times, so whatever’s being repeated may not be present at all, while + requires at least one occurrence. To use a similar example, ca+t will match 'cat' (1 'a'), 'caaat' (3 'a's), but won’t match 'ct'.

There are two more repeating qualifiers. The question mark character, ?, matches either once or zero times; you can think of it as marking something as being optional. For example, home-?brew matches either 'homebrew' or 'home-brew'.

The most complicated repeated qualifier is {m,n}, where m and n are decimal integers. This qualifier means there must be at least m repetitions, and at most n. For example, a/{1,3}b will match 'a/b', 'a//b', and 'a///b'. It won’t match 'ab', which has no slashes, or 'a////b', which has four.

You can omit either m or n; in that case, a reasonable value is assumed for the missing value. Omitting m is interpreted as a lower limit of 0, while omitting n results in an upper bound of infinity.

Readers of a reductionist bent may notice that the three other qualifiers can all be expressed using this notation. {0,} is the same as *, {1,} is equivalent to +, and {0,1} is the same as ?. It’s better to use *, +, or ? when you can, simply because they’re shorter and easier to read.

Using Regular Expressions
Now that we’ve looked at some simple regular expressions, how do we actually use them in Python? The re module provides an interface to the regular expression engine, allowing you to compile REs into objects and then perform matches with them.

Compiling Regular Expressions
Regular expressions are compiled into pattern objects, which have methods for various operations such as searching for pattern matches or performing string substitutions.

>>>
>>> import re
>>> p = re.compile('ab*')
>>> p
re.compile('ab*')
re.compile() also accepts an optional flags argument, used to enable various special features and syntax variations. We’ll go over the available settings later, but for now a single example will do:

>>>
>>> p = re.compile('ab*', re.IGNORECASE)
The RE is passed to re.compile() as a string. REs are handled as strings because regular expressions aren’t part of the core Python language, and no special syntax was created for expressing them. (There are applications that don’t need REs at all, so there’s no need to bloat the language specification by including them.) Instead, the re module is simply a C extension module included with Python, just like the socket or zlib modules.

Putting REs in strings keeps the Python language simpler, but has one disadvantage which is the topic of the next section.

The Backslash Plague
As stated earlier, regular expressions use the backslash character ('\') to indicate special forms or to allow special characters to be used without invoking their special meaning. This conflicts with Python’s usage of the same character for the same purpose in string literals.

Let’s say you want to write a RE that matches the string \section, which might be found in a LaTeX file. To figure out what to write in the program code, start with the desired string to be matched. Next, you must escape any backslashes and other metacharacters by preceding them with a backslash, resulting in the string \\section. The resulting string that must be passed to re.compile() must be \\section. However, to express this as a Python string literal, both backslashes must be escaped again.

Characters

Stage

\section

Text string to be matched

\\section

Escaped backslash for re.compile()

"\\\\section"

Escaped backslashes for a string literal

In short, to match a literal backslash, one has to write '\\\\' as the RE string, because the regular expression must be \\, and each backslash must be expressed as \\ inside a regular Python string literal. In REs that feature backslashes repeatedly, this leads to lots of repeated backslashes and makes the resulting strings difficult to understand.

The solution is to use Python’s raw string notation for regular expressions; backslashes are not handled in any special way in a string literal prefixed with 'r', so r"\n" is a two-character string containing '\' and 'n', while "\n" is a one-character string containing a newline. Regular expressions will often be written in Python code using this raw string notation.

In addition, special escape sequences that are valid in regular expressions, but not valid as Python string literals, now result in a DeprecationWarning and will eventually become a SyntaxError, which means the sequences will be invalid if raw string notation or escaping the backslashes isn’t used.

Regular String

Raw string

"ab*"

r"ab*"

"\\\\section"

r"\\section"

"\\w+\\s+\\1"

r"\w+\s+\1"

Performing Matches
Once you have an object representing a compiled regular expression, what do you do with it? Pattern objects have several methods and attributes. Only the most significant ones will be covered here; consult the re docs for a complete listing.

Method/Attribute

Purpose

match()

Determine if the RE matches at the beginning of the string.

search()

Scan through a string, looking for any location where this RE matches.

findall()

Find all substrings where the RE matches, and returns them as a list.

finditer()

Find all substrings where the RE matches, and returns them as an iterator.

match() and search() return None if no match can be found. If they’re successful, a match object instance is returned, containing information about the match: where it starts and ends, the substring it matched, and more.

You can learn about this by interactively experimenting with the re module. If you have tkinter available, you may also want to look at Tools/demo/redemo.py, a demonstration program included with the Python distribution. It allows you to enter REs and strings, and displays whether the RE matches or fails. redemo.py can be quite useful when trying to debug a complicated RE.

This HOWTO uses the standard Python interpreter for its examples. First, run the Python interpreter, import the re module, and compile a RE:

>>>
>>> import re
>>> p = re.compile('[a-z]+')
>>> p
re.compile('[a-z]+')
Now, you can try matching various strings against the RE [a-z]+. An empty string shouldn’t match at all, since + means ‘one or more repetitions’. match() should return None in this case, which will cause the interpreter to print no output. You can explicitly print the result of match() to make this clear.

>>>
>>> p.match("")
>>> print(p.match(""))
None
Now, let’s try it on a string that it should match, such as tempo. In this case, match() will return a match object, so you should store the result in a variable for later use.

>>>
>>> m = p.match('tempo')
>>> m
<re.Match object; span=(0, 5), match='tempo'>
Now you can query the match object for information about the matching string. Match object instances also have several methods and attributes; the most important ones are:

Method/Attribute

Purpose

group()

Return the string matched by the RE

start()

Return the starting position of the match

end()

Return the ending position of the match

span()

Return a tuple containing the (start, end) positions of the match

Trying these methods will soon clarify their meaning:

>>>
>>> m.group()
'tempo'
>>> m.start(), m.end()
(0, 5)
>>> m.span()
(0, 5)
group() returns the substring that was matched by the RE. start() and end() return the starting and ending index of the match. span() returns both start and end indexes in a single tuple. Since the match() method only checks if the RE matches at the start of a string, start() will always be zero. However, the search() method of patterns scans through the string, so the match may not start at zero in that case.

>>>
>>> print(p.match('::: message'))
None
>>> m = p.search('::: message'); print(m)
<re.Match object; span=(4, 11), match='message'>
>>> m.group()
'message'
>>> m.span()
(4, 11)
In actual programs, the most common style is to store the match object in a variable, and then check if it was None. This usually looks like:

p = re.compile( ... )
m = p.match( 'string goes here' )
if m:
    print('Match found: ', m.group())
else:
    print('No match')
Two pattern methods return all of the matches for a pattern. findall() returns a list of matching strings:

>>>
>>> p = re.compile(r'\d+')
>>> p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')
['12', '11', '10']
The r prefix, making the literal a raw string literal, is needed in this example because escape sequences in a normal “cooked” string literal that are not recognized by Python, as opposed to regular expressions, now result in a DeprecationWarning and will eventually become a SyntaxError. See The Backslash Plague.

findall() has to create the entire list before it can be returned as the result. The finditer() method returns a sequence of match object instances as an iterator:

>>>
>>> iterator = p.finditer('12 drummers drumming, 11 ... 10 ...')
>>> iterator  
<callable_iterator object at 0x...>
>>> for match in iterator:
...     print(match.span())
...
(0, 2)
(22, 24)
(29, 31)
Module-Level Functions
You don’t have to create a pattern object and call its methods; the re module also provides top-level functions called match(), search(), findall(), sub(), and so forth. These functions take the same arguments as the corresponding pattern method with the RE string added as the first argument, and still return either None or a match object instance.

>>>
>>> print(re.match(r'From\s+', 'Fromage amk'))
None
>>> re.match(r'From\s+', 'From amk Thu May 14 19:12:10 1998')  
<re.Match object; span=(0, 5), match='From '>
Under the hood, these functions simply create a pattern object for you and call the appropriate method on it. They also store the compiled object in a cache, so future calls using the same RE won’t need to parse the pattern again and again.

Should you use these module-level functions, or should you get the pattern and call its methods yourself? If you’re accessing a regex within a loop, pre-compiling it will save a few function calls. Outside of loops, there’s not much difference thanks to the internal cache.

Compilation Flags
Compilation flags let you modify some aspects of how regular expressions work. Flags are available in the re module under two names, a long name such as IGNORECASE and a short, one-letter form such as I. (If you’re familiar with Perl’s pattern modifiers, the one-letter forms use the same letters; the short form of re.VERBOSE is re.X, for example.) Multiple flags can be specified by bitwise OR-ing them; re.I | re.M sets both the I and M flags, for example.

Here’s a table of the available flags, followed by a more detailed explanation of each one.

Flag

Meaning

ASCII, A

Makes several escapes like \w, \b, \s and \d match only on ASCII characters with the respective property.

DOTALL, S

Make . match any character, including newlines.

IGNORECASE, I

Do case-insensitive matches.

LOCALE, L

Do a locale-aware match.

MULTILINE, M

Multi-line matching, affecting ^ and $.

VERBOSE, X (for ‘extended’)

Enable verbose REs, which can be organized more cleanly and understandably.

I
IGNORECASE
Perform case-insensitive matching; character class and literal strings will match letters by ignoring case. For example, [A-Z] will match lowercase letters, too. Full Unicode matching also works unless the ASCII flag is used to disable non-ASCII matches. When the Unicode patterns [a-z] or [A-Z] are used in combination with the IGNORECASE flag, they will match the 52 ASCII letters and 4 additional non-ASCII letters: ‘İ’ (U+0130, Latin capital letter I with dot above), ‘ı’ (U+0131, Latin small letter dotless i), ‘ſ’ (U+017F, Latin small letter long s) and ‘K’ (U+212A, Kelvin sign). Spam will match 'Spam', 'spam', 'spAM', or 'ſpam' (the latter is matched only in Unicode mode). This lowercasing doesn’t take the current locale into account; it will if you also set the LOCALE flag.

L
LOCALE
Make \w, \W, \b, \B and case-insensitive matching dependent on the current locale instead of the Unicode database.

Locales are a feature of the C library intended to help in writing programs that take account of language differences. For example, if you’re processing encoded French text, you’d want to be able to write \w+ to match words, but \w only matches the character class [A-Za-z] in bytes patterns; it won’t match bytes corresponding to é or ç. If your system is configured properly and a French locale is selected, certain C functions will tell the program that the byte corresponding to é should also be considered a letter. Setting the LOCALE flag when compiling a regular expression will cause the resulting compiled object to use these C functions for \w; this is slower, but also enables \w+ to match French words as you’d expect. The use of this flag is discouraged in Python 3 as the locale mechanism is very unreliable, it only handles one “culture” at a time, and it only works with 8-bit locales. Unicode matching is already enabled by default in Python 3 for Unicode (str) patterns, and it is able to handle different locales/languages.

M
MULTILINE
(^ and $ haven’t been explained yet; they’ll be introduced in section More Metacharacters.)

Usually ^ matches only at the beginning of the string, and $ matches only at the end of the string and immediately before the newline (if any) at the end of the string. When this flag is specified, ^ matches at the beginning of the string and at the beginning of each line within the string, immediately following each newline. Similarly, the $ metacharacter matches either at the end of the string and at the end of each line (immediately preceding each newline).

S
DOTALL
Makes the '.' special character match any character at all, including a newline; without this flag, '.' will match anything except a newline.

A
ASCII
Make \w, \W, \b, \B, \s and \S perform ASCII-only matching instead of full Unicode matching. This is only meaningful for Unicode patterns, and is ignored for byte patterns.

X
VERBOSE
This flag allows you to write regular expressions that are more readable by granting you more flexibility in how you can format them. When this flag has been specified, whitespace within the RE string is ignored, except when the whitespace is in a character class or preceded by an unescaped backslash; this lets you organize and indent the RE more clearly. This flag also lets you put comments within a RE that will be ignored by the engine; comments are marked by a '#' that’s neither in a character class or preceded by an unescaped backslash.

For example, here’s a RE that uses re.VERBOSE; see how much easier it is to read?

charref = re.compile(r"""
 &[#]                # Start of a numeric entity reference
 (
     0[0-7]+         # Octal form
   | [0-9]+          # Decimal form
   | x[0-9a-fA-F]+   # Hexadecimal form
 )
 ;                   # Trailing semicolon
""", re.VERBOSE)
Without the verbose setting, the RE would look like this:

charref = re.compile("&#(0[0-7]+"
                     "|[0-9]+"
                     "|x[0-9a-fA-F]+);")
In the above example, Python’s automatic concatenation of string literals has been used to break up the RE into smaller pieces, but it’s still more difficult to understand than the version using re.VERBOSE.

More Pattern Power
So far we’ve only covered a part of the features of regular expressions. In this section, we’ll cover some new metacharacters, and how to use groups to retrieve portions of the text that was matched.

More Metacharacters
There are some metacharacters that we haven’t covered yet. Most of them will be covered in this section.

Some of the remaining metacharacters to be discussed are zero-width assertions. They don’t cause the engine to advance through the string; instead, they consume no characters at all, and simply succeed or fail. For example, \b is an assertion that the current position is located at a word boundary; the position isn’t changed by the \b at all. This means that zero-width assertions should never be repeated, because if they match once at a given location, they can obviously be matched an infinite number of times.

|
Alternation, or the “or” operator. If A and B are regular expressions, A|B will match any string that matches either A or B. | has very low precedence in order to make it work reasonably when you’re alternating multi-character strings. Crow|Servo will match either 'Crow' or 'Servo', not 'Cro', a 'w' or an 'S', and 'ervo'.

To match a literal '|', use \|, or enclose it inside a character class, as in [|].

^
Matches at the beginning of lines. Unless the MULTILINE flag has been set, this will only match at the beginning of the string. In MULTILINE mode, this also matches immediately after each newline within the string.

For example, if you wish to match the word From only at the beginning of a line, the RE to use is ^From.

>>>
>>> print(re.search('^From', 'From Here to Eternity'))  
<re.Match object; span=(0, 4), match='From'>
>>> print(re.search('^From', 'Reciting From Memory'))
None
To match a literal '^', use \^.

$
Matches at the end of a line, which is defined as either the end of the string, or any location followed by a newline character.

>>>
>>> print(re.search('}$', '{block}'))  
<re.Match object; span=(6, 7), match='}'>
>>> print(re.search('}$', '{block} '))
None
>>> print(re.search('}$', '{block}\n'))  
<re.Match object; span=(6, 7), match='}'>
To match a literal '$', use \$ or enclose it inside a character class, as in [$].

\A
Matches only at the start of the string. When not in MULTILINE mode, \A and ^ are effectively the same. In MULTILINE mode, they’re different: \A still matches only at the beginning of the string, but ^ may match at any location inside the string that follows a newline character.

\Z
Matches only at the end of the string.

\b
Word boundary. This is a zero-width assertion that matches only at the beginning or end of a word. A word is defined as a sequence of alphanumeric characters, so the end of a word is indicated by whitespace or a non-alphanumeric character.

The following example matches class only when it’s a complete word; it won’t match when it’s contained inside another word.

>>>
>>> p = re.compile(r'\bclass\b')
>>> print(p.search('no class at all'))
<re.Match object; span=(3, 8), match='class'>
>>> print(p.search('the declassified algorithm'))
None
>>> print(p.search('one subclass is'))
None
There are two subtleties you should remember when using this special sequence. First, this is the worst collision between Python’s string literals and regular expression sequences. In Python’s string literals, \b is the backspace character, ASCII value 8. If you’re not using raw strings, then Python will convert the \b to a backspace, and your RE won’t match as you expect it to. The following example looks the same as our previous RE, but omits the 'r' in front of the RE string.

>>>
>>> p = re.compile('\bclass\b')
>>> print(p.search('no class at all'))
None
>>> print(p.search('\b' + 'class' + '\b'))
<re.Match object; span=(0, 7), match='\x08class\x08'>
Second, inside a character class, where there’s no use for this assertion, \b represents the backspace character, for compatibility with Python’s string literals.

\B
Another zero-width assertion, this is the opposite of \b, only matching when the current position is not at a word boundary.

Grouping
Frequently you need to obtain more information than just whether the RE matched or not. Regular expressions are often used to dissect strings by writing a RE divided into several subgroups which match different components of interest. For example, an RFC-822 header line is divided into a header name and a value, separated by a ':', like this:

From: author@example.com
User-Agent: Thunderbird 1.5.0.9 (X11/20061227)
MIME-Version: 1.0
To: editor@example.com
This can be handled by writing a regular expression which matches an entire header line, and has one group which matches the header name, and another group which matches the header’s value.

Groups are marked by the '(', ')' metacharacters. '(' and ')' have much the same meaning as they do in mathematical expressions; they group together the expressions contained inside them, and you can repeat the contents of a group with a repeating qualifier, such as *, +, ?, or {m,n}. For example, (ab)* will match zero or more repetitions of ab.

>>>
>>> p = re.compile('(ab)*')
>>> print(p.match('ababababab').span())
(0, 10)
Groups indicated with '(', ')' also capture the starting and ending index of the text that they match; this can be retrieved by passing an argument to group(), start(), end(), and span(). Groups are numbered starting with 0. Group 0 is always present; it’s the whole RE, so match object methods all have group 0 as their default argument. Later we’ll see how to express groups that don’t capture the span of text that they match.

>>>
>>> p = re.compile('(a)b')
>>> m = p.match('ab')
>>> m.group()
'ab'
>>> m.group(0)
'ab'
Subgroups are numbered from left to right, from 1 upward. Groups can be nested; to determine the number, just count the opening parenthesis characters, going from left to right.

>>>
>>> p = re.compile('(a(b)c)d')
>>> m = p.match('abcd')
>>> m.group(0)
'abcd'
>>> m.group(1)
'abc'
>>> m.group(2)
'b'
group() can be passed multiple group numbers at a time, in which case it will return a tuple containing the corresponding values for those groups.

>>>
>>> m.group(2,1,2)
('b', 'abc', 'b')
The groups() method returns a tuple containing the strings for all the subgroups, from 1 up to however many there are.

>>>
>>> m.groups()
('abc', 'b')
Backreferences in a pattern allow you to specify that the contents of an earlier capturing group must also be found at the current location in the string. For example, \1 will succeed if the exact contents of group 1 can be found at the current position, and fails otherwise. Remember that Python’s string literals also use a backslash followed by numbers to allow including arbitrary characters in a string, so be sure to use a raw string when incorporating backreferences in a RE.

For example, the following RE detects doubled words in a string.

>>>
>>> p = re.compile(r'\b(\w+)\s+\1\b')
>>> p.search('Paris in the the spring').group()
'the the'
Backreferences like this aren’t often useful for just searching through a string — there are few text formats which repeat data in this way — but you’ll soon find out that they’re very useful when performing string substitutions.

Non-capturing and Named Groups
Elaborate REs may use many groups, both to capture substrings of interest, and to group and structure the RE itself. In complex REs, it becomes difficult to keep track of the group numbers. There are two features which help with this problem. Both of them use a common syntax for regular expression extensions, so we’ll look at that first.

Perl 5 is well known for its powerful additions to standard regular expressions. For these new features the Perl developers couldn’t choose new single-keystroke metacharacters or new special sequences beginning with \ without making Perl’s regular expressions confusingly different from standard REs. If they chose & as a new metacharacter, for example, old expressions would be assuming that & was a regular character and wouldn’t have escaped it by writing \& or [&].

The solution chosen by the Perl developers was to use (?...) as the extension syntax. ? immediately after a parenthesis was a syntax error because the ? would have nothing to repeat, so this didn’t introduce any compatibility problems. The characters immediately after the ? indicate what extension is being used, so (?=foo) is one thing (a positive lookahead assertion) and (?:foo) is something else (a non-capturing group containing the subexpression foo).

Python supports several of Perl’s extensions and adds an extension syntax to Perl’s extension syntax. If the first character after the question mark is a P, you know that it’s an extension that’s specific to Python.

Now that we’ve looked at the general extension syntax, we can return to the features that simplify working with groups in complex REs.

Sometimes you’ll want to use a group to denote a part of a regular expression, but aren’t interested in retrieving the group’s contents. You can make this fact explicit by using a non-capturing group: (?:...), where you can replace the ... with any other regular expression.

>>>
>>> m = re.match("([abc])+", "abc")
>>> m.groups()
('c',)
>>> m = re.match("(?:[abc])+", "abc")
>>> m.groups()
()
Except for the fact that you can’t retrieve the contents of what the group matched, a non-capturing group behaves exactly the same as a capturing group; you can put anything inside it, repeat it with a repetition metacharacter such as *, and nest it within other groups (capturing or non-capturing). (?:...) is particularly useful when modifying an existing pattern, since you can add new groups without changing how all the other groups are numbered. It should be mentioned that there’s no performance difference in searching between capturing and non-capturing groups; neither form is any faster than the other.

A more significant feature is named groups: instead of referring to them by numbers, groups can be referenced by a name.

The syntax for a named group is one of the Python-specific extensions: (?P<name>...). name is, obviously, the name of the group. Named groups behave exactly like capturing groups, and additionally associate a name with a group. The match object methods that deal with capturing groups all accept either integers that refer to the group by number or strings that contain the desired group’s name. Named groups are still given numbers, so you can retrieve information about a group in two ways:

>>>
>>> p = re.compile(r'(?P<word>\b\w+\b)')
>>> m = p.search( '(((( Lots of punctuation )))' )
>>> m.group('word')
'Lots'
>>> m.group(1)
'Lots'
Additionally, you can retrieve named groups as a dictionary with groupdict():

>>>
>>> m = re.match(r'(?P<first>\w+) (?P<last>\w+)', 'Jane Doe')
>>> m.groupdict()
{'first': 'Jane', 'last': 'Doe'}
Named groups are handy because they let you use easily remembered names, instead of having to remember numbers. Here’s an example RE from the imaplib module:

InternalDate = re.compile(r'INTERNALDATE "'
        r'(?P<day>[ 123][0-9])-(?P<mon>[A-Z][a-z][a-z])-'
        r'(?P<year>[0-9][0-9][0-9][0-9])'
        r' (?P<hour>[0-9][0-9]):(?P<min>[0-9][0-9]):(?P<sec>[0-9][0-9])'
        r' (?P<zonen>[-+])(?P<zoneh>[0-9][0-9])(?P<zonem>[0-9][0-9])'
        r'"')
It’s obviously much easier to retrieve m.group('zonem'), instead of having to remember to retrieve group 9.

The syntax for backreferences in an expression such as (...)\1 refers to the number of the group. There’s naturally a variant that uses the group name instead of the number. This is another Python extension: (?P=name) indicates that the contents of the group called name should again be matched at the current point. The regular expression for finding doubled words, \b(\w+)\s+\1\b can also be written as \b(?P<word>\w+)\s+(?P=word)\b:

>>>
>>> p = re.compile(r'\b(?P<word>\w+)\s+(?P=word)\b')
>>> p.search('Paris in the the spring').group()
'the the'
Lookahead Assertions
Another zero-width assertion is the lookahead assertion. Lookahead assertions are available in both positive and negative form, and look like this:

(?=...)
Positive lookahead assertion. This succeeds if the contained regular expression, represented here by ..., successfully matches at the current location, and fails otherwise. But, once the contained expression has been tried, the matching engine doesn’t advance at all; the rest of the pattern is tried right where the assertion started.

(?!...)
Negative lookahead assertion. This is the opposite of the positive assertion; it succeeds if the contained expression doesn’t match at the current position in the string.

To make this concrete, let’s look at a case where a lookahead is useful. Consider a simple pattern to match a filename and split it apart into a base name and an extension, separated by a .. For example, in news.rc, news is the base name, and rc is the filename’s extension.

The pattern to match this is quite simple:

.*[.].*$

Notice that the . needs to be treated specially because it’s a metacharacter, so it’s inside a character class to only match that specific character. Also notice the trailing $; this is added to ensure that all the rest of the string must be included in the extension. This regular expression matches foo.bar and autoexec.bat and sendmail.cf and printers.conf.

Now, consider complicating the problem a bit; what if you want to match filenames where the extension is not bat? Some incorrect attempts:

.*[.][^b].*$ The first attempt above tries to exclude bat by requiring that the first character of the extension is not a b. This is wrong, because the pattern also doesn’t match foo.bar.

.*[.]([^b]..|.[^a].|..[^t])$

The expression gets messier when you try to patch up the first solution by requiring one of the following cases to match: the first character of the extension isn’t b; the second character isn’t a; or the third character isn’t t. This accepts foo.bar and rejects autoexec.bat, but it requires a three-letter extension and won’t accept a filename with a two-letter extension such as sendmail.cf. We’ll complicate the pattern again in an effort to fix it.

.*[.]([^b].?.?|.[^a]?.?|..?[^t]?)$

In the third attempt, the second and third letters are all made optional in order to allow matching extensions shorter than three characters, such as sendmail.cf.

The pattern’s getting really complicated now, which makes it hard to read and understand. Worse, if the problem changes and you want to exclude both bat and exe as extensions, the pattern would get even more complicated and confusing.

A negative lookahead cuts through all this confusion:

.*[.](?!bat$)[^.]*$ The negative lookahead means: if the expression bat doesn’t match at this point, try the rest of the pattern; if bat$ does match, the whole pattern will fail. The trailing $ is required to ensure that something like sample.batch, where the extension only starts with bat, will be allowed. The [^.]* makes sure that the pattern works when there are multiple dots in the filename.

Excluding another filename extension is now easy; simply add it as an alternative inside the assertion. The following pattern excludes filenames that end in either bat or exe:

.*[.](?!bat$|exe$)[^.]*$

Modifying Strings
Up to this point, we’ve simply performed searches against a static string. Regular expressions are also commonly used to modify strings in various ways, using the following pattern methods:

Method/Attribute

Purpose

split()

Split the string into a list, splitting it wherever the RE matches

sub()

Find all substrings where the RE matches, and replace them with a different string

subn()

Does the same thing as sub(), but returns the new string and the number of replacements

Splitting Strings
The split() method of a pattern splits a string apart wherever the RE matches, returning a list of the pieces. It’s similar to the split() method of strings but provides much more generality in the delimiters that you can split by; string split() only supports splitting by whitespace or by a fixed string. As you’d expect, there’s a module-level re.split() function, too.

.split(string[, maxsplit=0])
Split string by the matches of the regular expression. If capturing parentheses are used in the RE, then their contents will also be returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits are performed.

You can limit the number of splits made, by passing a value for maxsplit. When maxsplit is nonzero, at most maxsplit splits will be made, and the remainder of the string is returned as the final element of the list. In the following example, the delimiter is any sequence of non-alphanumeric characters.

>>>
>>> p = re.compile(r'\W+')
>>> p.split('This is a test, short and sweet, of split().')
['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']
>>> p.split('This is a test, short and sweet, of split().', 3)
['This', 'is', 'a', 'test, short and sweet, of split().']
Sometimes you’re not only interested in what the text between delimiters is, but also need to know what the delimiter was. If capturing parentheses are used in the RE, then their values are also returned as part of the list. Compare the following calls:

>>>
>>> p = re.compile(r'\W+')
>>> p2 = re.compile(r'(\W+)')
>>> p.split('This... is a test.')
['This', 'is', 'a', 'test', '']
>>> p2.split('This... is a test.')
['This', '... ', 'is', ' ', 'a', ' ', 'test', '.', '']
The module-level function re.split() adds the RE to be used as the first argument, but is otherwise the same.

>>>
>>> re.split(r'[\W]+', 'Words, words, words.')
['Words', 'words', 'words', '']
>>> re.split(r'([\W]+)', 'Words, words, words.')
['Words', ', ', 'words', ', ', 'words', '.', '']
>>> re.split(r'[\W]+', 'Words, words, words.', 1)
['Words', 'words, words.']
Search and Replace
Another common task is to find all the matches for a pattern, and replace them with a different string. The sub() method takes a replacement value, which can be either a string or a function, and the string to be processed.

.sub(replacement, string[, count=0])
Returns the string obtained by replacing the leftmost non-overlapping occurrences of the RE in string by the replacement replacement. If the pattern isn’t found, string is returned unchanged.

The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a non-negative integer. The default value of 0 means to replace all occurrences.

Here’s a simple example of using the sub() method. It replaces colour names with the word colour:

>>>
>>> p = re.compile('(blue|white|red)')
>>> p.sub('colour', 'blue socks and red shoes')
'colour socks and colour shoes'
>>> p.sub('colour', 'blue socks and red shoes', count=1)
'colour socks and red shoes'
The subn() method does the same work, but returns a 2-tuple containing the new string value and the number of replacements that were performed:

>>>
>>> p = re.compile('(blue|white|red)')
>>> p.subn('colour', 'blue socks and red shoes')
('colour socks and colour shoes', 2)
>>> p.subn('colour', 'no colours at all')
('no colours at all', 0)
Empty matches are replaced only when they’re not adjacent to a previous empty match.

>>>
>>> p = re.compile('x*')
>>> p.sub('-', 'abxd')
'-a-b--d-'
If replacement is a string, any backslash escapes in it are processed. That is, \n is converted to a single newline character, \r is converted to a carriage return, and so forth. Unknown escapes such as \& are left alone. Backreferences, such as \6, are replaced with the substring matched by the corresponding group in the RE. This lets you incorporate portions of the original text in the resulting replacement string.

This example matches the word section followed by a string enclosed in {, }, and changes section to subsection:

>>>
>>> p = re.compile('section{ ( [^}]* ) }', re.VERBOSE)
>>> p.sub(r'subsection{\1}','section{First} section{second}')
'subsection{First} subsection{second}'
There’s also a syntax for referring to named groups as defined by the (?P<name>...) syntax. \g<name> will use the substring matched by the group named name, and \g<number> uses the corresponding group number. \g<2> is therefore equivalent to \2, but isn’t ambiguous in a replacement string such as \g<2>0. (\20 would be interpreted as a reference to group 20, not a reference to group 2 followed by the literal character '0'.) The following substitutions are all equivalent, but use all three variations of the replacement string.

>>>
>>> p = re.compile('section{ (?P<name> [^}]* ) }', re.VERBOSE)
>>> p.sub(r'subsection{\1}','section{First}')
'subsection{First}'
>>> p.sub(r'subsection{\g<1>}','section{First}')
'subsection{First}'
>>> p.sub(r'subsection{\g<name>}','section{First}')
'subsection{First}'
replacement can also be a function, which gives you even more control. If replacement is a function, the function is called for every non-overlapping occurrence of pattern. On each call, the function is passed a match object argument for the match and can use this information to compute the desired replacement string and return it.

In the following example, the replacement function translates decimals into hexadecimal:

>>>
>>> def hexrepl(match):
...     "Return the hex string for a decimal number"
...     value = int(match.group())
...     return hex(value)
...
>>> p = re.compile(r'\d+')
>>> p.sub(hexrepl, 'Call 65490 for printing, 49152 for user code.')
'Call 0xffd2 for printing, 0xc000 for user code.'
When using the module-level re.sub() function, the pattern is passed as the first argument. The pattern may be provided as an object or as a string; if you need to specify regular expression flags, you must either use a pattern object as the first parameter, or use embedded modifiers in the pattern string, e.g. sub("(?i)b+", "x", "bbbb BBBB") returns 'x x'.

Common Problems
Regular expressions are a powerful tool for some applications, but in some ways their behaviour isn’t intuitive and at times they don’t behave the way you may expect them to. This section will point out some of the most common pitfalls.

Use String Methods
Sometimes using the re module is a mistake. If you’re matching a fixed string, or a single character class, and you’re not using any re features such as the IGNORECASE flag, then the full power of regular expressions may not be required. Strings have several methods for performing operations with fixed strings and they’re usually much faster, because the implementation is a single small C loop that’s been optimized for the purpose, instead of the large, more generalized regular expression engine.

One example might be replacing a single fixed string with another one; for example, you might replace word with deed. re.sub() seems like the function to use for this, but consider the replace() method. Note that replace() will also replace word inside words, turning swordfish into sdeedfish, but the naive RE word would have done that, too. (To avoid performing the substitution on parts of words, the pattern would have to be \bword\b, in order to require that word have a word boundary on either side. This takes the job beyond replace()’s abilities.)

Another common task is deleting every occurrence of a single character from a string or replacing it with another single character. You might do this with something like re.sub('\n', ' ', S), but translate() is capable of doing both tasks and will be faster than any regular expression operation can be.

In short, before turning to the re module, consider whether your problem can be solved with a faster and simpler string method.

match() versus search()
The match() function only checks if the RE matches at the beginning of the string while search() will scan forward through the string for a match. It’s important to keep this distinction in mind. Remember, match() will only report a successful match which will start at 0; if the match wouldn’t start at zero, match() will not report it.

>>>
>>> print(re.match('super', 'superstition').span())
(0, 5)
>>> print(re.match('super', 'insuperable'))
None
On the other hand, search() will scan forward through the string, reporting the first match it finds.

>>>
>>> print(re.search('super', 'superstition').span())
(0, 5)
>>> print(re.search('super', 'insuperable').span())
(2, 7)
Sometimes you’ll be tempted to keep using re.match(), and just add .* to the front of your RE. Resist this temptation and use re.search() instead. The regular expression compiler does some analysis of REs in order to speed up the process of looking for a match. One such analysis figures out what the first character of a match must be; for example, a pattern starting with Crow must match starting with a 'C'. The analysis lets the engine quickly scan through the string looking for the starting character, only trying the full match if a 'C' is found.

Adding .* defeats this optimization, requiring scanning to the end of the string and then backtracking to find a match for the rest of the RE. Use re.search() instead.

Greedy versus Non-Greedy
When repeating a regular expression, as in a*, the resulting action is to consume as much of the pattern as possible. This fact often bites you when you’re trying to match a pair of balanced delimiters, such as the angle brackets surrounding an HTML tag. The naive pattern for matching a single HTML tag doesn’t work because of the greedy nature of .*.

>>>
>>> s = '<html><head><title>Title</title>'
>>> len(s)
32
>>> print(re.match('<.*>', s).span())
(0, 32)
>>> print(re.match('<.*>', s).group())
<html><head><title>Title</title>
The RE matches the '<' in '<html>', and the .* consumes the rest of the string. There’s still more left in the RE, though, and the > can’t match at the end of the string, so the regular expression engine has to backtrack character by character until it finds a match for the >. The final match extends from the '<' in '<html>' to the '>' in '</title>', which isn’t what you want.

In this case, the solution is to use the non-greedy qualifiers *?, +?, ??, or {m,n}?, which match as little text as possible. In the above example, the '>' is tried immediately after the first '<' matches, and when it fails, the engine advances a character at a time, retrying the '>' at every step. This produces just the right result:

>>>
>>> print(re.match('<.*?>', s).group())
<html>
(Note that parsing HTML or XML with regular expressions is painful. Quick-and-dirty patterns will handle common cases, but HTML and XML have special cases that will break the obvious regular expression; by the time you’ve written a regular expression that handles all of the possible cases, the patterns will be very complicated. Use an HTML or XML parser module for such tasks.)

Using re.VERBOSE
By now you’ve probably noticed that regular expressions are a very compact notation, but they’re not terribly readable. REs of moderate complexity can become lengthy collections of backslashes, parentheses, and metacharacters, making them difficult to read and understand.

For such REs, specifying the re.VERBOSE flag when compiling the regular expression can be helpful, because it allows you to format the regular expression more clearly.

The re.VERBOSE flag has several effects. Whitespace in the regular expression that isn’t inside a character class is ignored. This means that an expression such as dog | cat is equivalent to the less readable dog|cat, but [a b] will still match the characters 'a', 'b', or a space. In addition, you can also put comments inside a RE; comments extend from a # character to the next newline. When used with triple-quoted strings, this enables REs to be formatted more neatly:

pat = re.compile(r"""
 \s*                 # Skip leading whitespace
 (?P<header>[^:]+)   # Header name
 \s* :               # Whitespace, and a colon
 (?P<value>.*?)      # The header's value -- *? used to
                     # lose the following trailing whitespace
 \s*$                # Trailing whitespace to end-of-line
""", re.VERBOSE)
This is far more readable than:

pat = re.compile(r"\s*(?P<header>[^:]+)\s*:(?P<value>.*?)\s*$")
Feedback
Regular expressions are a complicated topic. Did this document help you understand them? Were there parts that were unclear, or Problems you encountered that weren’t covered here? If so, please send suggestions for improvements to the author.

The most complete book on regular expressions is almost certainly Jeffrey Friedl’s Mastering Regular Expressions, published by O’Reilly. Unfortunately, it exclusively concentrates on Perl and Java’s flavours of regular expressions, and doesn’t contain any Python material at all, so it won’t be useful as a reference for programming in Python. (The first edition covered Python’s now-removed regex module, which won’t help you much.) Consider checking it out from your library.

Table of Contents
Regular Expression HOWTO
Introduction
Simple Patterns
Matching Characters
Repeating Things
Using Regular Expressions
Compiling Regular Expressions
The Backslash Plague
Performing Matches
Module-Level Functions
Compilation Flags
More Pattern Power
More Metacharacters
Grouping
Non-capturing and Named Groups
Lookahead Assertions
Modifying Strings
Splitting Strings
Search and Replace
Common Problems
Use String Methods
match() versus search()
Greedy versus Non-Greedy
Using re.VERBOSE
Feedback
Previous topic
Logging Cookbook

Next topic
Socket Programming HOWTO

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Regular Expression HOWTO
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Socket Programming HOWTO
Quick search
  |
Socket Programming HOWTO
Author
Gordon McMillan

Abstract

Sockets are used nearly everywhere, but are one of the most severely misunderstood technologies around. This is a 10,000 foot overview of sockets. It’s not really a tutorial - you’ll still have work to do in getting things operational. It doesn’t cover the fine points (and there are a lot of them), but I hope it will give you enough background to begin using them decently.

Sockets
I’m only going to talk about INET (i.e. IPv4) sockets, but they account for at least 99% of the sockets in use. And I’ll only talk about STREAM (i.e. TCP) sockets - unless you really know what you’re doing (in which case this HOWTO isn’t for you!), you’ll get better behavior and performance from a STREAM socket than anything else. I will try to clear up the mystery of what a socket is, as well as some hints on how to work with blocking and non-blocking sockets. But I’ll start by talking about blocking sockets. You’ll need to know how they work before dealing with non-blocking sockets.

Part of the trouble with understanding these things is that “socket” can mean a number of subtly different things, depending on context. So first, let’s make a distinction between a “client” socket - an endpoint of a conversation, and a “server” socket, which is more like a switchboard operator. The client application (your browser, for example) uses “client” sockets exclusively; the web server it’s talking to uses both “server” sockets and “client” sockets.

History
Of the various forms of IPC, sockets are by far the most popular. On any given platform, there are likely to be other forms of IPC that are faster, but for cross-platform communication, sockets are about the only game in town.

They were invented in Berkeley as part of the BSD flavor of Unix. They spread like wildfire with the internet. With good reason — the combination of sockets with INET makes talking to arbitrary machines around the world unbelievably easy (at least compared to other schemes).

Creating a Socket
Roughly speaking, when you clicked on the link that brought you to this page, your browser did something like the following:

# create an INET, STREAMing socket
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# now connect to the web server on port 80 - the normal http port
s.connect(("www.python.org", 80))
When the connect completes, the socket s can be used to send in a request for the text of the page. The same socket will read the reply, and then be destroyed. That’s right, destroyed. Client sockets are normally only used for one exchange (or a small set of sequential exchanges).

What happens in the web server is a bit more complex. First, the web server creates a “server socket”:

# create an INET, STREAMing socket
serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# bind the socket to a public host, and a well-known port
serversocket.bind((socket.gethostname(), 80))
# become a server socket
serversocket.listen(5)
A couple things to notice: we used socket.gethostname() so that the socket would be visible to the outside world. If we had used s.bind(('localhost', 80)) or s.bind(('127.0.0.1', 80)) we would still have a “server” socket, but one that was only visible within the same machine. s.bind(('', 80)) specifies that the socket is reachable by any address the machine happens to have.

A second thing to note: low number ports are usually reserved for “well known” services (HTTP, SNMP etc). If you’re playing around, use a nice high number (4 digits).

Finally, the argument to listen tells the socket library that we want it to queue up as many as 5 connect requests (the normal max) before refusing outside connections. If the rest of the code is written properly, that should be plenty.

Now that we have a “server” socket, listening on port 80, we can enter the mainloop of the web server:

while True:
    # accept connections from outside
    (clientsocket, address) = serversocket.accept()
    # now do something with the clientsocket
    # in this case, we'll pretend this is a threaded server
    ct = client_thread(clientsocket)
    ct.run()
There’s actually 3 general ways in which this loop could work - dispatching a thread to handle clientsocket, create a new process to handle clientsocket, or restructure this app to use non-blocking sockets, and multiplex between our “server” socket and any active clientsockets using select. More about that later. The important thing to understand now is this: this is all a “server” socket does. It doesn’t send any data. It doesn’t receive any data. It just produces “client” sockets. Each clientsocket is created in response to some other “client” socket doing a connect() to the host and port we’re bound to. As soon as we’ve created that clientsocket, we go back to listening for more connections. The two “clients” are free to chat it up - they are using some dynamically allocated port which will be recycled when the conversation ends.

IPC
If you need fast IPC between two processes on one machine, you should look into pipes or shared memory. If you do decide to use AF_INET sockets, bind the “server” socket to 'localhost'. On most platforms, this will take a shortcut around a couple of layers of network code and be quite a bit faster.

See also The multiprocessing integrates cross-platform IPC into a higher-level API.
Using a Socket
The first thing to note, is that the web browser’s “client” socket and the web server’s “client” socket are identical beasts. That is, this is a “peer to peer” conversation. Or to put it another way, as the designer, you will have to decide what the rules of etiquette are for a conversation. Normally, the connecting socket starts the conversation, by sending in a request, or perhaps a signon. But that’s a design decision - it’s not a rule of sockets.

Now there are two sets of verbs to use for communication. You can use send and recv, or you can transform your client socket into a file-like beast and use read and write. The latter is the way Java presents its sockets. I’m not going to talk about it here, except to warn you that you need to use flush on sockets. These are buffered “files”, and a common mistake is to write something, and then read for a reply. Without a flush in there, you may wait forever for the reply, because the request may still be in your output buffer.

Now we come to the major stumbling block of sockets - send and recv operate on the network buffers. They do not necessarily handle all the bytes you hand them (or expect from them), because their major focus is handling the network buffers. In general, they return when the associated network buffers have been filled (send) or emptied (recv). They then tell you how many bytes they handled. It is your responsibility to call them again until your message has been completely dealt with.

When a recv returns 0 bytes, it means the other side has closed (or is in the process of closing) the connection. You will not receive any more data on this connection. Ever. You may be able to send data successfully; I’ll talk more about this later.

A protocol like HTTP uses a socket for only one transfer. The client sends a request, then reads a reply. That’s it. The socket is discarded. This means that a client can detect the end of the reply by receiving 0 bytes.

But if you plan to reuse your socket for further transfers, you need to realize that there is no EOT on a socket. I repeat: if a socket send or recv returns after handling 0 bytes, the connection has been broken. If the connection has not been broken, you may wait on a recv forever, because the socket will not tell you that there’s nothing more to read (for now). Now if you think about that a bit, you’ll come to realize a fundamental truth of sockets: messages must either be fixed length (yuck), or be delimited (shrug), or indicate how long they are (much better), or end by shutting down the connection. The choice is entirely yours, (but some ways are righter than others).

Assuming you don’t want to end the connection, the simplest solution is a fixed length message:

class MySocket:
    """demonstration class only
      - coded for clarity, not efficiency
    """

    def __init__(self, sock=None):
        if sock is None:
            self.sock = socket.socket(
                            socket.AF_INET, socket.SOCK_STREAM)
        else:
            self.sock = sock

    def connect(self, host, port):
        self.sock.connect((host, port))

    def mysend(self, msg):
        totalsent = 0
        while totalsent < MSGLEN:
            sent = self.sock.send(msg[totalsent:])
            if sent == 0:
                raise RuntimeError("socket connection broken")
            totalsent = totalsent + sent

    def myreceive(self):
        chunks = []
        bytes_recd = 0
        while bytes_recd < MSGLEN:
            chunk = self.sock.recv(min(MSGLEN - bytes_recd, 2048))
            if chunk == b'':
                raise RuntimeError("socket connection broken")
            chunks.append(chunk)
            bytes_recd = bytes_recd + len(chunk)
        return b''.join(chunks)
The sending code here is usable for almost any messaging scheme - in Python you send strings, and you can use len() to determine its length (even if it has embedded \0 characters). It’s mostly the receiving code that gets more complex. (And in C, it’s not much worse, except you can’t use strlen if the message has embedded \0s.)

The easiest enhancement is to make the first character of the message an indicator of message type, and have the type determine the length. Now you have two recvs - the first to get (at least) that first character so you can look up the length, and the second in a loop to get the rest. If you decide to go the delimited route, you’ll be receiving in some arbitrary chunk size, (4096 or 8192 is frequently a good match for network buffer sizes), and scanning what you’ve received for a delimiter.

One complication to be aware of: if your conversational protocol allows multiple messages to be sent back to back (without some kind of reply), and you pass recv an arbitrary chunk size, you may end up reading the start of a following message. You’ll need to put that aside and hold onto it, until it’s needed.

Prefixing the message with its length (say, as 5 numeric characters) gets more complex, because (believe it or not), you may not get all 5 characters in one recv. In playing around, you’ll get away with it; but in high network loads, your code will very quickly break unless you use two recv loops - the first to determine the length, the second to get the data part of the message. Nasty. This is also when you’ll discover that send does not always manage to get rid of everything in one pass. And despite having read this, you will eventually get bit by it!

In the interests of space, building your character, (and preserving my competitive position), these enhancements are left as an exercise for the reader. Lets move on to cleaning up.

Binary Data
It is perfectly possible to send binary data over a socket. The major problem is that not all machines use the same formats for binary data. For example, network byte order is big-endian, with the most significant byte first, so a 16 bit integer with the value 1 would be the two hex bytes 00 01. However, most common processors (x86/AMD64, ARM, RISC-V), are little-endian, with the least significant byte first - that same 1 would be 01 00.

Socket libraries have calls for converting 16 and 32 bit integers - ntohl, htonl, ntohs, htons where “n” means network and “h” means host, “s” means short and “l” means long. Where network order is host order, these do nothing, but where the machine is byte-reversed, these swap the bytes around appropriately.

In these days of 64-bit machines, the ASCII representation of binary data is frequently smaller than the binary representation. That’s because a surprising amount of the time, most integers have the value 0, or maybe 1. The string "0" would be two bytes, while a full 64-bit integer would be 8. Of course, this doesn’t fit well with fixed-length messages. Decisions, decisions.

Disconnecting
Strictly speaking, you’re supposed to use shutdown on a socket before you close it. The shutdown is an advisory to the socket at the other end. Depending on the argument you pass it, it can mean “I’m not going to send anymore, but I’ll still listen”, or “I’m not listening, good riddance!”. Most socket libraries, however, are so used to programmers neglecting to use this piece of etiquette that normally a close is the same as shutdown(); close(). So in most situations, an explicit shutdown is not needed.

One way to use shutdown effectively is in an HTTP-like exchange. The client sends a request and then does a shutdown(1). This tells the server “This client is done sending, but can still receive.” The server can detect “EOF” by a receive of 0 bytes. It can assume it has the complete request. The server sends a reply. If the send completes successfully then, indeed, the client was still receiving.

Python takes the automatic shutdown a step further, and says that when a socket is garbage collected, it will automatically do a close if it’s needed. But relying on this is a very bad habit. If your socket just disappears without doing a close, the socket at the other end may hang indefinitely, thinking you’re just being slow. Please close your sockets when you’re done.

When Sockets Die
Probably the worst thing about using blocking sockets is what happens when the other side comes down hard (without doing a close). Your socket is likely to hang. TCP is a reliable protocol, and it will wait a long, long time before giving up on a connection. If you’re using threads, the entire thread is essentially dead. There’s not much you can do about it. As long as you aren’t doing something dumb, like holding a lock while doing a blocking read, the thread isn’t really consuming much in the way of resources. Do not try to kill the thread - part of the reason that threads are more efficient than processes is that they avoid the overhead associated with the automatic recycling of resources. In other words, if you do manage to kill the thread, your whole process is likely to be screwed up.

Non-blocking Sockets
If you’ve understood the preceding, you already know most of what you need to know about the mechanics of using sockets. You’ll still use the same calls, in much the same ways. It’s just that, if you do it right, your app will be almost inside-out.

In Python, you use socket.setblocking(False) to make it non-blocking. In C, it’s more complex, (for one thing, you’ll need to choose between the BSD flavor O_NONBLOCK and the almost indistinguishable POSIX flavor O_NDELAY, which is completely different from TCP_NODELAY), but it’s the exact same idea. You do this after creating the socket, but before using it. (Actually, if you’re nuts, you can switch back and forth.)

The major mechanical difference is that send, recv, connect and accept can return without having done anything. You have (of course) a number of choices. You can check return code and error codes and generally drive yourself crazy. If you don’t believe me, try it sometime. Your app will grow large, buggy and suck CPU. So let’s skip the brain-dead solutions and do it right.

Use select.

In C, coding select is fairly complex. In Python, it’s a piece of cake, but it’s close enough to the C version that if you understand select in Python, you’ll have little trouble with it in C:

ready_to_read, ready_to_write, in_error = \
               select.select(
                  potential_readers,
                  potential_writers,
                  potential_errs,
                  timeout)
You pass select three lists: the first contains all sockets that you might want to try reading; the second all the sockets you might want to try writing to, and the last (normally left empty) those that you want to check for errors. You should note that a socket can go into more than one list. The select call is blocking, but you can give it a timeout. This is generally a sensible thing to do - give it a nice long timeout (say a minute) unless you have good reason to do otherwise.

In return, you will get three lists. They contain the sockets that are actually readable, writable and in error. Each of these lists is a subset (possibly empty) of the corresponding list you passed in.

If a socket is in the output readable list, you can be as-close-to-certain-as-we-ever-get-in-this-business that a recv on that socket will return something. Same idea for the writable list. You’ll be able to send something. Maybe not all you want to, but something is better than nothing. (Actually, any reasonably healthy socket will return as writable - it just means outbound network buffer space is available.)

If you have a “server” socket, put it in the potential_readers list. If it comes out in the readable list, your accept will (almost certainly) work. If you have created a new socket to connect to someone else, put it in the potential_writers list. If it shows up in the writable list, you have a decent chance that it has connected.

Actually, select can be handy even with blocking sockets. It’s one way of determining whether you will block - the socket returns as readable when there’s something in the buffers. However, this still doesn’t help with the problem of determining whether the other end is done, or just busy with something else.

Portability alert: On Unix, select works both with the sockets and files. Don’t try this on Windows. On Windows, select works with sockets only. Also note that in C, many of the more advanced socket options are done differently on Windows. In fact, on Windows I usually use threads (which work very, very well) with my sockets.

Table of Contents
Socket Programming HOWTO
Sockets
History
Creating a Socket
IPC
Using a Socket
Binary Data
Disconnecting
When Sockets Die
Non-blocking Sockets
Previous topic
Regular Expression HOWTO

Next topic
Sorting HOW TO

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Socket Programming HOWTO
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Socket Programming HOWTO
Quick search
  |
Socket Programming HOWTO
Author
Gordon McMillan

Abstract

Sockets are used nearly everywhere, but are one of the most severely misunderstood technologies around. This is a 10,000 foot overview of sockets. It’s not really a tutorial - you’ll still have work to do in getting things operational. It doesn’t cover the fine points (and there are a lot of them), but I hope it will give you enough background to begin using them decently.

Sockets
I’m only going to talk about INET (i.e. IPv4) sockets, but they account for at least 99% of the sockets in use. And I’ll only talk about STREAM (i.e. TCP) sockets - unless you really know what you’re doing (in which case this HOWTO isn’t for you!), you’ll get better behavior and performance from a STREAM socket than anything else. I will try to clear up the mystery of what a socket is, as well as some hints on how to work with blocking and non-blocking sockets. But I’ll start by talking about blocking sockets. You’ll need to know how they work before dealing with non-blocking sockets.

Part of the trouble with understanding these things is that “socket” can mean a number of subtly different things, depending on context. So first, let’s make a distinction between a “client” socket - an endpoint of a conversation, and a “server” socket, which is more like a switchboard operator. The client application (your browser, for example) uses “client” sockets exclusively; the web server it’s talking to uses both “server” sockets and “client” sockets.

History
Of the various forms of IPC, sockets are by far the most popular. On any given platform, there are likely to be other forms of IPC that are faster, but for cross-platform communication, sockets are about the only game in town.

They were invented in Berkeley as part of the BSD flavor of Unix. They spread like wildfire with the internet. With good reason — the combination of sockets with INET makes talking to arbitrary machines around the world unbelievably easy (at least compared to other schemes).

Creating a Socket
Roughly speaking, when you clicked on the link that brought you to this page, your browser did something like the following:

# create an INET, STREAMing socket
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# now connect to the web server on port 80 - the normal http port
s.connect(("www.python.org", 80))
When the connect completes, the socket s can be used to send in a request for the text of the page. The same socket will read the reply, and then be destroyed. That’s right, destroyed. Client sockets are normally only used for one exchange (or a small set of sequential exchanges).

What happens in the web server is a bit more complex. First, the web server creates a “server socket”:

# create an INET, STREAMing socket
serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# bind the socket to a public host, and a well-known port
serversocket.bind((socket.gethostname(), 80))
# become a server socket
serversocket.listen(5)
A couple things to notice: we used socket.gethostname() so that the socket would be visible to the outside world. If we had used s.bind(('localhost', 80)) or s.bind(('127.0.0.1', 80)) we would still have a “server” socket, but one that was only visible within the same machine. s.bind(('', 80)) specifies that the socket is reachable by any address the machine happens to have.

A second thing to note: low number ports are usually reserved for “well known” services (HTTP, SNMP etc). If you’re playing around, use a nice high number (4 digits).

Finally, the argument to listen tells the socket library that we want it to queue up as many as 5 connect requests (the normal max) before refusing outside connections. If the rest of the code is written properly, that should be plenty.

Now that we have a “server” socket, listening on port 80, we can enter the mainloop of the web server:

while True:
    # accept connections from outside
    (clientsocket, address) = serversocket.accept()
    # now do something with the clientsocket
    # in this case, we'll pretend this is a threaded server
    ct = client_thread(clientsocket)
    ct.run()
There’s actually 3 general ways in which this loop could work - dispatching a thread to handle clientsocket, create a new process to handle clientsocket, or restructure this app to use non-blocking sockets, and multiplex between our “server” socket and any active clientsockets using select. More about that later. The important thing to understand now is this: this is all a “server” socket does. It doesn’t send any data. It doesn’t receive any data. It just produces “client” sockets. Each clientsocket is created in response to some other “client” socket doing a connect() to the host and port we’re bound to. As soon as we’ve created that clientsocket, we go back to listening for more connections. The two “clients” are free to chat it up - they are using some dynamically allocated port which will be recycled when the conversation ends.

IPC
If you need fast IPC between two processes on one machine, you should look into pipes or shared memory. If you do decide to use AF_INET sockets, bind the “server” socket to 'localhost'. On most platforms, this will take a shortcut around a couple of layers of network code and be quite a bit faster.

See also The multiprocessing integrates cross-platform IPC into a higher-level API.
Using a Socket
The first thing to note, is that the web browser’s “client” socket and the web server’s “client” socket are identical beasts. That is, this is a “peer to peer” conversation. Or to put it another way, as the designer, you will have to decide what the rules of etiquette are for a conversation. Normally, the connecting socket starts the conversation, by sending in a request, or perhaps a signon. But that’s a design decision - it’s not a rule of sockets.

Now there are two sets of verbs to use for communication. You can use send and recv, or you can transform your client socket into a file-like beast and use read and write. The latter is the way Java presents its sockets. I’m not going to talk about it here, except to warn you that you need to use flush on sockets. These are buffered “files”, and a common mistake is to write something, and then read for a reply. Without a flush in there, you may wait forever for the reply, because the request may still be in your output buffer.

Now we come to the major stumbling block of sockets - send and recv operate on the network buffers. They do not necessarily handle all the bytes you hand them (or expect from them), because their major focus is handling the network buffers. In general, they return when the associated network buffers have been filled (send) or emptied (recv). They then tell you how many bytes they handled. It is your responsibility to call them again until your message has been completely dealt with.

When a recv returns 0 bytes, it means the other side has closed (or is in the process of closing) the connection. You will not receive any more data on this connection. Ever. You may be able to send data successfully; I’ll talk more about this later.

A protocol like HTTP uses a socket for only one transfer. The client sends a request, then reads a reply. That’s it. The socket is discarded. This means that a client can detect the end of the reply by receiving 0 bytes.

But if you plan to reuse your socket for further transfers, you need to realize that there is no EOT on a socket. I repeat: if a socket send or recv returns after handling 0 bytes, the connection has been broken. If the connection has not been broken, you may wait on a recv forever, because the socket will not tell you that there’s nothing more to read (for now). Now if you think about that a bit, you’ll come to realize a fundamental truth of sockets: messages must either be fixed length (yuck), or be delimited (shrug), or indicate how long they are (much better), or end by shutting down the connection. The choice is entirely yours, (but some ways are righter than others).

Assuming you don’t want to end the connection, the simplest solution is a fixed length message:

class MySocket:
    """demonstration class only
      - coded for clarity, not efficiency
    """

    def __init__(self, sock=None):
        if sock is None:
            self.sock = socket.socket(
                            socket.AF_INET, socket.SOCK_STREAM)
        else:
            self.sock = sock

    def connect(self, host, port):
        self.sock.connect((host, port))

    def mysend(self, msg):
        totalsent = 0
        while totalsent < MSGLEN:
            sent = self.sock.send(msg[totalsent:])
            if sent == 0:
                raise RuntimeError("socket connection broken")
            totalsent = totalsent + sent

    def myreceive(self):
        chunks = []
        bytes_recd = 0
        while bytes_recd < MSGLEN:
            chunk = self.sock.recv(min(MSGLEN - bytes_recd, 2048))
            if chunk == b'':
                raise RuntimeError("socket connection broken")
            chunks.append(chunk)
            bytes_recd = bytes_recd + len(chunk)
        return b''.join(chunks)
The sending code here is usable for almost any messaging scheme - in Python you send strings, and you can use len() to determine its length (even if it has embedded \0 characters). It’s mostly the receiving code that gets more complex. (And in C, it’s not much worse, except you can’t use strlen if the message has embedded \0s.)

The easiest enhancement is to make the first character of the message an indicator of message type, and have the type determine the length. Now you have two recvs - the first to get (at least) that first character so you can look up the length, and the second in a loop to get the rest. If you decide to go the delimited route, you’ll be receiving in some arbitrary chunk size, (4096 or 8192 is frequently a good match for network buffer sizes), and scanning what you’ve received for a delimiter.

One complication to be aware of: if your conversational protocol allows multiple messages to be sent back to back (without some kind of reply), and you pass recv an arbitrary chunk size, you may end up reading the start of a following message. You’ll need to put that aside and hold onto it, until it’s needed.

Prefixing the message with its length (say, as 5 numeric characters) gets more complex, because (believe it or not), you may not get all 5 characters in one recv. In playing around, you’ll get away with it; but in high network loads, your code will very quickly break unless you use two recv loops - the first to determine the length, the second to get the data part of the message. Nasty. This is also when you’ll discover that send does not always manage to get rid of everything in one pass. And despite having read this, you will eventually get bit by it!

In the interests of space, building your character, (and preserving my competitive position), these enhancements are left as an exercise for the reader. Lets move on to cleaning up.

Binary Data
It is perfectly possible to send binary data over a socket. The major problem is that not all machines use the same formats for binary data. For example, network byte order is big-endian, with the most significant byte first, so a 16 bit integer with the value 1 would be the two hex bytes 00 01. However, most common processors (x86/AMD64, ARM, RISC-V), are little-endian, with the least significant byte first - that same 1 would be 01 00.

Socket libraries have calls for converting 16 and 32 bit integers - ntohl, htonl, ntohs, htons where “n” means network and “h” means host, “s” means short and “l” means long. Where network order is host order, these do nothing, but where the machine is byte-reversed, these swap the bytes around appropriately.

In these days of 64-bit machines, the ASCII representation of binary data is frequently smaller than the binary representation. That’s because a surprising amount of the time, most integers have the value 0, or maybe 1. The string "0" would be two bytes, while a full 64-bit integer would be 8. Of course, this doesn’t fit well with fixed-length messages. Decisions, decisions.

Disconnecting
Strictly speaking, you’re supposed to use shutdown on a socket before you close it. The shutdown is an advisory to the socket at the other end. Depending on the argument you pass it, it can mean “I’m not going to send anymore, but I’ll still listen”, or “I’m not listening, good riddance!”. Most socket libraries, however, are so used to programmers neglecting to use this piece of etiquette that normally a close is the same as shutdown(); close(). So in most situations, an explicit shutdown is not needed.

One way to use shutdown effectively is in an HTTP-like exchange. The client sends a request and then does a shutdown(1). This tells the server “This client is done sending, but can still receive.” The server can detect “EOF” by a receive of 0 bytes. It can assume it has the complete request. The server sends a reply. If the send completes successfully then, indeed, the client was still receiving.

Python takes the automatic shutdown a step further, and says that when a socket is garbage collected, it will automatically do a close if it’s needed. But relying on this is a very bad habit. If your socket just disappears without doing a close, the socket at the other end may hang indefinitely, thinking you’re just being slow. Please close your sockets when you’re done.

When Sockets Die
Probably the worst thing about using blocking sockets is what happens when the other side comes down hard (without doing a close). Your socket is likely to hang. TCP is a reliable protocol, and it will wait a long, long time before giving up on a connection. If you’re using threads, the entire thread is essentially dead. There’s not much you can do about it. As long as you aren’t doing something dumb, like holding a lock while doing a blocking read, the thread isn’t really consuming much in the way of resources. Do not try to kill the thread - part of the reason that threads are more efficient than processes is that they avoid the overhead associated with the automatic recycling of resources. In other words, if you do manage to kill the thread, your whole process is likely to be screwed up.

Non-blocking Sockets
If you’ve understood the preceding, you already know most of what you need to know about the mechanics of using sockets. You’ll still use the same calls, in much the same ways. It’s just that, if you do it right, your app will be almost inside-out.

In Python, you use socket.setblocking(False) to make it non-blocking. In C, it’s more complex, (for one thing, you’ll need to choose between the BSD flavor O_NONBLOCK and the almost indistinguishable POSIX flavor O_NDELAY, which is completely different from TCP_NODELAY), but it’s the exact same idea. You do this after creating the socket, but before using it. (Actually, if you’re nuts, you can switch back and forth.)

The major mechanical difference is that send, recv, connect and accept can return without having done anything. You have (of course) a number of choices. You can check return code and error codes and generally drive yourself crazy. If you don’t believe me, try it sometime. Your app will grow large, buggy and suck CPU. So let’s skip the brain-dead solutions and do it right.

Use select.

In C, coding select is fairly complex. In Python, it’s a piece of cake, but it’s close enough to the C version that if you understand select in Python, you’ll have little trouble with it in C:

ready_to_read, ready_to_write, in_error = \
               select.select(
                  potential_readers,
                  potential_writers,
                  potential_errs,
                  timeout)
You pass select three lists: the first contains all sockets that you might want to try reading; the second all the sockets you might want to try writing to, and the last (normally left empty) those that you want to check for errors. You should note that a socket can go into more than one list. The select call is blocking, but you can give it a timeout. This is generally a sensible thing to do - give it a nice long timeout (say a minute) unless you have good reason to do otherwise.

In return, you will get three lists. They contain the sockets that are actually readable, writable and in error. Each of these lists is a subset (possibly empty) of the corresponding list you passed in.

If a socket is in the output readable list, you can be as-close-to-certain-as-we-ever-get-in-this-business that a recv on that socket will return something. Same idea for the writable list. You’ll be able to send something. Maybe not all you want to, but something is better than nothing. (Actually, any reasonably healthy socket will return as writable - it just means outbound network buffer space is available.)

If you have a “server” socket, put it in the potential_readers list. If it comes out in the readable list, your accept will (almost certainly) work. If you have created a new socket to connect to someone else, put it in the potential_writers list. If it shows up in the writable list, you have a decent chance that it has connected.

Actually, select can be handy even with blocking sockets. It’s one way of determining whether you will block - the socket returns as readable when there’s something in the buffers. However, this still doesn’t help with the problem of determining whether the other end is done, or just busy with something else.

Portability alert: On Unix, select works both with the sockets and files. Don’t try this on Windows. On Windows, select works with sockets only. Also note that in C, many of the more advanced socket options are done differently on Windows. In fact, on Windows I usually use threads (which work very, very well) with my sockets.

Table of Contents
Socket Programming HOWTO
Sockets
History
Creating a Socket
IPC
Using a Socket
Binary Data
Disconnecting
When Sockets Die
Non-blocking Sockets
Previous topic
Regular Expression HOWTO

Next topic
Sorting HOW TO

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Socket Programming HOWTO
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » HOWTO Fetch Internet Resources Using The urllib Package
Quick search
  |
HOWTO Fetch Internet Resources Using The urllib Package
Author
Michael Foord

Note There is a French translation of an earlier revision of this HOWTO, available at urllib2 - Le Manuel manquant.
Introduction¶
Related Articles

You may also find useful the following article on fetching web resources with Python:

Basic Authentication

A tutorial on Basic Authentication, with examples in Python.

urllib.request is a Python module for fetching URLs (Uniform Resource Locators). It offers a very simple interface, in the form of the urlopen function. This is capable of fetching URLs using a variety of different protocols. It also offers a slightly more complex interface for handling common situations - like basic authentication, cookies, proxies and so on. These are provided by objects called handlers and openers.

urllib.request supports fetching URLs for many “URL schemes” (identified by the string before the ":" in URL - for example "ftp" is the URL scheme of "ftp://python.org/") using their associated network protocols (e.g. FTP, HTTP). This tutorial focuses on the most common case, HTTP.

For straightforward situations urlopen is very easy to use. But as soon as you encounter errors or non-trivial cases when opening HTTP URLs, you will need some understanding of the HyperText Transfer Protocol. The most comprehensive and authoritative reference to HTTP is RFC 2616. This is a technical document and not intended to be easy to read. This HOWTO aims to illustrate using urllib, with enough detail about HTTP to help you through. It is not intended to replace the urllib.request docs, but is supplementary to them.

Fetching URLs
The simplest way to use urllib.request is as follows:

import urllib.request
with urllib.request.urlopen('http://python.org/') as response:
   html = response.read()
If you wish to retrieve a resource via URL and store it in a temporary location, you can do so via the shutil.copyfileobj() and tempfile.NamedTemporaryFile() functions:

import shutil
import tempfile
import urllib.request

with urllib.request.urlopen('http://python.org/') as response:
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        shutil.copyfileobj(response, tmp_file)

with open(tmp_file.name) as html:
    pass
Many uses of urllib will be that simple (note that instead of an ‘http:’ URL we could have used a URL starting with ‘ftp:’, ‘file:’, etc.). However, it’s the purpose of this tutorial to explain the more complicated cases, concentrating on HTTP.

HTTP is based on requests and responses - the client makes requests and servers send responses. urllib.request mirrors this with a Request object which represents the HTTP request you are making. In its simplest form you create a Request object that specifies the URL you want to fetch. Calling urlopen with this Request object returns a response object for the URL requested. This response is a file-like object, which means you can for example call .read() on the response:

import urllib.request

req = urllib.request.Request('http://www.voidspace.org.uk')
with urllib.request.urlopen(req) as response:
   the_page = response.read()
Note that urllib.request makes use of the same Request interface to handle all URL schemes. For example, you can make an FTP request like so:

req = urllib.request.Request('ftp://example.com/')
In the case of HTTP, there are two extra things that Request objects allow you to do: First, you can pass data to be sent to the server. Second, you can pass extra information (“metadata”) about the data or about the request itself, to the server - this information is sent as HTTP “headers”. Let’s look at each of these in turn.

Data
Sometimes you want to send data to a URL (often the URL will refer to a CGI (Common Gateway Interface) script or other web application). With HTTP, this is often done using what’s known as a POST request. This is often what your browser does when you submit a HTML form that you filled in on the web. Not all POSTs have to come from forms: you can use a POST to transmit arbitrary data to your own application. In the common case of HTML forms, the data needs to be encoded in a standard way, and then passed to the Request object as the data argument. The encoding is done using a function from the urllib.parse library.

import urllib.parse
import urllib.request

url = 'http://www.someserver.com/cgi-bin/register.cgi'
values = {'name' : 'Michael Foord',
          'location' : 'Northampton',
          'language' : 'Python' }

data = urllib.parse.urlencode(values)
data = data.encode('ascii') # data should be bytes
req = urllib.request.Request(url, data)
with urllib.request.urlopen(req) as response:
   the_page = response.read()
Note that other encodings are sometimes required (e.g. for file upload from HTML forms - see HTML Specification, Form Submission for more details).

If you do not pass the data argument, urllib uses a GET request. One way in which GET and POST requests differ is that POST requests often have “side-effects”: they change the state of the system in some way (for example by placing an order with the website for a hundredweight of tinned spam to be delivered to your door). Though the HTTP standard makes it clear that POSTs are intended to always cause side-effects, and GET requests never to cause side-effects, nothing prevents a GET request from having side-effects, nor a POST requests from having no side-effects. Data can also be passed in an HTTP GET request by encoding it in the URL itself.

This is done as follows:

>>>
>>> import urllib.request
>>> import urllib.parse
>>> data = {}
>>> data['name'] = 'Somebody Here'
>>> data['location'] = 'Northampton'
>>> data['language'] = 'Python'
>>> url_values = urllib.parse.urlencode(data)
>>> print(url_values)  # The order may differ from below.  
name=Somebody+Here&language=Python&location=Northampton
>>> url = 'http://www.example.com/example.cgi'
>>> full_url = url + '?' + url_values
>>> data = urllib.request.urlopen(full_url)
Notice that the full URL is created by adding a ? to the URL, followed by the encoded values.

Headers
We’ll discuss here one particular HTTP header, to illustrate how to add headers to your HTTP request.

Some websites 1 dislike being browsed by programs, or send different versions to different browsers 2. By default urllib identifies itself as Python-urllib/x.y (where x and y are the major and minor version numbers of the Python release, e.g. Python-urllib/2.5), which may confuse the site, or just plain not work. The way a browser identifies itself is through the User-Agent header 3. When you create a Request object you can pass a dictionary of headers in. The following example makes the same request as above, but identifies itself as a version of Internet Explorer 4.

import urllib.parse
import urllib.request

url = 'http://www.someserver.com/cgi-bin/register.cgi'
user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'
values = {'name': 'Michael Foord',
          'location': 'Northampton',
          'language': 'Python' }
headers = {'User-Agent': user_agent}

data = urllib.parse.urlencode(values)
data = data.encode('ascii')
req = urllib.request.Request(url, data, headers)
with urllib.request.urlopen(req) as response:
   the_page = response.read()
The response also has two useful methods. See the section on info and geturl which comes after we have a look at what happens when things go wrong.

Handling Exceptions
urlopen raises URLError when it cannot handle a response (though as usual with Python APIs, built-in exceptions such as ValueError, TypeError etc. may also be raised).

HTTPError is the subclass of URLError raised in the specific case of HTTP URLs.

The exception classes are exported from the urllib.error module.

URLError
Often, URLError is raised because there is no network connection (no route to the specified server), or the specified server doesn’t exist. In this case, the exception raised will have a ‘reason’ attribute, which is a tuple containing an error code and a text error message.

e.g.

>>>
>>> req = urllib.request.Request('http://www.pretend_server.org')
>>> try: urllib.request.urlopen(req)
... except urllib.error.URLError as e:
...     print(e.reason)      
...
(4, 'getaddrinfo failed')
HTTPError
Every HTTP response from the server contains a numeric “status code”. Sometimes the status code indicates that the server is unable to fulfil the request. The default handlers will handle some of these responses for you (for example, if the response is a “redirection” that requests the client fetch the document from a different URL, urllib will handle that for you). For those it can’t handle, urlopen will raise an HTTPError. Typical errors include ‘404’ (page not found), ‘403’ (request forbidden), and ‘401’ (authentication required).

See section 10 of RFC 2616 for a reference on all the HTTP error codes.

The HTTPError instance raised will have an integer ‘code’ attribute, which corresponds to the error sent by the server.

Error Codes
Because the default handlers handle redirects (codes in the 300 range), and codes in the 100–299 range indicate success, you will usually only see error codes in the 400–599 range.

http.server.BaseHTTPRequestHandler.responses is a useful dictionary of response codes in that shows all the response codes used by RFC 2616. The dictionary is reproduced here for convenience

# Table mapping response codes to messages; entries have the
# form {code: (shortmessage, longmessage)}.
responses = {
    100: ('Continue', 'Request received, please continue'),
    101: ('Switching Protocols',
          'Switching to new protocol; obey Upgrade header'),

    200: ('OK', 'Request fulfilled, document follows'),
    201: ('Created', 'Document created, URL follows'),
    202: ('Accepted',
          'Request accepted, processing continues off-line'),
    203: ('Non-Authoritative Information', 'Request fulfilled from cache'),
    204: ('No Content', 'Request fulfilled, nothing follows'),
    205: ('Reset Content', 'Clear input form for further input.'),
    206: ('Partial Content', 'Partial content follows.'),

    300: ('Multiple Choices',
          'Object has several resources -- see URI list'),
    301: ('Moved Permanently', 'Object moved permanently -- see URI list'),
    302: ('Found', 'Object moved temporarily -- see URI list'),
    303: ('See Other', 'Object moved -- see Method and URL list'),
    304: ('Not Modified',
          'Document has not changed since given time'),
    305: ('Use Proxy',
          'You must use proxy specified in Location to access this '
          'resource.'),
    307: ('Temporary Redirect',
          'Object moved temporarily -- see URI list'),

    400: ('Bad Request',
          'Bad request syntax or unsupported method'),
    401: ('Unauthorized',
          'No permission -- see authorization schemes'),
    402: ('Payment Required',
          'No payment -- see charging schemes'),
    403: ('Forbidden',
          'Request forbidden -- authorization will not help'),
    404: ('Not Found', 'Nothing matches the given URI'),
    405: ('Method Not Allowed',
          'Specified method is invalid for this server.'),
    406: ('Not Acceptable', 'URI not available in preferred format.'),
    407: ('Proxy Authentication Required', 'You must authenticate with '
          'this proxy before proceeding.'),
    408: ('Request Timeout', 'Request timed out; try again later.'),
    409: ('Conflict', 'Request conflict.'),
    410: ('Gone',
          'URI no longer exists and has been permanently removed.'),
    411: ('Length Required', 'Client must specify Content-Length.'),
    412: ('Precondition Failed', 'Precondition in headers is false.'),
    413: ('Request Entity Too Large', 'Entity is too large.'),
    414: ('Request-URI Too Long', 'URI is too long.'),
    415: ('Unsupported Media Type', 'Entity body in unsupported format.'),
    416: ('Requested Range Not Satisfiable',
          'Cannot satisfy request range.'),
    417: ('Expectation Failed',
          'Expect condition could not be satisfied.'),

    500: ('Internal Server Error', 'Server got itself in trouble'),
    501: ('Not Implemented',
          'Server does not support this operation'),
    502: ('Bad Gateway', 'Invalid responses from another server/proxy.'),
    503: ('Service Unavailable',
          'The server cannot process the request due to a high load'),
    504: ('Gateway Timeout',
          'The gateway server did not receive a timely response'),
    505: ('HTTP Version Not Supported', 'Cannot fulfill request.'),
    }
When an error is raised the server responds by returning an HTTP error code and an error page. You can use the HTTPError instance as a response on the page returned. This means that as well as the code attribute, it also has read, geturl, and info, methods as returned by the urllib.response module:

>>>
>>> req = urllib.request.Request('http://www.python.org/fish.html')
>>> try:
...     urllib.request.urlopen(req)
... except urllib.error.HTTPError as e:
...     print(e.code)
...     print(e.read())  
...
404
b'<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">\n\n\n<html
  ...
  <title>Page Not Found</title>\n
  ...
Wrapping it Up
So if you want to be prepared for HTTPError or URLError there are two basic approaches. I prefer the second approach.

Number 1
from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError
req = Request(someurl)
try:
    response = urlopen(req)
except HTTPError as e:
    print('The server couldn\'t fulfill the request.')
    print('Error code: ', e.code)
except URLError as e:
    print('We failed to reach a server.')
    print('Reason: ', e.reason)
else:
    # everything is fine
Note The except HTTPError must come first, otherwise except URLError will also catch an HTTPError.
Number 2
from urllib.request import Request, urlopen
from urllib.error import URLError
req = Request(someurl)
try:
    response = urlopen(req)
except URLError as e:
    if hasattr(e, 'reason'):
        print('We failed to reach a server.')
        print('Reason: ', e.reason)
    elif hasattr(e, 'code'):
        print('The server couldn\'t fulfill the request.')
        print('Error code: ', e.code)
else:
    # everything is fine
info and geturl
The response returned by urlopen (or the HTTPError instance) has two useful methods info() and geturl() and is defined in the module urllib.response..

geturl - this returns the real URL of the page fetched. This is useful because urlopen (or the opener object used) may have followed a redirect. The URL of the page fetched may not be the same as the URL requested.

info - this returns a dictionary-like object that describes the page fetched, particularly the headers sent by the server. It is currently an http.client.HTTPMessage instance.

Typical headers include ‘Content-length’, ‘Content-type’, and so on. See the Quick Reference to HTTP Headers for a useful listing of HTTP headers with brief explanations of their meaning and use.

Openers and Handlers
When you fetch a URL you use an opener (an instance of the perhaps confusingly named urllib.request.OpenerDirector). Normally we have been using the default opener - via urlopen - but you can create custom openers. Openers use handlers. All the “heavy lifting” is done by the handlers. Each handler knows how to open URLs for a particular URL scheme (http, ftp, etc.), or how to handle an aspect of URL opening, for example HTTP redirections or HTTP cookies.

You will want to create openers if you want to fetch URLs with specific handlers installed, for example to get an opener that handles cookies, or to get an opener that does not handle redirections.

To create an opener, instantiate an OpenerDirector, and then call .add_handler(some_handler_instance) repeatedly.

Alternatively, you can use build_opener, which is a convenience function for creating opener objects with a single function call. build_opener adds several handlers by default, but provides a quick way to add more and/or override the default handlers.

Other sorts of handlers you might want to can handle proxies, authentication, and other common but slightly specialised situations.

install_opener can be used to make an opener object the (global) default opener. This means that calls to urlopen will use the opener you have installed.

Opener objects have an open method, which can be called directly to fetch urls in the same way as the urlopen function: there’s no need to call install_opener, except as a convenience.

Basic Authentication
To illustrate creating and installing a handler we will use the HTTPBasicAuthHandler. For a more detailed discussion of this subject – including an explanation of how Basic Authentication works - see the Basic Authentication Tutorial.

When authentication is required, the server sends a header (as well as the 401 error code) requesting authentication. This specifies the authentication scheme and a ‘realm’. The header looks like: WWW-Authenticate: SCHEME realm="REALM".

e.g.

WWW-Authenticate: Basic realm="cPanel Users"
The client should then retry the request with the appropriate name and password for the realm included as a header in the request. This is ‘basic authentication’. In order to simplify this process we can create an instance of HTTPBasicAuthHandler and an opener to use this handler.

The HTTPBasicAuthHandler uses an object called a password manager to handle the mapping of URLs and realms to passwords and usernames. If you know what the realm is (from the authentication header sent by the server), then you can use a HTTPPasswordMgr. Frequently one doesn’t care what the realm is. In that case, it is convenient to use HTTPPasswordMgrWithDefaultRealm. This allows you to specify a default username and password for a URL. This will be supplied in the absence of you providing an alternative combination for a specific realm. We indicate this by providing None as the realm argument to the add_password method.

The top-level URL is the first URL that requires authentication. URLs “deeper” than the URL you pass to .add_password() will also match.

# create a password manager
password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()

# Add the username and password.
# If we knew the realm, we could use it instead of None.
top_level_url = "http://example.com/foo/"
password_mgr.add_password(None, top_level_url, username, password)

handler = urllib.request.HTTPBasicAuthHandler(password_mgr)

# create "opener" (OpenerDirector instance)
opener = urllib.request.build_opener(handler)

# use the opener to fetch a URL
opener.open(a_url)

# Install the opener.
# Now all calls to urllib.request.urlopen use our opener.
urllib.request.install_opener(opener)
Note In the above example we only supplied our HTTPBasicAuthHandler to build_opener. By default openers have the handlers for normal situations – ProxyHandler (if a proxy setting such as an http_proxy environment variable is set), UnknownHandler, HTTPHandler, HTTPDefaultErrorHandler, HTTPRedirectHandler, FTPHandler, FileHandler, DataHandler, HTTPErrorProcessor.
top_level_url is in fact either a full URL (including the ‘http:’ scheme component and the hostname and optionally the port number) e.g. "http://example.com/" or an “authority” (i.e. the hostname, optionally including the port number) e.g. "example.com" or "example.com:8080" (the latter example includes a port number). The authority, if present, must NOT contain the “userinfo” component - for example "joe:password@example.com" is not correct.

Proxies
urllib will auto-detect your proxy settings and use those. This is through the ProxyHandler, which is part of the normal handler chain when a proxy setting is detected. Normally that’s a good thing, but there are occasions when it may not be helpful 5. One way to do this is to setup our own ProxyHandler, with no proxies defined. This is done using similar steps to setting up a Basic Authentication handler:

>>>
>>> proxy_support = urllib.request.ProxyHandler({})
>>> opener = urllib.request.build_opener(proxy_support)
>>> urllib.request.install_opener(opener)
Note Currently urllib.request does not support fetching of https locations through a proxy. However, this can be enabled by extending urllib.request as shown in the recipe 6.
Note HTTP_PROXY will be ignored if a variable REQUEST_METHOD is set; see the documentation on getproxies().
Sockets and Layers
The Python support for fetching resources from the web is layered. urllib uses the http.client library, which in turn uses the socket library.

As of Python 2.3 you can specify how long a socket should wait for a response before timing out. This can be useful in applications which have to fetch web pages. By default the socket module has no timeout and can hang. Currently, the socket timeout is not exposed at the http.client or urllib.request levels. However, you can set the default timeout globally for all sockets using

import socket
import urllib.request

# timeout in seconds
timeout = 10
socket.setdefaulttimeout(timeout)

# this call to urllib.request.urlopen now uses the default timeout
# we have set in the socket module
req = urllib.request.Request('http://www.voidspace.org.uk')
response = urllib.request.urlopen(req)
Footnotes
This document was reviewed and revised by John Lee.

1
Google for example.

2
Browser sniffing is a very bad practice for website design - building sites using web standards is much more sensible. Unfortunately a lot of sites still send different versions to different browsers.

3
The user agent for MSIE 6 is ‘Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)’

4
For details of more HTTP request headers, see Quick Reference to HTTP Headers.

5
In my case I have to use a proxy to access the internet at work. If you attempt to fetch localhost URLs through this proxy it blocks them. IE is set to use the proxy, which urllib picks up on. In order to test scripts with a localhost server, I have to prevent urllib from using the proxy.

6
urllib opener for SSL proxy (CONNECT method): ASPN Cookbook Recipe.

Table of Contents
HOWTO Fetch Internet Resources Using The urllib Package
Introduction
Fetching URLs
Data
Headers
Handling Exceptions
URLError
HTTPError
Error Codes
Wrapping it Up
Number 1
Number 2
info and geturl
Openers and Handlers
Basic Authentication
Proxies
Sockets and Layers
Footnotes
Previous topic
Unicode HOWTO

Next topic
Argparse Tutorial

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » HOWTO Fetch Internet Resources Using The urllib Package
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Argparse Tutorial
Quick search
  |
Argparse Tutorial
author
Tshepang Lekhonkhobe

This tutorial is intended to be a gentle introduction to argparse, the recommended command-line parsing module in the Python standard library.

Note There are two other modules that fulfill the same task, namely getopt (an equivalent for getopt() from the C language) and the deprecated optparse. Note also that argparse is based on optparse, and therefore very similar in terms of usage.
Concepts¶
Let’s show the sort of functionality that we are going to explore in this introductory tutorial by making use of the ls command:

$ ls
cpython  devguide  prog.py  pypy  rm-unused-function.patch
$ ls pypy
ctypes_configure  demo  dotviewer  include  lib_pypy  lib-python ...
$ ls -l
total 20
drwxr-xr-x 19 wena wena 4096 Feb 18 18:51 cpython
drwxr-xr-x  4 wena wena 4096 Feb  8 12:04 devguide
-rwxr-xr-x  1 wena wena  535 Feb 19 00:05 prog.py
drwxr-xr-x 14 wena wena 4096 Feb  7 00:59 pypy
-rw-r--r--  1 wena wena  741 Feb 18 01:01 rm-unused-function.patch
$ ls --help
Usage: ls [OPTION]... [FILE]...
List information about the FILEs (the current directory by default).
Sort entries alphabetically if none of -cftuvSUX nor --sort is specified.
...
A few concepts we can learn from the four commands:

The ls command is useful when run without any options at all. It defaults to displaying the contents of the current directory.

If we want beyond what it provides by default, we tell it a bit more. In this case, we want it to display a different directory, pypy. What we did is specify what is known as a positional argument. It’s named so because the program should know what to do with the value, solely based on where it appears on the command line. This concept is more relevant to a command like cp, whose most basic usage is cp SRC DEST. The first position is what you want copied, and the second position is where you want it copied to.

Now, say we want to change behaviour of the program. In our example, we display more info for each file instead of just showing the file names. The -l in that case is known as an optional argument.

That’s a snippet of the help text. It’s very useful in that you can come across a program you have never used before, and can figure out how it works simply by reading its help text.

The basics
Let us start with a very simple example which does (almost) nothing:

import argparse
parser = argparse.ArgumentParser()
parser.parse_args()
Following is a result of running the code:

$ python3 prog.py
$ python3 prog.py --help
usage: prog.py [-h]

options:
  -h, --help  show this help message and exit
$ python3 prog.py --verbose
usage: prog.py [-h]
prog.py: error: unrecognized arguments: --verbose
$ python3 prog.py foo
usage: prog.py [-h]
prog.py: error: unrecognized arguments: foo
Here is what is happening:

Running the script without any options results in nothing displayed to stdout. Not so useful.

The second one starts to display the usefulness of the argparse module. We have done almost nothing, but already we get a nice help message.

The --help option, which can also be shortened to -h, is the only option we get for free (i.e. no need to specify it). Specifying anything else results in an error. But even then, we do get a useful usage message, also for free.

Introducing Positional arguments
An example:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("echo")
args = parser.parse_args()
print(args.echo)
And running the code:

$ python3 prog.py
usage: prog.py [-h] echo
prog.py: error: the following arguments are required: echo
$ python3 prog.py --help
usage: prog.py [-h] echo

positional arguments:
  echo

options:
  -h, --help  show this help message and exit
$ python3 prog.py foo
foo
Here is what’s happening:

We’ve added the add_argument() method, which is what we use to specify which command-line options the program is willing to accept. In this case, I’ve named it echo so that it’s in line with its function.

Calling our program now requires us to specify an option.

The parse_args() method actually returns some data from the options specified, in this case, echo.

The variable is some form of ‘magic’ that argparse performs for free (i.e. no need to specify which variable that value is stored in). You will also notice that its name matches the string argument given to the method, echo.

Note however that, although the help display looks nice and all, it currently is not as helpful as it can be. For example we see that we got echo as a positional argument, but we don’t know what it does, other than by guessing or by reading the source code. So, let’s make it a bit more useful:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("echo", help="echo the string you use here")
args = parser.parse_args()
print(args.echo)
And we get:

$ python3 prog.py -h
usage: prog.py [-h] echo

positional arguments:
  echo        echo the string you use here

options:
  -h, --help  show this help message and exit
Now, how about doing something even more useful:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", help="display a square of a given number")
args = parser.parse_args()
print(args.square**2)
Following is a result of running the code:

$ python3 prog.py 4
Traceback (most recent call last):
  File "prog.py", line 5, in <module>
    print(args.square**2)
TypeError: unsupported operand type(s) for ** or pow(): 'str' and 'int'
That didn’t go so well. That’s because argparse treats the options we give it as strings, unless we tell it otherwise. So, let’s tell argparse to treat that input as an integer:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", help="display a square of a given number",
                    type=int)
args = parser.parse_args()
print(args.square**2)
Following is a result of running the code:

$ python3 prog.py 4
16
$ python3 prog.py four
usage: prog.py [-h] square
prog.py: error: argument square: invalid int value: 'four'
That went well. The program now even helpfully quits on bad illegal input before proceeding.

Introducing Optional arguments
So far we have been playing with positional arguments. Let us have a look on how to add optional ones:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("--verbosity", help="increase output verbosity")
args = parser.parse_args()
if args.verbosity:
    print("verbosity turned on")
And the output:

$ python3 prog.py --verbosity 1
verbosity turned on
$ python3 prog.py
$ python3 prog.py --help
usage: prog.py [-h] [--verbosity VERBOSITY]

options:
  -h, --help            show this help message and exit
  --verbosity VERBOSITY
                        increase output verbosity
$ python3 prog.py --verbosity
usage: prog.py [-h] [--verbosity VERBOSITY]
prog.py: error: argument --verbosity: expected one argument
Here is what is happening:

The program is written so as to display something when --verbosity is specified and display nothing when not.

To show that the option is actually optional, there is no error when running the program without it. Note that by default, if an optional argument isn’t used, the relevant variable, in this case args.verbosity, is given None as a value, which is the reason it fails the truth test of the if statement.

The help message is a bit different.

When using the --verbosity option, one must also specify some value, any value.

The above example accepts arbitrary integer values for --verbosity, but for our simple program, only two values are actually useful, True or False. Let’s modify the code accordingly:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("--verbose", help="increase output verbosity",
                    action="store_true")
args = parser.parse_args()
if args.verbose:
    print("verbosity turned on")
And the output:

$ python3 prog.py --verbose
verbosity turned on
$ python3 prog.py --verbose 1
usage: prog.py [-h] [--verbose]
prog.py: error: unrecognized arguments: 1
$ python3 prog.py --help
usage: prog.py [-h] [--verbose]

options:
  -h, --help  show this help message and exit
  --verbose   increase output verbosity
Here is what is happening:

The option is now more of a flag than something that requires a value. We even changed the name of the option to match that idea. Note that we now specify a new keyword, action, and give it the value "store_true". This means that, if the option is specified, assign the value True to args.verbose. Not specifying it implies False.

It complains when you specify a value, in true spirit of what flags actually are.

Notice the different help text.

Short options
If you are familiar with command line usage, you will notice that I haven’t yet touched on the topic of short versions of the options. It’s quite simple:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("-v", "--verbose", help="increase output verbosity",
                    action="store_true")
args = parser.parse_args()
if args.verbose:
    print("verbosity turned on")
And here goes:

$ python3 prog.py -v
verbosity turned on
$ python3 prog.py --help
usage: prog.py [-h] [-v]

options:
  -h, --help     show this help message and exit
  -v, --verbose  increase output verbosity
Note that the new ability is also reflected in the help text.

Combining Positional and Optional arguments
Our program keeps growing in complexity:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", type=int,
                    help="display a square of a given number")
parser.add_argument("-v", "--verbose", action="store_true",
                    help="increase output verbosity")
args = parser.parse_args()
answer = args.square**2
if args.verbose:
    print(f"the square of {args.square} equals {answer}")
else:
    print(answer)
And now the output:

$ python3 prog.py
usage: prog.py [-h] [-v] square
prog.py: error: the following arguments are required: square
$ python3 prog.py 4
16
$ python3 prog.py 4 --verbose
the square of 4 equals 16
$ python3 prog.py --verbose 4
the square of 4 equals 16
We’ve brought back a positional argument, hence the complaint.

Note that the order does not matter.

How about we give this program of ours back the ability to have multiple verbosity values, and actually get to use them:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", type=int,
                    help="display a square of a given number")
parser.add_argument("-v", "--verbosity", type=int,
                    help="increase output verbosity")
args = parser.parse_args()
answer = args.square**2
if args.verbosity == 2:
    print(f"the square of {args.square} equals {answer}")
elif args.verbosity == 1:
    print(f"{args.square}^2 == {answer}")
else:
    print(answer)
And the output:

$ python3 prog.py 4
16
$ python3 prog.py 4 -v
usage: prog.py [-h] [-v VERBOSITY] square
prog.py: error: argument -v/--verbosity: expected one argument
$ python3 prog.py 4 -v 1
4^2 == 16
$ python3 prog.py 4 -v 2
the square of 4 equals 16
$ python3 prog.py 4 -v 3
16
These all look good except the last one, which exposes a bug in our program. Let’s fix it by restricting the values the --verbosity option can accept:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", type=int,
                    help="display a square of a given number")
parser.add_argument("-v", "--verbosity", type=int, choices=[0, 1, 2],
                    help="increase output verbosity")
args = parser.parse_args()
answer = args.square**2
if args.verbosity == 2:
    print(f"the square of {args.square} equals {answer}")
elif args.verbosity == 1:
    print(f"{args.square}^2 == {answer}")
else:
    print(answer)
And the output:

$ python3 prog.py 4 -v 3
usage: prog.py [-h] [-v {0,1,2}] square
prog.py: error: argument -v/--verbosity: invalid choice: 3 (choose from 0, 1, 2)
$ python3 prog.py 4 -h
usage: prog.py [-h] [-v {0,1,2}] square

positional arguments:
  square                display a square of a given number

options:
  -h, --help            show this help message and exit
  -v {0,1,2}, --verbosity {0,1,2}
                        increase output verbosity
Note that the change also reflects both in the error message as well as the help string.

Now, let’s use a different approach of playing with verbosity, which is pretty common. It also matches the way the CPython executable handles its own verbosity argument (check the output of python --help):

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", type=int,
                    help="display the square of a given number")
parser.add_argument("-v", "--verbosity", action="count",
                    help="increase output verbosity")
args = parser.parse_args()
answer = args.square**2
if args.verbosity == 2:
    print(f"the square of {args.square} equals {answer}")
elif args.verbosity == 1:
    print(f"{args.square}^2 == {answer}")
else:
    print(answer)
We have introduced another action, “count”, to count the number of occurrences of specific options.

$ python3 prog.py 4
16
$ python3 prog.py 4 -v
4^2 == 16
$ python3 prog.py 4 -vv
the square of 4 equals 16
$ python3 prog.py 4 --verbosity --verbosity
the square of 4 equals 16
$ python3 prog.py 4 -v 1
usage: prog.py [-h] [-v] square
prog.py: error: unrecognized arguments: 1
$ python3 prog.py 4 -h
usage: prog.py [-h] [-v] square

positional arguments:
  square           display a square of a given number

options:
  -h, --help       show this help message and exit
  -v, --verbosity  increase output verbosity
$ python3 prog.py 4 -vvv
16
Yes, it’s now more of a flag (similar to action="store_true") in the previous version of our script. That should explain the complaint.

It also behaves similar to “store_true” action.

Now here’s a demonstration of what the “count” action gives. You’ve probably seen this sort of usage before.

And if you don’t specify the -v flag, that flag is considered to have None value.

As should be expected, specifying the long form of the flag, we should get the same output.

Sadly, our help output isn’t very informative on the new ability our script has acquired, but that can always be fixed by improving the documentation for our script (e.g. via the help keyword argument).

That last output exposes a bug in our program.

Let’s fix:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", type=int,
                    help="display a square of a given number")
parser.add_argument("-v", "--verbosity", action="count",
                    help="increase output verbosity")
args = parser.parse_args()
answer = args.square**2

# bugfix: replace == with >=
if args.verbosity >= 2:
    print(f"the square of {args.square} equals {answer}")
elif args.verbosity >= 1:
    print(f"{args.square}^2 == {answer}")
else:
    print(answer)
And this is what it gives:

$ python3 prog.py 4 -vvv
the square of 4 equals 16
$ python3 prog.py 4 -vvvv
the square of 4 equals 16
$ python3 prog.py 4
Traceback (most recent call last):
  File "prog.py", line 11, in <module>
    if args.verbosity >= 2:
TypeError: '>=' not supported between instances of 'NoneType' and 'int'
First output went well, and fixes the bug we had before. That is, we want any value >= 2 to be as verbose as possible.

Third output not so good.

Let’s fix that bug:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("square", type=int,
                    help="display a square of a given number")
parser.add_argument("-v", "--verbosity", action="count", default=0,
                    help="increase output verbosity")
args = parser.parse_args()
answer = args.square**2
if args.verbosity >= 2:
    print(f"the square of {args.square} equals {answer}")
elif args.verbosity >= 1:
    print(f"{args.square}^2 == {answer}")
else:
    print(answer)
We’ve just introduced yet another keyword, default. We’ve set it to 0 in order to make it comparable to the other int values. Remember that by default, if an optional argument isn’t specified, it gets the None value, and that cannot be compared to an int value (hence the TypeError exception).

And:

$ python3 prog.py 4
16
You can go quite far just with what we’ve learned so far, and we have only scratched the surface. The argparse module is very powerful, and we’ll explore a bit more of it before we end this tutorial.

Getting a little more advanced
What if we wanted to expand our tiny program to perform other powers, not just squares:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("x", type=int, help="the base")
parser.add_argument("y", type=int, help="the exponent")
parser.add_argument("-v", "--verbosity", action="count", default=0)
args = parser.parse_args()
answer = args.x**args.y
if args.verbosity >= 2:
    print(f"{args.x} to the power {args.y} equals {answer}")
elif args.verbosity >= 1:
    print(f"{args.x}^{args.y} == {answer}")
else:
    print(answer)
Output:

$ python3 prog.py
usage: prog.py [-h] [-v] x y
prog.py: error: the following arguments are required: x, y
$ python3 prog.py -h
usage: prog.py [-h] [-v] x y

positional arguments:
  x                the base
  y                the exponent

options:
  -h, --help       show this help message and exit
  -v, --verbosity
$ python3 prog.py 4 2 -v
4^2 == 16
Notice that so far we’ve been using verbosity level to change the text that gets displayed. The following example instead uses verbosity level to display more text instead:

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("x", type=int, help="the base")
parser.add_argument("y", type=int, help="the exponent")
parser.add_argument("-v", "--verbosity", action="count", default=0)
args = parser.parse_args()
answer = args.x**args.y
if args.verbosity >= 2:
    print(f"Running '{__file__}'")
if args.verbosity >= 1:
    print(f"{args.x}^{args.y} == ", end="")
print(answer)
Output:

$ python3 prog.py 4 2
16
$ python3 prog.py 4 2 -v
4^2 == 16
$ python3 prog.py 4 2 -vv
Running 'prog.py'
4^2 == 16
Conflicting options
So far, we have been working with two methods of an argparse.ArgumentParser instance. Let’s introduce a third one, add_mutually_exclusive_group(). It allows for us to specify options that conflict with each other. Let’s also change the rest of the program so that the new functionality makes more sense: we’ll introduce the --quiet option, which will be the opposite of the --verbose one:

import argparse

parser = argparse.ArgumentParser()
group = parser.add_mutually_exclusive_group()
group.add_argument("-v", "--verbose", action="store_true")
group.add_argument("-q", "--quiet", action="store_true")
parser.add_argument("x", type=int, help="the base")
parser.add_argument("y", type=int, help="the exponent")
args = parser.parse_args()
answer = args.x**args.y

if args.quiet:
    print(answer)
elif args.verbose:
    print(f"{args.x} to the power {args.y} equals {answer}")
else:
    print(f"{args.x}^{args.y} == {answer}")
Our program is now simpler, and we’ve lost some functionality for the sake of demonstration. Anyways, here’s the output:

$ python3 prog.py 4 2
4^2 == 16
$ python3 prog.py 4 2 -q
16
$ python3 prog.py 4 2 -v
4 to the power 2 equals 16
$ python3 prog.py 4 2 -vq
usage: prog.py [-h] [-v | -q] x y
prog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose
$ python3 prog.py 4 2 -v --quiet
usage: prog.py [-h] [-v | -q] x y
prog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose
That should be easy to follow. I’ve added that last output so you can see the sort of flexibility you get, i.e. mixing long form options with short form ones.

Before we conclude, you probably want to tell your users the main purpose of your program, just in case they don’t know:

import argparse

parser = argparse.ArgumentParser(description="calculate X to the power of Y")
group = parser.add_mutually_exclusive_group()
group.add_argument("-v", "--verbose", action="store_true")
group.add_argument("-q", "--quiet", action="store_true")
parser.add_argument("x", type=int, help="the base")
parser.add_argument("y", type=int, help="the exponent")
args = parser.parse_args()
answer = args.x**args.y

if args.quiet:
    print(answer)
elif args.verbose:
    print("{} to the power {} equals {}".format(args.x, args.y, answer))
else:
    print("{}^{} == {}".format(args.x, args.y, answer))
Note that slight difference in the usage text. Note the [-v | -q], which tells us that we can either use -v or -q, but not both at the same time:

$ python3 prog.py --help
usage: prog.py [-h] [-v | -q] x y

calculate X to the power of Y

positional arguments:
  x              the base
  y              the exponent

options:
  -h, --help     show this help message and exit
  -v, --verbose
  -q, --quiet
Conclusion
The argparse module offers a lot more than shown here. Its docs are quite detailed and thorough, and full of examples. Having gone through this tutorial, you should easily digest them without feeling overwhelmed.

Table of Contents
Argparse Tutorial
Concepts
The basics
Introducing Positional arguments
Introducing Optional arguments
Short options
Combining Positional and Optional arguments
Getting a little more advanced
Conflicting options
Conclusion
Previous topic
HOWTO Fetch Internet Resources Using The urllib Package

Next topic
An introduction to the ipaddress module

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Argparse Tutorial
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » An introduction to the ipaddress module
Quick search
  |
An introduction to the ipaddress module
author
Peter Moody

author
Nick Coghlan

Overview

This document aims to provide a gentle introduction to the ipaddress module. It is aimed primarily at users that aren’t already familiar with IP networking terminology, but may also be useful to network engineers wanting an overview of how ipaddress represents IP network addressing concepts.

Creating Address/Network/Interface objects
Since ipaddress is a module for inspecting and manipulating IP addresses, the first thing you’ll want to do is create some objects. You can use ipaddress to create objects from strings and integers.

A Note on IP Versions
For readers that aren’t particularly familiar with IP addressing, it’s important to know that the Internet Protocol (IP) is currently in the process of moving from version 4 of the protocol to version 6. This transition is occurring largely because version 4 of the protocol doesn’t provide enough addresses to handle the needs of the whole world, especially given the increasing number of devices with direct connections to the internet.

Explaining the details of the differences between the two versions of the protocol is beyond the scope of this introduction, but readers need to at least be aware that these two versions exist, and it will sometimes be necessary to force the use of one version or the other.

IP Host Addresses
Addresses, often referred to as “host addresses” are the most basic unit when working with IP addressing. The simplest way to create addresses is to use the ipaddress.ip_address() factory function, which automatically determines whether to create an IPv4 or IPv6 address based on the passed in value:

>>>
ipaddress.ip_address('192.0.2.1')
IPv4Address('192.0.2.1')
ipaddress.ip_address('2001:DB8::1')
IPv6Address('2001:db8::1')
Addresses can also be created directly from integers. Values that will fit within 32 bits are assumed to be IPv4 addresses:

>>>
>>> ipaddress.ip_address(3221225985)
IPv4Address('192.0.2.1')
>>> ipaddress.ip_address(42540766411282592856903984951653826561)
IPv6Address('2001:db8::1')
To force the use of IPv4 or IPv6 addresses, the relevant classes can be invoked directly. This is particularly useful to force creation of IPv6 addresses for small integers:

>>>
>>> ipaddress.ip_address(1)
IPv4Address('0.0.0.1')
>>> ipaddress.IPv4Address(1)
IPv4Address('0.0.0.1')
>>> ipaddress.IPv6Address(1)
IPv6Address('::1')
Defining Networks
Host addresses are usually grouped together into IP networks, so ipaddress provides a way to create, inspect and manipulate network definitions. IP network objects are constructed from strings that define the range of host addresses that are part of that network. The simplest form for that information is a “network address/network prefix” pair, where the prefix defines the number of leading bits that are compared to determine whether or not an address is part of the network and the network address defines the expected value of those bits.

As for addresses, a factory function is provided that determines the correct IP version automatically:

>>>
>>> ipaddress.ip_network('192.0.2.0/24')
IPv4Network('192.0.2.0/24')
>>> ipaddress.ip_network('2001:db8::0/96')
IPv6Network('2001:db8::/96')
Network objects cannot have any host bits set. The practical effect of this is that 192.0.2.1/24 does not describe a network. Such definitions are referred to as interface objects since the ip-on-a-network notation is commonly used to describe network interfaces of a computer on a given network and are described further in the next section.

By default, attempting to create a network object with host bits set will result in ValueError being raised. To request that the additional bits instead be coerced to zero, the flag strict=False can be passed to the constructor:

>>>
>>> ipaddress.ip_network('192.0.2.1/24')
Traceback (most recent call last):
   ...
ValueError: 192.0.2.1/24 has host bits set
>>> ipaddress.ip_network('192.0.2.1/24', strict=False)
IPv4Network('192.0.2.0/24')
While the string form offers significantly more flexibility, networks can also be defined with integers, just like host addresses. In this case, the network is considered to contain only the single address identified by the integer, so the network prefix includes the entire network address:

>>>
>>> ipaddress.ip_network(3221225984)
IPv4Network('192.0.2.0/32')
>>> ipaddress.ip_network(42540766411282592856903984951653826560)
IPv6Network('2001:db8::/128')
As with addresses, creation of a particular kind of network can be forced by calling the class constructor directly instead of using the factory function.

Host Interfaces
As mentioned just above, if you need to describe an address on a particular network, neither the address nor the network classes are sufficient. Notation like 192.0.2.1/24 is commonly used by network engineers and the people who write tools for firewalls and routers as shorthand for “the host 192.0.2.1 on the network 192.0.2.0/24”, Accordingly, ipaddress provides a set of hybrid classes that associate an address with a particular network. The interface for creation is identical to that for defining network objects, except that the address portion isn’t constrained to being a network address.

>>>
ipaddress.ip_interface('192.0.2.1/24')
IPv4Interface('192.0.2.1/24')
ipaddress.ip_interface('2001:db8::1/96')
IPv6Interface('2001:db8::1/96')
Integer inputs are accepted (as with networks), and use of a particular IP version can be forced by calling the relevant constructor directly.

Inspecting Address/Network/Interface Objects
You’ve gone to the trouble of creating an IPv(4|6)(Address|Network|Interface) object, so you probably want to get information about it. ipaddress tries to make doing this easy and intuitive.

Extracting the IP version:

>>>
>>> addr4 = ipaddress.ip_address('192.0.2.1')
>>> addr6 = ipaddress.ip_address('2001:db8::1')
>>> addr6.version
6
>>> addr4.version
4
Obtaining the network from an interface:

>>>
>>> host4 = ipaddress.ip_interface('192.0.2.1/24')
>>> host4.network
IPv4Network('192.0.2.0/24')
>>> host6 = ipaddress.ip_interface('2001:db8::1/96')
>>> host6.network
IPv6Network('2001:db8::/96')
Finding out how many individual addresses are in a network:

>>>
>>> net4 = ipaddress.ip_network('192.0.2.0/24')
>>> net4.num_addresses
256
>>> net6 = ipaddress.ip_network('2001:db8::0/96')
>>> net6.num_addresses
4294967296
Iterating through the “usable” addresses on a network:

>>>
>>> net4 = ipaddress.ip_network('192.0.2.0/24')
>>> for x in net4.hosts():
...     print(x)  
192.0.2.1
192.0.2.2
192.0.2.3
192.0.2.4
...
192.0.2.252
192.0.2.253
192.0.2.254
Obtaining the netmask (i.e. set bits corresponding to the network prefix) or the hostmask (any bits that are not part of the netmask):

>>>
net4 = ipaddress.ip_network('192.0.2.0/24')
net4.netmask
IPv4Address('255.255.255.0')
net4.hostmask
IPv4Address('0.0.0.255')
net6 = ipaddress.ip_network('2001:db8::0/96')
net6.netmask
IPv6Address('ffff:ffff:ffff:ffff:ffff:ffff::')
net6.hostmask
IPv6Address('::ffff:ffff')
Exploding or compressing the address:

>>>
>>> addr6.exploded
'2001:0db8:0000:0000:0000:0000:0000:0001'
>>> addr6.compressed
'2001:db8::1'
>>> net6.exploded
'2001:0db8:0000:0000:0000:0000:0000:0000/96'
>>> net6.compressed
'2001:db8::/96'
While IPv4 doesn’t support explosion or compression, the associated objects still provide the relevant properties so that version neutral code can easily ensure the most concise or most verbose form is used for IPv6 addresses while still correctly handling IPv4 addresses.

Networks as lists of Addresses
It’s sometimes useful to treat networks as lists. This means it is possible to index them like this:

>>>
>>> net4[1]
IPv4Address('192.0.2.1')
>>> net4[-1]
IPv4Address('192.0.2.255')
>>> net6[1]
IPv6Address('2001:db8::1')
>>> net6[-1]
IPv6Address('2001:db8::ffff:ffff')
It also means that network objects lend themselves to using the list membership test syntax like this:

if address in network:
    # do something
Containment testing is done efficiently based on the network prefix:

>>>
>>> addr4 = ipaddress.ip_address('192.0.2.1')
>>> addr4 in ipaddress.ip_network('192.0.2.0/24')
True
>>> addr4 in ipaddress.ip_network('192.0.3.0/24')
False
Comparisons
ipaddress provides some simple, hopefully intuitive ways to compare objects, where it makes sense:

>>>
>>> ipaddress.ip_address('192.0.2.1') < ipaddress.ip_address('192.0.2.2')
True
A TypeError exception is raised if you try to compare objects of different versions or different types.

Using IP Addresses with other modules
Other modules that use IP addresses (such as socket) usually won’t accept objects from this module directly. Instead, they must be coerced to an integer or string that the other module will accept:

>>>
>>> addr4 = ipaddress.ip_address('192.0.2.1')
>>> str(addr4)
'192.0.2.1'
>>> int(addr4)
3221225985
Getting more detail when instance creation fails
When creating address/network/interface objects using the version-agnostic factory functions, any errors will be reported as ValueError with a generic error message that simply says the passed in value was not recognized as an object of that type. The lack of a specific error is because it’s necessary to know whether the value is supposed to be IPv4 or IPv6 in order to provide more detail on why it has been rejected.

To support use cases where it is useful to have access to this additional detail, the individual class constructors actually raise the ValueError subclasses ipaddress.AddressValueError and ipaddress.NetmaskValueError to indicate exactly which part of the definition failed to parse correctly.

The error messages are significantly more detailed when using the class constructors directly. For example:

>>>
>>> ipaddress.ip_address("192.168.0.256")
Traceback (most recent call last):
  ...
ValueError: '192.168.0.256' does not appear to be an IPv4 or IPv6 address
>>> ipaddress.IPv4Address("192.168.0.256")
Traceback (most recent call last):
  ...
ipaddress.AddressValueError: Octet 256 (> 255) not permitted in '192.168.0.256'

>>> ipaddress.ip_network("192.168.0.1/64")
Traceback (most recent call last):
  ...
ValueError: '192.168.0.1/64' does not appear to be an IPv4 or IPv6 network
>>> ipaddress.IPv4Network("192.168.0.1/64")
Traceback (most recent call last):
  ...
ipaddress.NetmaskValueError: '64' is not a valid netmask
However, both of the module specific exceptions have ValueError as their parent class, so if you’re not concerned with the particular type of error, you can still write code like the following:

try:
    network = ipaddress.IPv4Network(address)
except ValueError:
    print('address/netmask is invalid for IPv4:', address)
Table of Contents
An introduction to the ipaddress module
Creating Address/Network/Interface objects
A Note on IP Versions
IP Host Addresses
Defining Networks
Host Interfaces
Inspecting Address/Network/Interface Objects
Networks as lists of Addresses
Comparisons
Using IP Addresses with other modules
Getting more detail when instance creation fails
Previous topic
Argparse Tutorial

Next topic
Argument Clinic How-To

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » An introduction to the ipaddress module
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Argument Clinic How-To
Quick search
  |
Argument Clinic How-To
author
Larry Hastings

Abstract

Argument Clinic is a preprocessor for CPython C files. Its purpose is to automate all the boilerplate involved with writing argument parsing code for “builtins”. This document shows you how to convert your first C function to work with Argument Clinic, and then introduces some advanced topics on Argument Clinic usage.

Currently Argument Clinic is considered internal-only for CPython. Its use is not supported for files outside CPython, and no guarantees are made regarding backwards compatibility for future versions. In other words: if you maintain an external C extension for CPython, you’re welcome to experiment with Argument Clinic in your own code. But the version of Argument Clinic that ships with the next version of CPython could be totally incompatible and break all your code.

The Goals Of Argument Clinic
Argument Clinic’s primary goal is to take over responsibility for all argument parsing code inside CPython. This means that, when you convert a function to work with Argument Clinic, that function should no longer do any of its own argument parsing—the code generated by Argument Clinic should be a “black box” to you, where CPython calls in at the top, and your code gets called at the bottom, with PyObject *args (and maybe PyObject *kwargs) magically converted into the C variables and types you need.

In order for Argument Clinic to accomplish its primary goal, it must be easy to use. Currently, working with CPython’s argument parsing library is a chore, requiring maintaining redundant information in a surprising number of places. When you use Argument Clinic, you don’t have to repeat yourself.

Obviously, no one would want to use Argument Clinic unless it’s solving their problem—and without creating new problems of its own. So it’s paramount that Argument Clinic generate correct code. It’d be nice if the code was faster, too, but at the very least it should not introduce a major speed regression. (Eventually Argument Clinic should make a major speedup possible—we could rewrite its code generator to produce tailor-made argument parsing code, rather than calling the general-purpose CPython argument parsing library. That would make for the fastest argument parsing possible!)

Additionally, Argument Clinic must be flexible enough to work with any approach to argument parsing. Python has some functions with some very strange parsing behaviors; Argument Clinic’s goal is to support all of them.

Finally, the original motivation for Argument Clinic was to provide introspection “signatures” for CPython builtins. It used to be, the introspection query functions would throw an exception if you passed in a builtin. With Argument Clinic, that’s a thing of the past!

One idea you should keep in mind, as you work with Argument Clinic: the more information you give it, the better job it’ll be able to do. Argument Clinic is admittedly relatively simple right now. But as it evolves it will get more sophisticated, and it should be able to do many interesting and smart things with all the information you give it.

Basic Concepts And Usage
Argument Clinic ships with CPython; you’ll find it in Tools/clinic/clinic.py. If you run that script, specifying a C file as an argument:

$ python3 Tools/clinic/clinic.py foo.c
Argument Clinic will scan over the file looking for lines that look exactly like this:

/*[clinic input]
When it finds one, it reads everything up to a line that looks exactly like this:

[clinic start generated code]*/
Everything in between these two lines is input for Argument Clinic. All of these lines, including the beginning and ending comment lines, are collectively called an Argument Clinic “block”.

When Argument Clinic parses one of these blocks, it generates output. This output is rewritten into the C file immediately after the block, followed by a comment containing a checksum. The Argument Clinic block now looks like this:

/*[clinic input]
... clinic input goes here ...
[clinic start generated code]*/
... clinic output goes here ...
/*[clinic end generated code: checksum=...]*/
If you run Argument Clinic on the same file a second time, Argument Clinic will discard the old output and write out the new output with a fresh checksum line. However, if the input hasn’t changed, the output won’t change either.

You should never modify the output portion of an Argument Clinic block. Instead, change the input until it produces the output you want. (That’s the purpose of the checksum—to detect if someone changed the output, as these edits would be lost the next time Argument Clinic writes out fresh output.)

For the sake of clarity, here’s the terminology we’ll use with Argument Clinic:

The first line of the comment (/*[clinic input]) is the start line.

The last line of the initial comment ([clinic start generated code]*/) is the end line.

The last line (/*[clinic end generated code: checksum=...]*/) is the checksum line.

In between the start line and the end line is the input.

In between the end line and the checksum line is the output.

All the text collectively, from the start line to the checksum line inclusively, is the block. (A block that hasn’t been successfully processed by Argument Clinic yet doesn’t have output or a checksum line, but it’s still considered a block.)

Converting Your First Function
The best way to get a sense of how Argument Clinic works is to convert a function to work with it. Here, then, are the bare minimum steps you’d need to follow to convert a function to work with Argument Clinic. Note that for code you plan to check in to CPython, you really should take the conversion farther, using some of the advanced concepts you’ll see later on in the document (like “return converters” and “self converters”). But we’ll keep it simple for this walkthrough so you can learn.

Let’s dive in!

Make sure you’re working with a freshly updated checkout of the CPython trunk.

Find a Python builtin that calls either PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords(), and hasn’t been converted to work with Argument Clinic yet. For my example I’m using _pickle.Pickler.dump().

If the call to the PyArg_Parse function uses any of the following format units:

O&
O!
es
es#
et
et#
or if it has multiple calls to PyArg_ParseTuple(), you should choose a different function. Argument Clinic does support all of these scenarios. But these are advanced topics—let’s do something simpler for your first function.

Also, if the function has multiple calls to PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords() where it supports different types for the same argument, or if the function uses something besides PyArg_Parse functions to parse its arguments, it probably isn’t suitable for conversion to Argument Clinic. Argument Clinic doesn’t support generic functions or polymorphic parameters.

Add the following boilerplate above the function, creating our block:

/*[clinic input]
[clinic start generated code]*/
Cut the docstring and paste it in between the [clinic] lines, removing all the junk that makes it a properly quoted C string. When you’re done you should have just the text, based at the left margin, with no line wider than 80 characters. (Argument Clinic will preserve indents inside the docstring.)

If the old docstring had a first line that looked like a function signature, throw that line away. (The docstring doesn’t need it anymore—when you use help() on your builtin in the future, the first line will be built automatically based on the function’s signature.)

Sample:

/*[clinic input]
Write a pickled representation of obj to the open file.
[clinic start generated code]*/
If your docstring doesn’t have a “summary” line, Argument Clinic will complain. So let’s make sure it has one. The “summary” line should be a paragraph consisting of a single 80-column line at the beginning of the docstring.

(Our example docstring consists solely of a summary line, so the sample code doesn’t have to change for this step.)

Above the docstring, enter the name of the function, followed by a blank line. This should be the Python name of the function, and should be the full dotted path to the function—it should start with the name of the module, include any sub-modules, and if the function is a method on a class it should include the class name too.

Sample:

/*[clinic input]
_pickle.Pickler.dump

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
If this is the first time that module or class has been used with Argument Clinic in this C file, you must declare the module and/or class. Proper Argument Clinic hygiene prefers declaring these in a separate block somewhere near the top of the C file, in the same way that include files and statics go at the top. (In our sample code we’ll just show the two blocks next to each other.)

The name of the class and module should be the same as the one seen by Python. Check the name defined in the PyModuleDef or PyTypeObject as appropriate.

When you declare a class, you must also specify two aspects of its type in C: the type declaration you’d use for a pointer to an instance of this class, and a pointer to the PyTypeObject for this class.

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/

/*[clinic input]
_pickle.Pickler.dump

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
Declare each of the parameters to the function. Each parameter should get its own line. All the parameter lines should be indented from the function name and the docstring.

The general form of these parameter lines is as follows:

name_of_parameter: converter
If the parameter has a default value, add that after the converter:

name_of_parameter: converter = default_value
Argument Clinic’s support for “default values” is quite sophisticated; please see the section below on default values for more information.

Add a blank line below the parameters.

What’s a “converter”? It establishes both the type of the variable used in C, and the method to convert the Python value into a C value at runtime. For now you’re going to use what’s called a “legacy converter”—a convenience syntax intended to make porting old code into Argument Clinic easier.

For each parameter, copy the “format unit” for that parameter from the PyArg_Parse() format argument and specify that as its converter, as a quoted string. (“format unit” is the formal name for the one-to-three character substring of the format parameter that tells the argument parsing function what the type of the variable is and how to convert it. For more on format units please see Parsing arguments and building values.)

For multicharacter format units like z#, use the entire two-or-three character string.

Sample:

 /*[clinic input]
 module _pickle
 class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
 [clinic start generated code]*/

 /*[clinic input]
 _pickle.Pickler.dump

    obj: 'O'

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
If your function has | in the format string, meaning some parameters have default values, you can ignore it. Argument Clinic infers which parameters are optional based on whether or not they have default values.

If your function has $ in the format string, meaning it takes keyword-only arguments, specify * on a line by itself before the first keyword-only argument, indented the same as the parameter lines.

(_pickle.Pickler.dump has neither, so our sample is unchanged.)

If the existing C function calls PyArg_ParseTuple() (as opposed to PyArg_ParseTupleAndKeywords()), then all its arguments are positional-only.

To mark all parameters as positional-only in Argument Clinic, add a / on a line by itself after the last parameter, indented the same as the parameter lines.

Currently this is all-or-nothing; either all parameters are positional-only, or none of them are. (In the future Argument Clinic may relax this restriction.)

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
It’s helpful to write a per-parameter docstring for each parameter. But per-parameter docstrings are optional; you can skip this step if you prefer.

Here’s how to add a per-parameter docstring. The first line of the per-parameter docstring must be indented further than the parameter definition. The left margin of this first line establishes the left margin for the whole per-parameter docstring; all the text you write will be outdented by this amount. You can write as much text as you like, across multiple lines if you wish.

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
Save and close the file, then run Tools/clinic/clinic.py on it. With luck everything worked—your block now has output, and a .c.h file has been generated! Reopen the file in your text editor to see:

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/

static PyObject *
_pickle_Pickler_dump(PicklerObject *self, PyObject *obj)
/*[clinic end generated code: output=87ecad1261e02ac7 input=552eb1c0f52260d9]*/
Obviously, if Argument Clinic didn’t produce any output, it’s because it found an error in your input. Keep fixing your errors and retrying until Argument Clinic processes your file without complaint.

For readability, most of the glue code has been generated to a .c.h file. You’ll need to include that in your original .c file, typically right after the clinic module block:

#include "clinic/_pickle.c.h"
Double-check that the argument-parsing code Argument Clinic generated looks basically the same as the existing code.

First, ensure both places use the same argument-parsing function. The existing code must call either PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords(); ensure that the code generated by Argument Clinic calls the exact same function.

Second, the format string passed in to PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords() should be exactly the same as the hand-written one in the existing function, up to the colon or semi-colon.

(Argument Clinic always generates its format strings with a : followed by the name of the function. If the existing code’s format string ends with ;, to provide usage help, this change is harmless—don’t worry about it.)

Third, for parameters whose format units require two arguments (like a length variable, or an encoding string, or a pointer to a conversion function), ensure that the second argument is exactly the same between the two invocations.

Fourth, inside the output portion of the block you’ll find a preprocessor macro defining the appropriate static PyMethodDef structure for this builtin:

#define __PICKLE_PICKLER_DUMP_METHODDEF    \
{"dump", (PyCFunction)__pickle_Pickler_dump, METH_O, __pickle_Pickler_dump__doc__},
This static structure should be exactly the same as the existing static PyMethodDef structure for this builtin.

If any of these items differ in any way, adjust your Argument Clinic function specification and rerun Tools/clinic/clinic.py until they are the same.

Notice that the last line of its output is the declaration of your “impl” function. This is where the builtin’s implementation goes. Delete the existing prototype of the function you’re modifying, but leave the opening curly brace. Now delete its argument parsing code and the declarations of all the variables it dumps the arguments into. Notice how the Python arguments are now arguments to this impl function; if the implementation used different names for these variables, fix it.

Let’s reiterate, just because it’s kind of weird. Your code should now look like this:

static return_type
your_function_impl(...)
/*[clinic end generated code: checksum=...]*/
{
...
Argument Clinic generated the checksum line and the function prototype just above it. You should write the opening (and closing) curly braces for the function, and the implementation inside.

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/
/*[clinic end generated code: checksum=da39a3ee5e6b4b0d3255bfef95601890afd80709]*/

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/

PyDoc_STRVAR(__pickle_Pickler_dump__doc__,
"Write a pickled representation of obj to the open file.\n"
"\n"
...
static PyObject *
_pickle_Pickler_dump_impl(PicklerObject *self, PyObject *obj)
/*[clinic end generated code: checksum=3bd30745bf206a48f8b576a1da3d90f55a0a4187]*/
{
    /* Check whether the Pickler was initialized correctly (issue3664).
       Developers often forget to call __init__() in their subclasses, which
       would trigger a segfault without this check. */
    if (self->write == NULL) {
        PyErr_Format(PicklingError,
                     "Pickler.__init__() was not called by %s.__init__()",
                     Py_TYPE(self)->tp_name);
        return NULL;
    }

    if (_Pickler_ClearBuffer(self) < 0)
        return NULL;

    ...
Remember the macro with the PyMethodDef structure for this function? Find the existing PyMethodDef structure for this function and replace it with a reference to the macro. (If the builtin is at module scope, this will probably be very near the end of the file; if the builtin is a class method, this will probably be below but relatively near to the implementation.)

Note that the body of the macro contains a trailing comma. So when you replace the existing static PyMethodDef structure with the macro, don’t add a comma to the end.

Sample:

static struct PyMethodDef Pickler_methods[] = {
    __PICKLE_PICKLER_DUMP_METHODDEF
    __PICKLE_PICKLER_CLEAR_MEMO_METHODDEF
    {NULL, NULL}                /* sentinel */
};
Compile, then run the relevant portions of the regression-test suite. This change should not introduce any new compile-time warnings or errors, and there should be no externally visible change to Python’s behavior.

Well, except for one difference: inspect.signature() run on your function should now provide a valid signature!

Congratulations, you’ve ported your first function to work with Argument Clinic!

Advanced Topics
Now that you’ve had some experience working with Argument Clinic, it’s time for some advanced topics.

Symbolic default values
The default value you provide for a parameter can’t be any arbitrary expression. Currently the following are explicitly supported:

Numeric constants (integer and float)

String constants

True, False, and None

Simple symbolic constants like sys.maxsize, which must start with the name of the module

In case you’re curious, this is implemented in from_builtin() in Lib/inspect.py.

(In the future, this may need to get even more elaborate, to allow full expressions like CONSTANT - 1.)

Renaming the C functions and variables generated by Argument Clinic
Argument Clinic automatically names the functions it generates for you. Occasionally this may cause a problem, if the generated name collides with the name of an existing C function. There’s an easy solution: override the names used for the C functions. Just add the keyword "as" to your function declaration line, followed by the function name you wish to use. Argument Clinic will use that function name for the base (generated) function, then add "_impl" to the end and use that for the name of the impl function.

For example, if we wanted to rename the C function names generated for pickle.Pickler.dump, it’d look like this:

/*[clinic input]
pickle.Pickler.dump as pickler_dumper

...
The base function would now be named pickler_dumper(), and the impl function would now be named pickler_dumper_impl().

Similarly, you may have a problem where you want to give a parameter a specific Python name, but that name may be inconvenient in C. Argument Clinic allows you to give a parameter different names in Python and in C, using the same "as" syntax:

/*[clinic input]
pickle.Pickler.dump

    obj: object
    file as file_obj: object
    protocol: object = NULL
    *
    fix_imports: bool = True
Here, the name used in Python (in the signature and the keywords array) would be file, but the C variable would be named file_obj.

You can use this to rename the self parameter too!

Converting functions using PyArg_UnpackTuple
To convert a function parsing its arguments with PyArg_UnpackTuple(), simply write out all the arguments, specifying each as an object. You may specify the type argument to cast the type as appropriate. All arguments should be marked positional-only (add a / on a line by itself after the last argument).

Currently the generated code will use PyArg_ParseTuple(), but this will change soon.

Optional Groups
Some legacy functions have a tricky approach to parsing their arguments: they count the number of positional arguments, then use a switch statement to call one of several different PyArg_ParseTuple() calls depending on how many positional arguments there are. (These functions cannot accept keyword-only arguments.) This approach was used to simulate optional arguments back before PyArg_ParseTupleAndKeywords() was created.

While functions using this approach can often be converted to use PyArg_ParseTupleAndKeywords(), optional arguments, and default values, it’s not always possible. Some of these legacy functions have behaviors PyArg_ParseTupleAndKeywords() doesn’t directly support. The most obvious example is the builtin function range(), which has an optional argument on the left side of its required argument! Another example is curses.window.addch(), which has a group of two arguments that must always be specified together. (The arguments are called x and y; if you call the function passing in x, you must also pass in y—and if you don’t pass in x you may not pass in y either.)

In any case, the goal of Argument Clinic is to support argument parsing for all existing CPython builtins without changing their semantics. Therefore Argument Clinic supports this alternate approach to parsing, using what are called optional groups. Optional groups are groups of arguments that must all be passed in together. They can be to the left or the right of the required arguments. They can only be used with positional-only parameters.

Note Optional groups are only intended for use when converting functions that make multiple calls to PyArg_ParseTuple()! Functions that use any other approach for parsing arguments should almost never be converted to Argument Clinic using optional groups. Functions using optional groups currently cannot have accurate signatures in Python, because Python just doesn’t understand the concept. Please avoid using optional groups wherever possible.
To specify an optional group, add a [ on a line by itself before the parameters you wish to group together, and a ] on a line by itself after these parameters. As an example, here’s how curses.window.addch uses optional groups to make the first two parameters and the last parameter optional:

/*[clinic input]

curses.window.addch

    [
    x: int
      X-coordinate.
    y: int
      Y-coordinate.
    ]

    ch: object
      Character to add.

    [
    attr: long
      Attributes for the character.
    ]
    /

...
Notes:

For every optional group, one additional parameter will be passed into the impl function representing the group. The parameter will be an int named group_{direction}_{number}, where {direction} is either right or left depending on whether the group is before or after the required parameters, and {number} is a monotonically increasing number (starting at 1) indicating how far away the group is from the required parameters. When the impl is called, this parameter will be set to zero if this group was unused, and set to non-zero if this group was used. (By used or unused, I mean whether or not the parameters received arguments in this invocation.)

If there are no required arguments, the optional groups will behave as if they’re to the right of the required arguments.

In the case of ambiguity, the argument parsing code favors parameters on the left (before the required parameters).

Optional groups can only contain positional-only parameters.

Optional groups are only intended for legacy code. Please do not use optional groups for new code.

Using real Argument Clinic converters, instead of “legacy converters”
To save time, and to minimize how much you need to learn to achieve your first port to Argument Clinic, the walkthrough above tells you to use “legacy converters”. “Legacy converters” are a convenience, designed explicitly to make porting existing code to Argument Clinic easier. And to be clear, their use is acceptable when porting code for Python 3.4.

However, in the long term we probably want all our blocks to use Argument Clinic’s real syntax for converters. Why? A couple reasons:

The proper converters are far easier to read and clearer in their intent.

There are some format units that are unsupported as “legacy converters”, because they require arguments, and the legacy converter syntax doesn’t support specifying arguments.

In the future we may have a new argument parsing library that isn’t restricted to what PyArg_ParseTuple() supports; this flexibility won’t be available to parameters using legacy converters.

Therefore, if you don’t mind a little extra effort, please use the normal converters instead of legacy converters.

In a nutshell, the syntax for Argument Clinic (non-legacy) converters looks like a Python function call. However, if there are no explicit arguments to the function (all functions take their default values), you may omit the parentheses. Thus bool and bool() are exactly the same converters.

All arguments to Argument Clinic converters are keyword-only. All Argument Clinic converters accept the following arguments:

c_default
The default value for this parameter when defined in C. Specifically, this will be the initializer for the variable declared in the “parse function”. See the section on default values for how to use this. Specified as a string.

annotation
The annotation value for this parameter. Not currently supported, because PEP 8 mandates that the Python library may not use annotations.

In addition, some converters accept additional arguments. Here is a list of these arguments, along with their meanings:

accept
A set of Python types (and possibly pseudo-types); this restricts the allowable Python argument to values of these types. (This is not a general-purpose facility; as a rule it only supports specific lists of types as shown in the legacy converter table.)

To accept None, add NoneType to this set.

bitwise
Only supported for unsigned integers. The native integer value of this Python argument will be written to the parameter without any range checking, even for negative values.

converter
Only supported by the object converter. Specifies the name of a C “converter function” to use to convert this object to a native type.

encoding
Only supported for strings. Specifies the encoding to use when converting this string from a Python str (Unicode) value into a C char * value.

subclass_of
Only supported for the object converter. Requires that the Python value be a subclass of a Python type, as expressed in C.

type
Only supported for the object and self converters. Specifies the C type that will be used to declare the variable. Default value is "PyObject *".

zeroes
Only supported for strings. If true, embedded NUL bytes ('\\0') are permitted inside the value. The length of the string will be passed in to the impl function, just after the string parameter, as a parameter named <parameter_name>_length.

Please note, not every possible combination of arguments will work. Usually these arguments are implemented by specific PyArg_ParseTuple format units, with specific behavior. For example, currently you cannot call unsigned_short without also specifying bitwise=True. Although it’s perfectly reasonable to think this would work, these semantics don’t map to any existing format unit. So Argument Clinic doesn’t support it. (Or, at least, not yet.)

Below is a table showing the mapping of legacy converters into real Argument Clinic converters. On the left is the legacy converter, on the right is the text you’d replace it with.

'B'

unsigned_char(bitwise=True)

'b'

unsigned_char

'c'

char

'C'

int(accept={str})

'd'

double

'D'

Py_complex

'es'

str(encoding='name_of_encoding')

'es#'

str(encoding='name_of_encoding', zeroes=True)

'et'

str(encoding='name_of_encoding', accept={bytes, bytearray, str})

'et#'

str(encoding='name_of_encoding', accept={bytes, bytearray, str}, zeroes=True)

'f'

float

'h'

short

'H'

unsigned_short(bitwise=True)

'i'

int

'I'

unsigned_int(bitwise=True)

'k'

unsigned_long(bitwise=True)

'K'

unsigned_long_long(bitwise=True)

'l'

long

'L'

long long

'n'

Py_ssize_t

'O'

object

'O!'

object(subclass_of='&PySomething_Type')

'O&'

object(converter='name_of_c_function')

'p'

bool

'S'

PyBytesObject

's'

str

's#'

str(zeroes=True)

's*'

Py_buffer(accept={buffer, str})

'U'

unicode

'u'

Py_UNICODE

'u#'

Py_UNICODE(zeroes=True)

'w*'

Py_buffer(accept={rwbuffer})

'Y'

PyByteArrayObject

'y'

str(accept={bytes})

'y#'

str(accept={robuffer}, zeroes=True)

'y*'

Py_buffer

'Z'

Py_UNICODE(accept={str, NoneType})

'Z#'

Py_UNICODE(accept={str, NoneType}, zeroes=True)

'z'

str(accept={str, NoneType})

'z#'

str(accept={str, NoneType}, zeroes=True)

'z*'

Py_buffer(accept={buffer, str, NoneType})

As an example, here’s our sample pickle.Pickler.dump using the proper converter:

/*[clinic input]
pickle.Pickler.dump

    obj: object
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
One advantage of real converters is that they’re more flexible than legacy converters. For example, the unsigned_int converter (and all the unsigned_ converters) can be specified without bitwise=True. Their default behavior performs range checking on the value, and they won’t accept negative numbers. You just can’t do that with a legacy converter!

Argument Clinic will show you all the converters it has available. For each converter it’ll show you all the parameters it accepts, along with the default value for each parameter. Just run Tools/clinic/clinic.py --converters to see the full list.

Py_buffer
When using the Py_buffer converter (or the 's*', 'w*', '*y', or 'z*' legacy converters), you must not call PyBuffer_Release() on the provided buffer. Argument Clinic generates code that does it for you (in the parsing function).

Advanced converters
Remember those format units you skipped for your first time because they were advanced? Here’s how to handle those too.

The trick is, all those format units take arguments—either conversion functions, or types, or strings specifying an encoding. (But “legacy converters” don’t support arguments. That’s why we skipped them for your first function.) The argument you specified to the format unit is now an argument to the converter; this argument is either converter (for O&), subclass_of (for O!), or encoding (for all the format units that start with e).

When using subclass_of, you may also want to use the other custom argument for object(): type, which lets you set the type actually used for the parameter. For example, if you want to ensure that the object is a subclass of PyUnicode_Type, you probably want to use the converter object(type='PyUnicodeObject *', subclass_of='&PyUnicode_Type').

One possible problem with using Argument Clinic: it takes away some possible flexibility for the format units starting with e. When writing a PyArg_Parse call by hand, you could theoretically decide at runtime what encoding string to pass in to PyArg_ParseTuple(). But now this string must be hard-coded at Argument-Clinic-preprocessing-time. This limitation is deliberate; it made supporting this format unit much easier, and may allow for future optimizations. This restriction doesn’t seem unreasonable; CPython itself always passes in static hard-coded encoding strings for parameters whose format units start with e.

Parameter default values
Default values for parameters can be any of a number of values. At their simplest, they can be string, int, or float literals:

foo: str = "abc"
bar: int = 123
bat: float = 45.6
They can also use any of Python’s built-in constants:

yep:  bool = True
nope: bool = False
nada: object = None
There’s also special support for a default value of NULL, and for simple expressions, documented in the following sections.

The NULL default value
For string and object parameters, you can set them to None to indicate that there’s no default. However, that means the C variable will be initialized to Py_None. For convenience’s sakes, there’s a special value called NULL for just this reason: from Python’s perspective it behaves like a default value of None, but the C variable is initialized with NULL.

Expressions specified as default values
The default value for a parameter can be more than just a literal value. It can be an entire expression, using math operators and looking up attributes on objects. However, this support isn’t exactly simple, because of some non-obvious semantics.

Consider the following example:

foo: Py_ssize_t = sys.maxsize - 1
sys.maxsize can have different values on different platforms. Therefore Argument Clinic can’t simply evaluate that expression locally and hard-code it in C. So it stores the default in such a way that it will get evaluated at runtime, when the user asks for the function’s signature.

What namespace is available when the expression is evaluated? It’s evaluated in the context of the module the builtin came from. So, if your module has an attribute called “max_widgets”, you may simply use it:

foo: Py_ssize_t = max_widgets
If the symbol isn’t found in the current module, it fails over to looking in sys.modules. That’s how it can find sys.maxsize for example. (Since you don’t know in advance what modules the user will load into their interpreter, it’s best to restrict yourself to modules that are preloaded by Python itself.)

Evaluating default values only at runtime means Argument Clinic can’t compute the correct equivalent C default value. So you need to tell it explicitly. When you use an expression, you must also specify the equivalent expression in C, using the c_default parameter to the converter:

foo: Py_ssize_t(c_default="PY_SSIZE_T_MAX - 1") = sys.maxsize - 1
Another complication: Argument Clinic can’t know in advance whether or not the expression you supply is valid. It parses it to make sure it looks legal, but it can’t actually know. You must be very careful when using expressions to specify values that are guaranteed to be valid at runtime!

Finally, because expressions must be representable as static C values, there are many restrictions on legal expressions. Here’s a list of Python features you’re not permitted to use:

Function calls.

Inline if statements (3 if foo else 5).

Automatic sequence unpacking (*[1, 2, 3]).

List/set/dict comprehensions and generator expressions.

Tuple/list/set/dict literals.

Using a return converter
By default the impl function Argument Clinic generates for you returns PyObject *. But your C function often computes some C type, then converts it into the PyObject * at the last moment. Argument Clinic handles converting your inputs from Python types into native C types—why not have it convert your return value from a native C type into a Python type too?

That’s what a “return converter” does. It changes your impl function to return some C type, then adds code to the generated (non-impl) function to handle converting that value into the appropriate PyObject *.

The syntax for return converters is similar to that of parameter converters. You specify the return converter like it was a return annotation on the function itself. Return converters behave much the same as parameter converters; they take arguments, the arguments are all keyword-only, and if you’re not changing any of the default arguments you can omit the parentheses.

(If you use both "as" and a return converter for your function, the "as" should come before the return converter.)

There’s one additional complication when using return converters: how do you indicate an error has occurred? Normally, a function returns a valid (non-NULL) pointer for success, and NULL for failure. But if you use an integer return converter, all integers are valid. How can Argument Clinic detect an error? Its solution: each return converter implicitly looks for a special value that indicates an error. If you return that value, and an error has been set (PyErr_Occurred() returns a true value), then the generated code will propagate the error. Otherwise it will encode the value you return like normal.

Currently Argument Clinic supports only a few return converters:

bool
int
unsigned int
long
unsigned int
size_t
Py_ssize_t
float
double
DecodeFSDefault
None of these take parameters. For the first three, return -1 to indicate error. For DecodeFSDefault, the return type is const char *; return a NULL pointer to indicate an error.

(There’s also an experimental NoneType converter, which lets you return Py_None on success or NULL on failure, without having to increment the reference count on Py_None. I’m not sure it adds enough clarity to be worth using.)

To see all the return converters Argument Clinic supports, along with their parameters (if any), just run Tools/clinic/clinic.py --converters for the full list.

Cloning existing functions
If you have a number of functions that look similar, you may be able to use Clinic’s “clone” feature. When you clone an existing function, you reuse:

its parameters, including

their names,

their converters, with all parameters,

their default values,

their per-parameter docstrings,

their kind (whether they’re positional only, positional or keyword, or keyword only), and

its return converter.

The only thing not copied from the original function is its docstring; the syntax allows you to specify a new docstring.

Here’s the syntax for cloning a function:

/*[clinic input]
module.class.new_function [as c_basename] = module.class.existing_function

Docstring for new_function goes here.
[clinic start generated code]*/
(The functions can be in different modules or classes. I wrote module.class in the sample just to illustrate that you must use the full path to both functions.)

Sorry, there’s no syntax for partially cloning a function, or cloning a function then modifying it. Cloning is an all-or nothing proposition.

Also, the function you are cloning from must have been previously defined in the current file.

Calling Python code
The rest of the advanced topics require you to write Python code which lives inside your C file and modifies Argument Clinic’s runtime state. This is simple: you simply define a Python block.

A Python block uses different delimiter lines than an Argument Clinic function block. It looks like this:

/*[python input]
# python code goes here
[python start generated code]*/
All the code inside the Python block is executed at the time it’s parsed. All text written to stdout inside the block is redirected into the “output” after the block.

As an example, here’s a Python block that adds a static integer variable to the C code:

/*[python input]
print('static int __ignored_unused_variable__ = 0;')
[python start generated code]*/
static int __ignored_unused_variable__ = 0;
/*[python checksum:...]*/
Using a “self converter”
Argument Clinic automatically adds a “self” parameter for you using a default converter. It automatically sets the type of this parameter to the “pointer to an instance” you specified when you declared the type. However, you can override Argument Clinic’s converter and specify one yourself. Just add your own self parameter as the first parameter in a block, and ensure that its converter is an instance of self_converter or a subclass thereof.

What’s the point? This lets you override the type of self, or give it a different default name.

How do you specify the custom type you want to cast self to? If you only have one or two functions with the same type for self, you can directly use Argument Clinic’s existing self converter, passing in the type you want to use as the type parameter:

/*[clinic input]

_pickle.Pickler.dump

  self: self(type="PicklerObject *")
  obj: object
  /

Write a pickled representation of the given object to the open file.
[clinic start generated code]*/
On the other hand, if you have a lot of functions that will use the same type for self, it’s best to create your own converter, subclassing self_converter but overwriting the type member:

/*[python input]
class PicklerObject_converter(self_converter):
    type = "PicklerObject *"
[python start generated code]*/

/*[clinic input]

_pickle.Pickler.dump

  self: PicklerObject
  obj: object
  /

Write a pickled representation of the given object to the open file.
[clinic start generated code]*/
Using a “defining class” converter
Argument Clinic facilitates gaining access to the defining class of a method. This is useful for heap type methods that need to fetch module level state. Use PyType_FromModuleAndSpec() to associate a new heap type with a module. You can now use PyType_GetModuleState() on the defining class to fetch the module state, for example from a module method.

Example from Modules/zlibmodule.c. First, defining_class is added to the clinic input:

/*[clinic input]
zlib.Compress.compress

  cls: defining_class
  data: Py_buffer
    Binary data to be compressed.
  /
After running the Argument Clinic tool, the following function signature is generated:

/*[clinic start generated code]*/
static PyObject *
zlib_Compress_compress_impl(compobject *self, PyTypeObject *cls,
                            Py_buffer *data)
/*[clinic end generated code: output=6731b3f0ff357ca6 input=04d00f65ab01d260]*/
The following code can now use PyType_GetModuleState(cls) to fetch the module state:

zlibstate *state = PyType_GetModuleState(cls);
Each method may only have one argument using this converter, and it must appear after self, or, if self is not used, as the first argument. The argument will be of type PyTypeObject *. The argument will not appear in the __text_signature__.

The defining_class converter is not compatible with __init__ and __new__ methods, which cannot use the METH_METHOD convention.

It is not possible to use defining_class with slot methods. In order to fetch the module state from such methods, use _PyType_GetModuleByDef to look up the module and then PyModule_GetState() to fetch the module state. Example from the setattro slot method in Modules/_threadmodule.c:

static int
local_setattro(localobject *self, PyObject *name, PyObject *v)
{
    PyObject *module = _PyType_GetModuleByDef(Py_TYPE(self), &thread_module);
    thread_module_state *state = get_thread_state(module);
    ...
}
See also PEP 573.

Writing a custom converter
As we hinted at in the previous section… you can write your own converters! A converter is simply a Python class that inherits from CConverter. The main purpose of a custom converter is if you have a parameter using the O& format unit—parsing this parameter means calling a PyArg_ParseTuple() “converter function”.

Your converter class should be named *something*_converter. If the name follows this convention, then your converter class will be automatically registered with Argument Clinic; its name will be the name of your class with the _converter suffix stripped off. (This is accomplished with a metaclass.)

You shouldn’t subclass CConverter.__init__. Instead, you should write a converter_init() function. converter_init() always accepts a self parameter; after that, all additional parameters must be keyword-only. Any arguments passed in to the converter in Argument Clinic will be passed along to your converter_init().

There are some additional members of CConverter you may wish to specify in your subclass. Here’s the current list:

type
The C type to use for this variable. type should be a Python string specifying the type, e.g. int. If this is a pointer type, the type string should end with ' *'.

default
The Python default value for this parameter, as a Python value. Or the magic value unspecified if there is no default.

py_default
default as it should appear in Python code, as a string. Or None if there is no default.

c_default
default as it should appear in C code, as a string. Or None if there is no default.

c_ignored_default
The default value used to initialize the C variable when there is no default, but not specifying a default may result in an “uninitialized variable” warning. This can easily happen when using option groups—although properly written code will never actually use this value, the variable does get passed in to the impl, and the C compiler will complain about the “use” of the uninitialized value. This value should always be a non-empty string.

converter
The name of the C converter function, as a string.

impl_by_reference
A boolean value. If true, Argument Clinic will add a & in front of the name of the variable when passing it into the impl function.

parse_by_reference
A boolean value. If true, Argument Clinic will add a & in front of the name of the variable when passing it into PyArg_ParseTuple().

Here’s the simplest example of a custom converter, from Modules/zlibmodule.c:

/*[python input]

class ssize_t_converter(CConverter):
    type = 'Py_ssize_t'
    converter = 'ssize_t_converter'

[python start generated code]*/
/*[python end generated code: output=da39a3ee5e6b4b0d input=35521e4e733823c7]*/
This block adds a converter to Argument Clinic named ssize_t. Parameters declared as ssize_t will be declared as type Py_ssize_t, and will be parsed by the 'O&' format unit, which will call the ssize_t_converter converter function. ssize_t variables automatically support default values.

More sophisticated custom converters can insert custom C code to handle initialization and cleanup. You can see more examples of custom converters in the CPython source tree; grep the C files for the string CConverter.

Writing a custom return converter
Writing a custom return converter is much like writing a custom converter. Except it’s somewhat simpler, because return converters are themselves much simpler.

Return converters must subclass CReturnConverter. There are no examples yet of custom return converters, because they are not widely used yet. If you wish to write your own return converter, please read Tools/clinic/clinic.py, specifically the implementation of CReturnConverter and all its subclasses.

METH_O and METH_NOARGS
To convert a function using METH_O, make sure the function’s single argument is using the object converter, and mark the arguments as positional-only:

/*[clinic input]
meth_o_sample

     argument: object
     /
[clinic start generated code]*/
To convert a function using METH_NOARGS, just don’t specify any arguments.

You can still use a self converter, a return converter, and specify a type argument to the object converter for METH_O.

tp_new and tp_init functions
You can convert tp_new and tp_init functions. Just name them __new__ or __init__ as appropriate. Notes:

The function name generated for __new__ doesn’t end in __new__ like it would by default. It’s just the name of the class, converted into a valid C identifier.

No PyMethodDef #define is generated for these functions.

__init__ functions return int, not PyObject *.

Use the docstring as the class docstring.

Although __new__ and __init__ functions must always accept both the args and kwargs objects, when converting you may specify any signature for these functions that you like. (If your function doesn’t support keywords, the parsing function generated will throw an exception if it receives any.)

Changing and redirecting Clinic’s output
It can be inconvenient to have Clinic’s output interspersed with your conventional hand-edited C code. Luckily, Clinic is configurable: you can buffer up its output for printing later (or earlier!), or write its output to a separate file. You can also add a prefix or suffix to every line of Clinic’s generated output.

While changing Clinic’s output in this manner can be a boon to readability, it may result in Clinic code using types before they are defined, or your code attempting to use Clinic-generated code before it is defined. These problems can be easily solved by rearranging the declarations in your file, or moving where Clinic’s generated code goes. (This is why the default behavior of Clinic is to output everything into the current block; while many people consider this hampers readability, it will never require rearranging your code to fix definition-before-use problems.)

Let’s start with defining some terminology:

field
A field, in this context, is a subsection of Clinic’s output. For example, the #define for the PyMethodDef structure is a field, called methoddef_define. Clinic has seven different fields it can output per function definition:

docstring_prototype
docstring_definition
methoddef_define
impl_prototype
parser_prototype
parser_definition
impl_definition
All the names are of the form "<a>_<b>", where "<a>" is the semantic object represented (the parsing function, the impl function, the docstring, or the methoddef structure) and "<b>" represents what kind of statement the field is. Field names that end in "_prototype" represent forward declarations of that thing, without the actual body/data of the thing; field names that end in "_definition" represent the actual definition of the thing, with the body/data of the thing. ("methoddef" is special, it’s the only one that ends with "_define", representing that it’s a preprocessor #define.)

destination
A destination is a place Clinic can write output to. There are five built-in destinations:

block
The default destination: printed in the output section of the current Clinic block.

buffer
A text buffer where you can save text for later. Text sent here is appended to the end of any existing text. It’s an error to have any text left in the buffer when Clinic finishes processing a file.

file
A separate “clinic file” that will be created automatically by Clinic. The filename chosen for the file is {basename}.clinic{extension}, where basename and extension were assigned the output from os.path.splitext() run on the current file. (Example: the file destination for _pickle.c would be written to _pickle.clinic.c.)

Important: When using a file destination, you must check in the generated file!

two-pass
A buffer like buffer. However, a two-pass buffer can only be dumped once, and it prints out all text sent to it during all processing, even from Clinic blocks after the dumping point.

suppress
The text is suppressed—thrown away.

Clinic defines five new directives that let you reconfigure its output.

The first new directive is dump:

dump <destination>
This dumps the current contents of the named destination into the output of the current block, and empties it. This only works with buffer and two-pass destinations.

The second new directive is output. The most basic form of output is like this:

output <field> <destination>
This tells Clinic to output field to destination. output also supports a special meta-destination, called everything, which tells Clinic to output all fields to that destination.

output has a number of other functions:

output push
output pop
output preset <preset>
output push and output pop allow you to push and pop configurations on an internal configuration stack, so that you can temporarily modify the output configuration, then easily restore the previous configuration. Simply push before your change to save the current configuration, then pop when you wish to restore the previous configuration.

output preset sets Clinic’s output to one of several built-in preset configurations, as follows:

block
Clinic’s original starting configuration. Writes everything immediately after the input block.

Suppress the parser_prototype and docstring_prototype, write everything else to block.

file
Designed to write everything to the “clinic file” that it can. You then #include this file near the top of your file. You may need to rearrange your file to make this work, though usually this just means creating forward declarations for various typedef and PyTypeObject definitions.

Suppress the parser_prototype and docstring_prototype, write the impl_definition to block, and write everything else to file.

The default filename is "{dirname}/clinic/{basename}.h".

buffer
Save up most of the output from Clinic, to be written into your file near the end. For Python files implementing modules or builtin types, it’s recommended that you dump the buffer just above the static structures for your module or builtin type; these are normally very near the end. Using buffer may require even more editing than file, if your file has static PyMethodDef arrays defined in the middle of the file.

Suppress the parser_prototype, impl_prototype, and docstring_prototype, write the impl_definition to block, and write everything else to file.

two-pass
Similar to the buffer preset, but writes forward declarations to the two-pass buffer, and definitions to the buffer. This is similar to the buffer preset, but may require less editing than buffer. Dump the two-pass buffer near the top of your file, and dump the buffer near the end just like you would when using the buffer preset.

Suppresses the impl_prototype, write the impl_definition to block, write docstring_prototype, methoddef_define, and parser_prototype to two-pass, write everything else to buffer.

partial-buffer
Similar to the buffer preset, but writes more things to block, only writing the really big chunks of generated code to buffer. This avoids the definition-before-use problem of buffer completely, at the small cost of having slightly more stuff in the block’s output. Dump the buffer near the end, just like you would when using the buffer preset.

Suppresses the impl_prototype, write the docstring_definition and parser_definition to buffer, write everything else to block.

The third new directive is destination:

destination <name> <command> [...]
This performs an operation on the destination named name.

There are two defined subcommands: new and clear.

The new subcommand works like this:

destination <name> new <type>
This creates a new destination with name <name> and type <type>.

There are five destination types:

suppress
Throws the text away.

block
Writes the text to the current block. This is what Clinic originally did.

buffer
A simple text buffer, like the “buffer” builtin destination above.

file
A text file. The file destination takes an extra argument, a template to use for building the filename, like so:

destination <name> new <type> <file_template>

The template can use three strings internally that will be replaced by bits of the filename:

{path}
The full path to the file, including directory and full filename.

{dirname}
The name of the directory the file is in.

{basename}
Just the name of the file, not including the directory.

{basename_root}
Basename with the extension clipped off (everything up to but not including the last ‘.’).

{basename_extension}
The last ‘.’ and everything after it. If the basename does not contain a period, this will be the empty string.

If there are no periods in the filename, {basename} and {filename} are the same, and {extension} is empty. “{basename}{extension}” is always exactly the same as “{filename}”.”

two-pass
A two-pass buffer, like the “two-pass” builtin destination above.

The clear subcommand works like this:

destination <name> clear
It removes all the accumulated text up to this point in the destination. (I don’t know what you’d need this for, but I thought maybe it’d be useful while someone’s experimenting.)

The fourth new directive is set:

set line_prefix "string"
set line_suffix "string"
set lets you set two internal variables in Clinic. line_prefix is a string that will be prepended to every line of Clinic’s output; line_suffix is a string that will be appended to every line of Clinic’s output.

Both of these support two format strings:

{block comment start}
Turns into the string /*, the start-comment text sequence for C files.

{block comment end}
Turns into the string */, the end-comment text sequence for C files.

The final new directive is one you shouldn’t need to use directly, called preserve:

preserve
This tells Clinic that the current contents of the output should be kept, unmodified. This is used internally by Clinic when dumping output into file files; wrapping it in a Clinic block lets Clinic use its existing checksum functionality to ensure the file was not modified by hand before it gets overwritten.

The #ifdef trick
If you’re converting a function that isn’t available on all platforms, there’s a trick you can use to make life a little easier. The existing code probably looks like this:

#ifdef HAVE_FUNCTIONNAME
static module_functionname(...)
{
...
}
#endif /* HAVE_FUNCTIONNAME */
And then in the PyMethodDef structure at the bottom the existing code will have:

#ifdef HAVE_FUNCTIONNAME
{'functionname', ... },
#endif /* HAVE_FUNCTIONNAME */
In this scenario, you should enclose the body of your impl function inside the #ifdef, like so:

#ifdef HAVE_FUNCTIONNAME
/*[clinic input]
module.functionname
...
[clinic start generated code]*/
static module_functionname(...)
{
...
}
#endif /* HAVE_FUNCTIONNAME */
Then, remove those three lines from the PyMethodDef structure, replacing them with the macro Argument Clinic generated:

MODULE_FUNCTIONNAME_METHODDEF
(You can find the real name for this macro inside the generated code. Or you can calculate it yourself: it’s the name of your function as defined on the first line of your block, but with periods changed to underscores, uppercased, and "_METHODDEF" added to the end.)

Perhaps you’re wondering: what if HAVE_FUNCTIONNAME isn’t defined? The MODULE_FUNCTIONNAME_METHODDEF macro won’t be defined either!

Here’s where Argument Clinic gets very clever. It actually detects that the Argument Clinic block might be deactivated by the #ifdef. When that happens, it generates a little extra code that looks like this:

#ifndef MODULE_FUNCTIONNAME_METHODDEF
    #define MODULE_FUNCTIONNAME_METHODDEF
#endif /* !defined(MODULE_FUNCTIONNAME_METHODDEF) */
That means the macro always works. If the function is defined, this turns into the correct structure, including the trailing comma. If the function is undefined, this turns into nothing.

However, this causes one ticklish problem: where should Argument Clinic put this extra code when using the “block” output preset? It can’t go in the output block, because that could be deactivated by the #ifdef. (That’s the whole point!)

In this situation, Argument Clinic writes the extra code to the “buffer” destination. This may mean that you get a complaint from Argument Clinic:

Warning in file "Modules/posixmodule.c" on line 12357:
Destination buffer 'buffer' not empty at end of file, emptying.
When this happens, just open your file, find the dump buffer block that Argument Clinic added to your file (it’ll be at the very bottom), then move it above the PyMethodDef structure where that macro is used.

Using Argument Clinic in Python files
It’s actually possible to use Argument Clinic to preprocess Python files. There’s no point to using Argument Clinic blocks, of course, as the output wouldn’t make any sense to the Python interpreter. But using Argument Clinic to run Python blocks lets you use Python as a Python preprocessor!

Since Python comments are different from C comments, Argument Clinic blocks embedded in Python files look slightly different. They look like this:

#/*[python input]
#print("def foo(): pass")
#[python start generated code]*/
def foo(): pass
#/*[python checksum:...]*/
Table of Contents
Argument Clinic How-To
The Goals Of Argument Clinic
Basic Concepts And Usage
Converting Your First Function
Advanced Topics
Symbolic default values
Renaming the C functions and variables generated by Argument Clinic
Converting functions using PyArg_UnpackTuple
Optional Groups
Using real Argument Clinic converters, instead of “legacy converters”
Py_buffer
Advanced converters
Parameter default values
The NULL default value
Expressions specified as default values
Using a return converter
Cloning existing functions
Calling Python code
Using a “self converter”
Using a “defining class” converter
Writing a custom converter
Writing a custom return converter
METH_O and METH_NOARGS
tp_new and tp_init functions
Changing and redirecting Clinic’s output
The #ifdef trick
Using Argument Clinic in Python files
Previous topic
An introduction to the ipaddress module

Next topic
Instrumenting CPython with DTrace and SystemTap

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Argument Clinic How-To
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Argument Clinic How-To
Quick search
  |
Argument Clinic How-To
author
Larry Hastings

Abstract

Argument Clinic is a preprocessor for CPython C files. Its purpose is to automate all the boilerplate involved with writing argument parsing code for “builtins”. This document shows you how to convert your first C function to work with Argument Clinic, and then introduces some advanced topics on Argument Clinic usage.

Currently Argument Clinic is considered internal-only for CPython. Its use is not supported for files outside CPython, and no guarantees are made regarding backwards compatibility for future versions. In other words: if you maintain an external C extension for CPython, you’re welcome to experiment with Argument Clinic in your own code. But the version of Argument Clinic that ships with the next version of CPython could be totally incompatible and break all your code.

The Goals Of Argument Clinic
Argument Clinic’s primary goal is to take over responsibility for all argument parsing code inside CPython. This means that, when you convert a function to work with Argument Clinic, that function should no longer do any of its own argument parsing—the code generated by Argument Clinic should be a “black box” to you, where CPython calls in at the top, and your code gets called at the bottom, with PyObject *args (and maybe PyObject *kwargs) magically converted into the C variables and types you need.

In order for Argument Clinic to accomplish its primary goal, it must be easy to use. Currently, working with CPython’s argument parsing library is a chore, requiring maintaining redundant information in a surprising number of places. When you use Argument Clinic, you don’t have to repeat yourself.

Obviously, no one would want to use Argument Clinic unless it’s solving their problem—and without creating new problems of its own. So it’s paramount that Argument Clinic generate correct code. It’d be nice if the code was faster, too, but at the very least it should not introduce a major speed regression. (Eventually Argument Clinic should make a major speedup possible—we could rewrite its code generator to produce tailor-made argument parsing code, rather than calling the general-purpose CPython argument parsing library. That would make for the fastest argument parsing possible!)

Additionally, Argument Clinic must be flexible enough to work with any approach to argument parsing. Python has some functions with some very strange parsing behaviors; Argument Clinic’s goal is to support all of them.

Finally, the original motivation for Argument Clinic was to provide introspection “signatures” for CPython builtins. It used to be, the introspection query functions would throw an exception if you passed in a builtin. With Argument Clinic, that’s a thing of the past!

One idea you should keep in mind, as you work with Argument Clinic: the more information you give it, the better job it’ll be able to do. Argument Clinic is admittedly relatively simple right now. But as it evolves it will get more sophisticated, and it should be able to do many interesting and smart things with all the information you give it.

Basic Concepts And Usage
Argument Clinic ships with CPython; you’ll find it in Tools/clinic/clinic.py. If you run that script, specifying a C file as an argument:

$ python3 Tools/clinic/clinic.py foo.c
Argument Clinic will scan over the file looking for lines that look exactly like this:

/*[clinic input]
When it finds one, it reads everything up to a line that looks exactly like this:

[clinic start generated code]*/
Everything in between these two lines is input for Argument Clinic. All of these lines, including the beginning and ending comment lines, are collectively called an Argument Clinic “block”.

When Argument Clinic parses one of these blocks, it generates output. This output is rewritten into the C file immediately after the block, followed by a comment containing a checksum. The Argument Clinic block now looks like this:

/*[clinic input]
... clinic input goes here ...
[clinic start generated code]*/
... clinic output goes here ...
/*[clinic end generated code: checksum=...]*/
If you run Argument Clinic on the same file a second time, Argument Clinic will discard the old output and write out the new output with a fresh checksum line. However, if the input hasn’t changed, the output won’t change either.

You should never modify the output portion of an Argument Clinic block. Instead, change the input until it produces the output you want. (That’s the purpose of the checksum—to detect if someone changed the output, as these edits would be lost the next time Argument Clinic writes out fresh output.)

For the sake of clarity, here’s the terminology we’ll use with Argument Clinic:

The first line of the comment (/*[clinic input]) is the start line.

The last line of the initial comment ([clinic start generated code]*/) is the end line.

The last line (/*[clinic end generated code: checksum=...]*/) is the checksum line.

In between the start line and the end line is the input.

In between the end line and the checksum line is the output.

All the text collectively, from the start line to the checksum line inclusively, is the block. (A block that hasn’t been successfully processed by Argument Clinic yet doesn’t have output or a checksum line, but it’s still considered a block.)

Converting Your First Function
The best way to get a sense of how Argument Clinic works is to convert a function to work with it. Here, then, are the bare minimum steps you’d need to follow to convert a function to work with Argument Clinic. Note that for code you plan to check in to CPython, you really should take the conversion farther, using some of the advanced concepts you’ll see later on in the document (like “return converters” and “self converters”). But we’ll keep it simple for this walkthrough so you can learn.

Let’s dive in!

Make sure you’re working with a freshly updated checkout of the CPython trunk.

Find a Python builtin that calls either PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords(), and hasn’t been converted to work with Argument Clinic yet. For my example I’m using _pickle.Pickler.dump().

If the call to the PyArg_Parse function uses any of the following format units:

O&
O!
es
es#
et
et#
or if it has multiple calls to PyArg_ParseTuple(), you should choose a different function. Argument Clinic does support all of these scenarios. But these are advanced topics—let’s do something simpler for your first function.

Also, if the function has multiple calls to PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords() where it supports different types for the same argument, or if the function uses something besides PyArg_Parse functions to parse its arguments, it probably isn’t suitable for conversion to Argument Clinic. Argument Clinic doesn’t support generic functions or polymorphic parameters.

Add the following boilerplate above the function, creating our block:

/*[clinic input]
[clinic start generated code]*/
Cut the docstring and paste it in between the [clinic] lines, removing all the junk that makes it a properly quoted C string. When you’re done you should have just the text, based at the left margin, with no line wider than 80 characters. (Argument Clinic will preserve indents inside the docstring.)

If the old docstring had a first line that looked like a function signature, throw that line away. (The docstring doesn’t need it anymore—when you use help() on your builtin in the future, the first line will be built automatically based on the function’s signature.)

Sample:

/*[clinic input]
Write a pickled representation of obj to the open file.
[clinic start generated code]*/
If your docstring doesn’t have a “summary” line, Argument Clinic will complain. So let’s make sure it has one. The “summary” line should be a paragraph consisting of a single 80-column line at the beginning of the docstring.

(Our example docstring consists solely of a summary line, so the sample code doesn’t have to change for this step.)

Above the docstring, enter the name of the function, followed by a blank line. This should be the Python name of the function, and should be the full dotted path to the function—it should start with the name of the module, include any sub-modules, and if the function is a method on a class it should include the class name too.

Sample:

/*[clinic input]
_pickle.Pickler.dump

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
If this is the first time that module or class has been used with Argument Clinic in this C file, you must declare the module and/or class. Proper Argument Clinic hygiene prefers declaring these in a separate block somewhere near the top of the C file, in the same way that include files and statics go at the top. (In our sample code we’ll just show the two blocks next to each other.)

The name of the class and module should be the same as the one seen by Python. Check the name defined in the PyModuleDef or PyTypeObject as appropriate.

When you declare a class, you must also specify two aspects of its type in C: the type declaration you’d use for a pointer to an instance of this class, and a pointer to the PyTypeObject for this class.

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/

/*[clinic input]
_pickle.Pickler.dump

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
Declare each of the parameters to the function. Each parameter should get its own line. All the parameter lines should be indented from the function name and the docstring.

The general form of these parameter lines is as follows:

name_of_parameter: converter
If the parameter has a default value, add that after the converter:

name_of_parameter: converter = default_value
Argument Clinic’s support for “default values” is quite sophisticated; please see the section below on default values for more information.

Add a blank line below the parameters.

What’s a “converter”? It establishes both the type of the variable used in C, and the method to convert the Python value into a C value at runtime. For now you’re going to use what’s called a “legacy converter”—a convenience syntax intended to make porting old code into Argument Clinic easier.

For each parameter, copy the “format unit” for that parameter from the PyArg_Parse() format argument and specify that as its converter, as a quoted string. (“format unit” is the formal name for the one-to-three character substring of the format parameter that tells the argument parsing function what the type of the variable is and how to convert it. For more on format units please see Parsing arguments and building values.)

For multicharacter format units like z#, use the entire two-or-three character string.

Sample:

 /*[clinic input]
 module _pickle
 class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
 [clinic start generated code]*/

 /*[clinic input]
 _pickle.Pickler.dump

    obj: 'O'

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
If your function has | in the format string, meaning some parameters have default values, you can ignore it. Argument Clinic infers which parameters are optional based on whether or not they have default values.

If your function has $ in the format string, meaning it takes keyword-only arguments, specify * on a line by itself before the first keyword-only argument, indented the same as the parameter lines.

(_pickle.Pickler.dump has neither, so our sample is unchanged.)

If the existing C function calls PyArg_ParseTuple() (as opposed to PyArg_ParseTupleAndKeywords()), then all its arguments are positional-only.

To mark all parameters as positional-only in Argument Clinic, add a / on a line by itself after the last parameter, indented the same as the parameter lines.

Currently this is all-or-nothing; either all parameters are positional-only, or none of them are. (In the future Argument Clinic may relax this restriction.)

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
It’s helpful to write a per-parameter docstring for each parameter. But per-parameter docstrings are optional; you can skip this step if you prefer.

Here’s how to add a per-parameter docstring. The first line of the per-parameter docstring must be indented further than the parameter definition. The left margin of this first line establishes the left margin for the whole per-parameter docstring; all the text you write will be outdented by this amount. You can write as much text as you like, across multiple lines if you wish.

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
Save and close the file, then run Tools/clinic/clinic.py on it. With luck everything worked—your block now has output, and a .c.h file has been generated! Reopen the file in your text editor to see:

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/

static PyObject *
_pickle_Pickler_dump(PicklerObject *self, PyObject *obj)
/*[clinic end generated code: output=87ecad1261e02ac7 input=552eb1c0f52260d9]*/
Obviously, if Argument Clinic didn’t produce any output, it’s because it found an error in your input. Keep fixing your errors and retrying until Argument Clinic processes your file without complaint.

For readability, most of the glue code has been generated to a .c.h file. You’ll need to include that in your original .c file, typically right after the clinic module block:

#include "clinic/_pickle.c.h"
Double-check that the argument-parsing code Argument Clinic generated looks basically the same as the existing code.

First, ensure both places use the same argument-parsing function. The existing code must call either PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords(); ensure that the code generated by Argument Clinic calls the exact same function.

Second, the format string passed in to PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords() should be exactly the same as the hand-written one in the existing function, up to the colon or semi-colon.

(Argument Clinic always generates its format strings with a : followed by the name of the function. If the existing code’s format string ends with ;, to provide usage help, this change is harmless—don’t worry about it.)

Third, for parameters whose format units require two arguments (like a length variable, or an encoding string, or a pointer to a conversion function), ensure that the second argument is exactly the same between the two invocations.

Fourth, inside the output portion of the block you’ll find a preprocessor macro defining the appropriate static PyMethodDef structure for this builtin:

#define __PICKLE_PICKLER_DUMP_METHODDEF    \
{"dump", (PyCFunction)__pickle_Pickler_dump, METH_O, __pickle_Pickler_dump__doc__},
This static structure should be exactly the same as the existing static PyMethodDef structure for this builtin.

If any of these items differ in any way, adjust your Argument Clinic function specification and rerun Tools/clinic/clinic.py until they are the same.

Notice that the last line of its output is the declaration of your “impl” function. This is where the builtin’s implementation goes. Delete the existing prototype of the function you’re modifying, but leave the opening curly brace. Now delete its argument parsing code and the declarations of all the variables it dumps the arguments into. Notice how the Python arguments are now arguments to this impl function; if the implementation used different names for these variables, fix it.

Let’s reiterate, just because it’s kind of weird. Your code should now look like this:

static return_type
your_function_impl(...)
/*[clinic end generated code: checksum=...]*/
{
...
Argument Clinic generated the checksum line and the function prototype just above it. You should write the opening (and closing) curly braces for the function, and the implementation inside.

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/
/*[clinic end generated code: checksum=da39a3ee5e6b4b0d3255bfef95601890afd80709]*/

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/

PyDoc_STRVAR(__pickle_Pickler_dump__doc__,
"Write a pickled representation of obj to the open file.\n"
"\n"
...
static PyObject *
_pickle_Pickler_dump_impl(PicklerObject *self, PyObject *obj)
/*[clinic end generated code: checksum=3bd30745bf206a48f8b576a1da3d90f55a0a4187]*/
{
    /* Check whether the Pickler was initialized correctly (issue3664).
       Developers often forget to call __init__() in their subclasses, which
       would trigger a segfault without this check. */
    if (self->write == NULL) {
        PyErr_Format(PicklingError,
                     "Pickler.__init__() was not called by %s.__init__()",
                     Py_TYPE(self)->tp_name);
        return NULL;
    }

    if (_Pickler_ClearBuffer(self) < 0)
        return NULL;

    ...
Remember the macro with the PyMethodDef structure for this function? Find the existing PyMethodDef structure for this function and replace it with a reference to the macro. (If the builtin is at module scope, this will probably be very near the end of the file; if the builtin is a class method, this will probably be below but relatively near to the implementation.)

Note that the body of the macro contains a trailing comma. So when you replace the existing static PyMethodDef structure with the macro, don’t add a comma to the end.

Sample:

static struct PyMethodDef Pickler_methods[] = {
    __PICKLE_PICKLER_DUMP_METHODDEF
    __PICKLE_PICKLER_CLEAR_MEMO_METHODDEF
    {NULL, NULL}                /* sentinel */
};
Compile, then run the relevant portions of the regression-test suite. This change should not introduce any new compile-time warnings or errors, and there should be no externally visible change to Python’s behavior.

Well, except for one difference: inspect.signature() run on your function should now provide a valid signature!

Congratulations, you’ve ported your first function to work with Argument Clinic!

Advanced Topics
Now that you’ve had some experience working with Argument Clinic, it’s time for some advanced topics.

Symbolic default values
The default value you provide for a parameter can’t be any arbitrary expression. Currently the following are explicitly supported:

Numeric constants (integer and float)

String constants

True, False, and None

Simple symbolic constants like sys.maxsize, which must start with the name of the module

In case you’re curious, this is implemented in from_builtin() in Lib/inspect.py.

(In the future, this may need to get even more elaborate, to allow full expressions like CONSTANT - 1.)

Renaming the C functions and variables generated by Argument Clinic
Argument Clinic automatically names the functions it generates for you. Occasionally this may cause a problem, if the generated name collides with the name of an existing C function. There’s an easy solution: override the names used for the C functions. Just add the keyword "as" to your function declaration line, followed by the function name you wish to use. Argument Clinic will use that function name for the base (generated) function, then add "_impl" to the end and use that for the name of the impl function.

For example, if we wanted to rename the C function names generated for pickle.Pickler.dump, it’d look like this:

/*[clinic input]
pickle.Pickler.dump as pickler_dumper

...
The base function would now be named pickler_dumper(), and the impl function would now be named pickler_dumper_impl().

Similarly, you may have a problem where you want to give a parameter a specific Python name, but that name may be inconvenient in C. Argument Clinic allows you to give a parameter different names in Python and in C, using the same "as" syntax:

/*[clinic input]
pickle.Pickler.dump

    obj: object
    file as file_obj: object
    protocol: object = NULL
    *
    fix_imports: bool = True
Here, the name used in Python (in the signature and the keywords array) would be file, but the C variable would be named file_obj.

You can use this to rename the self parameter too!

Converting functions using PyArg_UnpackTuple
To convert a function parsing its arguments with PyArg_UnpackTuple(), simply write out all the arguments, specifying each as an object. You may specify the type argument to cast the type as appropriate. All arguments should be marked positional-only (add a / on a line by itself after the last argument).

Currently the generated code will use PyArg_ParseTuple(), but this will change soon.

Optional Groups
Some legacy functions have a tricky approach to parsing their arguments: they count the number of positional arguments, then use a switch statement to call one of several different PyArg_ParseTuple() calls depending on how many positional arguments there are. (These functions cannot accept keyword-only arguments.) This approach was used to simulate optional arguments back before PyArg_ParseTupleAndKeywords() was created.

While functions using this approach can often be converted to use PyArg_ParseTupleAndKeywords(), optional arguments, and default values, it’s not always possible. Some of these legacy functions have behaviors PyArg_ParseTupleAndKeywords() doesn’t directly support. The most obvious example is the builtin function range(), which has an optional argument on the left side of its required argument! Another example is curses.window.addch(), which has a group of two arguments that must always be specified together. (The arguments are called x and y; if you call the function passing in x, you must also pass in y—and if you don’t pass in x you may not pass in y either.)

In any case, the goal of Argument Clinic is to support argument parsing for all existing CPython builtins without changing their semantics. Therefore Argument Clinic supports this alternate approach to parsing, using what are called optional groups. Optional groups are groups of arguments that must all be passed in together. They can be to the left or the right of the required arguments. They can only be used with positional-only parameters.

Note Optional groups are only intended for use when converting functions that make multiple calls to PyArg_ParseTuple()! Functions that use any other approach for parsing arguments should almost never be converted to Argument Clinic using optional groups. Functions using optional groups currently cannot have accurate signatures in Python, because Python just doesn’t understand the concept. Please avoid using optional groups wherever possible.
To specify an optional group, add a [ on a line by itself before the parameters you wish to group together, and a ] on a line by itself after these parameters. As an example, here’s how curses.window.addch uses optional groups to make the first two parameters and the last parameter optional:

/*[clinic input]

curses.window.addch

    [
    x: int
      X-coordinate.
    y: int
      Y-coordinate.
    ]

    ch: object
      Character to add.

    [
    attr: long
      Attributes for the character.
    ]
    /

...
Notes:

For every optional group, one additional parameter will be passed into the impl function representing the group. The parameter will be an int named group_{direction}_{number}, where {direction} is either right or left depending on whether the group is before or after the required parameters, and {number} is a monotonically increasing number (starting at 1) indicating how far away the group is from the required parameters. When the impl is called, this parameter will be set to zero if this group was unused, and set to non-zero if this group was used. (By used or unused, I mean whether or not the parameters received arguments in this invocation.)

If there are no required arguments, the optional groups will behave as if they’re to the right of the required arguments.

In the case of ambiguity, the argument parsing code favors parameters on the left (before the required parameters).

Optional groups can only contain positional-only parameters.

Optional groups are only intended for legacy code. Please do not use optional groups for new code.

Using real Argument Clinic converters, instead of “legacy converters”
To save time, and to minimize how much you need to learn to achieve your first port to Argument Clinic, the walkthrough above tells you to use “legacy converters”. “Legacy converters” are a convenience, designed explicitly to make porting existing code to Argument Clinic easier. And to be clear, their use is acceptable when porting code for Python 3.4.

However, in the long term we probably want all our blocks to use Argument Clinic’s real syntax for converters. Why? A couple reasons:

The proper converters are far easier to read and clearer in their intent.

There are some format units that are unsupported as “legacy converters”, because they require arguments, and the legacy converter syntax doesn’t support specifying arguments.

In the future we may have a new argument parsing library that isn’t restricted to what PyArg_ParseTuple() supports; this flexibility won’t be available to parameters using legacy converters.

Therefore, if you don’t mind a little extra effort, please use the normal converters instead of legacy converters.

In a nutshell, the syntax for Argument Clinic (non-legacy) converters looks like a Python function call. However, if there are no explicit arguments to the function (all functions take their default values), you may omit the parentheses. Thus bool and bool() are exactly the same converters.

All arguments to Argument Clinic converters are keyword-only. All Argument Clinic converters accept the following arguments:

c_default
The default value for this parameter when defined in C. Specifically, this will be the initializer for the variable declared in the “parse function”. See the section on default values for how to use this. Specified as a string.

annotation
The annotation value for this parameter. Not currently supported, because PEP 8 mandates that the Python library may not use annotations.

In addition, some converters accept additional arguments. Here is a list of these arguments, along with their meanings:

accept
A set of Python types (and possibly pseudo-types); this restricts the allowable Python argument to values of these types. (This is not a general-purpose facility; as a rule it only supports specific lists of types as shown in the legacy converter table.)

To accept None, add NoneType to this set.

bitwise
Only supported for unsigned integers. The native integer value of this Python argument will be written to the parameter without any range checking, even for negative values.

converter
Only supported by the object converter. Specifies the name of a C “converter function” to use to convert this object to a native type.

encoding
Only supported for strings. Specifies the encoding to use when converting this string from a Python str (Unicode) value into a C char * value.

subclass_of
Only supported for the object converter. Requires that the Python value be a subclass of a Python type, as expressed in C.

type
Only supported for the object and self converters. Specifies the C type that will be used to declare the variable. Default value is "PyObject *".

zeroes
Only supported for strings. If true, embedded NUL bytes ('\\0') are permitted inside the value. The length of the string will be passed in to the impl function, just after the string parameter, as a parameter named <parameter_name>_length.

Please note, not every possible combination of arguments will work. Usually these arguments are implemented by specific PyArg_ParseTuple format units, with specific behavior. For example, currently you cannot call unsigned_short without also specifying bitwise=True. Although it’s perfectly reasonable to think this would work, these semantics don’t map to any existing format unit. So Argument Clinic doesn’t support it. (Or, at least, not yet.)

Below is a table showing the mapping of legacy converters into real Argument Clinic converters. On the left is the legacy converter, on the right is the text you’d replace it with.

'B'

unsigned_char(bitwise=True)

'b'

unsigned_char

'c'

char

'C'

int(accept={str})

'd'

double

'D'

Py_complex

'es'

str(encoding='name_of_encoding')

'es#'

str(encoding='name_of_encoding', zeroes=True)

'et'

str(encoding='name_of_encoding', accept={bytes, bytearray, str})

'et#'

str(encoding='name_of_encoding', accept={bytes, bytearray, str}, zeroes=True)

'f'

float

'h'

short

'H'

unsigned_short(bitwise=True)

'i'

int

'I'

unsigned_int(bitwise=True)

'k'

unsigned_long(bitwise=True)

'K'

unsigned_long_long(bitwise=True)

'l'

long

'L'

long long

'n'

Py_ssize_t

'O'

object

'O!'

object(subclass_of='&PySomething_Type')

'O&'

object(converter='name_of_c_function')

'p'

bool

'S'

PyBytesObject

's'

str

's#'

str(zeroes=True)

's*'

Py_buffer(accept={buffer, str})

'U'

unicode

'u'

Py_UNICODE

'u#'

Py_UNICODE(zeroes=True)

'w*'

Py_buffer(accept={rwbuffer})

'Y'

PyByteArrayObject

'y'

str(accept={bytes})

'y#'

str(accept={robuffer}, zeroes=True)

'y*'

Py_buffer

'Z'

Py_UNICODE(accept={str, NoneType})

'Z#'

Py_UNICODE(accept={str, NoneType}, zeroes=True)

'z'

str(accept={str, NoneType})

'z#'

str(accept={str, NoneType}, zeroes=True)

'z*'

Py_buffer(accept={buffer, str, NoneType})

As an example, here’s our sample pickle.Pickler.dump using the proper converter:

/*[clinic input]
pickle.Pickler.dump

    obj: object
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
One advantage of real converters is that they’re more flexible than legacy converters. For example, the unsigned_int converter (and all the unsigned_ converters) can be specified without bitwise=True. Their default behavior performs range checking on the value, and they won’t accept negative numbers. You just can’t do that with a legacy converter!

Argument Clinic will show you all the converters it has available. For each converter it’ll show you all the parameters it accepts, along with the default value for each parameter. Just run Tools/clinic/clinic.py --converters to see the full list.

Py_buffer
When using the Py_buffer converter (or the 's*', 'w*', '*y', or 'z*' legacy converters), you must not call PyBuffer_Release() on the provided buffer. Argument Clinic generates code that does it for you (in the parsing function).

Advanced converters
Remember those format units you skipped for your first time because they were advanced? Here’s how to handle those too.

The trick is, all those format units take arguments—either conversion functions, or types, or strings specifying an encoding. (But “legacy converters” don’t support arguments. That’s why we skipped them for your first function.) The argument you specified to the format unit is now an argument to the converter; this argument is either converter (for O&), subclass_of (for O!), or encoding (for all the format units that start with e).

When using subclass_of, you may also want to use the other custom argument for object(): type, which lets you set the type actually used for the parameter. For example, if you want to ensure that the object is a subclass of PyUnicode_Type, you probably want to use the converter object(type='PyUnicodeObject *', subclass_of='&PyUnicode_Type').

One possible problem with using Argument Clinic: it takes away some possible flexibility for the format units starting with e. When writing a PyArg_Parse call by hand, you could theoretically decide at runtime what encoding string to pass in to PyArg_ParseTuple(). But now this string must be hard-coded at Argument-Clinic-preprocessing-time. This limitation is deliberate; it made supporting this format unit much easier, and may allow for future optimizations. This restriction doesn’t seem unreasonable; CPython itself always passes in static hard-coded encoding strings for parameters whose format units start with e.

Parameter default values
Default values for parameters can be any of a number of values. At their simplest, they can be string, int, or float literals:

foo: str = "abc"
bar: int = 123
bat: float = 45.6
They can also use any of Python’s built-in constants:

yep:  bool = True
nope: bool = False
nada: object = None
There’s also special support for a default value of NULL, and for simple expressions, documented in the following sections.

The NULL default value
For string and object parameters, you can set them to None to indicate that there’s no default. However, that means the C variable will be initialized to Py_None. For convenience’s sakes, there’s a special value called NULL for just this reason: from Python’s perspective it behaves like a default value of None, but the C variable is initialized with NULL.

Expressions specified as default values
The default value for a parameter can be more than just a literal value. It can be an entire expression, using math operators and looking up attributes on objects. However, this support isn’t exactly simple, because of some non-obvious semantics.

Consider the following example:

foo: Py_ssize_t = sys.maxsize - 1
sys.maxsize can have different values on different platforms. Therefore Argument Clinic can’t simply evaluate that expression locally and hard-code it in C. So it stores the default in such a way that it will get evaluated at runtime, when the user asks for the function’s signature.

What namespace is available when the expression is evaluated? It’s evaluated in the context of the module the builtin came from. So, if your module has an attribute called “max_widgets”, you may simply use it:

foo: Py_ssize_t = max_widgets
If the symbol isn’t found in the current module, it fails over to looking in sys.modules. That’s how it can find sys.maxsize for example. (Since you don’t know in advance what modules the user will load into their interpreter, it’s best to restrict yourself to modules that are preloaded by Python itself.)

Evaluating default values only at runtime means Argument Clinic can’t compute the correct equivalent C default value. So you need to tell it explicitly. When you use an expression, you must also specify the equivalent expression in C, using the c_default parameter to the converter:

foo: Py_ssize_t(c_default="PY_SSIZE_T_MAX - 1") = sys.maxsize - 1
Another complication: Argument Clinic can’t know in advance whether or not the expression you supply is valid. It parses it to make sure it looks legal, but it can’t actually know. You must be very careful when using expressions to specify values that are guaranteed to be valid at runtime!

Finally, because expressions must be representable as static C values, there are many restrictions on legal expressions. Here’s a list of Python features you’re not permitted to use:

Function calls.

Inline if statements (3 if foo else 5).

Automatic sequence unpacking (*[1, 2, 3]).

List/set/dict comprehensions and generator expressions.

Tuple/list/set/dict literals.

Using a return converter
By default the impl function Argument Clinic generates for you returns PyObject *. But your C function often computes some C type, then converts it into the PyObject * at the last moment. Argument Clinic handles converting your inputs from Python types into native C types—why not have it convert your return value from a native C type into a Python type too?

That’s what a “return converter” does. It changes your impl function to return some C type, then adds code to the generated (non-impl) function to handle converting that value into the appropriate PyObject *.

The syntax for return converters is similar to that of parameter converters. You specify the return converter like it was a return annotation on the function itself. Return converters behave much the same as parameter converters; they take arguments, the arguments are all keyword-only, and if you’re not changing any of the default arguments you can omit the parentheses.

(If you use both "as" and a return converter for your function, the "as" should come before the return converter.)

There’s one additional complication when using return converters: how do you indicate an error has occurred? Normally, a function returns a valid (non-NULL) pointer for success, and NULL for failure. But if you use an integer return converter, all integers are valid. How can Argument Clinic detect an error? Its solution: each return converter implicitly looks for a special value that indicates an error. If you return that value, and an error has been set (PyErr_Occurred() returns a true value), then the generated code will propagate the error. Otherwise it will encode the value you return like normal.

Currently Argument Clinic supports only a few return converters:

bool
int
unsigned int
long
unsigned int
size_t
Py_ssize_t
float
double
DecodeFSDefault
None of these take parameters. For the first three, return -1 to indicate error. For DecodeFSDefault, the return type is const char *; return a NULL pointer to indicate an error.

(There’s also an experimental NoneType converter, which lets you return Py_None on success or NULL on failure, without having to increment the reference count on Py_None. I’m not sure it adds enough clarity to be worth using.)

To see all the return converters Argument Clinic supports, along with their parameters (if any), just run Tools/clinic/clinic.py --converters for the full list.

Cloning existing functions
If you have a number of functions that look similar, you may be able to use Clinic’s “clone” feature. When you clone an existing function, you reuse:

its parameters, including

their names,

their converters, with all parameters,

their default values,

their per-parameter docstrings,

their kind (whether they’re positional only, positional or keyword, or keyword only), and

its return converter.

The only thing not copied from the original function is its docstring; the syntax allows you to specify a new docstring.

Here’s the syntax for cloning a function:

/*[clinic input]
module.class.new_function [as c_basename] = module.class.existing_function

Docstring for new_function goes here.
[clinic start generated code]*/
(The functions can be in different modules or classes. I wrote module.class in the sample just to illustrate that you must use the full path to both functions.)

Sorry, there’s no syntax for partially cloning a function, or cloning a function then modifying it. Cloning is an all-or nothing proposition.

Also, the function you are cloning from must have been previously defined in the current file.

Calling Python code
The rest of the advanced topics require you to write Python code which lives inside your C file and modifies Argument Clinic’s runtime state. This is simple: you simply define a Python block.

A Python block uses different delimiter lines than an Argument Clinic function block. It looks like this:

/*[python input]
# python code goes here
[python start generated code]*/
All the code inside the Python block is executed at the time it’s parsed. All text written to stdout inside the block is redirected into the “output” after the block.

As an example, here’s a Python block that adds a static integer variable to the C code:

/*[python input]
print('static int __ignored_unused_variable__ = 0;')
[python start generated code]*/
static int __ignored_unused_variable__ = 0;
/*[python checksum:...]*/
Using a “self converter”
Argument Clinic automatically adds a “self” parameter for you using a default converter. It automatically sets the type of this parameter to the “pointer to an instance” you specified when you declared the type. However, you can override Argument Clinic’s converter and specify one yourself. Just add your own self parameter as the first parameter in a block, and ensure that its converter is an instance of self_converter or a subclass thereof.

What’s the point? This lets you override the type of self, or give it a different default name.

How do you specify the custom type you want to cast self to? If you only have one or two functions with the same type for self, you can directly use Argument Clinic’s existing self converter, passing in the type you want to use as the type parameter:

/*[clinic input]

_pickle.Pickler.dump

  self: self(type="PicklerObject *")
  obj: object
  /

Write a pickled representation of the given object to the open file.
[clinic start generated code]*/
On the other hand, if you have a lot of functions that will use the same type for self, it’s best to create your own converter, subclassing self_converter but overwriting the type member:

/*[python input]
class PicklerObject_converter(self_converter):
    type = "PicklerObject *"
[python start generated code]*/

/*[clinic input]

_pickle.Pickler.dump

  self: PicklerObject
  obj: object
  /

Write a pickled representation of the given object to the open file.
[clinic start generated code]*/
Using a “defining class” converter
Argument Clinic facilitates gaining access to the defining class of a method. This is useful for heap type methods that need to fetch module level state. Use PyType_FromModuleAndSpec() to associate a new heap type with a module. You can now use PyType_GetModuleState() on the defining class to fetch the module state, for example from a module method.

Example from Modules/zlibmodule.c. First, defining_class is added to the clinic input:

/*[clinic input]
zlib.Compress.compress

  cls: defining_class
  data: Py_buffer
    Binary data to be compressed.
  /
After running the Argument Clinic tool, the following function signature is generated:

/*[clinic start generated code]*/
static PyObject *
zlib_Compress_compress_impl(compobject *self, PyTypeObject *cls,
                            Py_buffer *data)
/*[clinic end generated code: output=6731b3f0ff357ca6 input=04d00f65ab01d260]*/
The following code can now use PyType_GetModuleState(cls) to fetch the module state:

zlibstate *state = PyType_GetModuleState(cls);
Each method may only have one argument using this converter, and it must appear after self, or, if self is not used, as the first argument. The argument will be of type PyTypeObject *. The argument will not appear in the __text_signature__.

The defining_class converter is not compatible with __init__ and __new__ methods, which cannot use the METH_METHOD convention.

It is not possible to use defining_class with slot methods. In order to fetch the module state from such methods, use _PyType_GetModuleByDef to look up the module and then PyModule_GetState() to fetch the module state. Example from the setattro slot method in Modules/_threadmodule.c:

static int
local_setattro(localobject *self, PyObject *name, PyObject *v)
{
    PyObject *module = _PyType_GetModuleByDef(Py_TYPE(self), &thread_module);
    thread_module_state *state = get_thread_state(module);
    ...
}
See also PEP 573.

Writing a custom converter
As we hinted at in the previous section… you can write your own converters! A converter is simply a Python class that inherits from CConverter. The main purpose of a custom converter is if you have a parameter using the O& format unit—parsing this parameter means calling a PyArg_ParseTuple() “converter function”.

Your converter class should be named *something*_converter. If the name follows this convention, then your converter class will be automatically registered with Argument Clinic; its name will be the name of your class with the _converter suffix stripped off. (This is accomplished with a metaclass.)

You shouldn’t subclass CConverter.__init__. Instead, you should write a converter_init() function. converter_init() always accepts a self parameter; after that, all additional parameters must be keyword-only. Any arguments passed in to the converter in Argument Clinic will be passed along to your converter_init().

There are some additional members of CConverter you may wish to specify in your subclass. Here’s the current list:

type
The C type to use for this variable. type should be a Python string specifying the type, e.g. int. If this is a pointer type, the type string should end with ' *'.

default
The Python default value for this parameter, as a Python value. Or the magic value unspecified if there is no default.

py_default
default as it should appear in Python code, as a string. Or None if there is no default.

c_default
default as it should appear in C code, as a string. Or None if there is no default.

c_ignored_default
The default value used to initialize the C variable when there is no default, but not specifying a default may result in an “uninitialized variable” warning. This can easily happen when using option groups—although properly written code will never actually use this value, the variable does get passed in to the impl, and the C compiler will complain about the “use” of the uninitialized value. This value should always be a non-empty string.

converter
The name of the C converter function, as a string.

impl_by_reference
A boolean value. If true, Argument Clinic will add a & in front of the name of the variable when passing it into the impl function.

parse_by_reference
A boolean value. If true, Argument Clinic will add a & in front of the name of the variable when passing it into PyArg_ParseTuple().

Here’s the simplest example of a custom converter, from Modules/zlibmodule.c:

/*[python input]

class ssize_t_converter(CConverter):
    type = 'Py_ssize_t'
    converter = 'ssize_t_converter'

[python start generated code]*/
/*[python end generated code: output=da39a3ee5e6b4b0d input=35521e4e733823c7]*/
This block adds a converter to Argument Clinic named ssize_t. Parameters declared as ssize_t will be declared as type Py_ssize_t, and will be parsed by the 'O&' format unit, which will call the ssize_t_converter converter function. ssize_t variables automatically support default values.

More sophisticated custom converters can insert custom C code to handle initialization and cleanup. You can see more examples of custom converters in the CPython source tree; grep the C files for the string CConverter.

Writing a custom return converter
Writing a custom return converter is much like writing a custom converter. Except it’s somewhat simpler, because return converters are themselves much simpler.

Return converters must subclass CReturnConverter. There are no examples yet of custom return converters, because they are not widely used yet. If you wish to write your own return converter, please read Tools/clinic/clinic.py, specifically the implementation of CReturnConverter and all its subclasses.

METH_O and METH_NOARGS
To convert a function using METH_O, make sure the function’s single argument is using the object converter, and mark the arguments as positional-only:

/*[clinic input]
meth_o_sample

     argument: object
     /
[clinic start generated code]*/
To convert a function using METH_NOARGS, just don’t specify any arguments.

You can still use a self converter, a return converter, and specify a type argument to the object converter for METH_O.

tp_new and tp_init functions
You can convert tp_new and tp_init functions. Just name them __new__ or __init__ as appropriate. Notes:

The function name generated for __new__ doesn’t end in __new__ like it would by default. It’s just the name of the class, converted into a valid C identifier.

No PyMethodDef #define is generated for these functions.

__init__ functions return int, not PyObject *.

Use the docstring as the class docstring.

Although __new__ and __init__ functions must always accept both the args and kwargs objects, when converting you may specify any signature for these functions that you like. (If your function doesn’t support keywords, the parsing function generated will throw an exception if it receives any.)

Changing and redirecting Clinic’s output
It can be inconvenient to have Clinic’s output interspersed with your conventional hand-edited C code. Luckily, Clinic is configurable: you can buffer up its output for printing later (or earlier!), or write its output to a separate file. You can also add a prefix or suffix to every line of Clinic’s generated output.

While changing Clinic’s output in this manner can be a boon to readability, it may result in Clinic code using types before they are defined, or your code attempting to use Clinic-generated code before it is defined. These problems can be easily solved by rearranging the declarations in your file, or moving where Clinic’s generated code goes. (This is why the default behavior of Clinic is to output everything into the current block; while many people consider this hampers readability, it will never require rearranging your code to fix definition-before-use problems.)

Let’s start with defining some terminology:

field
A field, in this context, is a subsection of Clinic’s output. For example, the #define for the PyMethodDef structure is a field, called methoddef_define. Clinic has seven different fields it can output per function definition:

docstring_prototype
docstring_definition
methoddef_define
impl_prototype
parser_prototype
parser_definition
impl_definition
All the names are of the form "<a>_<b>", where "<a>" is the semantic object represented (the parsing function, the impl function, the docstring, or the methoddef structure) and "<b>" represents what kind of statement the field is. Field names that end in "_prototype" represent forward declarations of that thing, without the actual body/data of the thing; field names that end in "_definition" represent the actual definition of the thing, with the body/data of the thing. ("methoddef" is special, it’s the only one that ends with "_define", representing that it’s a preprocessor #define.)

destination
A destination is a place Clinic can write output to. There are five built-in destinations:

block
The default destination: printed in the output section of the current Clinic block.

buffer
A text buffer where you can save text for later. Text sent here is appended to the end of any existing text. It’s an error to have any text left in the buffer when Clinic finishes processing a file.

file
A separate “clinic file” that will be created automatically by Clinic. The filename chosen for the file is {basename}.clinic{extension}, where basename and extension were assigned the output from os.path.splitext() run on the current file. (Example: the file destination for _pickle.c would be written to _pickle.clinic.c.)

Important: When using a file destination, you must check in the generated file!

two-pass
A buffer like buffer. However, a two-pass buffer can only be dumped once, and it prints out all text sent to it during all processing, even from Clinic blocks after the dumping point.

suppress
The text is suppressed—thrown away.

Clinic defines five new directives that let you reconfigure its output.

The first new directive is dump:

dump <destination>
This dumps the current contents of the named destination into the output of the current block, and empties it. This only works with buffer and two-pass destinations.

The second new directive is output. The most basic form of output is like this:

output <field> <destination>
This tells Clinic to output field to destination. output also supports a special meta-destination, called everything, which tells Clinic to output all fields to that destination.

output has a number of other functions:

output push
output pop
output preset <preset>
output push and output pop allow you to push and pop configurations on an internal configuration stack, so that you can temporarily modify the output configuration, then easily restore the previous configuration. Simply push before your change to save the current configuration, then pop when you wish to restore the previous configuration.

output preset sets Clinic’s output to one of several built-in preset configurations, as follows:

block
Clinic’s original starting configuration. Writes everything immediately after the input block.

Suppress the parser_prototype and docstring_prototype, write everything else to block.

file
Designed to write everything to the “clinic file” that it can. You then #include this file near the top of your file. You may need to rearrange your file to make this work, though usually this just means creating forward declarations for various typedef and PyTypeObject definitions.

Suppress the parser_prototype and docstring_prototype, write the impl_definition to block, and write everything else to file.

The default filename is "{dirname}/clinic/{basename}.h".

buffer
Save up most of the output from Clinic, to be written into your file near the end. For Python files implementing modules or builtin types, it’s recommended that you dump the buffer just above the static structures for your module or builtin type; these are normally very near the end. Using buffer may require even more editing than file, if your file has static PyMethodDef arrays defined in the middle of the file.

Suppress the parser_prototype, impl_prototype, and docstring_prototype, write the impl_definition to block, and write everything else to file.

two-pass
Similar to the buffer preset, but writes forward declarations to the two-pass buffer, and definitions to the buffer. This is similar to the buffer preset, but may require less editing than buffer. Dump the two-pass buffer near the top of your file, and dump the buffer near the end just like you would when using the buffer preset.

Suppresses the impl_prototype, write the impl_definition to block, write docstring_prototype, methoddef_define, and parser_prototype to two-pass, write everything else to buffer.

partial-buffer
Similar to the buffer preset, but writes more things to block, only writing the really big chunks of generated code to buffer. This avoids the definition-before-use problem of buffer completely, at the small cost of having slightly more stuff in the block’s output. Dump the buffer near the end, just like you would when using the buffer preset.

Suppresses the impl_prototype, write the docstring_definition and parser_definition to buffer, write everything else to block.

The third new directive is destination:

destination <name> <command> [...]
This performs an operation on the destination named name.

There are two defined subcommands: new and clear.

The new subcommand works like this:

destination <name> new <type>
This creates a new destination with name <name> and type <type>.

There are five destination types:

suppress
Throws the text away.

block
Writes the text to the current block. This is what Clinic originally did.

buffer
A simple text buffer, like the “buffer” builtin destination above.

file
A text file. The file destination takes an extra argument, a template to use for building the filename, like so:

destination <name> new <type> <file_template>

The template can use three strings internally that will be replaced by bits of the filename:

{path}
The full path to the file, including directory and full filename.

{dirname}
The name of the directory the file is in.

{basename}
Just the name of the file, not including the directory.

{basename_root}
Basename with the extension clipped off (everything up to but not including the last ‘.’).

{basename_extension}
The last ‘.’ and everything after it. If the basename does not contain a period, this will be the empty string.

If there are no periods in the filename, {basename} and {filename} are the same, and {extension} is empty. “{basename}{extension}” is always exactly the same as “{filename}”.”

two-pass
A two-pass buffer, like the “two-pass” builtin destination above.

The clear subcommand works like this:

destination <name> clear
It removes all the accumulated text up to this point in the destination. (I don’t know what you’d need this for, but I thought maybe it’d be useful while someone’s experimenting.)

The fourth new directive is set:

set line_prefix "string"
set line_suffix "string"
set lets you set two internal variables in Clinic. line_prefix is a string that will be prepended to every line of Clinic’s output; line_suffix is a string that will be appended to every line of Clinic’s output.

Both of these support two format strings:

{block comment start}
Turns into the string /*, the start-comment text sequence for C files.

{block comment end}
Turns into the string */, the end-comment text sequence for C files.

The final new directive is one you shouldn’t need to use directly, called preserve:

preserve
This tells Clinic that the current contents of the output should be kept, unmodified. This is used internally by Clinic when dumping output into file files; wrapping it in a Clinic block lets Clinic use its existing checksum functionality to ensure the file was not modified by hand before it gets overwritten.

The #ifdef trick
If you’re converting a function that isn’t available on all platforms, there’s a trick you can use to make life a little easier. The existing code probably looks like this:

#ifdef HAVE_FUNCTIONNAME
static module_functionname(...)
{
...
}
#endif /* HAVE_FUNCTIONNAME */
And then in the PyMethodDef structure at the bottom the existing code will have:

#ifdef HAVE_FUNCTIONNAME
{'functionname', ... },
#endif /* HAVE_FUNCTIONNAME */
In this scenario, you should enclose the body of your impl function inside the #ifdef, like so:

#ifdef HAVE_FUNCTIONNAME
/*[clinic input]
module.functionname
...
[clinic start generated code]*/
static module_functionname(...)
{
...
}
#endif /* HAVE_FUNCTIONNAME */
Then, remove those three lines from the PyMethodDef structure, replacing them with the macro Argument Clinic generated:

MODULE_FUNCTIONNAME_METHODDEF
(You can find the real name for this macro inside the generated code. Or you can calculate it yourself: it’s the name of your function as defined on the first line of your block, but with periods changed to underscores, uppercased, and "_METHODDEF" added to the end.)

Perhaps you’re wondering: what if HAVE_FUNCTIONNAME isn’t defined? The MODULE_FUNCTIONNAME_METHODDEF macro won’t be defined either!

Here’s where Argument Clinic gets very clever. It actually detects that the Argument Clinic block might be deactivated by the #ifdef. When that happens, it generates a little extra code that looks like this:

#ifndef MODULE_FUNCTIONNAME_METHODDEF
    #define MODULE_FUNCTIONNAME_METHODDEF
#endif /* !defined(MODULE_FUNCTIONNAME_METHODDEF) */
That means the macro always works. If the function is defined, this turns into the correct structure, including the trailing comma. If the function is undefined, this turns into nothing.

However, this causes one ticklish problem: where should Argument Clinic put this extra code when using the “block” output preset? It can’t go in the output block, because that could be deactivated by the #ifdef. (That’s the whole point!)

In this situation, Argument Clinic writes the extra code to the “buffer” destination. This may mean that you get a complaint from Argument Clinic:

Warning in file "Modules/posixmodule.c" on line 12357:
Destination buffer 'buffer' not empty at end of file, emptying.
When this happens, just open your file, find the dump buffer block that Argument Clinic added to your file (it’ll be at the very bottom), then move it above the PyMethodDef structure where that macro is used.

Using Argument Clinic in Python files
It’s actually possible to use Argument Clinic to preprocess Python files. There’s no point to using Argument Clinic blocks, of course, as the output wouldn’t make any sense to the Python interpreter. But using Argument Clinic to run Python blocks lets you use Python as a Python preprocessor!

Since Python comments are different from C comments, Argument Clinic blocks embedded in Python files look slightly different. They look like this:

#/*[python input]
#print("def foo(): pass")
#[python start generated code]*/
def foo(): pass
#/*[python checksum:...]*/
Table of Contents
Argument Clinic How-To
The Goals Of Argument Clinic
Basic Concepts And Usage
Converting Your First Function
Advanced Topics
Symbolic default values
Renaming the C functions and variables generated by Argument Clinic
Converting functions using PyArg_UnpackTuple
Optional Groups
Using real Argument Clinic converters, instead of “legacy converters”
Py_buffer
Advanced converters
Parameter default values
The NULL default value
Expressions specified as default values
Using a return converter
Cloning existing functions
Calling Python code
Using a “self converter”
Using a “defining class” converter
Writing a custom converter
Writing a custom return converter
METH_O and METH_NOARGS
tp_new and tp_init functions
Changing and redirecting Clinic’s output
The #ifdef trick
Using Argument Clinic in Python files
Previous topic
An introduction to the ipaddress module

Next topic
Instrumenting CPython with DTrace and SystemTap

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Argument Clinic How-To
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Argument Clinic How-To
Quick search
  |
Argument Clinic How-To
author
Larry Hastings

Abstract

Argument Clinic is a preprocessor for CPython C files. Its purpose is to automate all the boilerplate involved with writing argument parsing code for “builtins”. This document shows you how to convert your first C function to work with Argument Clinic, and then introduces some advanced topics on Argument Clinic usage.

Currently Argument Clinic is considered internal-only for CPython. Its use is not supported for files outside CPython, and no guarantees are made regarding backwards compatibility for future versions. In other words: if you maintain an external C extension for CPython, you’re welcome to experiment with Argument Clinic in your own code. But the version of Argument Clinic that ships with the next version of CPython could be totally incompatible and break all your code.

The Goals Of Argument Clinic
Argument Clinic’s primary goal is to take over responsibility for all argument parsing code inside CPython. This means that, when you convert a function to work with Argument Clinic, that function should no longer do any of its own argument parsing—the code generated by Argument Clinic should be a “black box” to you, where CPython calls in at the top, and your code gets called at the bottom, with PyObject *args (and maybe PyObject *kwargs) magically converted into the C variables and types you need.

In order for Argument Clinic to accomplish its primary goal, it must be easy to use. Currently, working with CPython’s argument parsing library is a chore, requiring maintaining redundant information in a surprising number of places. When you use Argument Clinic, you don’t have to repeat yourself.

Obviously, no one would want to use Argument Clinic unless it’s solving their problem—and without creating new problems of its own. So it’s paramount that Argument Clinic generate correct code. It’d be nice if the code was faster, too, but at the very least it should not introduce a major speed regression. (Eventually Argument Clinic should make a major speedup possible—we could rewrite its code generator to produce tailor-made argument parsing code, rather than calling the general-purpose CPython argument parsing library. That would make for the fastest argument parsing possible!)

Additionally, Argument Clinic must be flexible enough to work with any approach to argument parsing. Python has some functions with some very strange parsing behaviors; Argument Clinic’s goal is to support all of them.

Finally, the original motivation for Argument Clinic was to provide introspection “signatures” for CPython builtins. It used to be, the introspection query functions would throw an exception if you passed in a builtin. With Argument Clinic, that’s a thing of the past!

One idea you should keep in mind, as you work with Argument Clinic: the more information you give it, the better job it’ll be able to do. Argument Clinic is admittedly relatively simple right now. But as it evolves it will get more sophisticated, and it should be able to do many interesting and smart things with all the information you give it.

Basic Concepts And Usage
Argument Clinic ships with CPython; you’ll find it in Tools/clinic/clinic.py. If you run that script, specifying a C file as an argument:

$ python3 Tools/clinic/clinic.py foo.c
Argument Clinic will scan over the file looking for lines that look exactly like this:

/*[clinic input]
When it finds one, it reads everything up to a line that looks exactly like this:

[clinic start generated code]*/
Everything in between these two lines is input for Argument Clinic. All of these lines, including the beginning and ending comment lines, are collectively called an Argument Clinic “block”.

When Argument Clinic parses one of these blocks, it generates output. This output is rewritten into the C file immediately after the block, followed by a comment containing a checksum. The Argument Clinic block now looks like this:

/*[clinic input]
... clinic input goes here ...
[clinic start generated code]*/
... clinic output goes here ...
/*[clinic end generated code: checksum=...]*/
If you run Argument Clinic on the same file a second time, Argument Clinic will discard the old output and write out the new output with a fresh checksum line. However, if the input hasn’t changed, the output won’t change either.

You should never modify the output portion of an Argument Clinic block. Instead, change the input until it produces the output you want. (That’s the purpose of the checksum—to detect if someone changed the output, as these edits would be lost the next time Argument Clinic writes out fresh output.)

For the sake of clarity, here’s the terminology we’ll use with Argument Clinic:

The first line of the comment (/*[clinic input]) is the start line.

The last line of the initial comment ([clinic start generated code]*/) is the end line.

The last line (/*[clinic end generated code: checksum=...]*/) is the checksum line.

In between the start line and the end line is the input.

In between the end line and the checksum line is the output.

All the text collectively, from the start line to the checksum line inclusively, is the block. (A block that hasn’t been successfully processed by Argument Clinic yet doesn’t have output or a checksum line, but it’s still considered a block.)

Converting Your First Function
The best way to get a sense of how Argument Clinic works is to convert a function to work with it. Here, then, are the bare minimum steps you’d need to follow to convert a function to work with Argument Clinic. Note that for code you plan to check in to CPython, you really should take the conversion farther, using some of the advanced concepts you’ll see later on in the document (like “return converters” and “self converters”). But we’ll keep it simple for this walkthrough so you can learn.

Let’s dive in!

Make sure you’re working with a freshly updated checkout of the CPython trunk.

Find a Python builtin that calls either PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords(), and hasn’t been converted to work with Argument Clinic yet. For my example I’m using _pickle.Pickler.dump().

If the call to the PyArg_Parse function uses any of the following format units:

O&
O!
es
es#
et
et#
or if it has multiple calls to PyArg_ParseTuple(), you should choose a different function. Argument Clinic does support all of these scenarios. But these are advanced topics—let’s do something simpler for your first function.

Also, if the function has multiple calls to PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords() where it supports different types for the same argument, or if the function uses something besides PyArg_Parse functions to parse its arguments, it probably isn’t suitable for conversion to Argument Clinic. Argument Clinic doesn’t support generic functions or polymorphic parameters.

Add the following boilerplate above the function, creating our block:

/*[clinic input]
[clinic start generated code]*/
Cut the docstring and paste it in between the [clinic] lines, removing all the junk that makes it a properly quoted C string. When you’re done you should have just the text, based at the left margin, with no line wider than 80 characters. (Argument Clinic will preserve indents inside the docstring.)

If the old docstring had a first line that looked like a function signature, throw that line away. (The docstring doesn’t need it anymore—when you use help() on your builtin in the future, the first line will be built automatically based on the function’s signature.)

Sample:

/*[clinic input]
Write a pickled representation of obj to the open file.
[clinic start generated code]*/
If your docstring doesn’t have a “summary” line, Argument Clinic will complain. So let’s make sure it has one. The “summary” line should be a paragraph consisting of a single 80-column line at the beginning of the docstring.

(Our example docstring consists solely of a summary line, so the sample code doesn’t have to change for this step.)

Above the docstring, enter the name of the function, followed by a blank line. This should be the Python name of the function, and should be the full dotted path to the function—it should start with the name of the module, include any sub-modules, and if the function is a method on a class it should include the class name too.

Sample:

/*[clinic input]
_pickle.Pickler.dump

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
If this is the first time that module or class has been used with Argument Clinic in this C file, you must declare the module and/or class. Proper Argument Clinic hygiene prefers declaring these in a separate block somewhere near the top of the C file, in the same way that include files and statics go at the top. (In our sample code we’ll just show the two blocks next to each other.)

The name of the class and module should be the same as the one seen by Python. Check the name defined in the PyModuleDef or PyTypeObject as appropriate.

When you declare a class, you must also specify two aspects of its type in C: the type declaration you’d use for a pointer to an instance of this class, and a pointer to the PyTypeObject for this class.

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/

/*[clinic input]
_pickle.Pickler.dump

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
Declare each of the parameters to the function. Each parameter should get its own line. All the parameter lines should be indented from the function name and the docstring.

The general form of these parameter lines is as follows:

name_of_parameter: converter
If the parameter has a default value, add that after the converter:

name_of_parameter: converter = default_value
Argument Clinic’s support for “default values” is quite sophisticated; please see the section below on default values for more information.

Add a blank line below the parameters.

What’s a “converter”? It establishes both the type of the variable used in C, and the method to convert the Python value into a C value at runtime. For now you’re going to use what’s called a “legacy converter”—a convenience syntax intended to make porting old code into Argument Clinic easier.

For each parameter, copy the “format unit” for that parameter from the PyArg_Parse() format argument and specify that as its converter, as a quoted string. (“format unit” is the formal name for the one-to-three character substring of the format parameter that tells the argument parsing function what the type of the variable is and how to convert it. For more on format units please see Parsing arguments and building values.)

For multicharacter format units like z#, use the entire two-or-three character string.

Sample:

 /*[clinic input]
 module _pickle
 class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
 [clinic start generated code]*/

 /*[clinic input]
 _pickle.Pickler.dump

    obj: 'O'

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
If your function has | in the format string, meaning some parameters have default values, you can ignore it. Argument Clinic infers which parameters are optional based on whether or not they have default values.

If your function has $ in the format string, meaning it takes keyword-only arguments, specify * on a line by itself before the first keyword-only argument, indented the same as the parameter lines.

(_pickle.Pickler.dump has neither, so our sample is unchanged.)

If the existing C function calls PyArg_ParseTuple() (as opposed to PyArg_ParseTupleAndKeywords()), then all its arguments are positional-only.

To mark all parameters as positional-only in Argument Clinic, add a / on a line by itself after the last parameter, indented the same as the parameter lines.

Currently this is all-or-nothing; either all parameters are positional-only, or none of them are. (In the future Argument Clinic may relax this restriction.)

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
It’s helpful to write a per-parameter docstring for each parameter. But per-parameter docstrings are optional; you can skip this step if you prefer.

Here’s how to add a per-parameter docstring. The first line of the per-parameter docstring must be indented further than the parameter definition. The left margin of this first line establishes the left margin for the whole per-parameter docstring; all the text you write will be outdented by this amount. You can write as much text as you like, across multiple lines if you wish.

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
Save and close the file, then run Tools/clinic/clinic.py on it. With luck everything worked—your block now has output, and a .c.h file has been generated! Reopen the file in your text editor to see:

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/

static PyObject *
_pickle_Pickler_dump(PicklerObject *self, PyObject *obj)
/*[clinic end generated code: output=87ecad1261e02ac7 input=552eb1c0f52260d9]*/
Obviously, if Argument Clinic didn’t produce any output, it’s because it found an error in your input. Keep fixing your errors and retrying until Argument Clinic processes your file without complaint.

For readability, most of the glue code has been generated to a .c.h file. You’ll need to include that in your original .c file, typically right after the clinic module block:

#include "clinic/_pickle.c.h"
Double-check that the argument-parsing code Argument Clinic generated looks basically the same as the existing code.

First, ensure both places use the same argument-parsing function. The existing code must call either PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords(); ensure that the code generated by Argument Clinic calls the exact same function.

Second, the format string passed in to PyArg_ParseTuple() or PyArg_ParseTupleAndKeywords() should be exactly the same as the hand-written one in the existing function, up to the colon or semi-colon.

(Argument Clinic always generates its format strings with a : followed by the name of the function. If the existing code’s format string ends with ;, to provide usage help, this change is harmless—don’t worry about it.)

Third, for parameters whose format units require two arguments (like a length variable, or an encoding string, or a pointer to a conversion function), ensure that the second argument is exactly the same between the two invocations.

Fourth, inside the output portion of the block you’ll find a preprocessor macro defining the appropriate static PyMethodDef structure for this builtin:

#define __PICKLE_PICKLER_DUMP_METHODDEF    \
{"dump", (PyCFunction)__pickle_Pickler_dump, METH_O, __pickle_Pickler_dump__doc__},
This static structure should be exactly the same as the existing static PyMethodDef structure for this builtin.

If any of these items differ in any way, adjust your Argument Clinic function specification and rerun Tools/clinic/clinic.py until they are the same.

Notice that the last line of its output is the declaration of your “impl” function. This is where the builtin’s implementation goes. Delete the existing prototype of the function you’re modifying, but leave the opening curly brace. Now delete its argument parsing code and the declarations of all the variables it dumps the arguments into. Notice how the Python arguments are now arguments to this impl function; if the implementation used different names for these variables, fix it.

Let’s reiterate, just because it’s kind of weird. Your code should now look like this:

static return_type
your_function_impl(...)
/*[clinic end generated code: checksum=...]*/
{
...
Argument Clinic generated the checksum line and the function prototype just above it. You should write the opening (and closing) curly braces for the function, and the implementation inside.

Sample:

/*[clinic input]
module _pickle
class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
[clinic start generated code]*/
/*[clinic end generated code: checksum=da39a3ee5e6b4b0d3255bfef95601890afd80709]*/

/*[clinic input]
_pickle.Pickler.dump

    obj: 'O'
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/

PyDoc_STRVAR(__pickle_Pickler_dump__doc__,
"Write a pickled representation of obj to the open file.\n"
"\n"
...
static PyObject *
_pickle_Pickler_dump_impl(PicklerObject *self, PyObject *obj)
/*[clinic end generated code: checksum=3bd30745bf206a48f8b576a1da3d90f55a0a4187]*/
{
    /* Check whether the Pickler was initialized correctly (issue3664).
       Developers often forget to call __init__() in their subclasses, which
       would trigger a segfault without this check. */
    if (self->write == NULL) {
        PyErr_Format(PicklingError,
                     "Pickler.__init__() was not called by %s.__init__()",
                     Py_TYPE(self)->tp_name);
        return NULL;
    }

    if (_Pickler_ClearBuffer(self) < 0)
        return NULL;

    ...
Remember the macro with the PyMethodDef structure for this function? Find the existing PyMethodDef structure for this function and replace it with a reference to the macro. (If the builtin is at module scope, this will probably be very near the end of the file; if the builtin is a class method, this will probably be below but relatively near to the implementation.)

Note that the body of the macro contains a trailing comma. So when you replace the existing static PyMethodDef structure with the macro, don’t add a comma to the end.

Sample:

static struct PyMethodDef Pickler_methods[] = {
    __PICKLE_PICKLER_DUMP_METHODDEF
    __PICKLE_PICKLER_CLEAR_MEMO_METHODDEF
    {NULL, NULL}                /* sentinel */
};
Compile, then run the relevant portions of the regression-test suite. This change should not introduce any new compile-time warnings or errors, and there should be no externally visible change to Python’s behavior.

Well, except for one difference: inspect.signature() run on your function should now provide a valid signature!

Congratulations, you’ve ported your first function to work with Argument Clinic!

Advanced Topics
Now that you’ve had some experience working with Argument Clinic, it’s time for some advanced topics.

Symbolic default values
The default value you provide for a parameter can’t be any arbitrary expression. Currently the following are explicitly supported:

Numeric constants (integer and float)

String constants

True, False, and None

Simple symbolic constants like sys.maxsize, which must start with the name of the module

In case you’re curious, this is implemented in from_builtin() in Lib/inspect.py.

(In the future, this may need to get even more elaborate, to allow full expressions like CONSTANT - 1.)

Renaming the C functions and variables generated by Argument Clinic
Argument Clinic automatically names the functions it generates for you. Occasionally this may cause a problem, if the generated name collides with the name of an existing C function. There’s an easy solution: override the names used for the C functions. Just add the keyword "as" to your function declaration line, followed by the function name you wish to use. Argument Clinic will use that function name for the base (generated) function, then add "_impl" to the end and use that for the name of the impl function.

For example, if we wanted to rename the C function names generated for pickle.Pickler.dump, it’d look like this:

/*[clinic input]
pickle.Pickler.dump as pickler_dumper

...
The base function would now be named pickler_dumper(), and the impl function would now be named pickler_dumper_impl().

Similarly, you may have a problem where you want to give a parameter a specific Python name, but that name may be inconvenient in C. Argument Clinic allows you to give a parameter different names in Python and in C, using the same "as" syntax:

/*[clinic input]
pickle.Pickler.dump

    obj: object
    file as file_obj: object
    protocol: object = NULL
    *
    fix_imports: bool = True
Here, the name used in Python (in the signature and the keywords array) would be file, but the C variable would be named file_obj.

You can use this to rename the self parameter too!

Converting functions using PyArg_UnpackTuple
To convert a function parsing its arguments with PyArg_UnpackTuple(), simply write out all the arguments, specifying each as an object. You may specify the type argument to cast the type as appropriate. All arguments should be marked positional-only (add a / on a line by itself after the last argument).

Currently the generated code will use PyArg_ParseTuple(), but this will change soon.

Optional Groups
Some legacy functions have a tricky approach to parsing their arguments: they count the number of positional arguments, then use a switch statement to call one of several different PyArg_ParseTuple() calls depending on how many positional arguments there are. (These functions cannot accept keyword-only arguments.) This approach was used to simulate optional arguments back before PyArg_ParseTupleAndKeywords() was created.

While functions using this approach can often be converted to use PyArg_ParseTupleAndKeywords(), optional arguments, and default values, it’s not always possible. Some of these legacy functions have behaviors PyArg_ParseTupleAndKeywords() doesn’t directly support. The most obvious example is the builtin function range(), which has an optional argument on the left side of its required argument! Another example is curses.window.addch(), which has a group of two arguments that must always be specified together. (The arguments are called x and y; if you call the function passing in x, you must also pass in y—and if you don’t pass in x you may not pass in y either.)

In any case, the goal of Argument Clinic is to support argument parsing for all existing CPython builtins without changing their semantics. Therefore Argument Clinic supports this alternate approach to parsing, using what are called optional groups. Optional groups are groups of arguments that must all be passed in together. They can be to the left or the right of the required arguments. They can only be used with positional-only parameters.

Note Optional groups are only intended for use when converting functions that make multiple calls to PyArg_ParseTuple()! Functions that use any other approach for parsing arguments should almost never be converted to Argument Clinic using optional groups. Functions using optional groups currently cannot have accurate signatures in Python, because Python just doesn’t understand the concept. Please avoid using optional groups wherever possible.
To specify an optional group, add a [ on a line by itself before the parameters you wish to group together, and a ] on a line by itself after these parameters. As an example, here’s how curses.window.addch uses optional groups to make the first two parameters and the last parameter optional:

/*[clinic input]

curses.window.addch

    [
    x: int
      X-coordinate.
    y: int
      Y-coordinate.
    ]

    ch: object
      Character to add.

    [
    attr: long
      Attributes for the character.
    ]
    /

...
Notes:

For every optional group, one additional parameter will be passed into the impl function representing the group. The parameter will be an int named group_{direction}_{number}, where {direction} is either right or left depending on whether the group is before or after the required parameters, and {number} is a monotonically increasing number (starting at 1) indicating how far away the group is from the required parameters. When the impl is called, this parameter will be set to zero if this group was unused, and set to non-zero if this group was used. (By used or unused, I mean whether or not the parameters received arguments in this invocation.)

If there are no required arguments, the optional groups will behave as if they’re to the right of the required arguments.

In the case of ambiguity, the argument parsing code favors parameters on the left (before the required parameters).

Optional groups can only contain positional-only parameters.

Optional groups are only intended for legacy code. Please do not use optional groups for new code.

Using real Argument Clinic converters, instead of “legacy converters”
To save time, and to minimize how much you need to learn to achieve your first port to Argument Clinic, the walkthrough above tells you to use “legacy converters”. “Legacy converters” are a convenience, designed explicitly to make porting existing code to Argument Clinic easier. And to be clear, their use is acceptable when porting code for Python 3.4.

However, in the long term we probably want all our blocks to use Argument Clinic’s real syntax for converters. Why? A couple reasons:

The proper converters are far easier to read and clearer in their intent.

There are some format units that are unsupported as “legacy converters”, because they require arguments, and the legacy converter syntax doesn’t support specifying arguments.

In the future we may have a new argument parsing library that isn’t restricted to what PyArg_ParseTuple() supports; this flexibility won’t be available to parameters using legacy converters.

Therefore, if you don’t mind a little extra effort, please use the normal converters instead of legacy converters.

In a nutshell, the syntax for Argument Clinic (non-legacy) converters looks like a Python function call. However, if there are no explicit arguments to the function (all functions take their default values), you may omit the parentheses. Thus bool and bool() are exactly the same converters.

All arguments to Argument Clinic converters are keyword-only. All Argument Clinic converters accept the following arguments:

c_default
The default value for this parameter when defined in C. Specifically, this will be the initializer for the variable declared in the “parse function”. See the section on default values for how to use this. Specified as a string.

annotation
The annotation value for this parameter. Not currently supported, because PEP 8 mandates that the Python library may not use annotations.

In addition, some converters accept additional arguments. Here is a list of these arguments, along with their meanings:

accept
A set of Python types (and possibly pseudo-types); this restricts the allowable Python argument to values of these types. (This is not a general-purpose facility; as a rule it only supports specific lists of types as shown in the legacy converter table.)

To accept None, add NoneType to this set.

bitwise
Only supported for unsigned integers. The native integer value of this Python argument will be written to the parameter without any range checking, even for negative values.

converter
Only supported by the object converter. Specifies the name of a C “converter function” to use to convert this object to a native type.

encoding
Only supported for strings. Specifies the encoding to use when converting this string from a Python str (Unicode) value into a C char * value.

subclass_of
Only supported for the object converter. Requires that the Python value be a subclass of a Python type, as expressed in C.

type
Only supported for the object and self converters. Specifies the C type that will be used to declare the variable. Default value is "PyObject *".

zeroes
Only supported for strings. If true, embedded NUL bytes ('\\0') are permitted inside the value. The length of the string will be passed in to the impl function, just after the string parameter, as a parameter named <parameter_name>_length.

Please note, not every possible combination of arguments will work. Usually these arguments are implemented by specific PyArg_ParseTuple format units, with specific behavior. For example, currently you cannot call unsigned_short without also specifying bitwise=True. Although it’s perfectly reasonable to think this would work, these semantics don’t map to any existing format unit. So Argument Clinic doesn’t support it. (Or, at least, not yet.)

Below is a table showing the mapping of legacy converters into real Argument Clinic converters. On the left is the legacy converter, on the right is the text you’d replace it with.

'B'

unsigned_char(bitwise=True)

'b'

unsigned_char

'c'

char

'C'

int(accept={str})

'd'

double

'D'

Py_complex

'es'

str(encoding='name_of_encoding')

'es#'

str(encoding='name_of_encoding', zeroes=True)

'et'

str(encoding='name_of_encoding', accept={bytes, bytearray, str})

'et#'

str(encoding='name_of_encoding', accept={bytes, bytearray, str}, zeroes=True)

'f'

float

'h'

short

'H'

unsigned_short(bitwise=True)

'i'

int

'I'

unsigned_int(bitwise=True)

'k'

unsigned_long(bitwise=True)

'K'

unsigned_long_long(bitwise=True)

'l'

long

'L'

long long

'n'

Py_ssize_t

'O'

object

'O!'

object(subclass_of='&PySomething_Type')

'O&'

object(converter='name_of_c_function')

'p'

bool

'S'

PyBytesObject

's'

str

's#'

str(zeroes=True)

's*'

Py_buffer(accept={buffer, str})

'U'

unicode

'u'

Py_UNICODE

'u#'

Py_UNICODE(zeroes=True)

'w*'

Py_buffer(accept={rwbuffer})

'Y'

PyByteArrayObject

'y'

str(accept={bytes})

'y#'

str(accept={robuffer}, zeroes=True)

'y*'

Py_buffer

'Z'

Py_UNICODE(accept={str, NoneType})

'Z#'

Py_UNICODE(accept={str, NoneType}, zeroes=True)

'z'

str(accept={str, NoneType})

'z#'

str(accept={str, NoneType}, zeroes=True)

'z*'

Py_buffer(accept={buffer, str, NoneType})

As an example, here’s our sample pickle.Pickler.dump using the proper converter:

/*[clinic input]
pickle.Pickler.dump

    obj: object
        The object to be pickled.
    /

Write a pickled representation of obj to the open file.
[clinic start generated code]*/
One advantage of real converters is that they’re more flexible than legacy converters. For example, the unsigned_int converter (and all the unsigned_ converters) can be specified without bitwise=True. Their default behavior performs range checking on the value, and they won’t accept negative numbers. You just can’t do that with a legacy converter!

Argument Clinic will show you all the converters it has available. For each converter it’ll show you all the parameters it accepts, along with the default value for each parameter. Just run Tools/clinic/clinic.py --converters to see the full list.

Py_buffer
When using the Py_buffer converter (or the 's*', 'w*', '*y', or 'z*' legacy converters), you must not call PyBuffer_Release() on the provided buffer. Argument Clinic generates code that does it for you (in the parsing function).

Advanced converters
Remember those format units you skipped for your first time because they were advanced? Here’s how to handle those too.

The trick is, all those format units take arguments—either conversion functions, or types, or strings specifying an encoding. (But “legacy converters” don’t support arguments. That’s why we skipped them for your first function.) The argument you specified to the format unit is now an argument to the converter; this argument is either converter (for O&), subclass_of (for O!), or encoding (for all the format units that start with e).

When using subclass_of, you may also want to use the other custom argument for object(): type, which lets you set the type actually used for the parameter. For example, if you want to ensure that the object is a subclass of PyUnicode_Type, you probably want to use the converter object(type='PyUnicodeObject *', subclass_of='&PyUnicode_Type').

One possible problem with using Argument Clinic: it takes away some possible flexibility for the format units starting with e. When writing a PyArg_Parse call by hand, you could theoretically decide at runtime what encoding string to pass in to PyArg_ParseTuple(). But now this string must be hard-coded at Argument-Clinic-preprocessing-time. This limitation is deliberate; it made supporting this format unit much easier, and may allow for future optimizations. This restriction doesn’t seem unreasonable; CPython itself always passes in static hard-coded encoding strings for parameters whose format units start with e.

Parameter default values
Default values for parameters can be any of a number of values. At their simplest, they can be string, int, or float literals:

foo: str = "abc"
bar: int = 123
bat: float = 45.6
They can also use any of Python’s built-in constants:

yep:  bool = True
nope: bool = False
nada: object = None
There’s also special support for a default value of NULL, and for simple expressions, documented in the following sections.

The NULL default value
For string and object parameters, you can set them to None to indicate that there’s no default. However, that means the C variable will be initialized to Py_None. For convenience’s sakes, there’s a special value called NULL for just this reason: from Python’s perspective it behaves like a default value of None, but the C variable is initialized with NULL.

Expressions specified as default values
The default value for a parameter can be more than just a literal value. It can be an entire expression, using math operators and looking up attributes on objects. However, this support isn’t exactly simple, because of some non-obvious semantics.

Consider the following example:

foo: Py_ssize_t = sys.maxsize - 1
sys.maxsize can have different values on different platforms. Therefore Argument Clinic can’t simply evaluate that expression locally and hard-code it in C. So it stores the default in such a way that it will get evaluated at runtime, when the user asks for the function’s signature.

What namespace is available when the expression is evaluated? It’s evaluated in the context of the module the builtin came from. So, if your module has an attribute called “max_widgets”, you may simply use it:

foo: Py_ssize_t = max_widgets
If the symbol isn’t found in the current module, it fails over to looking in sys.modules. That’s how it can find sys.maxsize for example. (Since you don’t know in advance what modules the user will load into their interpreter, it’s best to restrict yourself to modules that are preloaded by Python itself.)

Evaluating default values only at runtime means Argument Clinic can’t compute the correct equivalent C default value. So you need to tell it explicitly. When you use an expression, you must also specify the equivalent expression in C, using the c_default parameter to the converter:

foo: Py_ssize_t(c_default="PY_SSIZE_T_MAX - 1") = sys.maxsize - 1
Another complication: Argument Clinic can’t know in advance whether or not the expression you supply is valid. It parses it to make sure it looks legal, but it can’t actually know. You must be very careful when using expressions to specify values that are guaranteed to be valid at runtime!

Finally, because expressions must be representable as static C values, there are many restrictions on legal expressions. Here’s a list of Python features you’re not permitted to use:

Function calls.

Inline if statements (3 if foo else 5).

Automatic sequence unpacking (*[1, 2, 3]).

List/set/dict comprehensions and generator expressions.

Tuple/list/set/dict literals.

Using a return converter
By default the impl function Argument Clinic generates for you returns PyObject *. But your C function often computes some C type, then converts it into the PyObject * at the last moment. Argument Clinic handles converting your inputs from Python types into native C types—why not have it convert your return value from a native C type into a Python type too?

That’s what a “return converter” does. It changes your impl function to return some C type, then adds code to the generated (non-impl) function to handle converting that value into the appropriate PyObject *.

The syntax for return converters is similar to that of parameter converters. You specify the return converter like it was a return annotation on the function itself. Return converters behave much the same as parameter converters; they take arguments, the arguments are all keyword-only, and if you’re not changing any of the default arguments you can omit the parentheses.

(If you use both "as" and a return converter for your function, the "as" should come before the return converter.)

There’s one additional complication when using return converters: how do you indicate an error has occurred? Normally, a function returns a valid (non-NULL) pointer for success, and NULL for failure. But if you use an integer return converter, all integers are valid. How can Argument Clinic detect an error? Its solution: each return converter implicitly looks for a special value that indicates an error. If you return that value, and an error has been set (PyErr_Occurred() returns a true value), then the generated code will propagate the error. Otherwise it will encode the value you return like normal.

Currently Argument Clinic supports only a few return converters:

bool
int
unsigned int
long
unsigned int
size_t
Py_ssize_t
float
double
DecodeFSDefault
None of these take parameters. For the first three, return -1 to indicate error. For DecodeFSDefault, the return type is const char *; return a NULL pointer to indicate an error.

(There’s also an experimental NoneType converter, which lets you return Py_None on success or NULL on failure, without having to increment the reference count on Py_None. I’m not sure it adds enough clarity to be worth using.)

To see all the return converters Argument Clinic supports, along with their parameters (if any), just run Tools/clinic/clinic.py --converters for the full list.

Cloning existing functions
If you have a number of functions that look similar, you may be able to use Clinic’s “clone” feature. When you clone an existing function, you reuse:

its parameters, including

their names,

their converters, with all parameters,

their default values,

their per-parameter docstrings,

their kind (whether they’re positional only, positional or keyword, or keyword only), and

its return converter.

The only thing not copied from the original function is its docstring; the syntax allows you to specify a new docstring.

Here’s the syntax for cloning a function:

/*[clinic input]
module.class.new_function [as c_basename] = module.class.existing_function

Docstring for new_function goes here.
[clinic start generated code]*/
(The functions can be in different modules or classes. I wrote module.class in the sample just to illustrate that you must use the full path to both functions.)

Sorry, there’s no syntax for partially cloning a function, or cloning a function then modifying it. Cloning is an all-or nothing proposition.

Also, the function you are cloning from must have been previously defined in the current file.

Calling Python code
The rest of the advanced topics require you to write Python code which lives inside your C file and modifies Argument Clinic’s runtime state. This is simple: you simply define a Python block.

A Python block uses different delimiter lines than an Argument Clinic function block. It looks like this:

/*[python input]
# python code goes here
[python start generated code]*/
All the code inside the Python block is executed at the time it’s parsed. All text written to stdout inside the block is redirected into the “output” after the block.

As an example, here’s a Python block that adds a static integer variable to the C code:

/*[python input]
print('static int __ignored_unused_variable__ = 0;')
[python start generated code]*/
static int __ignored_unused_variable__ = 0;
/*[python checksum:...]*/
Using a “self converter”
Argument Clinic automatically adds a “self” parameter for you using a default converter. It automatically sets the type of this parameter to the “pointer to an instance” you specified when you declared the type. However, you can override Argument Clinic’s converter and specify one yourself. Just add your own self parameter as the first parameter in a block, and ensure that its converter is an instance of self_converter or a subclass thereof.

What’s the point? This lets you override the type of self, or give it a different default name.

How do you specify the custom type you want to cast self to? If you only have one or two functions with the same type for self, you can directly use Argument Clinic’s existing self converter, passing in the type you want to use as the type parameter:

/*[clinic input]

_pickle.Pickler.dump

  self: self(type="PicklerObject *")
  obj: object
  /

Write a pickled representation of the given object to the open file.
[clinic start generated code]*/
On the other hand, if you have a lot of functions that will use the same type for self, it’s best to create your own converter, subclassing self_converter but overwriting the type member:

/*[python input]
class PicklerObject_converter(self_converter):
    type = "PicklerObject *"
[python start generated code]*/

/*[clinic input]

_pickle.Pickler.dump

  self: PicklerObject
  obj: object
  /

Write a pickled representation of the given object to the open file.
[clinic start generated code]*/
Using a “defining class” converter
Argument Clinic facilitates gaining access to the defining class of a method. This is useful for heap type methods that need to fetch module level state. Use PyType_FromModuleAndSpec() to associate a new heap type with a module. You can now use PyType_GetModuleState() on the defining class to fetch the module state, for example from a module method.

Example from Modules/zlibmodule.c. First, defining_class is added to the clinic input:

/*[clinic input]
zlib.Compress.compress

  cls: defining_class
  data: Py_buffer
    Binary data to be compressed.
  /
After running the Argument Clinic tool, the following function signature is generated:

/*[clinic start generated code]*/
static PyObject *
zlib_Compress_compress_impl(compobject *self, PyTypeObject *cls,
                            Py_buffer *data)
/*[clinic end generated code: output=6731b3f0ff357ca6 input=04d00f65ab01d260]*/
The following code can now use PyType_GetModuleState(cls) to fetch the module state:

zlibstate *state = PyType_GetModuleState(cls);
Each method may only have one argument using this converter, and it must appear after self, or, if self is not used, as the first argument. The argument will be of type PyTypeObject *. The argument will not appear in the __text_signature__.

The defining_class converter is not compatible with __init__ and __new__ methods, which cannot use the METH_METHOD convention.

It is not possible to use defining_class with slot methods. In order to fetch the module state from such methods, use _PyType_GetModuleByDef to look up the module and then PyModule_GetState() to fetch the module state. Example from the setattro slot method in Modules/_threadmodule.c:

static int
local_setattro(localobject *self, PyObject *name, PyObject *v)
{
    PyObject *module = _PyType_GetModuleByDef(Py_TYPE(self), &thread_module);
    thread_module_state *state = get_thread_state(module);
    ...
}
See also PEP 573.

Writing a custom converter
As we hinted at in the previous section… you can write your own converters! A converter is simply a Python class that inherits from CConverter. The main purpose of a custom converter is if you have a parameter using the O& format unit—parsing this parameter means calling a PyArg_ParseTuple() “converter function”.

Your converter class should be named *something*_converter. If the name follows this convention, then your converter class will be automatically registered with Argument Clinic; its name will be the name of your class with the _converter suffix stripped off. (This is accomplished with a metaclass.)

You shouldn’t subclass CConverter.__init__. Instead, you should write a converter_init() function. converter_init() always accepts a self parameter; after that, all additional parameters must be keyword-only. Any arguments passed in to the converter in Argument Clinic will be passed along to your converter_init().

There are some additional members of CConverter you may wish to specify in your subclass. Here’s the current list:

type
The C type to use for this variable. type should be a Python string specifying the type, e.g. int. If this is a pointer type, the type string should end with ' *'.

default
The Python default value for this parameter, as a Python value. Or the magic value unspecified if there is no default.

py_default
default as it should appear in Python code, as a string. Or None if there is no default.

c_default
default as it should appear in C code, as a string. Or None if there is no default.

c_ignored_default
The default value used to initialize the C variable when there is no default, but not specifying a default may result in an “uninitialized variable” warning. This can easily happen when using option groups—although properly written code will never actually use this value, the variable does get passed in to the impl, and the C compiler will complain about the “use” of the uninitialized value. This value should always be a non-empty string.

converter
The name of the C converter function, as a string.

impl_by_reference
A boolean value. If true, Argument Clinic will add a & in front of the name of the variable when passing it into the impl function.

parse_by_reference
A boolean value. If true, Argument Clinic will add a & in front of the name of the variable when passing it into PyArg_ParseTuple().

Here’s the simplest example of a custom converter, from Modules/zlibmodule.c:

/*[python input]

class ssize_t_converter(CConverter):
    type = 'Py_ssize_t'
    converter = 'ssize_t_converter'

[python start generated code]*/
/*[python end generated code: output=da39a3ee5e6b4b0d input=35521e4e733823c7]*/
This block adds a converter to Argument Clinic named ssize_t. Parameters declared as ssize_t will be declared as type Py_ssize_t, and will be parsed by the 'O&' format unit, which will call the ssize_t_converter converter function. ssize_t variables automatically support default values.

More sophisticated custom converters can insert custom C code to handle initialization and cleanup. You can see more examples of custom converters in the CPython source tree; grep the C files for the string CConverter.

Writing a custom return converter
Writing a custom return converter is much like writing a custom converter. Except it’s somewhat simpler, because return converters are themselves much simpler.

Return converters must subclass CReturnConverter. There are no examples yet of custom return converters, because they are not widely used yet. If you wish to write your own return converter, please read Tools/clinic/clinic.py, specifically the implementation of CReturnConverter and all its subclasses.

METH_O and METH_NOARGS
To convert a function using METH_O, make sure the function’s single argument is using the object converter, and mark the arguments as positional-only:

/*[clinic input]
meth_o_sample

     argument: object
     /
[clinic start generated code]*/
To convert a function using METH_NOARGS, just don’t specify any arguments.

You can still use a self converter, a return converter, and specify a type argument to the object converter for METH_O.

tp_new and tp_init functions
You can convert tp_new and tp_init functions. Just name them __new__ or __init__ as appropriate. Notes:

The function name generated for __new__ doesn’t end in __new__ like it would by default. It’s just the name of the class, converted into a valid C identifier.

No PyMethodDef #define is generated for these functions.

__init__ functions return int, not PyObject *.

Use the docstring as the class docstring.

Although __new__ and __init__ functions must always accept both the args and kwargs objects, when converting you may specify any signature for these functions that you like. (If your function doesn’t support keywords, the parsing function generated will throw an exception if it receives any.)

Changing and redirecting Clinic’s output
It can be inconvenient to have Clinic’s output interspersed with your conventional hand-edited C code. Luckily, Clinic is configurable: you can buffer up its output for printing later (or earlier!), or write its output to a separate file. You can also add a prefix or suffix to every line of Clinic’s generated output.

While changing Clinic’s output in this manner can be a boon to readability, it may result in Clinic code using types before they are defined, or your code attempting to use Clinic-generated code before it is defined. These problems can be easily solved by rearranging the declarations in your file, or moving where Clinic’s generated code goes. (This is why the default behavior of Clinic is to output everything into the current block; while many people consider this hampers readability, it will never require rearranging your code to fix definition-before-use problems.)

Let’s start with defining some terminology:

field
A field, in this context, is a subsection of Clinic’s output. For example, the #define for the PyMethodDef structure is a field, called methoddef_define. Clinic has seven different fields it can output per function definition:

docstring_prototype
docstring_definition
methoddef_define
impl_prototype
parser_prototype
parser_definition
impl_definition
All the names are of the form "<a>_<b>", where "<a>" is the semantic object represented (the parsing function, the impl function, the docstring, or the methoddef structure) and "<b>" represents what kind of statement the field is. Field names that end in "_prototype" represent forward declarations of that thing, without the actual body/data of the thing; field names that end in "_definition" represent the actual definition of the thing, with the body/data of the thing. ("methoddef" is special, it’s the only one that ends with "_define", representing that it’s a preprocessor #define.)

destination
A destination is a place Clinic can write output to. There are five built-in destinations:

block
The default destination: printed in the output section of the current Clinic block.

buffer
A text buffer where you can save text for later. Text sent here is appended to the end of any existing text. It’s an error to have any text left in the buffer when Clinic finishes processing a file.

file
A separate “clinic file” that will be created automatically by Clinic. The filename chosen for the file is {basename}.clinic{extension}, where basename and extension were assigned the output from os.path.splitext() run on the current file. (Example: the file destination for _pickle.c would be written to _pickle.clinic.c.)

Important: When using a file destination, you must check in the generated file!

two-pass
A buffer like buffer. However, a two-pass buffer can only be dumped once, and it prints out all text sent to it during all processing, even from Clinic blocks after the dumping point.

suppress
The text is suppressed—thrown away.

Clinic defines five new directives that let you reconfigure its output.

The first new directive is dump:

dump <destination>
This dumps the current contents of the named destination into the output of the current block, and empties it. This only works with buffer and two-pass destinations.

The second new directive is output. The most basic form of output is like this:

output <field> <destination>
This tells Clinic to output field to destination. output also supports a special meta-destination, called everything, which tells Clinic to output all fields to that destination.

output has a number of other functions:

output push
output pop
output preset <preset>
output push and output pop allow you to push and pop configurations on an internal configuration stack, so that you can temporarily modify the output configuration, then easily restore the previous configuration. Simply push before your change to save the current configuration, then pop when you wish to restore the previous configuration.

output preset sets Clinic’s output to one of several built-in preset configurations, as follows:

block
Clinic’s original starting configuration. Writes everything immediately after the input block.

Suppress the parser_prototype and docstring_prototype, write everything else to block.

file
Designed to write everything to the “clinic file” that it can. You then #include this file near the top of your file. You may need to rearrange your file to make this work, though usually this just means creating forward declarations for various typedef and PyTypeObject definitions.

Suppress the parser_prototype and docstring_prototype, write the impl_definition to block, and write everything else to file.

The default filename is "{dirname}/clinic/{basename}.h".

buffer
Save up most of the output from Clinic, to be written into your file near the end. For Python files implementing modules or builtin types, it’s recommended that you dump the buffer just above the static structures for your module or builtin type; these are normally very near the end. Using buffer may require even more editing than file, if your file has static PyMethodDef arrays defined in the middle of the file.

Suppress the parser_prototype, impl_prototype, and docstring_prototype, write the impl_definition to block, and write everything else to file.

two-pass
Similar to the buffer preset, but writes forward declarations to the two-pass buffer, and definitions to the buffer. This is similar to the buffer preset, but may require less editing than buffer. Dump the two-pass buffer near the top of your file, and dump the buffer near the end just like you would when using the buffer preset.

Suppresses the impl_prototype, write the impl_definition to block, write docstring_prototype, methoddef_define, and parser_prototype to two-pass, write everything else to buffer.

partial-buffer
Similar to the buffer preset, but writes more things to block, only writing the really big chunks of generated code to buffer. This avoids the definition-before-use problem of buffer completely, at the small cost of having slightly more stuff in the block’s output. Dump the buffer near the end, just like you would when using the buffer preset.

Suppresses the impl_prototype, write the docstring_definition and parser_definition to buffer, write everything else to block.

The third new directive is destination:

destination <name> <command> [...]
This performs an operation on the destination named name.

There are two defined subcommands: new and clear.

The new subcommand works like this:

destination <name> new <type>
This creates a new destination with name <name> and type <type>.

There are five destination types:

suppress
Throws the text away.

block
Writes the text to the current block. This is what Clinic originally did.

buffer
A simple text buffer, like the “buffer” builtin destination above.

file
A text file. The file destination takes an extra argument, a template to use for building the filename, like so:

destination <name> new <type> <file_template>

The template can use three strings internally that will be replaced by bits of the filename:

{path}
The full path to the file, including directory and full filename.

{dirname}
The name of the directory the file is in.

{basename}
Just the name of the file, not including the directory.

{basename_root}
Basename with the extension clipped off (everything up to but not including the last ‘.’).

{basename_extension}
The last ‘.’ and everything after it. If the basename does not contain a period, this will be the empty string.

If there are no periods in the filename, {basename} and {filename} are the same, and {extension} is empty. “{basename}{extension}” is always exactly the same as “{filename}”.”

two-pass
A two-pass buffer, like the “two-pass” builtin destination above.

The clear subcommand works like this:

destination <name> clear
It removes all the accumulated text up to this point in the destination. (I don’t know what you’d need this for, but I thought maybe it’d be useful while someone’s experimenting.)

The fourth new directive is set:

set line_prefix "string"
set line_suffix "string"
set lets you set two internal variables in Clinic. line_prefix is a string that will be prepended to every line of Clinic’s output; line_suffix is a string that will be appended to every line of Clinic’s output.

Both of these support two format strings:

{block comment start}
Turns into the string /*, the start-comment text sequence for C files.

{block comment end}
Turns into the string */, the end-comment text sequence for C files.

The final new directive is one you shouldn’t need to use directly, called preserve:

preserve
This tells Clinic that the current contents of the output should be kept, unmodified. This is used internally by Clinic when dumping output into file files; wrapping it in a Clinic block lets Clinic use its existing checksum functionality to ensure the file was not modified by hand before it gets overwritten.

The #ifdef trick
If you’re converting a function that isn’t available on all platforms, there’s a trick you can use to make life a little easier. The existing code probably looks like this:

#ifdef HAVE_FUNCTIONNAME
static module_functionname(...)
{
...
}
#endif /* HAVE_FUNCTIONNAME */
And then in the PyMethodDef structure at the bottom the existing code will have:

#ifdef HAVE_FUNCTIONNAME
{'functionname', ... },
#endif /* HAVE_FUNCTIONNAME */
In this scenario, you should enclose the body of your impl function inside the #ifdef, like so:

#ifdef HAVE_FUNCTIONNAME
/*[clinic input]
module.functionname
...
[clinic start generated code]*/
static module_functionname(...)
{
...
}
#endif /* HAVE_FUNCTIONNAME */
Then, remove those three lines from the PyMethodDef structure, replacing them with the macro Argument Clinic generated:

MODULE_FUNCTIONNAME_METHODDEF
(You can find the real name for this macro inside the generated code. Or you can calculate it yourself: it’s the name of your function as defined on the first line of your block, but with periods changed to underscores, uppercased, and "_METHODDEF" added to the end.)

Perhaps you’re wondering: what if HAVE_FUNCTIONNAME isn’t defined? The MODULE_FUNCTIONNAME_METHODDEF macro won’t be defined either!

Here’s where Argument Clinic gets very clever. It actually detects that the Argument Clinic block might be deactivated by the #ifdef. When that happens, it generates a little extra code that looks like this:

#ifndef MODULE_FUNCTIONNAME_METHODDEF
    #define MODULE_FUNCTIONNAME_METHODDEF
#endif /* !defined(MODULE_FUNCTIONNAME_METHODDEF) */
That means the macro always works. If the function is defined, this turns into the correct structure, including the trailing comma. If the function is undefined, this turns into nothing.

However, this causes one ticklish problem: where should Argument Clinic put this extra code when using the “block” output preset? It can’t go in the output block, because that could be deactivated by the #ifdef. (That’s the whole point!)

In this situation, Argument Clinic writes the extra code to the “buffer” destination. This may mean that you get a complaint from Argument Clinic:

Warning in file "Modules/posixmodule.c" on line 12357:
Destination buffer 'buffer' not empty at end of file, emptying.
When this happens, just open your file, find the dump buffer block that Argument Clinic added to your file (it’ll be at the very bottom), then move it above the PyMethodDef structure where that macro is used.

Using Argument Clinic in Python files
It’s actually possible to use Argument Clinic to preprocess Python files. There’s no point to using Argument Clinic blocks, of course, as the output wouldn’t make any sense to the Python interpreter. But using Argument Clinic to run Python blocks lets you use Python as a Python preprocessor!

Since Python comments are different from C comments, Argument Clinic blocks embedded in Python files look slightly different. They look like this:

#/*[python input]
#print("def foo(): pass")
#[python start generated code]*/
def foo(): pass
#/*[python checksum:...]*/
Table of Contents
Argument Clinic How-To
The Goals Of Argument Clinic
Basic Concepts And Usage
Converting Your First Function
Advanced Topics
Symbolic default values
Renaming the C functions and variables generated by Argument Clinic
Converting functions using PyArg_UnpackTuple
Optional Groups
Using real Argument Clinic converters, instead of “legacy converters”
Py_buffer
Advanced converters
Parameter default values
The NULL default value
Expressions specified as default values
Using a return converter
Cloning existing functions
Calling Python code
Using a “self converter”
Using a “defining class” converter
Writing a custom converter
Writing a custom return converter
METH_O and METH_NOARGS
tp_new and tp_init functions
Changing and redirecting Clinic’s output
The #ifdef trick
Using Argument Clinic in Python files
Previous topic
An introduction to the ipaddress module

Next topic
Instrumenting CPython with DTrace and SystemTap

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Argument Clinic How-To
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
The Python Software Foundation is a non-profit corporation. Please donate.

indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Instrumenting CPython with DTrace and SystemTap
Quick search
  |
Instrumenting CPython with DTrace and SystemTap
author
David Malcolm

author
Łukasz Langa

DTrace and SystemTap are monitoring tools, each providing a way to inspect what the processes on a computer system are doing. They both use domain-specific languages allowing a user to write scripts which:

filter which processes are to be observed

gather data from the processes of interest

generate reports on the data

As of Python 3.6, CPython can be built with embedded “markers”, also known as “probes”, that can be observed by a DTrace or SystemTap script, making it easier to monitor what the CPython processes on a system are doing.

CPython implementation detail: DTrace markers are implementation details of the CPython interpreter. No guarantees are made about probe compatibility between versions of CPython. DTrace scripts can stop working or work incorrectly without warning when changing CPython versions.

Enabling the static markers
macOS comes with built-in support for DTrace. On Linux, in order to build CPython with the embedded markers for SystemTap, the SystemTap development tools must be installed.

On a Linux machine, this can be done via:

$ yum install systemtap-sdt-devel
or:

$ sudo apt-get install systemtap-sdt-dev
CPython must then be configured with the --with-dtrace option:

checking for --with-dtrace... yes
On macOS, you can list available DTrace probes by running a Python process in the background and listing all probes made available by the Python provider:

$ python3.6 -q &
$ sudo dtrace -l -P python$!  # or: dtrace -l -m python3.6

   ID   PROVIDER            MODULE                          FUNCTION NAME
29564 python18035        python3.6          _PyEval_EvalFrameDefault function-entry
29565 python18035        python3.6             dtrace_function_entry function-entry
29566 python18035        python3.6          _PyEval_EvalFrameDefault function-return
29567 python18035        python3.6            dtrace_function_return function-return
29568 python18035        python3.6                           collect gc-done
29569 python18035        python3.6                           collect gc-start
29570 python18035        python3.6          _PyEval_EvalFrameDefault line
29571 python18035        python3.6                 maybe_dtrace_line line
On Linux, you can verify if the SystemTap static markers are present in the built binary by seeing if it contains a “.note.stapsdt” section.

$ readelf -S ./python | grep .note.stapsdt
[30] .note.stapsdt        NOTE         0000000000000000 00308d78
If you’ve built Python as a shared library (with the --enable-shared configure option), you need to look instead within the shared library. For example:

$ readelf -S libpython3.3dm.so.1.0 | grep .note.stapsdt
[29] .note.stapsdt        NOTE         0000000000000000 00365b68
Sufficiently modern readelf can print the metadata:

$ readelf -n ./python

Displaying notes found at file offset 0x00000254 with length 0x00000020:
    Owner                 Data size          Description
    GNU                  0x00000010          NT_GNU_ABI_TAG (ABI version tag)
        OS: Linux, ABI: 2.6.32

Displaying notes found at file offset 0x00000274 with length 0x00000024:
    Owner                 Data size          Description
    GNU                  0x00000014          NT_GNU_BUILD_ID (unique build ID bitstring)
        Build ID: df924a2b08a7e89f6e11251d4602022977af2670

Displaying notes found at file offset 0x002d6c30 with length 0x00000144:
    Owner                 Data size          Description
    stapsdt              0x00000031          NT_STAPSDT (SystemTap probe descriptors)
        Provider: python
        Name: gc__start
        Location: 0x00000000004371c3, Base: 0x0000000000630ce2, Semaphore: 0x00000000008d6bf6
        Arguments: -4@%ebx
    stapsdt              0x00000030          NT_STAPSDT (SystemTap probe descriptors)
        Provider: python
        Name: gc__done
        Location: 0x00000000004374e1, Base: 0x0000000000630ce2, Semaphore: 0x00000000008d6bf8
        Arguments: -8@%rax
    stapsdt              0x00000045          NT_STAPSDT (SystemTap probe descriptors)
        Provider: python
        Name: function__entry
        Location: 0x000000000053db6c, Base: 0x0000000000630ce2, Semaphore: 0x00000000008d6be8
        Arguments: 8@%rbp 8@%r12 -4@%eax
    stapsdt              0x00000046          NT_STAPSDT (SystemTap probe descriptors)
        Provider: python
        Name: function__return
        Location: 0x000000000053dba8, Base: 0x0000000000630ce2, Semaphore: 0x00000000008d6bea
        Arguments: 8@%rbp 8@%r12 -4@%eax
The above metadata contains information for SystemTap describing how it can patch strategically placed machine code instructions to enable the tracing hooks used by a SystemTap script.

Static DTrace probes
The following example DTrace script can be used to show the call/return hierarchy of a Python script, only tracing within the invocation of a function called “start”. In other words, import-time function invocations are not going to be listed:

self int indent;

python$target:::function-entry
/copyinstr(arg1) == "start"/
{
        self->trace = 1;
}

python$target:::function-entry
/self->trace/
{
        printf("%d\t%*s:", timestamp, 15, probename);
        printf("%*s", self->indent, "");
        printf("%s:%s:%d\n", basename(copyinstr(arg0)), copyinstr(arg1), arg2);
        self->indent++;
}

python$target:::function-return
/self->trace/
{
        self->indent--;
        printf("%d\t%*s:", timestamp, 15, probename);
        printf("%*s", self->indent, "");
        printf("%s:%s:%d\n", basename(copyinstr(arg0)), copyinstr(arg1), arg2);
}

python$target:::function-return
/copyinstr(arg1) == "start"/
{
        self->trace = 0;
}
It can be invoked like this:

$ sudo dtrace -q -s call_stack.d -c "python3.6 script.py"
The output looks like this:

156641360502280  function-entry:call_stack.py:start:23
156641360518804  function-entry: call_stack.py:function_1:1
156641360532797  function-entry:  call_stack.py:function_3:9
156641360546807 function-return:  call_stack.py:function_3:10
156641360563367 function-return: call_stack.py:function_1:2
156641360578365  function-entry: call_stack.py:function_2:5
156641360591757  function-entry:  call_stack.py:function_1:1
156641360605556  function-entry:   call_stack.py:function_3:9
156641360617482 function-return:   call_stack.py:function_3:10
156641360629814 function-return:  call_stack.py:function_1:2
156641360642285 function-return: call_stack.py:function_2:6
156641360656770  function-entry: call_stack.py:function_3:9
156641360669707 function-return: call_stack.py:function_3:10
156641360687853  function-entry: call_stack.py:function_4:13
156641360700719 function-return: call_stack.py:function_4:14
156641360719640  function-entry: call_stack.py:function_5:18
156641360732567 function-return: call_stack.py:function_5:21
156641360747370 function-return:call_stack.py:start:28
Static SystemTap markers
The low-level way to use the SystemTap integration is to use the static markers directly. This requires you to explicitly state the binary file containing them.

For example, this SystemTap script can be used to show the call/return hierarchy of a Python script:

probe process("python").mark("function__entry") {
     filename = user_string($arg1);
     funcname = user_string($arg2);
     lineno = $arg3;

     printf("%s => %s in %s:%d\\n",
            thread_indent(1), funcname, filename, lineno);
}

probe process("python").mark("function__return") {
    filename = user_string($arg1);
    funcname = user_string($arg2);
    lineno = $arg3;

    printf("%s <= %s in %s:%d\\n",
           thread_indent(-1), funcname, filename, lineno);
}
It can be invoked like this:

$ stap \
  show-call-hierarchy.stp \
  -c "./python test.py"
The output looks like this:

11408 python(8274):        => __contains__ in Lib/_abcoll.py:362
11414 python(8274):         => __getitem__ in Lib/os.py:425
11418 python(8274):          => encode in Lib/os.py:490
11424 python(8274):          <= encode in Lib/os.py:493
11428 python(8274):         <= __getitem__ in Lib/os.py:426
11433 python(8274):        <= __contains__ in Lib/_abcoll.py:366
where the columns are:

time in microseconds since start of script

name of executable

PID of process

and the remainder indicates the call/return hierarchy as the script executes.

For a --enable-shared build of CPython, the markers are contained within the libpython shared library, and the probe’s dotted path needs to reflect this. For example, this line from the above example:

probe process("python").mark("function__entry") {
should instead read:

probe process("python").library("libpython3.6dm.so.1.0").mark("function__entry") {
(assuming a debug build of CPython 3.6)

Available static markers
function__entry(str filename, str funcname, int lineno)
This marker indicates that execution of a Python function has begun. It is only triggered for pure-Python (bytecode) functions.

The filename, function name, and line number are provided back to the tracing script as positional arguments, which must be accessed using $arg1, $arg2, $arg3:

$arg1 : (const char *) filename, accessible using user_string($arg1)

$arg2 : (const char *) function name, accessible using user_string($arg2)

$arg3 : int line number

function__return(str filename, str funcname, int lineno)
This marker is the converse of function__entry(), and indicates that execution of a Python function has ended (either via return, or via an exception). It is only triggered for pure-Python (bytecode) functions.

The arguments are the same as for function__entry()

line(str filename, str funcname, int lineno)
This marker indicates a Python line is about to be executed. It is the equivalent of line-by-line tracing with a Python profiler. It is not triggered within C functions.

The arguments are the same as for function__entry().

gc__start(int generation)
Fires when the Python interpreter starts a garbage collection cycle. arg0 is the generation to scan, like gc.collect().

gc__done(long collected)
Fires when the Python interpreter finishes a garbage collection cycle. arg0 is the number of collected objects.

import__find__load__start(str modulename)
Fires before importlib attempts to find and load the module. arg0 is the module name.

New in version 3.7.

import__find__load__done(str modulename, int found)
Fires after importlib’s find_and_load function is called. arg0 is the module name, arg1 indicates if module was successfully loaded.

New in version 3.7.

audit(str event, void *tuple)
Fires when sys.audit() or PySys_Audit() is called. arg0 is the event name as C string, arg1 is a PyObject pointer to a tuple object.

New in version 3.8.

SystemTap Tapsets
The higher-level way to use the SystemTap integration is to use a “tapset”: SystemTap’s equivalent of a library, which hides some of the lower-level details of the static markers.

Here is a tapset file, based on a non-shared build of CPython:

/*
   Provide a higher-level wrapping around the function__entry and
   function__return markers:
 \*/
probe python.function.entry = process("python").mark("function__entry")
{
    filename = user_string($arg1);
    funcname = user_string($arg2);
    lineno = $arg3;
    frameptr = $arg4
}
probe python.function.return = process("python").mark("function__return")
{
    filename = user_string($arg1);
    funcname = user_string($arg2);
    lineno = $arg3;
    frameptr = $arg4
}
If this file is installed in SystemTap’s tapset directory (e.g. /usr/share/systemtap/tapset), then these additional probepoints become available:

python.function.entry(str filename, str funcname, int lineno, frameptr)
This probe point indicates that execution of a Python function has begun. It is only triggered for pure-Python (bytecode) functions.

python.function.return(str filename, str funcname, int lineno, frameptr)
This probe point is the converse of python.function.return, and indicates that execution of a Python function has ended (either via return, or via an exception). It is only triggered for pure-Python (bytecode) functions.

Examples
This SystemTap script uses the tapset above to more cleanly implement the example given above of tracing the Python function-call hierarchy, without needing to directly name the static markers:

probe python.function.entry
{
  printf("%s => %s in %s:%d\n",
         thread_indent(1), funcname, filename, lineno);
}

probe python.function.return
{
  printf("%s <= %s in %s:%d\n",
         thread_indent(-1), funcname, filename, lineno);
}
The following script uses the tapset above to provide a top-like view of all running CPython code, showing the top 20 most frequently entered bytecode frames, each second, across the whole system:

global fn_calls;

probe python.function.entry
{
    fn_calls[pid(), filename, funcname, lineno] += 1;
}

probe timer.ms(1000) {
    printf("\033[2J\033[1;1H") /* clear screen \*/
    printf("%6s %80s %6s %30s %6s\n",
           "PID", "FILENAME", "LINE", "FUNCTION", "CALLS")
    foreach ([pid, filename, funcname, lineno] in fn_calls- limit 20) {
        printf("%6d %80s %6d %30s %6d\n",
            pid, filename, lineno, funcname,
            fn_calls[pid, filename, funcname, lineno]);
    }
    delete fn_calls;
}
Table of Contents
Instrumenting CPython with DTrace and SystemTap
Enabling the static markers
Static DTrace probes
Static SystemTap markers
Available static markers
SystemTap Tapsets
Examples
Previous topic
Argument Clinic How-To

Next topic
Annotations Best Practices

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Instrumenting CPython with DTrace and SystemTap
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Annotations Best Practices
Quick search
  |
Annotations Best Practices
author
Larry Hastings

Abstract

This document is designed to encapsulate the best practices for working with annotations dicts. If you write Python code that examines __annotations__ on Python objects, we encourage you to follow the guidelines described below.

The document is organized into four sections: best practices for accessing the annotations of an object in Python versions 3.10 and newer, best practices for accessing the annotations of an object in Python versions 3.9 and older, other best practices for __annotations__ that apply to any Python version, and quirks of __annotations__.

Note that this document is specifically about working with __annotations__, not uses for annotations. If you’re looking for information on how to use “type hints” in your code, please see the typing module.

Accessing The Annotations Dict Of An Object In Python 3.10 And Newer
Python 3.10 adds a new function to the standard library: inspect.get_annotations(). In Python versions 3.10 and newer, calling this function is the best practice for accessing the annotations dict of any object that supports annotations. This function can also “un-stringize” stringized annotations for you.

If for some reason inspect.get_annotations() isn’t viable for your use case, you may access the __annotations__ data member manually. Best practice for this changed in Python 3.10 as well: as of Python 3.10, o.__annotations__ is guaranteed to always work on Python functions, classes, and modules. If you’re certain the object you’re examining is one of these three specific objects, you may simply use o.__annotations__ to get at the object’s annotations dict.

However, other types of callables–for example, callables created by functools.partial()–may not have an __annotations__ attribute defined. When accessing the __annotations__ of a possibly unknown object, best practice in Python versions 3.10 and newer is to call getattr() with three arguments, for example getattr(o, '__annotations__', None).

Accessing The Annotations Dict Of An Object In Python 3.9 And Older
In Python 3.9 and older, accessing the annotations dict of an object is much more complicated than in newer versions. The problem is a design flaw in these older versions of Python, specifically to do with class annotations.

Best practice for accessing the annotations dict of other objects–functions, other callables, and modules–is the same as best practice for 3.10, assuming you aren’t calling inspect.get_annotations(): you should use three-argument getattr() to access the object’s __annotations__ attribute.

Unfortunately, this isn’t best practice for classes. The problem is that, since __annotations__ is optional on classes, and because classes can inherit attributes from their base classes, accessing the __annotations__ attribute of a class may inadvertently return the annotations dict of a base class. As an example:

class Base:
    a: int = 3
    b: str = 'abc'

class Derived(Base):
    pass

print(Derived.__annotations__)
This will print the annotations dict from Base, not Derived.

Your code will have to have a separate code path if the object you’re examining is a class (isinstance(o, type)). In that case, best practice relies on an implementation detail of Python 3.9 and before: if a class has annotations defined, they are stored in the class’s __dict__ dictionary. Since the class may or may not have annotations defined, best practice is to call the get method on the class dict.

To put it all together, here is some sample code that safely accesses the __annotations__ attribute on an arbitrary object in Python 3.9 and before:

if isinstance(o, type):
    ann = o.__dict__.get('__annotations__', None)
else:
    ann = getattr(o, '__annotations__', None)
After running this code, ann should be either a dictionary or None. You’re encouraged to double-check the type of ann using isinstance() before further examination.

Note that some exotic or malformed type objects may not have a __dict__ attribute, so for extra safety you may also wish to use getattr() to access __dict__.

Manually Un-Stringizing Stringized Annotations
In situations where some annotations may be “stringized”, and you wish to evaluate those strings to produce the Python values they represent, it really is best to call inspect.get_annotations() to do this work for you.

If you’re using Python 3.9 or older, or if for some reason you can’t use inspect.get_annotations(), you’ll need to duplicate its logic. You’re encouraged to examine the implementation of inspect.get_annotations() in the current Python version and follow a similar approach.

In a nutshell, if you wish to evaluate a stringized annotation on an arbitrary object o:

If o is a module, use o.__dict__ as the globals when calling eval().

If o is a class, use sys.modules[o.__module__].__dict__ as the globals, and dict(vars(o)) as the locals, when calling eval().

If o is a wrapped callable using functools.update_wrapper(), functools.wraps(), or functools.partial(), iteratively unwrap it by accessing either o.__wrapped__ or o.func as appropriate, until you have found the root unwrapped function.

If o is a callable (but not a class), use o.__globals__ as the globals when calling eval().

However, not all string values used as annotations can be successfully turned into Python values by eval(). String values could theoretically contain any valid string, and in practice there are valid use cases for type hints that require annotating with string values that specifically can’t be evaluated. For example:

PEP 604 union types using |, before support for this was added to Python 3.10.

Definitions that aren’t needed at runtime, only imported when typing.TYPE_CHECKING is true.

If eval() attempts to evaluate such values, it will fail and raise an exception. So, when designing a library API that works with annotations, it’s recommended to only attempt to evaluate string values when explicitly requested to by the caller.

Best Practices For __annotations__ In Any Python Version
You should avoid assigning to the __annotations__ member of objects directly. Let Python manage setting __annotations__.

If you do assign directly to the __annotations__ member of an object, you should always set it to a dict object.

If you directly access the __annotations__ member of an object, you should ensure that it’s a dictionary before attempting to examine its contents.

You should avoid modifying __annotations__ dicts.

You should avoid deleting the __annotations__ attribute of an object.

__annotations__ Quirks
In all versions of Python 3, function objects lazy-create an annotations dict if no annotations are defined on that object. You can delete the __annotations__ attribute using del fn.__annotations__, but if you then access fn.__annotations__ the object will create a new empty dict that it will store and return as its annotations. Deleting the annotations on a function before it has lazily created its annotations dict will throw an AttributeError; using del fn.__annotations__ twice in a row is guaranteed to always throw an AttributeError.

Everything in the above paragraph also applies to class and module objects in Python 3.10 and newer.

In all versions of Python 3, you can set __annotations__ on a function object to None. However, subsequently accessing the annotations on that object using fn.__annotations__ will lazy-create an empty dictionary as per the first paragraph of this section. This is not true of modules and classes, in any Python version; those objects permit setting __annotations__ to any Python value, and will retain whatever value is set.

If Python stringizes your annotations for you (using from __future__ import annotations), and you specify a string as an annotation, the string will itself be quoted. In effect the annotation is quoted twice. For example:

from __future__ import annotations
def foo(a: "str"): pass

print(foo.__annotations__)
This prints {'a': "'str'"}. This shouldn’t really be considered a “quirk”; it’s mentioned here simply because it might be surprising.

Table of Contents
Annotations Best Practices
Accessing The Annotations Dict Of An Object In Python 3.10 And Newer
Accessing The Annotations Dict Of An Object In Python 3.9 And Older
Manually Un-Stringizing Stringized Annotations
Best Practices For __annotations__ In Any Python Version
__annotations__ Quirks
Previous topic
Instrumenting CPython with DTrace and SystemTap

Next topic
Python Frequently Asked Questions

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python HOWTOs » Annotations Best Practices
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Installing Python Modules
Quick search
  |
Installing Python Modules
Email
distutils-sig@python.org

As a popular open source development project, Python has an active supporting community of contributors and users that also make their software available for other Python developers to use under open source license terms.

This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created to common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the common pool.

This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects, refer to the distribution guide.

Note For corporate and other institutional users, be aware that many organisations have their own policies around using and contributing to open source software. Please take such policies into account when making use of the distribution and installation tools provided with Python.
Key terms
pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python binary installers.

A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a particular application, rather than being installed system wide.

venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments.

virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used on versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install pip into created environments.

The Python Package Index is a public repository of open source licensed packages made available for use by other Python users.

the Python Packaging Authority is the group of developers and documentation authors responsible for the maintenance and evolution of the standard packaging tools and the associated metadata and file format standards. They maintain a variety of tools, documentation, and issue trackers on both GitHub and Bitbucket.

distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and distribution infrastructure, and it not only remains part of the standard library, but its name lives on in other ways (such as the name of the mailing list used to coordinate Python packaging standards development).

Changed in version 3.5: The use of venv is now recommended for creating virtual environments.

See also Python Packaging User Guide: Creating and using virtual environments
Basic usage
The standard packaging tools are all designed to be used from the command line.

The following command will install the latest version of a module and its dependencies from the Python Package Index:

python -m pip install SomePackage
Note For POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual environment.
For Windows users, the examples in this guide assume that the option to adjust the system PATH environment variable was selected when installing Python.

It’s also possible to specify an exact or minimum version directly on the command line. When using comparator operators such as >, < or some other special character which get interpreted by shell, the package name and the version should be enclosed within double quotes:

python -m pip install SomePackage==1.0.4    # specific version
python -m pip install "SomePackage>=1.0.4"  # minimum version
Normally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing modules must be requested explicitly:

python -m pip install --upgrade SomePackage
More information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide.

Creation of virtual environments is done through the venv module. Installing packages into an active virtual environment uses the commands shown above.

See also Python Packaging User Guide: Installing Python Distribution Packages
How do I …?
These are quick answers or links for some common tasks.

… install pip in versions of Python prior to Python 3.4?
Python only started bundling pip with Python 3.4. For earlier versions, pip needs to be “bootstrapped” as described in the Python Packaging User Guide.

See also Python Packaging User Guide: Requirements for Installing Packages
… install packages just for the current user?
Passing the --user option to python -m pip install will install a package just for the current user, rather than for all users of the system.

… install scientific Python packages?
A number of scientific Python packages have complex binary dependencies, and aren’t currently easy to install using pip directly. At this point in time, it will often be easier for users to install these packages by other means rather than attempting to install them with pip.

See also Python Packaging User Guide: Installing Scientific Packages
… work with multiple versions of Python installed in parallel?
On Linux, macOS, and other POSIX systems, use the versioned Python commands in combination with the -m switch to run the appropriate copy of pip:

python2   -m pip install SomePackage  # default Python 2
python2.7 -m pip install SomePackage  # specifically Python 2.7
python3   -m pip install SomePackage  # default Python 3
python3.4 -m pip install SomePackage  # specifically Python 3.4
Appropriately versioned pip commands may also be available.

On Windows, use the py Python launcher in combination with the -m switch:

py -2   -m pip install SomePackage  # default Python 2
py -2.7 -m pip install SomePackage  # specifically Python 2.7
py -3   -m pip install SomePackage  # default Python 3
py -3.4 -m pip install SomePackage  # specifically Python 3.4
Common installation issues
Installing into the system Python on Linux
On Linux systems, a Python installation will typically be included as part of the distribution. Installing into this Python installation requires root access to the system, and may interfere with the operation of the system package manager and other components of the system if a component is unexpectedly upgraded using pip.

On such systems, it is often better to use a virtual environment or a per-user installation when installing packages with pip.

Pip not installed
It is possible that pip does not get installed by default. One potential fix is:

python -m ensurepip --default-pip
There are also additional resources for installing pip.

Installing binary extensions
Python has typically relied heavily on source based distribution, with end users being expected to compile extension modules from source as part of the installation process.

With the introduction of support for the binary wheel format, and the ability to publish wheels for at least Windows and macOS through the Python Package Index, this problem is expected to diminish over time, as users are more regularly able to install pre-built extensions rather than needing to build them themselves.

Some of the solutions for installing scientific software that are not yet available as pre-built wheel files may also help with obtaining other binary extensions without needing to build them locally.

See also Python Packaging User Guide: Binary Extensions
Table of Contents
Installing Python Modules
Key terms
Basic usage
How do I …?
… install pip in versions of Python prior to Python 3.4?
… install packages just for the current user?
… install scientific Python packages?
… work with multiple versions of Python installed in parallel?
Common installation issues
Installing into the system Python on Linux
Pip not installed
Installing binary extensions
Previous topic
Distributing Python Modules

Next topic
Python HOWTOs

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Installing Python Modules
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Distributing Python Modules
Quick search
  |
Distributing Python Modules
Email
distutils-sig@python.org

As a popular open source development project, Python has an active supporting community of contributors and users that also make their software available for other Python developers to use under open source license terms.

This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created to common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the common pool.

This guide covers the distribution part of the process. For a guide to installing other Python projects, refer to the installation guide.

Note For corporate and other institutional users, be aware that many organisations have their own policies around using and contributing to open source software. Please take such policies into account when making use of the distribution and installation tools provided with Python.
Key terms
the Python Package Index is a public repository of open source licensed packages made available for use by other Python users

the Python Packaging Authority are the group of developers and documentation authors responsible for the maintenance and evolution of the standard packaging tools and the associated metadata and file format standards. They maintain a variety of tools, documentation and issue trackers on both GitHub and Bitbucket.

distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and distribution infrastructure, and it not only remains part of the standard library, but its name lives on in other ways (such as the name of the mailing list used to coordinate Python packaging standards development).

setuptools is a (largely) drop-in replacement for distutils first published in 2004. Its most notable addition over the unmodified distutils tools was the ability to declare dependencies on other packages. It is currently recommended as a more regularly updated alternative to distutils that offers consistent support for more recent packaging standards across a wide range of Python versions.

wheel (in this context) is a project that adds the bdist_wheel command to distutils/setuptools. This produces a cross platform binary packaging format (called “wheels” or “wheel files” and defined in PEP 427) that allows Python libraries, even those including binary extensions, to be installed on a system without needing to be built locally.

Open source licensing and collaboration
In most parts of the world, software is automatically covered by copyright. This means that other developers require explicit permission to copy, use, modify and redistribute the software.

Open source licensing is a way of explicitly granting such permission in a relatively consistent way, allowing developers to share and collaborate efficiently by making common solutions to various problems freely available. This leaves many developers free to spend more time focusing on the problems that are relatively unique to their specific situation.

The distribution tools provided with Python are designed to make it reasonably straightforward for developers to make their own contributions back to that common pool of software if they choose to do so.

The same distribution tools can also be used to distribute software within an organisation, regardless of whether that software is published as open source software or not.

Installing the tools
The standard library does not include build tools that support modern Python packaging standards, as the core development team has found that it is important to have standard tools that work consistently, even on older versions of Python.

The currently recommended build and distribution tools can be installed by invoking the pip module at the command line:

python -m pip install setuptools wheel twine
Note For POSIX users (including macOS and Linux users), these instructions assume the use of a virtual environment.
For Windows users, these instructions assume that the option to adjust the system PATH environment variable was selected when installing Python.

The Python Packaging User Guide includes more details on the currently recommended tools.

Reading the Python Packaging User Guide
The Python Packaging User Guide covers the various key steps and elements involved in creating and publishing a project:

Project structure

Building and packaging the project

Uploading the project to the Python Package Index

The .pypirc file

How do I…?
These are quick answers or links for some common tasks.

… choose a name for my project?
This isn’t an easy topic, but here are a few tips:

check the Python Package Index to see if the name is already in use

check popular hosting sites like GitHub, Bitbucket, etc to see if there is already a project with that name

check what comes up in a web search for the name you’re considering

avoid particularly common words, especially ones with multiple meanings, as they can make it difficult for users to find your software when searching for it

… create and distribute binary extensions?
This is actually quite a complex topic, with a variety of alternatives available depending on exactly what you’re aiming to achieve. See the Python Packaging User Guide for more information and recommendations.

See also Python Packaging User Guide: Binary Extensions
Table of Contents
Distributing Python Modules
Key terms
Open source licensing and collaboration
Installing the tools
Reading the Python Packaging User Guide
How do I…?
… choose a name for my project?
… create and distribute binary extensions?
Previous topic
API and ABI Versioning

Next topic
Installing Python Modules

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Distributing Python Modules
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Extending and Embedding the Python Interpreter
Quick search
  |
Extending and Embedding the Python Interpreter
This document describes how to write modules in C or C++ to extend the Python interpreter with new modules. Those modules can not only define new functions but also new object types and their methods. The document also describes how to embed the Python interpreter in another application, for use as an extension language. Finally, it shows how to compile and link extension modules so that they can be loaded dynamically (at run time) into the interpreter, if the underlying operating system supports this feature.

This document assumes basic knowledge about Python. For an informal introduction to the language, see The Python Tutorial. The Python Language Reference gives a more formal definition of the language. The Python Standard Library documents the existing object types, functions and modules (both built-in and written in Python) that give the language its wide application range.

For a detailed description of the whole Python/C API, see the separate Python/C API Reference Manual.

Recommended third party tools
This guide only covers the basic tools for creating extensions provided as part of this version of CPython. Third party tools like Cython, cffi, SWIG and Numba offer both simpler and more sophisticated approaches to creating C and C++ extensions for Python.

See also
Python Packaging User Guide: Binary Extensions
The Python Packaging User Guide not only covers several available tools that simplify the creation of binary extensions, but also discusses the various reasons why creating an extension module may be desirable in the first place.

Creating extensions without third party tools
This section of the guide covers creating C and C++ extensions without assistance from third party tools. It is intended primarily for creators of those tools, rather than being a recommended way to create your own C extensions.

1. Extending Python with C or C++
1.1. A Simple Example
1.2. Intermezzo: Errors and Exceptions
1.3. Back to the Example
1.4. The Module’s Method Table and Initialization Function
1.5. Compilation and Linkage
1.6. Calling Python Functions from C
1.7. Extracting Parameters in Extension Functions
1.8. Keyword Parameters for Extension Functions
1.9. Building Arbitrary Values
1.10. Reference Counts
1.11. Writing Extensions in C++
1.12. Providing a C API for an Extension Module
2. Defining Extension Types: Tutorial
2.1. The Basics
2.2. Adding data and methods to the Basic example
2.3. Providing finer control over data attributes
2.4. Supporting cyclic garbage collection
2.5. Subclassing other types
3. Defining Extension Types: Assorted Topics
3.1. Finalization and De-allocation
3.2. Object Presentation
3.3. Attribute Management
3.4. Object Comparison
3.5. Abstract Protocol Support
3.6. Weak Reference Support
3.7. More Suggestions
4. Building C and C++ Extensions
4.1. Building C and C++ Extensions with distutils
4.2. Distributing your extension modules
5. Building C and C++ Extensions on Windows
5.1. A Cookbook Approach
5.2. Differences Between Unix and Windows
5.3. Using DLLs in Practice
Embedding the CPython runtime in a larger application
Sometimes, rather than creating an extension that runs inside the Python interpreter as the main application, it is desirable to instead embed the CPython runtime inside a larger application. This section covers some of the details involved in doing that successfully.

1. Embedding Python in Another Application
1.1. Very High Level Embedding
1.2. Beyond Very High Level Embedding: An overview
1.3. Pure Embedding
1.4. Extending Embedded Python
1.5. Embedding Python in C++
1.6. Compiling and Linking under Unix-like systems
Table of Contents
Extending and Embedding the Python Interpreter
Recommended third party tools
Creating extensions without third party tools
Embedding the CPython runtime in a larger application
Previous topic
Security Considerations

Next topic
1. Extending Python with C or C++

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Extending and Embedding the Python Interpreter
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual
Quick search
  |
Python/C API Reference Manual
This manual documents the API used by C and C++ programmers who want to write extension modules or embed Python. It is a companion to Extending and Embedding the Python Interpreter, which describes the general principles of extension writing but does not document the API functions in detail.

Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Exceptions
Embedding Python
Debugging Builds
C API Stability
Stable Application Binary Interface
Platform Considerations
Contents of Limited API
The Very High Level Layer
Reference Counting
Exception Handling
Printing and clearing
Raising exceptions
Issuing warnings
Querying the error indicator
Signal Handling
Exception Classes
Exception Objects
Unicode Exception Objects
Recursion Control
Standard Exceptions
Standard Warning Categories
Utilities
Operating System Utilities
System Functions
Process Control
Importing Modules
Data marshalling support
Parsing arguments and building values
String conversion and formatting
Reflection
Codec registry and support functions
Abstract Objects Layer
Object Protocol
Call Protocol
Number Protocol
Sequence Protocol
Mapping Protocol
Iterator Protocol
Buffer Protocol
Old Buffer Protocol
Concrete Objects Layer
Fundamental Objects
Numeric Objects
Sequence Objects
Container Objects
Function Objects
Other Objects
Initialization, Finalization, and Threads
Before Python Initialization
Global configuration variables
Initializing and finalizing the interpreter
Process-wide parameters
Thread State and the Global Interpreter Lock
Sub-interpreter support
Asynchronous Notifications
Profiling and Tracing
Advanced Debugger Support
Thread Local Storage Support
Python Initialization Configuration
Example
PyWideStringList
PyStatus
PyPreConfig
Preinitialize Python with PyPreConfig
PyConfig
Initialization with PyConfig
Isolated Configuration
Python Configuration
Python Path Configuration
Py_RunMain()
Py_GetArgcArgv()
Multi-Phase Initialization Private Provisional API
Memory Management
Overview
Allocator Domains
Raw Memory Interface
Memory Interface
Object allocators
Default Memory Allocators
Customize Memory Allocators
Debug hooks on the Python memory allocators
The pymalloc allocator
tracemalloc C API
Examples
Object Implementation Support
Allocating Objects on the Heap
Common Object Structures
Type Objects
Number Object Structures
Mapping Object Structures
Sequence Object Structures
Buffer Object Structures
Async Object Structures
Slot Type typedefs
Examples
Supporting Cyclic Garbage Collection
API and ABI Versioning
Previous topic
1. Embedding Python in Another Application

Next topic
Introduction

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
Introduction
The Application Programmer’s Interface to Python gives C and C++ programmers access to the Python interpreter at a variety of levels. The API is equally usable from C++, but for brevity it is generally referred to as the Python/C API. There are two fundamentally different reasons for using the Python/C API. The first reason is to write extension modules for specific purposes; these are C modules that extend the Python interpreter. This is probably the most common use. The second reason is to use Python as a component in a larger application; this technique is generally referred to as embedding Python in an application.

Writing an extension module is a relatively well-understood process, where a “cookbook” approach works well. There are several tools that automate the process to some extent. While people have embedded Python in other applications since its early existence, the process of embedding Python is less straightforward than writing an extension.

Many API functions are useful independent of whether you’re embedding or extending Python; moreover, most applications that embed Python will need to provide a custom extension as well, so it’s probably a good idea to become familiar with writing an extension before attempting to embed Python in a real application.

Coding standards
If you’re writing C code for inclusion in CPython, you must follow the guidelines and standards defined in PEP 7. These guidelines apply regardless of the version of Python you are contributing to. Following these conventions is not necessary for your own third party extension modules, unless you eventually expect to contribute them to Python.

Include Files
All function, type and macro definitions needed to use the Python/C API are included in your code by the following line:

#define PY_SSIZE_T_CLEAN
#include <Python.h>
This implies inclusion of the following standard headers: <stdio.h>, <string.h>, <errno.h>, <limits.h>, <assert.h> and <stdlib.h> (if available).

Note Since Python may define some pre-processor definitions which affect the standard headers on some systems, you must include Python.h before any standard headers are included.
It is recommended to always define PY_SSIZE_T_CLEAN before including Python.h. See Parsing arguments and building values for a description of this macro.

All user visible names defined by Python.h (except those defined by the included standard headers) have one of the prefixes Py or _Py. Names beginning with _Py are for internal use by the Python implementation and should not be used by extension writers. Structure member names do not have a reserved prefix.

Note User code should never define names that begin with Py or _Py. This confuses the reader, and jeopardizes the portability of the user code to future Python versions, which may define additional names beginning with one of these prefixes.
The header files are typically installed with Python. On Unix, these are located in the directories prefix/include/pythonversion/ and exec_prefix/include/pythonversion/, where prefix and exec_prefix are defined by the corresponding parameters to Python’s configure script and version is '%d.%d' % sys.version_info[:2]. On Windows, the headers are installed in prefix/include, where prefix is the installation directory specified to the installer.

To include the headers, place both directories (if different) on your compiler’s search path for includes. Do not place the parent directories on the search path and then use #include <pythonX.Y/Python.h>; this will break on multi-platform builds since the platform independent headers under prefix include the platform specific headers from exec_prefix.

C++ users should note that although the API is defined entirely using C, the header files properly declare the entry points to be extern "C". As a result, there is no need to do anything special to use the API from C++.

Useful macros
Several useful macros are defined in the Python header files. Many are defined closer to where they are useful (e.g. Py_RETURN_NONE). Others of a more general utility are defined here. This is not necessarily a complete listing.

Py_UNREACHABLE()
Use this when you have a code path that cannot be reached by design. For example, in the default: clause in a switch statement for which all possible values are covered in case statements. Use this in places where you might be tempted to put an assert(0) or abort() call.

In release mode, the macro helps the compiler to optimize the code, and avoids a warning about unreachable code. For example, the macro is implemented with __builtin_unreachable() on GCC in release mode.

A use for Py_UNREACHABLE() is following a call a function that never returns but that is not declared _Py_NO_RETURN.

If a code path is very unlikely code but can be reached under exceptional case, this macro must not be used. For example, under low memory condition or if a system call returns a value out of the expected range. In this case, it’s better to report the error to the caller. If the error cannot be reported to caller, Py_FatalError() can be used.

New in version 3.7.

Py_ABS(x)
Return the absolute value of x.

New in version 3.3.

Py_MIN(x, y)
Return the minimum value between x and y.

New in version 3.3.

Py_MAX(x, y)
Return the maximum value between x and y.

New in version 3.3.

Py_STRINGIFY(x)
Convert x to a C string. E.g. Py_STRINGIFY(123) returns "123".

New in version 3.4.

Py_MEMBER_SIZE(type, member)
Return the size of a structure (type) member in bytes.

New in version 3.6.

Py_CHARMASK(c)
Argument must be a character or an integer in the range [-128, 127] or [0, 255]. This macro returns c cast to an unsigned char.

Py_GETENV(s)
Like getenv(s), but returns NULL if -E was passed on the command line (i.e. if Py_IgnoreEnvironmentFlag is set).

Py_UNUSED(arg)
Use this for unused arguments in a function definition to silence compiler warnings. Example: int func(int a, int Py_UNUSED(b)) { return a; }.

New in version 3.4.

Py_DEPRECATED(version)
Use this for deprecated declarations. The macro must be placed before the symbol name.

Example:

Py_DEPRECATED(3.8) PyAPI_FUNC(int) Py_OldFunction(void);
Changed in version 3.8: MSVC support was added.

PyDoc_STRVAR(name, str)
Creates a variable with name name that can be used in docstrings. If Python is built without docstrings, the value will be empty.

Use PyDoc_STRVAR for docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

PyDoc_STRVAR(pop_doc, "Remove and return the rightmost element.");

static PyMethodDef deque_methods[] = {
    // ...
    {"pop", (PyCFunction)deque_pop, METH_NOARGS, pop_doc},
    // ...
}
PyDoc_STR(str)
Creates a docstring for the given input string or an empty string if docstrings are disabled.

Use PyDoc_STR in specifying docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

static PyMethodDef pysqlite_row_methods[] = {
    {"keys", (PyCFunction)pysqlite_row_keys, METH_NOARGS,
        PyDoc_STR("Returns the keys of the row.")},
    {NULL, NULL}
};
Objects, Types and Reference Counts
Most Python/C API functions have one or more arguments as well as a return value of type PyObject*. This type is a pointer to an opaque data type representing an arbitrary Python object. Since all Python object types are treated the same way by the Python language in most situations (e.g., assignments, scope rules, and argument passing), it is only fitting that they should be represented by a single C type. Almost all Python objects live on the heap: you never declare an automatic or static variable of type PyObject, only pointer variables of type PyObject* can be declared. The sole exception are the type objects; since these must never be deallocated, they are typically static PyTypeObject objects.

All Python objects (even Python integers) have a type and a reference count. An object’s type determines what kind of object it is (e.g., an integer, a list, or a user-defined function; there are many more as explained in The standard type hierarchy). For each of the well-known types there is a macro to check whether an object is of that type; for instance, PyList_Check(a) is true if (and only if) the object pointed to by a is a Python list.

Reference Counts
The reference count is important because today’s computers have a finite (and often severely limited) memory size; it counts how many different places there are that have a reference to an object. Such a place could be another object, or a global (or static) C variable, or a local variable in some C function. When an object’s reference count becomes zero, the object is deallocated. If it contains references to other objects, their reference count is decremented. Those other objects may be deallocated in turn, if this decrement makes their reference count become zero, and so on. (There’s an obvious problem with objects that reference each other here; for now, the solution is “don’t do that.”)

Reference counts are always manipulated explicitly. The normal way is to use the macro Py_INCREF() to increment an object’s reference count by one, and Py_DECREF() to decrement it by one. The Py_DECREF() macro is considerably more complex than the incref one, since it must check whether the reference count becomes zero and then cause the object’s deallocator to be called. The deallocator is a function pointer contained in the object’s type structure. The type-specific deallocator takes care of decrementing the reference counts for other objects contained in the object if this is a compound object type, such as a list, as well as performing any additional finalization that’s needed. There’s no chance that the reference count can overflow; at least as many bits are used to hold the reference count as there are distinct memory locations in virtual memory (assuming sizeof(Py_ssize_t) >= sizeof(void*)). Thus, the reference count increment is a simple operation.

It is not necessary to increment an object’s reference count for every local variable that contains a pointer to an object. In theory, the object’s reference count goes up by one when the variable is made to point to it and it goes down by one when the variable goes out of scope. However, these two cancel each other out, so at the end the reference count hasn’t changed. The only real reason to use the reference count is to prevent the object from being deallocated as long as our variable is pointing to it. If we know that there is at least one other reference to the object that lives at least as long as our variable, there is no need to increment the reference count temporarily. An important situation where this arises is in objects that are passed as arguments to C functions in an extension module that are called from Python; the call mechanism guarantees to hold a reference to every argument for the duration of the call.

However, a common pitfall is to extract an object from a list and hold on to it for a while without incrementing its reference count. Some other operation might conceivably remove the object from the list, decrementing its reference count and possibly deallocating it. The real danger is that innocent-looking operations may invoke arbitrary Python code which could do this; there is a code path which allows control to flow back to the user from a Py_DECREF(), so almost any operation is potentially dangerous.

A safe approach is to always use the generic operations (functions whose name begins with PyObject_, PyNumber_, PySequence_ or PyMapping_). These operations always increment the reference count of the object they return. This leaves the caller with the responsibility to call Py_DECREF() when they are done with the result; this soon becomes second nature.

Reference Count Details
The reference count behavior of functions in the Python/C API is best explained in terms of ownership of references. Ownership pertains to references, never to objects (objects are not owned: they are always shared). “Owning a reference” means being responsible for calling Py_DECREF on it when the reference is no longer needed. Ownership can also be transferred, meaning that the code that receives ownership of the reference then becomes responsible for eventually decref’ing it by calling Py_DECREF() or Py_XDECREF() when it’s no longer needed—or passing on this responsibility (usually to its caller). When a function passes ownership of a reference on to its caller, the caller is said to receive a new reference. When no ownership is transferred, the caller is said to borrow the reference. Nothing needs to be done for a borrowed reference.

Conversely, when a calling function passes in a reference to an object, there are two possibilities: the function steals a reference to the object, or it does not. Stealing a reference means that when you pass a reference to a function, that function assumes that it now owns that reference, and you are not responsible for it any longer.

Few functions steal references; the two notable exceptions are PyList_SetItem() and PyTuple_SetItem(), which steal a reference to the item (but not to the tuple or list into which the item is put!). These functions were designed to steal a reference because of a common idiom for populating a tuple or list with newly created objects; for example, the code to create the tuple (1, 2, "three") could look like this (forgetting about error handling for the moment; a better way to code this is shown below):

PyObject *t;

t = PyTuple_New(3);
PyTuple_SetItem(t, 0, PyLong_FromLong(1L));
PyTuple_SetItem(t, 1, PyLong_FromLong(2L));
PyTuple_SetItem(t, 2, PyUnicode_FromString("three"));
Here, PyLong_FromLong() returns a new reference which is immediately stolen by PyTuple_SetItem(). When you want to keep using an object although the reference to it will be stolen, use Py_INCREF() to grab another reference before calling the reference-stealing function.

Incidentally, PyTuple_SetItem() is the only way to set tuple items; PySequence_SetItem() and PyObject_SetItem() refuse to do this since tuples are an immutable data type. You should only use PyTuple_SetItem() for tuples that you are creating yourself.

Equivalent code for populating a list can be written using PyList_New() and PyList_SetItem().

However, in practice, you will rarely use these ways of creating and populating a tuple or list. There’s a generic function, Py_BuildValue(), that can create most common objects from C values, directed by a format string. For example, the above two blocks of code could be replaced by the following (which also takes care of the error checking):

PyObject *tuple, *list;

tuple = Py_BuildValue("(iis)", 1, 2, "three");
list = Py_BuildValue("[iis]", 1, 2, "three");
It is much more common to use PyObject_SetItem() and friends with items whose references you are only borrowing, like arguments that were passed in to the function you are writing. In that case, their behaviour regarding reference counts is much saner, since you don’t have to increment a reference count so you can give a reference away (“have it be stolen”). For example, this function sets all items of a list (actually, any mutable sequence) to a given item:

int
set_all(PyObject *target, PyObject *item)
{
    Py_ssize_t i, n;

    n = PyObject_Length(target);
    if (n < 0)
        return -1;
    for (i = 0; i < n; i++) {
        PyObject *index = PyLong_FromSsize_t(i);
        if (!index)
            return -1;
        if (PyObject_SetItem(target, index, item) < 0) {
            Py_DECREF(index);
            return -1;
        }
        Py_DECREF(index);
    }
    return 0;
}
The situation is slightly different for function return values. While passing a reference to most functions does not change your ownership responsibilities for that reference, many functions that return a reference to an object give you ownership of the reference. The reason is simple: in many cases, the returned object is created on the fly, and the reference you get is the only reference to the object. Therefore, the generic functions that return object references, like PyObject_GetItem() and PySequence_GetItem(), always return a new reference (the caller becomes the owner of the reference).

It is important to realize that whether you own a reference returned by a function depends on which function you call only — the plumage (the type of the object passed as an argument to the function) doesn’t enter into it! Thus, if you extract an item from a list using PyList_GetItem(), you don’t own the reference — but if you obtain the same item from the same list using PySequence_GetItem() (which happens to take exactly the same arguments), you do own a reference to the returned object.

Here is an example of how you could write a function that computes the sum of the items in a list of integers; once using PyList_GetItem(), and once using PySequence_GetItem().

long
sum_list(PyObject *list)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;

    n = PyList_Size(list);
    if (n < 0)
        return -1; /* Not a list */
    for (i = 0; i < n; i++) {
        item = PyList_GetItem(list, i); /* Can't fail */
        if (!PyLong_Check(item)) continue; /* Skip non-integers */
        value = PyLong_AsLong(item);
        if (value == -1 && PyErr_Occurred())
            /* Integer too big to fit in a C long, bail out */
            return -1;
        total += value;
    }
    return total;
}
long
sum_sequence(PyObject *sequence)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;
    n = PySequence_Length(sequence);
    if (n < 0)
        return -1; /* Has no length */
    for (i = 0; i < n; i++) {
        item = PySequence_GetItem(sequence, i);
        if (item == NULL)
            return -1; /* Not a sequence, or other failure */
        if (PyLong_Check(item)) {
            value = PyLong_AsLong(item);
            Py_DECREF(item);
            if (value == -1 && PyErr_Occurred())
                /* Integer too big to fit in a C long, bail out */
                return -1;
            total += value;
        }
        else {
            Py_DECREF(item); /* Discard reference ownership */
        }
    }
    return total;
}
Types
There are few other data types that play a significant role in the Python/C API; most are simple C types such as int, long, double and char*. A few structure types are used to describe static tables used to list the functions exported by a module or the data attributes of a new object type, and another is used to describe the value of a complex number. These will be discussed together with the functions that use them.

type Py_ssize_t
Part of the Stable ABI.
A signed integral type such that sizeof(Py_ssize_t) == sizeof(size_t). C99 doesn’t define such a thing directly (size_t is an unsigned integral type). See PEP 353 for details. PY_SSIZE_T_MAX is the largest positive value of type Py_ssize_t.

Exceptions
The Python programmer only needs to deal with exceptions if specific error handling is required; unhandled exceptions are automatically propagated to the caller, then to the caller’s caller, and so on, until they reach the top-level interpreter, where they are reported to the user accompanied by a stack traceback.

For C programmers, however, error checking always has to be explicit. All functions in the Python/C API can raise exceptions, unless an explicit claim is made otherwise in a function’s documentation. In general, when a function encounters an error, it sets an exception, discards any object references that it owns, and returns an error indicator. If not documented otherwise, this indicator is either NULL or -1, depending on the function’s return type. A few functions return a Boolean true/false result, with false indicating an error. Very few functions return no explicit error indicator or have an ambiguous return value, and require explicit testing for errors with PyErr_Occurred(). These exceptions are always explicitly documented.

Exception state is maintained in per-thread storage (this is equivalent to using global storage in an unthreaded application). A thread can be in one of two states: an exception has occurred, or not. The function PyErr_Occurred() can be used to check for this: it returns a borrowed reference to the exception type object when an exception has occurred, and NULL otherwise. There are a number of functions to set the exception state: PyErr_SetString() is the most common (though not the most general) function to set the exception state, and PyErr_Clear() clears the exception state.

The full exception state consists of three objects (all of which can be NULL): the exception type, the corresponding exception value, and the traceback. These have the same meanings as the Python result of sys.exc_info(); however, they are not the same: the Python objects represent the last exception being handled by a Python try … except statement, while the C level exception state only exists while an exception is being passed on between C functions until it reaches the Python bytecode interpreter’s main loop, which takes care of transferring it to sys.exc_info() and friends.

Note that starting with Python 1.5, the preferred, thread-safe way to access the exception state from Python code is to call the function sys.exc_info(), which returns the per-thread exception state for Python code. Also, the semantics of both ways to access the exception state have changed so that a function which catches an exception will save and restore its thread’s exception state so as to preserve the exception state of its caller. This prevents common bugs in exception handling code caused by an innocent-looking function overwriting the exception being handled; it also reduces the often unwanted lifetime extension for objects that are referenced by the stack frames in the traceback.

As a general principle, a function that calls another function to perform some task should check whether the called function raised an exception, and if so, pass the exception state on to its caller. It should discard any object references that it owns, and return an error indicator, but it should not set another exception — that would overwrite the exception that was just raised, and lose important information about the exact cause of the error.

A simple example of detecting exceptions and passing them on is shown in the sum_sequence() example above. It so happens that this example doesn’t need to clean up any owned references when it detects an error. The following example function shows some error cleanup. First, to remind you why you like Python, we show the equivalent Python code:

def incr_item(dict, key):
    try:
        item = dict[key]
    except KeyError:
        item = 0
    dict[key] = item + 1
Here is the corresponding C code, in all its glory:

int
incr_item(PyObject *dict, PyObject *key)
{
    /* Objects all initialized to NULL for Py_XDECREF */
    PyObject *item = NULL, *const_one = NULL, *incremented_item = NULL;
    int rv = -1; /* Return value initialized to -1 (failure) */

    item = PyObject_GetItem(dict, key);
    if (item == NULL) {
        /* Handle KeyError only: */
        if (!PyErr_ExceptionMatches(PyExc_KeyError))
            goto error;

        /* Clear the error and use zero: */
        PyErr_Clear();
        item = PyLong_FromLong(0L);
        if (item == NULL)
            goto error;
    }
    const_one = PyLong_FromLong(1L);
    if (const_one == NULL)
        goto error;

    incremented_item = PyNumber_Add(item, const_one);
    if (incremented_item == NULL)
        goto error;

    if (PyObject_SetItem(dict, key, incremented_item) < 0)
        goto error;
    rv = 0; /* Success */
    /* Continue with cleanup code */

 error:
    /* Cleanup code, shared by success and failure path */

    /* Use Py_XDECREF() to ignore NULL references */
    Py_XDECREF(item);
    Py_XDECREF(const_one);
    Py_XDECREF(incremented_item);

    return rv; /* -1 for error, 0 for success */
}
This example represents an endorsed use of the goto statement in C! It illustrates the use of PyErr_ExceptionMatches() and PyErr_Clear() to handle specific exceptions, and the use of Py_XDECREF() to dispose of owned references that may be NULL (note the 'X' in the name; Py_DECREF() would crash when confronted with a NULL reference). It is important that the variables used to hold owned references are initialized to NULL for this to work; likewise, the proposed return value is initialized to -1 (failure) and only set to success after the final call made is successful.

Embedding Python
The one important task that only embedders (as opposed to extension writers) of the Python interpreter have to worry about is the initialization, and possibly the finalization, of the Python interpreter. Most functionality of the interpreter can only be used after the interpreter has been initialized.

The basic initialization function is Py_Initialize(). This initializes the table of loaded modules, and creates the fundamental modules builtins, __main__, and sys. It also initializes the module search path (sys.path).

Py_Initialize() does not set the “script argument list” (sys.argv). If this variable is needed by Python code that will be executed later, it must be set explicitly with a call to PySys_SetArgvEx(argc, argv, updatepath) after the call to Py_Initialize().

On most systems (in particular, on Unix and Windows, although the details are slightly different), Py_Initialize() calculates the module search path based upon its best guess for the location of the standard Python interpreter executable, assuming that the Python library is found in a fixed location relative to the Python interpreter executable. In particular, it looks for a directory named lib/pythonX.Y relative to the parent directory where the executable named python is found on the shell command search path (the environment variable PATH).

For instance, if the Python executable is found in /usr/local/bin/python, it will assume that the libraries are in /usr/local/lib/pythonX.Y. (In fact, this particular path is also the “fallback” location, used when no executable file named python is found along PATH.) The user can override this behavior by setting the environment variable PYTHONHOME, or insert additional directories in front of the standard path by setting PYTHONPATH.

The embedding application can steer the search by calling Py_SetProgramName(file) before calling Py_Initialize(). Note that PYTHONHOME still overrides this and PYTHONPATH is still inserted in front of the standard path. An application that requires total control has to provide its own implementation of Py_GetPath(), Py_GetPrefix(), Py_GetExecPrefix(), and Py_GetProgramFullPath() (all defined in Modules/getpath.c).

Sometimes, it is desirable to “uninitialize” Python. For instance, the application may want to start over (make another call to Py_Initialize()) or the application is simply done with its use of Python and wants to free memory allocated by Python. This can be accomplished by calling Py_FinalizeEx(). The function Py_IsInitialized() returns true if Python is currently in the initialized state. More information about these functions is given in a later chapter. Notice that Py_FinalizeEx() does not free all memory allocated by the Python interpreter, e.g. memory allocated by extension modules currently cannot be released.

Debugging Builds
Python can be built with several macros to enable extra checks of the interpreter and extension modules. These checks tend to add a large amount of overhead to the runtime so they are not enabled by default.

A full list of the various types of debugging builds is in the file Misc/SpecialBuilds.txt in the Python source distribution. Builds are available that support tracing of reference counts, debugging the memory allocator, or low-level profiling of the main interpreter loop. Only the most frequently used builds will be described in the remainder of this section.

Compiling the interpreter with the Py_DEBUG macro defined produces what is generally meant by a debug build of Python. Py_DEBUG is enabled in the Unix build by adding --with-pydebug to the ./configure command. It is also implied by the presence of the not-Python-specific _DEBUG macro. When Py_DEBUG is enabled in the Unix build, compiler optimization is disabled.

In addition to the reference count debugging described below, extra checks are performed, see Python Debug Build.

Defining Py_TRACE_REFS enables reference tracing (see the configure --with-trace-refs option). When defined, a circular doubly linked list of active objects is maintained by adding two extra fields to every PyObject. Total allocations are tracked as well. Upon exit, all existing references are printed. (In interactive mode this happens after every statement run by the interpreter.)

Please refer to Misc/SpecialBuilds.txt in the Python source distribution for more detailed information.

Table of Contents
Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Reference Counts
Reference Count Details
Types
Exceptions
Embedding Python
Debugging Builds
Previous topic
Python/C API Reference Manual

Next topic
C API Stability

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
Introduction
The Application Programmer’s Interface to Python gives C and C++ programmers access to the Python interpreter at a variety of levels. The API is equally usable from C++, but for brevity it is generally referred to as the Python/C API. There are two fundamentally different reasons for using the Python/C API. The first reason is to write extension modules for specific purposes; these are C modules that extend the Python interpreter. This is probably the most common use. The second reason is to use Python as a component in a larger application; this technique is generally referred to as embedding Python in an application.

Writing an extension module is a relatively well-understood process, where a “cookbook” approach works well. There are several tools that automate the process to some extent. While people have embedded Python in other applications since its early existence, the process of embedding Python is less straightforward than writing an extension.

Many API functions are useful independent of whether you’re embedding or extending Python; moreover, most applications that embed Python will need to provide a custom extension as well, so it’s probably a good idea to become familiar with writing an extension before attempting to embed Python in a real application.

Coding standards
If you’re writing C code for inclusion in CPython, you must follow the guidelines and standards defined in PEP 7. These guidelines apply regardless of the version of Python you are contributing to. Following these conventions is not necessary for your own third party extension modules, unless you eventually expect to contribute them to Python.

Include Files
All function, type and macro definitions needed to use the Python/C API are included in your code by the following line:

#define PY_SSIZE_T_CLEAN
#include <Python.h>
This implies inclusion of the following standard headers: <stdio.h>, <string.h>, <errno.h>, <limits.h>, <assert.h> and <stdlib.h> (if available).

Note Since Python may define some pre-processor definitions which affect the standard headers on some systems, you must include Python.h before any standard headers are included.
It is recommended to always define PY_SSIZE_T_CLEAN before including Python.h. See Parsing arguments and building values for a description of this macro.

All user visible names defined by Python.h (except those defined by the included standard headers) have one of the prefixes Py or _Py. Names beginning with _Py are for internal use by the Python implementation and should not be used by extension writers. Structure member names do not have a reserved prefix.

Note User code should never define names that begin with Py or _Py. This confuses the reader, and jeopardizes the portability of the user code to future Python versions, which may define additional names beginning with one of these prefixes.
The header files are typically installed with Python. On Unix, these are located in the directories prefix/include/pythonversion/ and exec_prefix/include/pythonversion/, where prefix and exec_prefix are defined by the corresponding parameters to Python’s configure script and version is '%d.%d' % sys.version_info[:2]. On Windows, the headers are installed in prefix/include, where prefix is the installation directory specified to the installer.

To include the headers, place both directories (if different) on your compiler’s search path for includes. Do not place the parent directories on the search path and then use #include <pythonX.Y/Python.h>; this will break on multi-platform builds since the platform independent headers under prefix include the platform specific headers from exec_prefix.

C++ users should note that although the API is defined entirely using C, the header files properly declare the entry points to be extern "C". As a result, there is no need to do anything special to use the API from C++.

Useful macros
Several useful macros are defined in the Python header files. Many are defined closer to where they are useful (e.g. Py_RETURN_NONE). Others of a more general utility are defined here. This is not necessarily a complete listing.

Py_UNREACHABLE()
Use this when you have a code path that cannot be reached by design. For example, in the default: clause in a switch statement for which all possible values are covered in case statements. Use this in places where you might be tempted to put an assert(0) or abort() call.

In release mode, the macro helps the compiler to optimize the code, and avoids a warning about unreachable code. For example, the macro is implemented with __builtin_unreachable() on GCC in release mode.

A use for Py_UNREACHABLE() is following a call a function that never returns but that is not declared _Py_NO_RETURN.

If a code path is very unlikely code but can be reached under exceptional case, this macro must not be used. For example, under low memory condition or if a system call returns a value out of the expected range. In this case, it’s better to report the error to the caller. If the error cannot be reported to caller, Py_FatalError() can be used.

New in version 3.7.

Py_ABS(x)
Return the absolute value of x.

New in version 3.3.

Py_MIN(x, y)
Return the minimum value between x and y.

New in version 3.3.

Py_MAX(x, y)
Return the maximum value between x and y.

New in version 3.3.

Py_STRINGIFY(x)
Convert x to a C string. E.g. Py_STRINGIFY(123) returns "123".

New in version 3.4.

Py_MEMBER_SIZE(type, member)
Return the size of a structure (type) member in bytes.

New in version 3.6.

Py_CHARMASK(c)
Argument must be a character or an integer in the range [-128, 127] or [0, 255]. This macro returns c cast to an unsigned char.

Py_GETENV(s)
Like getenv(s), but returns NULL if -E was passed on the command line (i.e. if Py_IgnoreEnvironmentFlag is set).

Py_UNUSED(arg)
Use this for unused arguments in a function definition to silence compiler warnings. Example: int func(int a, int Py_UNUSED(b)) { return a; }.

New in version 3.4.

Py_DEPRECATED(version)
Use this for deprecated declarations. The macro must be placed before the symbol name.

Example:

Py_DEPRECATED(3.8) PyAPI_FUNC(int) Py_OldFunction(void);
Changed in version 3.8: MSVC support was added.

PyDoc_STRVAR(name, str)
Creates a variable with name name that can be used in docstrings. If Python is built without docstrings, the value will be empty.

Use PyDoc_STRVAR for docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

PyDoc_STRVAR(pop_doc, "Remove and return the rightmost element.");

static PyMethodDef deque_methods[] = {
    // ...
    {"pop", (PyCFunction)deque_pop, METH_NOARGS, pop_doc},
    // ...
}
PyDoc_STR(str)
Creates a docstring for the given input string or an empty string if docstrings are disabled.

Use PyDoc_STR in specifying docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

static PyMethodDef pysqlite_row_methods[] = {
    {"keys", (PyCFunction)pysqlite_row_keys, METH_NOARGS,
        PyDoc_STR("Returns the keys of the row.")},
    {NULL, NULL}
};
Objects, Types and Reference Counts
Most Python/C API functions have one or more arguments as well as a return value of type PyObject*. This type is a pointer to an opaque data type representing an arbitrary Python object. Since all Python object types are treated the same way by the Python language in most situations (e.g., assignments, scope rules, and argument passing), it is only fitting that they should be represented by a single C type. Almost all Python objects live on the heap: you never declare an automatic or static variable of type PyObject, only pointer variables of type PyObject* can be declared. The sole exception are the type objects; since these must never be deallocated, they are typically static PyTypeObject objects.

All Python objects (even Python integers) have a type and a reference count. An object’s type determines what kind of object it is (e.g., an integer, a list, or a user-defined function; there are many more as explained in The standard type hierarchy). For each of the well-known types there is a macro to check whether an object is of that type; for instance, PyList_Check(a) is true if (and only if) the object pointed to by a is a Python list.

Reference Counts
The reference count is important because today’s computers have a finite (and often severely limited) memory size; it counts how many different places there are that have a reference to an object. Such a place could be another object, or a global (or static) C variable, or a local variable in some C function. When an object’s reference count becomes zero, the object is deallocated. If it contains references to other objects, their reference count is decremented. Those other objects may be deallocated in turn, if this decrement makes their reference count become zero, and so on. (There’s an obvious problem with objects that reference each other here; for now, the solution is “don’t do that.”)

Reference counts are always manipulated explicitly. The normal way is to use the macro Py_INCREF() to increment an object’s reference count by one, and Py_DECREF() to decrement it by one. The Py_DECREF() macro is considerably more complex than the incref one, since it must check whether the reference count becomes zero and then cause the object’s deallocator to be called. The deallocator is a function pointer contained in the object’s type structure. The type-specific deallocator takes care of decrementing the reference counts for other objects contained in the object if this is a compound object type, such as a list, as well as performing any additional finalization that’s needed. There’s no chance that the reference count can overflow; at least as many bits are used to hold the reference count as there are distinct memory locations in virtual memory (assuming sizeof(Py_ssize_t) >= sizeof(void*)). Thus, the reference count increment is a simple operation.

It is not necessary to increment an object’s reference count for every local variable that contains a pointer to an object. In theory, the object’s reference count goes up by one when the variable is made to point to it and it goes down by one when the variable goes out of scope. However, these two cancel each other out, so at the end the reference count hasn’t changed. The only real reason to use the reference count is to prevent the object from being deallocated as long as our variable is pointing to it. If we know that there is at least one other reference to the object that lives at least as long as our variable, there is no need to increment the reference count temporarily. An important situation where this arises is in objects that are passed as arguments to C functions in an extension module that are called from Python; the call mechanism guarantees to hold a reference to every argument for the duration of the call.

However, a common pitfall is to extract an object from a list and hold on to it for a while without incrementing its reference count. Some other operation might conceivably remove the object from the list, decrementing its reference count and possibly deallocating it. The real danger is that innocent-looking operations may invoke arbitrary Python code which could do this; there is a code path which allows control to flow back to the user from a Py_DECREF(), so almost any operation is potentially dangerous.

A safe approach is to always use the generic operations (functions whose name begins with PyObject_, PyNumber_, PySequence_ or PyMapping_). These operations always increment the reference count of the object they return. This leaves the caller with the responsibility to call Py_DECREF() when they are done with the result; this soon becomes second nature.

Reference Count Details
The reference count behavior of functions in the Python/C API is best explained in terms of ownership of references. Ownership pertains to references, never to objects (objects are not owned: they are always shared). “Owning a reference” means being responsible for calling Py_DECREF on it when the reference is no longer needed. Ownership can also be transferred, meaning that the code that receives ownership of the reference then becomes responsible for eventually decref’ing it by calling Py_DECREF() or Py_XDECREF() when it’s no longer needed—or passing on this responsibility (usually to its caller). When a function passes ownership of a reference on to its caller, the caller is said to receive a new reference. When no ownership is transferred, the caller is said to borrow the reference. Nothing needs to be done for a borrowed reference.

Conversely, when a calling function passes in a reference to an object, there are two possibilities: the function steals a reference to the object, or it does not. Stealing a reference means that when you pass a reference to a function, that function assumes that it now owns that reference, and you are not responsible for it any longer.

Few functions steal references; the two notable exceptions are PyList_SetItem() and PyTuple_SetItem(), which steal a reference to the item (but not to the tuple or list into which the item is put!). These functions were designed to steal a reference because of a common idiom for populating a tuple or list with newly created objects; for example, the code to create the tuple (1, 2, "three") could look like this (forgetting about error handling for the moment; a better way to code this is shown below):

PyObject *t;

t = PyTuple_New(3);
PyTuple_SetItem(t, 0, PyLong_FromLong(1L));
PyTuple_SetItem(t, 1, PyLong_FromLong(2L));
PyTuple_SetItem(t, 2, PyUnicode_FromString("three"));
Here, PyLong_FromLong() returns a new reference which is immediately stolen by PyTuple_SetItem(). When you want to keep using an object although the reference to it will be stolen, use Py_INCREF() to grab another reference before calling the reference-stealing function.

Incidentally, PyTuple_SetItem() is the only way to set tuple items; PySequence_SetItem() and PyObject_SetItem() refuse to do this since tuples are an immutable data type. You should only use PyTuple_SetItem() for tuples that you are creating yourself.

Equivalent code for populating a list can be written using PyList_New() and PyList_SetItem().

However, in practice, you will rarely use these ways of creating and populating a tuple or list. There’s a generic function, Py_BuildValue(), that can create most common objects from C values, directed by a format string. For example, the above two blocks of code could be replaced by the following (which also takes care of the error checking):

PyObject *tuple, *list;

tuple = Py_BuildValue("(iis)", 1, 2, "three");
list = Py_BuildValue("[iis]", 1, 2, "three");
It is much more common to use PyObject_SetItem() and friends with items whose references you are only borrowing, like arguments that were passed in to the function you are writing. In that case, their behaviour regarding reference counts is much saner, since you don’t have to increment a reference count so you can give a reference away (“have it be stolen”). For example, this function sets all items of a list (actually, any mutable sequence) to a given item:

int
set_all(PyObject *target, PyObject *item)
{
    Py_ssize_t i, n;

    n = PyObject_Length(target);
    if (n < 0)
        return -1;
    for (i = 0; i < n; i++) {
        PyObject *index = PyLong_FromSsize_t(i);
        if (!index)
            return -1;
        if (PyObject_SetItem(target, index, item) < 0) {
            Py_DECREF(index);
            return -1;
        }
        Py_DECREF(index);
    }
    return 0;
}
The situation is slightly different for function return values. While passing a reference to most functions does not change your ownership responsibilities for that reference, many functions that return a reference to an object give you ownership of the reference. The reason is simple: in many cases, the returned object is created on the fly, and the reference you get is the only reference to the object. Therefore, the generic functions that return object references, like PyObject_GetItem() and PySequence_GetItem(), always return a new reference (the caller becomes the owner of the reference).

It is important to realize that whether you own a reference returned by a function depends on which function you call only — the plumage (the type of the object passed as an argument to the function) doesn’t enter into it! Thus, if you extract an item from a list using PyList_GetItem(), you don’t own the reference — but if you obtain the same item from the same list using PySequence_GetItem() (which happens to take exactly the same arguments), you do own a reference to the returned object.

Here is an example of how you could write a function that computes the sum of the items in a list of integers; once using PyList_GetItem(), and once using PySequence_GetItem().

long
sum_list(PyObject *list)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;

    n = PyList_Size(list);
    if (n < 0)
        return -1; /* Not a list */
    for (i = 0; i < n; i++) {
        item = PyList_GetItem(list, i); /* Can't fail */
        if (!PyLong_Check(item)) continue; /* Skip non-integers */
        value = PyLong_AsLong(item);
        if (value == -1 && PyErr_Occurred())
            /* Integer too big to fit in a C long, bail out */
            return -1;
        total += value;
    }
    return total;
}
long
sum_sequence(PyObject *sequence)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;
    n = PySequence_Length(sequence);
    if (n < 0)
        return -1; /* Has no length */
    for (i = 0; i < n; i++) {
        item = PySequence_GetItem(sequence, i);
        if (item == NULL)
            return -1; /* Not a sequence, or other failure */
        if (PyLong_Check(item)) {
            value = PyLong_AsLong(item);
            Py_DECREF(item);
            if (value == -1 && PyErr_Occurred())
                /* Integer too big to fit in a C long, bail out */
                return -1;
            total += value;
        }
        else {
            Py_DECREF(item); /* Discard reference ownership */
        }
    }
    return total;
}
Types
There are few other data types that play a significant role in the Python/C API; most are simple C types such as int, long, double and char*. A few structure types are used to describe static tables used to list the functions exported by a module or the data attributes of a new object type, and another is used to describe the value of a complex number. These will be discussed together with the functions that use them.

type Py_ssize_t
Part of the Stable ABI.
A signed integral type such that sizeof(Py_ssize_t) == sizeof(size_t). C99 doesn’t define such a thing directly (size_t is an unsigned integral type). See PEP 353 for details. PY_SSIZE_T_MAX is the largest positive value of type Py_ssize_t.

Exceptions
The Python programmer only needs to deal with exceptions if specific error handling is required; unhandled exceptions are automatically propagated to the caller, then to the caller’s caller, and so on, until they reach the top-level interpreter, where they are reported to the user accompanied by a stack traceback.

For C programmers, however, error checking always has to be explicit. All functions in the Python/C API can raise exceptions, unless an explicit claim is made otherwise in a function’s documentation. In general, when a function encounters an error, it sets an exception, discards any object references that it owns, and returns an error indicator. If not documented otherwise, this indicator is either NULL or -1, depending on the function’s return type. A few functions return a Boolean true/false result, with false indicating an error. Very few functions return no explicit error indicator or have an ambiguous return value, and require explicit testing for errors with PyErr_Occurred(). These exceptions are always explicitly documented.

Exception state is maintained in per-thread storage (this is equivalent to using global storage in an unthreaded application). A thread can be in one of two states: an exception has occurred, or not. The function PyErr_Occurred() can be used to check for this: it returns a borrowed reference to the exception type object when an exception has occurred, and NULL otherwise. There are a number of functions to set the exception state: PyErr_SetString() is the most common (though not the most general) function to set the exception state, and PyErr_Clear() clears the exception state.

The full exception state consists of three objects (all of which can be NULL): the exception type, the corresponding exception value, and the traceback. These have the same meanings as the Python result of sys.exc_info(); however, they are not the same: the Python objects represent the last exception being handled by a Python try … except statement, while the C level exception state only exists while an exception is being passed on between C functions until it reaches the Python bytecode interpreter’s main loop, which takes care of transferring it to sys.exc_info() and friends.

Note that starting with Python 1.5, the preferred, thread-safe way to access the exception state from Python code is to call the function sys.exc_info(), which returns the per-thread exception state for Python code. Also, the semantics of both ways to access the exception state have changed so that a function which catches an exception will save and restore its thread’s exception state so as to preserve the exception state of its caller. This prevents common bugs in exception handling code caused by an innocent-looking function overwriting the exception being handled; it also reduces the often unwanted lifetime extension for objects that are referenced by the stack frames in the traceback.

As a general principle, a function that calls another function to perform some task should check whether the called function raised an exception, and if so, pass the exception state on to its caller. It should discard any object references that it owns, and return an error indicator, but it should not set another exception — that would overwrite the exception that was just raised, and lose important information about the exact cause of the error.

A simple example of detecting exceptions and passing them on is shown in the sum_sequence() example above. It so happens that this example doesn’t need to clean up any owned references when it detects an error. The following example function shows some error cleanup. First, to remind you why you like Python, we show the equivalent Python code:

def incr_item(dict, key):
    try:
        item = dict[key]
    except KeyError:
        item = 0
    dict[key] = item + 1
Here is the corresponding C code, in all its glory:

int
incr_item(PyObject *dict, PyObject *key)
{
    /* Objects all initialized to NULL for Py_XDECREF */
    PyObject *item = NULL, *const_one = NULL, *incremented_item = NULL;
    int rv = -1; /* Return value initialized to -1 (failure) */

    item = PyObject_GetItem(dict, key);
    if (item == NULL) {
        /* Handle KeyError only: */
        if (!PyErr_ExceptionMatches(PyExc_KeyError))
            goto error;

        /* Clear the error and use zero: */
        PyErr_Clear();
        item = PyLong_FromLong(0L);
        if (item == NULL)
            goto error;
    }
    const_one = PyLong_FromLong(1L);
    if (const_one == NULL)
        goto error;

    incremented_item = PyNumber_Add(item, const_one);
    if (incremented_item == NULL)
        goto error;

    if (PyObject_SetItem(dict, key, incremented_item) < 0)
        goto error;
    rv = 0; /* Success */
    /* Continue with cleanup code */

 error:
    /* Cleanup code, shared by success and failure path */

    /* Use Py_XDECREF() to ignore NULL references */
    Py_XDECREF(item);
    Py_XDECREF(const_one);
    Py_XDECREF(incremented_item);

    return rv; /* -1 for error, 0 for success */
}
This example represents an endorsed use of the goto statement in C! It illustrates the use of PyErr_ExceptionMatches() and PyErr_Clear() to handle specific exceptions, and the use of Py_XDECREF() to dispose of owned references that may be NULL (note the 'X' in the name; Py_DECREF() would crash when confronted with a NULL reference). It is important that the variables used to hold owned references are initialized to NULL for this to work; likewise, the proposed return value is initialized to -1 (failure) and only set to success after the final call made is successful.

Embedding Python
The one important task that only embedders (as opposed to extension writers) of the Python interpreter have to worry about is the initialization, and possibly the finalization, of the Python interpreter. Most functionality of the interpreter can only be used after the interpreter has been initialized.

The basic initialization function is Py_Initialize(). This initializes the table of loaded modules, and creates the fundamental modules builtins, __main__, and sys. It also initializes the module search path (sys.path).

Py_Initialize() does not set the “script argument list” (sys.argv). If this variable is needed by Python code that will be executed later, it must be set explicitly with a call to PySys_SetArgvEx(argc, argv, updatepath) after the call to Py_Initialize().

On most systems (in particular, on Unix and Windows, although the details are slightly different), Py_Initialize() calculates the module search path based upon its best guess for the location of the standard Python interpreter executable, assuming that the Python library is found in a fixed location relative to the Python interpreter executable. In particular, it looks for a directory named lib/pythonX.Y relative to the parent directory where the executable named python is found on the shell command search path (the environment variable PATH).

For instance, if the Python executable is found in /usr/local/bin/python, it will assume that the libraries are in /usr/local/lib/pythonX.Y. (In fact, this particular path is also the “fallback” location, used when no executable file named python is found along PATH.) The user can override this behavior by setting the environment variable PYTHONHOME, or insert additional directories in front of the standard path by setting PYTHONPATH.

The embedding application can steer the search by calling Py_SetProgramName(file) before calling Py_Initialize(). Note that PYTHONHOME still overrides this and PYTHONPATH is still inserted in front of the standard path. An application that requires total control has to provide its own implementation of Py_GetPath(), Py_GetPrefix(), Py_GetExecPrefix(), and Py_GetProgramFullPath() (all defined in Modules/getpath.c).

Sometimes, it is desirable to “uninitialize” Python. For instance, the application may want to start over (make another call to Py_Initialize()) or the application is simply done with its use of Python and wants to free memory allocated by Python. This can be accomplished by calling Py_FinalizeEx(). The function Py_IsInitialized() returns true if Python is currently in the initialized state. More information about these functions is given in a later chapter. Notice that Py_FinalizeEx() does not free all memory allocated by the Python interpreter, e.g. memory allocated by extension modules currently cannot be released.

Debugging Builds
Python can be built with several macros to enable extra checks of the interpreter and extension modules. These checks tend to add a large amount of overhead to the runtime so they are not enabled by default.

A full list of the various types of debugging builds is in the file Misc/SpecialBuilds.txt in the Python source distribution. Builds are available that support tracing of reference counts, debugging the memory allocator, or low-level profiling of the main interpreter loop. Only the most frequently used builds will be described in the remainder of this section.

Compiling the interpreter with the Py_DEBUG macro defined produces what is generally meant by a debug build of Python. Py_DEBUG is enabled in the Unix build by adding --with-pydebug to the ./configure command. It is also implied by the presence of the not-Python-specific _DEBUG macro. When Py_DEBUG is enabled in the Unix build, compiler optimization is disabled.

In addition to the reference count debugging described below, extra checks are performed, see Python Debug Build.

Defining Py_TRACE_REFS enables reference tracing (see the configure --with-trace-refs option). When defined, a circular doubly linked list of active objects is maintained by adding two extra fields to every PyObject. Total allocations are tracked as well. Upon exit, all existing references are printed. (In interactive mode this happens after every statement run by the interpreter.)

Please refer to Misc/SpecialBuilds.txt in the Python source distribution for more detailed information.

Table of Contents
Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Reference Counts
Reference Count Details
Types
Exceptions
Embedding Python
Debugging Builds
Previous topic
Python/C API Reference Manual

Next topic
C API Stability

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
Introduction
The Application Programmer’s Interface to Python gives C and C++ programmers access to the Python interpreter at a variety of levels. The API is equally usable from C++, but for brevity it is generally referred to as the Python/C API. There are two fundamentally different reasons for using the Python/C API. The first reason is to write extension modules for specific purposes; these are C modules that extend the Python interpreter. This is probably the most common use. The second reason is to use Python as a component in a larger application; this technique is generally referred to as embedding Python in an application.

Writing an extension module is a relatively well-understood process, where a “cookbook” approach works well. There are several tools that automate the process to some extent. While people have embedded Python in other applications since its early existence, the process of embedding Python is less straightforward than writing an extension.

Many API functions are useful independent of whether you’re embedding or extending Python; moreover, most applications that embed Python will need to provide a custom extension as well, so it’s probably a good idea to become familiar with writing an extension before attempting to embed Python in a real application.

Coding standards
If you’re writing C code for inclusion in CPython, you must follow the guidelines and standards defined in PEP 7. These guidelines apply regardless of the version of Python you are contributing to. Following these conventions is not necessary for your own third party extension modules, unless you eventually expect to contribute them to Python.

Include Files
All function, type and macro definitions needed to use the Python/C API are included in your code by the following line:

#define PY_SSIZE_T_CLEAN
#include <Python.h>
This implies inclusion of the following standard headers: <stdio.h>, <string.h>, <errno.h>, <limits.h>, <assert.h> and <stdlib.h> (if available).

Note Since Python may define some pre-processor definitions which affect the standard headers on some systems, you must include Python.h before any standard headers are included.
It is recommended to always define PY_SSIZE_T_CLEAN before including Python.h. See Parsing arguments and building values for a description of this macro.

All user visible names defined by Python.h (except those defined by the included standard headers) have one of the prefixes Py or _Py. Names beginning with _Py are for internal use by the Python implementation and should not be used by extension writers. Structure member names do not have a reserved prefix.

Note User code should never define names that begin with Py or _Py. This confuses the reader, and jeopardizes the portability of the user code to future Python versions, which may define additional names beginning with one of these prefixes.
The header files are typically installed with Python. On Unix, these are located in the directories prefix/include/pythonversion/ and exec_prefix/include/pythonversion/, where prefix and exec_prefix are defined by the corresponding parameters to Python’s configure script and version is '%d.%d' % sys.version_info[:2]. On Windows, the headers are installed in prefix/include, where prefix is the installation directory specified to the installer.

To include the headers, place both directories (if different) on your compiler’s search path for includes. Do not place the parent directories on the search path and then use #include <pythonX.Y/Python.h>; this will break on multi-platform builds since the platform independent headers under prefix include the platform specific headers from exec_prefix.

C++ users should note that although the API is defined entirely using C, the header files properly declare the entry points to be extern "C". As a result, there is no need to do anything special to use the API from C++.

Useful macros
Several useful macros are defined in the Python header files. Many are defined closer to where they are useful (e.g. Py_RETURN_NONE). Others of a more general utility are defined here. This is not necessarily a complete listing.

Py_UNREACHABLE()
Use this when you have a code path that cannot be reached by design. For example, in the default: clause in a switch statement for which all possible values are covered in case statements. Use this in places where you might be tempted to put an assert(0) or abort() call.

In release mode, the macro helps the compiler to optimize the code, and avoids a warning about unreachable code. For example, the macro is implemented with __builtin_unreachable() on GCC in release mode.

A use for Py_UNREACHABLE() is following a call a function that never returns but that is not declared _Py_NO_RETURN.

If a code path is very unlikely code but can be reached under exceptional case, this macro must not be used. For example, under low memory condition or if a system call returns a value out of the expected range. In this case, it’s better to report the error to the caller. If the error cannot be reported to caller, Py_FatalError() can be used.

New in version 3.7.

Py_ABS(x)
Return the absolute value of x.

New in version 3.3.

Py_MIN(x, y)
Return the minimum value between x and y.

New in version 3.3.

Py_MAX(x, y)
Return the maximum value between x and y.

New in version 3.3.

Py_STRINGIFY(x)
Convert x to a C string. E.g. Py_STRINGIFY(123) returns "123".

New in version 3.4.

Py_MEMBER_SIZE(type, member)
Return the size of a structure (type) member in bytes.

New in version 3.6.

Py_CHARMASK(c)
Argument must be a character or an integer in the range [-128, 127] or [0, 255]. This macro returns c cast to an unsigned char.

Py_GETENV(s)
Like getenv(s), but returns NULL if -E was passed on the command line (i.e. if Py_IgnoreEnvironmentFlag is set).

Py_UNUSED(arg)
Use this for unused arguments in a function definition to silence compiler warnings. Example: int func(int a, int Py_UNUSED(b)) { return a; }.

New in version 3.4.

Py_DEPRECATED(version)
Use this for deprecated declarations. The macro must be placed before the symbol name.

Example:

Py_DEPRECATED(3.8) PyAPI_FUNC(int) Py_OldFunction(void);
Changed in version 3.8: MSVC support was added.

PyDoc_STRVAR(name, str)
Creates a variable with name name that can be used in docstrings. If Python is built without docstrings, the value will be empty.

Use PyDoc_STRVAR for docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

PyDoc_STRVAR(pop_doc, "Remove and return the rightmost element.");

static PyMethodDef deque_methods[] = {
    // ...
    {"pop", (PyCFunction)deque_pop, METH_NOARGS, pop_doc},
    // ...
}
PyDoc_STR(str)
Creates a docstring for the given input string or an empty string if docstrings are disabled.

Use PyDoc_STR in specifying docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

static PyMethodDef pysqlite_row_methods[] = {
    {"keys", (PyCFunction)pysqlite_row_keys, METH_NOARGS,
        PyDoc_STR("Returns the keys of the row.")},
    {NULL, NULL}
};
Objects, Types and Reference Counts
Most Python/C API functions have one or more arguments as well as a return value of type PyObject*. This type is a pointer to an opaque data type representing an arbitrary Python object. Since all Python object types are treated the same way by the Python language in most situations (e.g., assignments, scope rules, and argument passing), it is only fitting that they should be represented by a single C type. Almost all Python objects live on the heap: you never declare an automatic or static variable of type PyObject, only pointer variables of type PyObject* can be declared. The sole exception are the type objects; since these must never be deallocated, they are typically static PyTypeObject objects.

All Python objects (even Python integers) have a type and a reference count. An object’s type determines what kind of object it is (e.g., an integer, a list, or a user-defined function; there are many more as explained in The standard type hierarchy). For each of the well-known types there is a macro to check whether an object is of that type; for instance, PyList_Check(a) is true if (and only if) the object pointed to by a is a Python list.

Reference Counts
The reference count is important because today’s computers have a finite (and often severely limited) memory size; it counts how many different places there are that have a reference to an object. Such a place could be another object, or a global (or static) C variable, or a local variable in some C function. When an object’s reference count becomes zero, the object is deallocated. If it contains references to other objects, their reference count is decremented. Those other objects may be deallocated in turn, if this decrement makes their reference count become zero, and so on. (There’s an obvious problem with objects that reference each other here; for now, the solution is “don’t do that.”)

Reference counts are always manipulated explicitly. The normal way is to use the macro Py_INCREF() to increment an object’s reference count by one, and Py_DECREF() to decrement it by one. The Py_DECREF() macro is considerably more complex than the incref one, since it must check whether the reference count becomes zero and then cause the object’s deallocator to be called. The deallocator is a function pointer contained in the object’s type structure. The type-specific deallocator takes care of decrementing the reference counts for other objects contained in the object if this is a compound object type, such as a list, as well as performing any additional finalization that’s needed. There’s no chance that the reference count can overflow; at least as many bits are used to hold the reference count as there are distinct memory locations in virtual memory (assuming sizeof(Py_ssize_t) >= sizeof(void*)). Thus, the reference count increment is a simple operation.

It is not necessary to increment an object’s reference count for every local variable that contains a pointer to an object. In theory, the object’s reference count goes up by one when the variable is made to point to it and it goes down by one when the variable goes out of scope. However, these two cancel each other out, so at the end the reference count hasn’t changed. The only real reason to use the reference count is to prevent the object from being deallocated as long as our variable is pointing to it. If we know that there is at least one other reference to the object that lives at least as long as our variable, there is no need to increment the reference count temporarily. An important situation where this arises is in objects that are passed as arguments to C functions in an extension module that are called from Python; the call mechanism guarantees to hold a reference to every argument for the duration of the call.

However, a common pitfall is to extract an object from a list and hold on to it for a while without incrementing its reference count. Some other operation might conceivably remove the object from the list, decrementing its reference count and possibly deallocating it. The real danger is that innocent-looking operations may invoke arbitrary Python code which could do this; there is a code path which allows control to flow back to the user from a Py_DECREF(), so almost any operation is potentially dangerous.

A safe approach is to always use the generic operations (functions whose name begins with PyObject_, PyNumber_, PySequence_ or PyMapping_). These operations always increment the reference count of the object they return. This leaves the caller with the responsibility to call Py_DECREF() when they are done with the result; this soon becomes second nature.

Reference Count Details
The reference count behavior of functions in the Python/C API is best explained in terms of ownership of references. Ownership pertains to references, never to objects (objects are not owned: they are always shared). “Owning a reference” means being responsible for calling Py_DECREF on it when the reference is no longer needed. Ownership can also be transferred, meaning that the code that receives ownership of the reference then becomes responsible for eventually decref’ing it by calling Py_DECREF() or Py_XDECREF() when it’s no longer needed—or passing on this responsibility (usually to its caller). When a function passes ownership of a reference on to its caller, the caller is said to receive a new reference. When no ownership is transferred, the caller is said to borrow the reference. Nothing needs to be done for a borrowed reference.

Conversely, when a calling function passes in a reference to an object, there are two possibilities: the function steals a reference to the object, or it does not. Stealing a reference means that when you pass a reference to a function, that function assumes that it now owns that reference, and you are not responsible for it any longer.

Few functions steal references; the two notable exceptions are PyList_SetItem() and PyTuple_SetItem(), which steal a reference to the item (but not to the tuple or list into which the item is put!). These functions were designed to steal a reference because of a common idiom for populating a tuple or list with newly created objects; for example, the code to create the tuple (1, 2, "three") could look like this (forgetting about error handling for the moment; a better way to code this is shown below):

PyObject *t;

t = PyTuple_New(3);
PyTuple_SetItem(t, 0, PyLong_FromLong(1L));
PyTuple_SetItem(t, 1, PyLong_FromLong(2L));
PyTuple_SetItem(t, 2, PyUnicode_FromString("three"));
Here, PyLong_FromLong() returns a new reference which is immediately stolen by PyTuple_SetItem(). When you want to keep using an object although the reference to it will be stolen, use Py_INCREF() to grab another reference before calling the reference-stealing function.

Incidentally, PyTuple_SetItem() is the only way to set tuple items; PySequence_SetItem() and PyObject_SetItem() refuse to do this since tuples are an immutable data type. You should only use PyTuple_SetItem() for tuples that you are creating yourself.

Equivalent code for populating a list can be written using PyList_New() and PyList_SetItem().

However, in practice, you will rarely use these ways of creating and populating a tuple or list. There’s a generic function, Py_BuildValue(), that can create most common objects from C values, directed by a format string. For example, the above two blocks of code could be replaced by the following (which also takes care of the error checking):

PyObject *tuple, *list;

tuple = Py_BuildValue("(iis)", 1, 2, "three");
list = Py_BuildValue("[iis]", 1, 2, "three");
It is much more common to use PyObject_SetItem() and friends with items whose references you are only borrowing, like arguments that were passed in to the function you are writing. In that case, their behaviour regarding reference counts is much saner, since you don’t have to increment a reference count so you can give a reference away (“have it be stolen”). For example, this function sets all items of a list (actually, any mutable sequence) to a given item:

int
set_all(PyObject *target, PyObject *item)
{
    Py_ssize_t i, n;

    n = PyObject_Length(target);
    if (n < 0)
        return -1;
    for (i = 0; i < n; i++) {
        PyObject *index = PyLong_FromSsize_t(i);
        if (!index)
            return -1;
        if (PyObject_SetItem(target, index, item) < 0) {
            Py_DECREF(index);
            return -1;
        }
        Py_DECREF(index);
    }
    return 0;
}
The situation is slightly different for function return values. While passing a reference to most functions does not change your ownership responsibilities for that reference, many functions that return a reference to an object give you ownership of the reference. The reason is simple: in many cases, the returned object is created on the fly, and the reference you get is the only reference to the object. Therefore, the generic functions that return object references, like PyObject_GetItem() and PySequence_GetItem(), always return a new reference (the caller becomes the owner of the reference).

It is important to realize that whether you own a reference returned by a function depends on which function you call only — the plumage (the type of the object passed as an argument to the function) doesn’t enter into it! Thus, if you extract an item from a list using PyList_GetItem(), you don’t own the reference — but if you obtain the same item from the same list using PySequence_GetItem() (which happens to take exactly the same arguments), you do own a reference to the returned object.

Here is an example of how you could write a function that computes the sum of the items in a list of integers; once using PyList_GetItem(), and once using PySequence_GetItem().

long
sum_list(PyObject *list)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;

    n = PyList_Size(list);
    if (n < 0)
        return -1; /* Not a list */
    for (i = 0; i < n; i++) {
        item = PyList_GetItem(list, i); /* Can't fail */
        if (!PyLong_Check(item)) continue; /* Skip non-integers */
        value = PyLong_AsLong(item);
        if (value == -1 && PyErr_Occurred())
            /* Integer too big to fit in a C long, bail out */
            return -1;
        total += value;
    }
    return total;
}
long
sum_sequence(PyObject *sequence)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;
    n = PySequence_Length(sequence);
    if (n < 0)
        return -1; /* Has no length */
    for (i = 0; i < n; i++) {
        item = PySequence_GetItem(sequence, i);
        if (item == NULL)
            return -1; /* Not a sequence, or other failure */
        if (PyLong_Check(item)) {
            value = PyLong_AsLong(item);
            Py_DECREF(item);
            if (value == -1 && PyErr_Occurred())
                /* Integer too big to fit in a C long, bail out */
                return -1;
            total += value;
        }
        else {
            Py_DECREF(item); /* Discard reference ownership */
        }
    }
    return total;
}
Types
There are few other data types that play a significant role in the Python/C API; most are simple C types such as int, long, double and char*. A few structure types are used to describe static tables used to list the functions exported by a module or the data attributes of a new object type, and another is used to describe the value of a complex number. These will be discussed together with the functions that use them.

type Py_ssize_t
Part of the Stable ABI.
A signed integral type such that sizeof(Py_ssize_t) == sizeof(size_t). C99 doesn’t define such a thing directly (size_t is an unsigned integral type). See PEP 353 for details. PY_SSIZE_T_MAX is the largest positive value of type Py_ssize_t.

Exceptions
The Python programmer only needs to deal with exceptions if specific error handling is required; unhandled exceptions are automatically propagated to the caller, then to the caller’s caller, and so on, until they reach the top-level interpreter, where they are reported to the user accompanied by a stack traceback.

For C programmers, however, error checking always has to be explicit. All functions in the Python/C API can raise exceptions, unless an explicit claim is made otherwise in a function’s documentation. In general, when a function encounters an error, it sets an exception, discards any object references that it owns, and returns an error indicator. If not documented otherwise, this indicator is either NULL or -1, depending on the function’s return type. A few functions return a Boolean true/false result, with false indicating an error. Very few functions return no explicit error indicator or have an ambiguous return value, and require explicit testing for errors with PyErr_Occurred(). These exceptions are always explicitly documented.

Exception state is maintained in per-thread storage (this is equivalent to using global storage in an unthreaded application). A thread can be in one of two states: an exception has occurred, or not. The function PyErr_Occurred() can be used to check for this: it returns a borrowed reference to the exception type object when an exception has occurred, and NULL otherwise. There are a number of functions to set the exception state: PyErr_SetString() is the most common (though not the most general) function to set the exception state, and PyErr_Clear() clears the exception state.

The full exception state consists of three objects (all of which can be NULL): the exception type, the corresponding exception value, and the traceback. These have the same meanings as the Python result of sys.exc_info(); however, they are not the same: the Python objects represent the last exception being handled by a Python try … except statement, while the C level exception state only exists while an exception is being passed on between C functions until it reaches the Python bytecode interpreter’s main loop, which takes care of transferring it to sys.exc_info() and friends.

Note that starting with Python 1.5, the preferred, thread-safe way to access the exception state from Python code is to call the function sys.exc_info(), which returns the per-thread exception state for Python code. Also, the semantics of both ways to access the exception state have changed so that a function which catches an exception will save and restore its thread’s exception state so as to preserve the exception state of its caller. This prevents common bugs in exception handling code caused by an innocent-looking function overwriting the exception being handled; it also reduces the often unwanted lifetime extension for objects that are referenced by the stack frames in the traceback.

As a general principle, a function that calls another function to perform some task should check whether the called function raised an exception, and if so, pass the exception state on to its caller. It should discard any object references that it owns, and return an error indicator, but it should not set another exception — that would overwrite the exception that was just raised, and lose important information about the exact cause of the error.

A simple example of detecting exceptions and passing them on is shown in the sum_sequence() example above. It so happens that this example doesn’t need to clean up any owned references when it detects an error. The following example function shows some error cleanup. First, to remind you why you like Python, we show the equivalent Python code:

def incr_item(dict, key):
    try:
        item = dict[key]
    except KeyError:
        item = 0
    dict[key] = item + 1
Here is the corresponding C code, in all its glory:

int
incr_item(PyObject *dict, PyObject *key)
{
    /* Objects all initialized to NULL for Py_XDECREF */
    PyObject *item = NULL, *const_one = NULL, *incremented_item = NULL;
    int rv = -1; /* Return value initialized to -1 (failure) */

    item = PyObject_GetItem(dict, key);
    if (item == NULL) {
        /* Handle KeyError only: */
        if (!PyErr_ExceptionMatches(PyExc_KeyError))
            goto error;

        /* Clear the error and use zero: */
        PyErr_Clear();
        item = PyLong_FromLong(0L);
        if (item == NULL)
            goto error;
    }
    const_one = PyLong_FromLong(1L);
    if (const_one == NULL)
        goto error;

    incremented_item = PyNumber_Add(item, const_one);
    if (incremented_item == NULL)
        goto error;

    if (PyObject_SetItem(dict, key, incremented_item) < 0)
        goto error;
    rv = 0; /* Success */
    /* Continue with cleanup code */

 error:
    /* Cleanup code, shared by success and failure path */

    /* Use Py_XDECREF() to ignore NULL references */
    Py_XDECREF(item);
    Py_XDECREF(const_one);
    Py_XDECREF(incremented_item);

    return rv; /* -1 for error, 0 for success */
}
This example represents an endorsed use of the goto statement in C! It illustrates the use of PyErr_ExceptionMatches() and PyErr_Clear() to handle specific exceptions, and the use of Py_XDECREF() to dispose of owned references that may be NULL (note the 'X' in the name; Py_DECREF() would crash when confronted with a NULL reference). It is important that the variables used to hold owned references are initialized to NULL for this to work; likewise, the proposed return value is initialized to -1 (failure) and only set to success after the final call made is successful.

Embedding Python
The one important task that only embedders (as opposed to extension writers) of the Python interpreter have to worry about is the initialization, and possibly the finalization, of the Python interpreter. Most functionality of the interpreter can only be used after the interpreter has been initialized.

The basic initialization function is Py_Initialize(). This initializes the table of loaded modules, and creates the fundamental modules builtins, __main__, and sys. It also initializes the module search path (sys.path).

Py_Initialize() does not set the “script argument list” (sys.argv). If this variable is needed by Python code that will be executed later, it must be set explicitly with a call to PySys_SetArgvEx(argc, argv, updatepath) after the call to Py_Initialize().

On most systems (in particular, on Unix and Windows, although the details are slightly different), Py_Initialize() calculates the module search path based upon its best guess for the location of the standard Python interpreter executable, assuming that the Python library is found in a fixed location relative to the Python interpreter executable. In particular, it looks for a directory named lib/pythonX.Y relative to the parent directory where the executable named python is found on the shell command search path (the environment variable PATH).

For instance, if the Python executable is found in /usr/local/bin/python, it will assume that the libraries are in /usr/local/lib/pythonX.Y. (In fact, this particular path is also the “fallback” location, used when no executable file named python is found along PATH.) The user can override this behavior by setting the environment variable PYTHONHOME, or insert additional directories in front of the standard path by setting PYTHONPATH.

The embedding application can steer the search by calling Py_SetProgramName(file) before calling Py_Initialize(). Note that PYTHONHOME still overrides this and PYTHONPATH is still inserted in front of the standard path. An application that requires total control has to provide its own implementation of Py_GetPath(), Py_GetPrefix(), Py_GetExecPrefix(), and Py_GetProgramFullPath() (all defined in Modules/getpath.c).

Sometimes, it is desirable to “uninitialize” Python. For instance, the application may want to start over (make another call to Py_Initialize()) or the application is simply done with its use of Python and wants to free memory allocated by Python. This can be accomplished by calling Py_FinalizeEx(). The function Py_IsInitialized() returns true if Python is currently in the initialized state. More information about these functions is given in a later chapter. Notice that Py_FinalizeEx() does not free all memory allocated by the Python interpreter, e.g. memory allocated by extension modules currently cannot be released.

Debugging Builds
Python can be built with several macros to enable extra checks of the interpreter and extension modules. These checks tend to add a large amount of overhead to the runtime so they are not enabled by default.

A full list of the various types of debugging builds is in the file Misc/SpecialBuilds.txt in the Python source distribution. Builds are available that support tracing of reference counts, debugging the memory allocator, or low-level profiling of the main interpreter loop. Only the most frequently used builds will be described in the remainder of this section.

Compiling the interpreter with the Py_DEBUG macro defined produces what is generally meant by a debug build of Python. Py_DEBUG is enabled in the Unix build by adding --with-pydebug to the ./configure command. It is also implied by the presence of the not-Python-specific _DEBUG macro. When Py_DEBUG is enabled in the Unix build, compiler optimization is disabled.

In addition to the reference count debugging described below, extra checks are performed, see Python Debug Build.

Defining Py_TRACE_REFS enables reference tracing (see the configure --with-trace-refs option). When defined, a circular doubly linked list of active objects is maintained by adding two extra fields to every PyObject. Total allocations are tracked as well. Upon exit, all existing references are printed. (In interactive mode this happens after every statement run by the interpreter.)

Please refer to Misc/SpecialBuilds.txt in the Python source distribution for more detailed information.

Table of Contents
Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Reference Counts
Reference Count Details
Types
Exceptions
Embedding Python
Debugging Builds
Previous topic
Python/C API Reference Manual

Next topic
C API Stability

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
Introduction
The Application Programmer’s Interface to Python gives C and C++ programmers access to the Python interpreter at a variety of levels. The API is equally usable from C++, but for brevity it is generally referred to as the Python/C API. There are two fundamentally different reasons for using the Python/C API. The first reason is to write extension modules for specific purposes; these are C modules that extend the Python interpreter. This is probably the most common use. The second reason is to use Python as a component in a larger application; this technique is generally referred to as embedding Python in an application.

Writing an extension module is a relatively well-understood process, where a “cookbook” approach works well. There are several tools that automate the process to some extent. While people have embedded Python in other applications since its early existence, the process of embedding Python is less straightforward than writing an extension.

Many API functions are useful independent of whether you’re embedding or extending Python; moreover, most applications that embed Python will need to provide a custom extension as well, so it’s probably a good idea to become familiar with writing an extension before attempting to embed Python in a real application.

Coding standards
If you’re writing C code for inclusion in CPython, you must follow the guidelines and standards defined in PEP 7. These guidelines apply regardless of the version of Python you are contributing to. Following these conventions is not necessary for your own third party extension modules, unless you eventually expect to contribute them to Python.

Include Files
All function, type and macro definitions needed to use the Python/C API are included in your code by the following line:

#define PY_SSIZE_T_CLEAN
#include <Python.h>
This implies inclusion of the following standard headers: <stdio.h>, <string.h>, <errno.h>, <limits.h>, <assert.h> and <stdlib.h> (if available).

Note Since Python may define some pre-processor definitions which affect the standard headers on some systems, you must include Python.h before any standard headers are included.
It is recommended to always define PY_SSIZE_T_CLEAN before including Python.h. See Parsing arguments and building values for a description of this macro.

All user visible names defined by Python.h (except those defined by the included standard headers) have one of the prefixes Py or _Py. Names beginning with _Py are for internal use by the Python implementation and should not be used by extension writers. Structure member names do not have a reserved prefix.

Note User code should never define names that begin with Py or _Py. This confuses the reader, and jeopardizes the portability of the user code to future Python versions, which may define additional names beginning with one of these prefixes.
The header files are typically installed with Python. On Unix, these are located in the directories prefix/include/pythonversion/ and exec_prefix/include/pythonversion/, where prefix and exec_prefix are defined by the corresponding parameters to Python’s configure script and version is '%d.%d' % sys.version_info[:2]. On Windows, the headers are installed in prefix/include, where prefix is the installation directory specified to the installer.

To include the headers, place both directories (if different) on your compiler’s search path for includes. Do not place the parent directories on the search path and then use #include <pythonX.Y/Python.h>; this will break on multi-platform builds since the platform independent headers under prefix include the platform specific headers from exec_prefix.

C++ users should note that although the API is defined entirely using C, the header files properly declare the entry points to be extern "C". As a result, there is no need to do anything special to use the API from C++.

Useful macros
Several useful macros are defined in the Python header files. Many are defined closer to where they are useful (e.g. Py_RETURN_NONE). Others of a more general utility are defined here. This is not necessarily a complete listing.

Py_UNREACHABLE()
Use this when you have a code path that cannot be reached by design. For example, in the default: clause in a switch statement for which all possible values are covered in case statements. Use this in places where you might be tempted to put an assert(0) or abort() call.

In release mode, the macro helps the compiler to optimize the code, and avoids a warning about unreachable code. For example, the macro is implemented with __builtin_unreachable() on GCC in release mode.

A use for Py_UNREACHABLE() is following a call a function that never returns but that is not declared _Py_NO_RETURN.

If a code path is very unlikely code but can be reached under exceptional case, this macro must not be used. For example, under low memory condition or if a system call returns a value out of the expected range. In this case, it’s better to report the error to the caller. If the error cannot be reported to caller, Py_FatalError() can be used.

New in version 3.7.

Py_ABS(x)
Return the absolute value of x.

New in version 3.3.

Py_MIN(x, y)
Return the minimum value between x and y.

New in version 3.3.

Py_MAX(x, y)
Return the maximum value between x and y.

New in version 3.3.

Py_STRINGIFY(x)
Convert x to a C string. E.g. Py_STRINGIFY(123) returns "123".

New in version 3.4.

Py_MEMBER_SIZE(type, member)
Return the size of a structure (type) member in bytes.

New in version 3.6.

Py_CHARMASK(c)
Argument must be a character or an integer in the range [-128, 127] or [0, 255]. This macro returns c cast to an unsigned char.

Py_GETENV(s)
Like getenv(s), but returns NULL if -E was passed on the command line (i.e. if Py_IgnoreEnvironmentFlag is set).

Py_UNUSED(arg)
Use this for unused arguments in a function definition to silence compiler warnings. Example: int func(int a, int Py_UNUSED(b)) { return a; }.

New in version 3.4.

Py_DEPRECATED(version)
Use this for deprecated declarations. The macro must be placed before the symbol name.

Example:

Py_DEPRECATED(3.8) PyAPI_FUNC(int) Py_OldFunction(void);
Changed in version 3.8: MSVC support was added.

PyDoc_STRVAR(name, str)
Creates a variable with name name that can be used in docstrings. If Python is built without docstrings, the value will be empty.

Use PyDoc_STRVAR for docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

PyDoc_STRVAR(pop_doc, "Remove and return the rightmost element.");

static PyMethodDef deque_methods[] = {
    // ...
    {"pop", (PyCFunction)deque_pop, METH_NOARGS, pop_doc},
    // ...
}
PyDoc_STR(str)
Creates a docstring for the given input string or an empty string if docstrings are disabled.

Use PyDoc_STR in specifying docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

static PyMethodDef pysqlite_row_methods[] = {
    {"keys", (PyCFunction)pysqlite_row_keys, METH_NOARGS,
        PyDoc_STR("Returns the keys of the row.")},
    {NULL, NULL}
};
Objects, Types and Reference Counts
Most Python/C API functions have one or more arguments as well as a return value of type PyObject*. This type is a pointer to an opaque data type representing an arbitrary Python object. Since all Python object types are treated the same way by the Python language in most situations (e.g., assignments, scope rules, and argument passing), it is only fitting that they should be represented by a single C type. Almost all Python objects live on the heap: you never declare an automatic or static variable of type PyObject, only pointer variables of type PyObject* can be declared. The sole exception are the type objects; since these must never be deallocated, they are typically static PyTypeObject objects.

All Python objects (even Python integers) have a type and a reference count. An object’s type determines what kind of object it is (e.g., an integer, a list, or a user-defined function; there are many more as explained in The standard type hierarchy). For each of the well-known types there is a macro to check whether an object is of that type; for instance, PyList_Check(a) is true if (and only if) the object pointed to by a is a Python list.

Reference Counts
The reference count is important because today’s computers have a finite (and often severely limited) memory size; it counts how many different places there are that have a reference to an object. Such a place could be another object, or a global (or static) C variable, or a local variable in some C function. When an object’s reference count becomes zero, the object is deallocated. If it contains references to other objects, their reference count is decremented. Those other objects may be deallocated in turn, if this decrement makes their reference count become zero, and so on. (There’s an obvious problem with objects that reference each other here; for now, the solution is “don’t do that.”)

Reference counts are always manipulated explicitly. The normal way is to use the macro Py_INCREF() to increment an object’s reference count by one, and Py_DECREF() to decrement it by one. The Py_DECREF() macro is considerably more complex than the incref one, since it must check whether the reference count becomes zero and then cause the object’s deallocator to be called. The deallocator is a function pointer contained in the object’s type structure. The type-specific deallocator takes care of decrementing the reference counts for other objects contained in the object if this is a compound object type, such as a list, as well as performing any additional finalization that’s needed. There’s no chance that the reference count can overflow; at least as many bits are used to hold the reference count as there are distinct memory locations in virtual memory (assuming sizeof(Py_ssize_t) >= sizeof(void*)). Thus, the reference count increment is a simple operation.

It is not necessary to increment an object’s reference count for every local variable that contains a pointer to an object. In theory, the object’s reference count goes up by one when the variable is made to point to it and it goes down by one when the variable goes out of scope. However, these two cancel each other out, so at the end the reference count hasn’t changed. The only real reason to use the reference count is to prevent the object from being deallocated as long as our variable is pointing to it. If we know that there is at least one other reference to the object that lives at least as long as our variable, there is no need to increment the reference count temporarily. An important situation where this arises is in objects that are passed as arguments to C functions in an extension module that are called from Python; the call mechanism guarantees to hold a reference to every argument for the duration of the call.

However, a common pitfall is to extract an object from a list and hold on to it for a while without incrementing its reference count. Some other operation might conceivably remove the object from the list, decrementing its reference count and possibly deallocating it. The real danger is that innocent-looking operations may invoke arbitrary Python code which could do this; there is a code path which allows control to flow back to the user from a Py_DECREF(), so almost any operation is potentially dangerous.

A safe approach is to always use the generic operations (functions whose name begins with PyObject_, PyNumber_, PySequence_ or PyMapping_). These operations always increment the reference count of the object they return. This leaves the caller with the responsibility to call Py_DECREF() when they are done with the result; this soon becomes second nature.

Reference Count Details
The reference count behavior of functions in the Python/C API is best explained in terms of ownership of references. Ownership pertains to references, never to objects (objects are not owned: they are always shared). “Owning a reference” means being responsible for calling Py_DECREF on it when the reference is no longer needed. Ownership can also be transferred, meaning that the code that receives ownership of the reference then becomes responsible for eventually decref’ing it by calling Py_DECREF() or Py_XDECREF() when it’s no longer needed—or passing on this responsibility (usually to its caller). When a function passes ownership of a reference on to its caller, the caller is said to receive a new reference. When no ownership is transferred, the caller is said to borrow the reference. Nothing needs to be done for a borrowed reference.

Conversely, when a calling function passes in a reference to an object, there are two possibilities: the function steals a reference to the object, or it does not. Stealing a reference means that when you pass a reference to a function, that function assumes that it now owns that reference, and you are not responsible for it any longer.

Few functions steal references; the two notable exceptions are PyList_SetItem() and PyTuple_SetItem(), which steal a reference to the item (but not to the tuple or list into which the item is put!). These functions were designed to steal a reference because of a common idiom for populating a tuple or list with newly created objects; for example, the code to create the tuple (1, 2, "three") could look like this (forgetting about error handling for the moment; a better way to code this is shown below):

PyObject *t;

t = PyTuple_New(3);
PyTuple_SetItem(t, 0, PyLong_FromLong(1L));
PyTuple_SetItem(t, 1, PyLong_FromLong(2L));
PyTuple_SetItem(t, 2, PyUnicode_FromString("three"));
Here, PyLong_FromLong() returns a new reference which is immediately stolen by PyTuple_SetItem(). When you want to keep using an object although the reference to it will be stolen, use Py_INCREF() to grab another reference before calling the reference-stealing function.

Incidentally, PyTuple_SetItem() is the only way to set tuple items; PySequence_SetItem() and PyObject_SetItem() refuse to do this since tuples are an immutable data type. You should only use PyTuple_SetItem() for tuples that you are creating yourself.

Equivalent code for populating a list can be written using PyList_New() and PyList_SetItem().

However, in practice, you will rarely use these ways of creating and populating a tuple or list. There’s a generic function, Py_BuildValue(), that can create most common objects from C values, directed by a format string. For example, the above two blocks of code could be replaced by the following (which also takes care of the error checking):

PyObject *tuple, *list;

tuple = Py_BuildValue("(iis)", 1, 2, "three");
list = Py_BuildValue("[iis]", 1, 2, "three");
It is much more common to use PyObject_SetItem() and friends with items whose references you are only borrowing, like arguments that were passed in to the function you are writing. In that case, their behaviour regarding reference counts is much saner, since you don’t have to increment a reference count so you can give a reference away (“have it be stolen”). For example, this function sets all items of a list (actually, any mutable sequence) to a given item:

int
set_all(PyObject *target, PyObject *item)
{
    Py_ssize_t i, n;

    n = PyObject_Length(target);
    if (n < 0)
        return -1;
    for (i = 0; i < n; i++) {
        PyObject *index = PyLong_FromSsize_t(i);
        if (!index)
            return -1;
        if (PyObject_SetItem(target, index, item) < 0) {
            Py_DECREF(index);
            return -1;
        }
        Py_DECREF(index);
    }
    return 0;
}
The situation is slightly different for function return values. While passing a reference to most functions does not change your ownership responsibilities for that reference, many functions that return a reference to an object give you ownership of the reference. The reason is simple: in many cases, the returned object is created on the fly, and the reference you get is the only reference to the object. Therefore, the generic functions that return object references, like PyObject_GetItem() and PySequence_GetItem(), always return a new reference (the caller becomes the owner of the reference).

It is important to realize that whether you own a reference returned by a function depends on which function you call only — the plumage (the type of the object passed as an argument to the function) doesn’t enter into it! Thus, if you extract an item from a list using PyList_GetItem(), you don’t own the reference — but if you obtain the same item from the same list using PySequence_GetItem() (which happens to take exactly the same arguments), you do own a reference to the returned object.

Here is an example of how you could write a function that computes the sum of the items in a list of integers; once using PyList_GetItem(), and once using PySequence_GetItem().

long
sum_list(PyObject *list)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;

    n = PyList_Size(list);
    if (n < 0)
        return -1; /* Not a list */
    for (i = 0; i < n; i++) {
        item = PyList_GetItem(list, i); /* Can't fail */
        if (!PyLong_Check(item)) continue; /* Skip non-integers */
        value = PyLong_AsLong(item);
        if (value == -1 && PyErr_Occurred())
            /* Integer too big to fit in a C long, bail out */
            return -1;
        total += value;
    }
    return total;
}
long
sum_sequence(PyObject *sequence)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;
    n = PySequence_Length(sequence);
    if (n < 0)
        return -1; /* Has no length */
    for (i = 0; i < n; i++) {
        item = PySequence_GetItem(sequence, i);
        if (item == NULL)
            return -1; /* Not a sequence, or other failure */
        if (PyLong_Check(item)) {
            value = PyLong_AsLong(item);
            Py_DECREF(item);
            if (value == -1 && PyErr_Occurred())
                /* Integer too big to fit in a C long, bail out */
                return -1;
            total += value;
        }
        else {
            Py_DECREF(item); /* Discard reference ownership */
        }
    }
    return total;
}
Types
There are few other data types that play a significant role in the Python/C API; most are simple C types such as int, long, double and char*. A few structure types are used to describe static tables used to list the functions exported by a module or the data attributes of a new object type, and another is used to describe the value of a complex number. These will be discussed together with the functions that use them.

type Py_ssize_t
Part of the Stable ABI.
A signed integral type such that sizeof(Py_ssize_t) == sizeof(size_t). C99 doesn’t define such a thing directly (size_t is an unsigned integral type). See PEP 353 for details. PY_SSIZE_T_MAX is the largest positive value of type Py_ssize_t.

Exceptions
The Python programmer only needs to deal with exceptions if specific error handling is required; unhandled exceptions are automatically propagated to the caller, then to the caller’s caller, and so on, until they reach the top-level interpreter, where they are reported to the user accompanied by a stack traceback.

For C programmers, however, error checking always has to be explicit. All functions in the Python/C API can raise exceptions, unless an explicit claim is made otherwise in a function’s documentation. In general, when a function encounters an error, it sets an exception, discards any object references that it owns, and returns an error indicator. If not documented otherwise, this indicator is either NULL or -1, depending on the function’s return type. A few functions return a Boolean true/false result, with false indicating an error. Very few functions return no explicit error indicator or have an ambiguous return value, and require explicit testing for errors with PyErr_Occurred(). These exceptions are always explicitly documented.

Exception state is maintained in per-thread storage (this is equivalent to using global storage in an unthreaded application). A thread can be in one of two states: an exception has occurred, or not. The function PyErr_Occurred() can be used to check for this: it returns a borrowed reference to the exception type object when an exception has occurred, and NULL otherwise. There are a number of functions to set the exception state: PyErr_SetString() is the most common (though not the most general) function to set the exception state, and PyErr_Clear() clears the exception state.

The full exception state consists of three objects (all of which can be NULL): the exception type, the corresponding exception value, and the traceback. These have the same meanings as the Python result of sys.exc_info(); however, they are not the same: the Python objects represent the last exception being handled by a Python try … except statement, while the C level exception state only exists while an exception is being passed on between C functions until it reaches the Python bytecode interpreter’s main loop, which takes care of transferring it to sys.exc_info() and friends.

Note that starting with Python 1.5, the preferred, thread-safe way to access the exception state from Python code is to call the function sys.exc_info(), which returns the per-thread exception state for Python code. Also, the semantics of both ways to access the exception state have changed so that a function which catches an exception will save and restore its thread’s exception state so as to preserve the exception state of its caller. This prevents common bugs in exception handling code caused by an innocent-looking function overwriting the exception being handled; it also reduces the often unwanted lifetime extension for objects that are referenced by the stack frames in the traceback.

As a general principle, a function that calls another function to perform some task should check whether the called function raised an exception, and if so, pass the exception state on to its caller. It should discard any object references that it owns, and return an error indicator, but it should not set another exception — that would overwrite the exception that was just raised, and lose important information about the exact cause of the error.

A simple example of detecting exceptions and passing them on is shown in the sum_sequence() example above. It so happens that this example doesn’t need to clean up any owned references when it detects an error. The following example function shows some error cleanup. First, to remind you why you like Python, we show the equivalent Python code:

def incr_item(dict, key):
    try:
        item = dict[key]
    except KeyError:
        item = 0
    dict[key] = item + 1
Here is the corresponding C code, in all its glory:

int
incr_item(PyObject *dict, PyObject *key)
{
    /* Objects all initialized to NULL for Py_XDECREF */
    PyObject *item = NULL, *const_one = NULL, *incremented_item = NULL;
    int rv = -1; /* Return value initialized to -1 (failure) */

    item = PyObject_GetItem(dict, key);
    if (item == NULL) {
        /* Handle KeyError only: */
        if (!PyErr_ExceptionMatches(PyExc_KeyError))
            goto error;

        /* Clear the error and use zero: */
        PyErr_Clear();
        item = PyLong_FromLong(0L);
        if (item == NULL)
            goto error;
    }
    const_one = PyLong_FromLong(1L);
    if (const_one == NULL)
        goto error;

    incremented_item = PyNumber_Add(item, const_one);
    if (incremented_item == NULL)
        goto error;

    if (PyObject_SetItem(dict, key, incremented_item) < 0)
        goto error;
    rv = 0; /* Success */
    /* Continue with cleanup code */

 error:
    /* Cleanup code, shared by success and failure path */

    /* Use Py_XDECREF() to ignore NULL references */
    Py_XDECREF(item);
    Py_XDECREF(const_one);
    Py_XDECREF(incremented_item);

    return rv; /* -1 for error, 0 for success */
}
This example represents an endorsed use of the goto statement in C! It illustrates the use of PyErr_ExceptionMatches() and PyErr_Clear() to handle specific exceptions, and the use of Py_XDECREF() to dispose of owned references that may be NULL (note the 'X' in the name; Py_DECREF() would crash when confronted with a NULL reference). It is important that the variables used to hold owned references are initialized to NULL for this to work; likewise, the proposed return value is initialized to -1 (failure) and only set to success after the final call made is successful.

Embedding Python
The one important task that only embedders (as opposed to extension writers) of the Python interpreter have to worry about is the initialization, and possibly the finalization, of the Python interpreter. Most functionality of the interpreter can only be used after the interpreter has been initialized.

The basic initialization function is Py_Initialize(). This initializes the table of loaded modules, and creates the fundamental modules builtins, __main__, and sys. It also initializes the module search path (sys.path).

Py_Initialize() does not set the “script argument list” (sys.argv). If this variable is needed by Python code that will be executed later, it must be set explicitly with a call to PySys_SetArgvEx(argc, argv, updatepath) after the call to Py_Initialize().

On most systems (in particular, on Unix and Windows, although the details are slightly different), Py_Initialize() calculates the module search path based upon its best guess for the location of the standard Python interpreter executable, assuming that the Python library is found in a fixed location relative to the Python interpreter executable. In particular, it looks for a directory named lib/pythonX.Y relative to the parent directory where the executable named python is found on the shell command search path (the environment variable PATH).

For instance, if the Python executable is found in /usr/local/bin/python, it will assume that the libraries are in /usr/local/lib/pythonX.Y. (In fact, this particular path is also the “fallback” location, used when no executable file named python is found along PATH.) The user can override this behavior by setting the environment variable PYTHONHOME, or insert additional directories in front of the standard path by setting PYTHONPATH.

The embedding application can steer the search by calling Py_SetProgramName(file) before calling Py_Initialize(). Note that PYTHONHOME still overrides this and PYTHONPATH is still inserted in front of the standard path. An application that requires total control has to provide its own implementation of Py_GetPath(), Py_GetPrefix(), Py_GetExecPrefix(), and Py_GetProgramFullPath() (all defined in Modules/getpath.c).

Sometimes, it is desirable to “uninitialize” Python. For instance, the application may want to start over (make another call to Py_Initialize()) or the application is simply done with its use of Python and wants to free memory allocated by Python. This can be accomplished by calling Py_FinalizeEx(). The function Py_IsInitialized() returns true if Python is currently in the initialized state. More information about these functions is given in a later chapter. Notice that Py_FinalizeEx() does not free all memory allocated by the Python interpreter, e.g. memory allocated by extension modules currently cannot be released.

Debugging Builds
Python can be built with several macros to enable extra checks of the interpreter and extension modules. These checks tend to add a large amount of overhead to the runtime so they are not enabled by default.

A full list of the various types of debugging builds is in the file Misc/SpecialBuilds.txt in the Python source distribution. Builds are available that support tracing of reference counts, debugging the memory allocator, or low-level profiling of the main interpreter loop. Only the most frequently used builds will be described in the remainder of this section.

Compiling the interpreter with the Py_DEBUG macro defined produces what is generally meant by a debug build of Python. Py_DEBUG is enabled in the Unix build by adding --with-pydebug to the ./configure command. It is also implied by the presence of the not-Python-specific _DEBUG macro. When Py_DEBUG is enabled in the Unix build, compiler optimization is disabled.

In addition to the reference count debugging described below, extra checks are performed, see Python Debug Build.

Defining Py_TRACE_REFS enables reference tracing (see the configure --with-trace-refs option). When defined, a circular doubly linked list of active objects is maintained by adding two extra fields to every PyObject. Total allocations are tracked as well. Upon exit, all existing references are printed. (In interactive mode this happens after every statement run by the interpreter.)

Please refer to Misc/SpecialBuilds.txt in the Python source distribution for more detailed information.

Table of Contents
Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Reference Counts
Reference Count Details
Types
Exceptions
Embedding Python
Debugging Builds
Previous topic
Python/C API Reference Manual

Next topic
C API Stability

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
Introduction
The Application Programmer’s Interface to Python gives C and C++ programmers access to the Python interpreter at a variety of levels. The API is equally usable from C++, but for brevity it is generally referred to as the Python/C API. There are two fundamentally different reasons for using the Python/C API. The first reason is to write extension modules for specific purposes; these are C modules that extend the Python interpreter. This is probably the most common use. The second reason is to use Python as a component in a larger application; this technique is generally referred to as embedding Python in an application.

Writing an extension module is a relatively well-understood process, where a “cookbook” approach works well. There are several tools that automate the process to some extent. While people have embedded Python in other applications since its early existence, the process of embedding Python is less straightforward than writing an extension.

Many API functions are useful independent of whether you’re embedding or extending Python; moreover, most applications that embed Python will need to provide a custom extension as well, so it’s probably a good idea to become familiar with writing an extension before attempting to embed Python in a real application.

Coding standards
If you’re writing C code for inclusion in CPython, you must follow the guidelines and standards defined in PEP 7. These guidelines apply regardless of the version of Python you are contributing to. Following these conventions is not necessary for your own third party extension modules, unless you eventually expect to contribute them to Python.

Include Files
All function, type and macro definitions needed to use the Python/C API are included in your code by the following line:

#define PY_SSIZE_T_CLEAN
#include <Python.h>
This implies inclusion of the following standard headers: <stdio.h>, <string.h>, <errno.h>, <limits.h>, <assert.h> and <stdlib.h> (if available).

Note Since Python may define some pre-processor definitions which affect the standard headers on some systems, you must include Python.h before any standard headers are included.
It is recommended to always define PY_SSIZE_T_CLEAN before including Python.h. See Parsing arguments and building values for a description of this macro.

All user visible names defined by Python.h (except those defined by the included standard headers) have one of the prefixes Py or _Py. Names beginning with _Py are for internal use by the Python implementation and should not be used by extension writers. Structure member names do not have a reserved prefix.

Note User code should never define names that begin with Py or _Py. This confuses the reader, and jeopardizes the portability of the user code to future Python versions, which may define additional names beginning with one of these prefixes.
The header files are typically installed with Python. On Unix, these are located in the directories prefix/include/pythonversion/ and exec_prefix/include/pythonversion/, where prefix and exec_prefix are defined by the corresponding parameters to Python’s configure script and version is '%d.%d' % sys.version_info[:2]. On Windows, the headers are installed in prefix/include, where prefix is the installation directory specified to the installer.

To include the headers, place both directories (if different) on your compiler’s search path for includes. Do not place the parent directories on the search path and then use #include <pythonX.Y/Python.h>; this will break on multi-platform builds since the platform independent headers under prefix include the platform specific headers from exec_prefix.

C++ users should note that although the API is defined entirely using C, the header files properly declare the entry points to be extern "C". As a result, there is no need to do anything special to use the API from C++.

Useful macros
Several useful macros are defined in the Python header files. Many are defined closer to where they are useful (e.g. Py_RETURN_NONE). Others of a more general utility are defined here. This is not necessarily a complete listing.

Py_UNREACHABLE()
Use this when you have a code path that cannot be reached by design. For example, in the default: clause in a switch statement for which all possible values are covered in case statements. Use this in places where you might be tempted to put an assert(0) or abort() call.

In release mode, the macro helps the compiler to optimize the code, and avoids a warning about unreachable code. For example, the macro is implemented with __builtin_unreachable() on GCC in release mode.

A use for Py_UNREACHABLE() is following a call a function that never returns but that is not declared _Py_NO_RETURN.

If a code path is very unlikely code but can be reached under exceptional case, this macro must not be used. For example, under low memory condition or if a system call returns a value out of the expected range. In this case, it’s better to report the error to the caller. If the error cannot be reported to caller, Py_FatalError() can be used.

New in version 3.7.

Py_ABS(x)
Return the absolute value of x.

New in version 3.3.

Py_MIN(x, y)
Return the minimum value between x and y.

New in version 3.3.

Py_MAX(x, y)
Return the maximum value between x and y.

New in version 3.3.

Py_STRINGIFY(x)
Convert x to a C string. E.g. Py_STRINGIFY(123) returns "123".

New in version 3.4.

Py_MEMBER_SIZE(type, member)
Return the size of a structure (type) member in bytes.

New in version 3.6.

Py_CHARMASK(c)
Argument must be a character or an integer in the range [-128, 127] or [0, 255]. This macro returns c cast to an unsigned char.

Py_GETENV(s)
Like getenv(s), but returns NULL if -E was passed on the command line (i.e. if Py_IgnoreEnvironmentFlag is set).

Py_UNUSED(arg)
Use this for unused arguments in a function definition to silence compiler warnings. Example: int func(int a, int Py_UNUSED(b)) { return a; }.

New in version 3.4.

Py_DEPRECATED(version)
Use this for deprecated declarations. The macro must be placed before the symbol name.

Example:

Py_DEPRECATED(3.8) PyAPI_FUNC(int) Py_OldFunction(void);
Changed in version 3.8: MSVC support was added.

PyDoc_STRVAR(name, str)
Creates a variable with name name that can be used in docstrings. If Python is built without docstrings, the value will be empty.

Use PyDoc_STRVAR for docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

PyDoc_STRVAR(pop_doc, "Remove and return the rightmost element.");

static PyMethodDef deque_methods[] = {
    // ...
    {"pop", (PyCFunction)deque_pop, METH_NOARGS, pop_doc},
    // ...
}
PyDoc_STR(str)
Creates a docstring for the given input string or an empty string if docstrings are disabled.

Use PyDoc_STR in specifying docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

static PyMethodDef pysqlite_row_methods[] = {
    {"keys", (PyCFunction)pysqlite_row_keys, METH_NOARGS,
        PyDoc_STR("Returns the keys of the row.")},
    {NULL, NULL}
};
Objects, Types and Reference Counts
Most Python/C API functions have one or more arguments as well as a return value of type PyObject*. This type is a pointer to an opaque data type representing an arbitrary Python object. Since all Python object types are treated the same way by the Python language in most situations (e.g., assignments, scope rules, and argument passing), it is only fitting that they should be represented by a single C type. Almost all Python objects live on the heap: you never declare an automatic or static variable of type PyObject, only pointer variables of type PyObject* can be declared. The sole exception are the type objects; since these must never be deallocated, they are typically static PyTypeObject objects.

All Python objects (even Python integers) have a type and a reference count. An object’s type determines what kind of object it is (e.g., an integer, a list, or a user-defined function; there are many more as explained in The standard type hierarchy). For each of the well-known types there is a macro to check whether an object is of that type; for instance, PyList_Check(a) is true if (and only if) the object pointed to by a is a Python list.

Reference Counts¶
The reference count is important because today’s computers have a finite (and often severely limited) memory size; it counts how many different places there are that have a reference to an object. Such a place could be another object, or a global (or static) C variable, or a local variable in some C function. When an object’s reference count becomes zero, the object is deallocated. If it contains references to other objects, their reference count is decremented. Those other objects may be deallocated in turn, if this decrement makes their reference count become zero, and so on. (There’s an obvious problem with objects that reference each other here; for now, the solution is “don’t do that.”)

Reference counts are always manipulated explicitly. The normal way is to use the macro Py_INCREF() to increment an object’s reference count by one, and Py_DECREF() to decrement it by one. The Py_DECREF() macro is considerably more complex than the incref one, since it must check whether the reference count becomes zero and then cause the object’s deallocator to be called. The deallocator is a function pointer contained in the object’s type structure. The type-specific deallocator takes care of decrementing the reference counts for other objects contained in the object if this is a compound object type, such as a list, as well as performing any additional finalization that’s needed. There’s no chance that the reference count can overflow; at least as many bits are used to hold the reference count as there are distinct memory locations in virtual memory (assuming sizeof(Py_ssize_t) >= sizeof(void*)). Thus, the reference count increment is a simple operation.

It is not necessary to increment an object’s reference count for every local variable that contains a pointer to an object. In theory, the object’s reference count goes up by one when the variable is made to point to it and it goes down by one when the variable goes out of scope. However, these two cancel each other out, so at the end the reference count hasn’t changed. The only real reason to use the reference count is to prevent the object from being deallocated as long as our variable is pointing to it. If we know that there is at least one other reference to the object that lives at least as long as our variable, there is no need to increment the reference count temporarily. An important situation where this arises is in objects that are passed as arguments to C functions in an extension module that are called from Python; the call mechanism guarantees to hold a reference to every argument for the duration of the call.

However, a common pitfall is to extract an object from a list and hold on to it for a while without incrementing its reference count. Some other operation might conceivably remove the object from the list, decrementing its reference count and possibly deallocating it. The real danger is that innocent-looking operations may invoke arbitrary Python code which could do this; there is a code path which allows control to flow back to the user from a Py_DECREF(), so almost any operation is potentially dangerous.

A safe approach is to always use the generic operations (functions whose name begins with PyObject_, PyNumber_, PySequence_ or PyMapping_). These operations always increment the reference count of the object they return. This leaves the caller with the responsibility to call Py_DECREF() when they are done with the result; this soon becomes second nature.

Reference Count Details
The reference count behavior of functions in the Python/C API is best explained in terms of ownership of references. Ownership pertains to references, never to objects (objects are not owned: they are always shared). “Owning a reference” means being responsible for calling Py_DECREF on it when the reference is no longer needed. Ownership can also be transferred, meaning that the code that receives ownership of the reference then becomes responsible for eventually decref’ing it by calling Py_DECREF() or Py_XDECREF() when it’s no longer needed—or passing on this responsibility (usually to its caller). When a function passes ownership of a reference on to its caller, the caller is said to receive a new reference. When no ownership is transferred, the caller is said to borrow the reference. Nothing needs to be done for a borrowed reference.

Conversely, when a calling function passes in a reference to an object, there are two possibilities: the function steals a reference to the object, or it does not. Stealing a reference means that when you pass a reference to a function, that function assumes that it now owns that reference, and you are not responsible for it any longer.

Few functions steal references; the two notable exceptions are PyList_SetItem() and PyTuple_SetItem(), which steal a reference to the item (but not to the tuple or list into which the item is put!). These functions were designed to steal a reference because of a common idiom for populating a tuple or list with newly created objects; for example, the code to create the tuple (1, 2, "three") could look like this (forgetting about error handling for the moment; a better way to code this is shown below):

PyObject *t;

t = PyTuple_New(3);
PyTuple_SetItem(t, 0, PyLong_FromLong(1L));
PyTuple_SetItem(t, 1, PyLong_FromLong(2L));
PyTuple_SetItem(t, 2, PyUnicode_FromString("three"));
Here, PyLong_FromLong() returns a new reference which is immediately stolen by PyTuple_SetItem(). When you want to keep using an object although the reference to it will be stolen, use Py_INCREF() to grab another reference before calling the reference-stealing function.

Incidentally, PyTuple_SetItem() is the only way to set tuple items; PySequence_SetItem() and PyObject_SetItem() refuse to do this since tuples are an immutable data type. You should only use PyTuple_SetItem() for tuples that you are creating yourself.

Equivalent code for populating a list can be written using PyList_New() and PyList_SetItem().

However, in practice, you will rarely use these ways of creating and populating a tuple or list. There’s a generic function, Py_BuildValue(), that can create most common objects from C values, directed by a format string. For example, the above two blocks of code could be replaced by the following (which also takes care of the error checking):

PyObject *tuple, *list;

tuple = Py_BuildValue("(iis)", 1, 2, "three");
list = Py_BuildValue("[iis]", 1, 2, "three");
It is much more common to use PyObject_SetItem() and friends with items whose references you are only borrowing, like arguments that were passed in to the function you are writing. In that case, their behaviour regarding reference counts is much saner, since you don’t have to increment a reference count so you can give a reference away (“have it be stolen”). For example, this function sets all items of a list (actually, any mutable sequence) to a given item:

int
set_all(PyObject *target, PyObject *item)
{
    Py_ssize_t i, n;

    n = PyObject_Length(target);
    if (n < 0)
        return -1;
    for (i = 0; i < n; i++) {
        PyObject *index = PyLong_FromSsize_t(i);
        if (!index)
            return -1;
        if (PyObject_SetItem(target, index, item) < 0) {
            Py_DECREF(index);
            return -1;
        }
        Py_DECREF(index);
    }
    return 0;
}
The situation is slightly different for function return values. While passing a reference to most functions does not change your ownership responsibilities for that reference, many functions that return a reference to an object give you ownership of the reference. The reason is simple: in many cases, the returned object is created on the fly, and the reference you get is the only reference to the object. Therefore, the generic functions that return object references, like PyObject_GetItem() and PySequence_GetItem(), always return a new reference (the caller becomes the owner of the reference).

It is important to realize that whether you own a reference returned by a function depends on which function you call only — the plumage (the type of the object passed as an argument to the function) doesn’t enter into it! Thus, if you extract an item from a list using PyList_GetItem(), you don’t own the reference — but if you obtain the same item from the same list using PySequence_GetItem() (which happens to take exactly the same arguments), you do own a reference to the returned object.

Here is an example of how you could write a function that computes the sum of the items in a list of integers; once using PyList_GetItem(), and once using PySequence_GetItem().

long
sum_list(PyObject *list)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;

    n = PyList_Size(list);
    if (n < 0)
        return -1; /* Not a list */
    for (i = 0; i < n; i++) {
        item = PyList_GetItem(list, i); /* Can't fail */
        if (!PyLong_Check(item)) continue; /* Skip non-integers */
        value = PyLong_AsLong(item);
        if (value == -1 && PyErr_Occurred())
            /* Integer too big to fit in a C long, bail out */
            return -1;
        total += value;
    }
    return total;
}
long
sum_sequence(PyObject *sequence)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;
    n = PySequence_Length(sequence);
    if (n < 0)
        return -1; /* Has no length */
    for (i = 0; i < n; i++) {
        item = PySequence_GetItem(sequence, i);
        if (item == NULL)
            return -1; /* Not a sequence, or other failure */
        if (PyLong_Check(item)) {
            value = PyLong_AsLong(item);
            Py_DECREF(item);
            if (value == -1 && PyErr_Occurred())
                /* Integer too big to fit in a C long, bail out */
                return -1;
            total += value;
        }
        else {
            Py_DECREF(item); /* Discard reference ownership */
        }
    }
    return total;
}
Types
There are few other data types that play a significant role in the Python/C API; most are simple C types such as int, long, double and char*. A few structure types are used to describe static tables used to list the functions exported by a module or the data attributes of a new object type, and another is used to describe the value of a complex number. These will be discussed together with the functions that use them.

type Py_ssize_t
Part of the Stable ABI.
A signed integral type such that sizeof(Py_ssize_t) == sizeof(size_t). C99 doesn’t define such a thing directly (size_t is an unsigned integral type). See PEP 353 for details. PY_SSIZE_T_MAX is the largest positive value of type Py_ssize_t.

Exceptions
The Python programmer only needs to deal with exceptions if specific error handling is required; unhandled exceptions are automatically propagated to the caller, then to the caller’s caller, and so on, until they reach the top-level interpreter, where they are reported to the user accompanied by a stack traceback.

For C programmers, however, error checking always has to be explicit. All functions in the Python/C API can raise exceptions, unless an explicit claim is made otherwise in a function’s documentation. In general, when a function encounters an error, it sets an exception, discards any object references that it owns, and returns an error indicator. If not documented otherwise, this indicator is either NULL or -1, depending on the function’s return type. A few functions return a Boolean true/false result, with false indicating an error. Very few functions return no explicit error indicator or have an ambiguous return value, and require explicit testing for errors with PyErr_Occurred(). These exceptions are always explicitly documented.

Exception state is maintained in per-thread storage (this is equivalent to using global storage in an unthreaded application). A thread can be in one of two states: an exception has occurred, or not. The function PyErr_Occurred() can be used to check for this: it returns a borrowed reference to the exception type object when an exception has occurred, and NULL otherwise. There are a number of functions to set the exception state: PyErr_SetString() is the most common (though not the most general) function to set the exception state, and PyErr_Clear() clears the exception state.

The full exception state consists of three objects (all of which can be NULL): the exception type, the corresponding exception value, and the traceback. These have the same meanings as the Python result of sys.exc_info(); however, they are not the same: the Python objects represent the last exception being handled by a Python try … except statement, while the C level exception state only exists while an exception is being passed on between C functions until it reaches the Python bytecode interpreter’s main loop, which takes care of transferring it to sys.exc_info() and friends.

Note that starting with Python 1.5, the preferred, thread-safe way to access the exception state from Python code is to call the function sys.exc_info(), which returns the per-thread exception state for Python code. Also, the semantics of both ways to access the exception state have changed so that a function which catches an exception will save and restore its thread’s exception state so as to preserve the exception state of its caller. This prevents common bugs in exception handling code caused by an innocent-looking function overwriting the exception being handled; it also reduces the often unwanted lifetime extension for objects that are referenced by the stack frames in the traceback.

As a general principle, a function that calls another function to perform some task should check whether the called function raised an exception, and if so, pass the exception state on to its caller. It should discard any object references that it owns, and return an error indicator, but it should not set another exception — that would overwrite the exception that was just raised, and lose important information about the exact cause of the error.

A simple example of detecting exceptions and passing them on is shown in the sum_sequence() example above. It so happens that this example doesn’t need to clean up any owned references when it detects an error. The following example function shows some error cleanup. First, to remind you why you like Python, we show the equivalent Python code:

def incr_item(dict, key):
    try:
        item = dict[key]
    except KeyError:
        item = 0
    dict[key] = item + 1
Here is the corresponding C code, in all its glory:

int
incr_item(PyObject *dict, PyObject *key)
{
    /* Objects all initialized to NULL for Py_XDECREF */
    PyObject *item = NULL, *const_one = NULL, *incremented_item = NULL;
    int rv = -1; /* Return value initialized to -1 (failure) */

    item = PyObject_GetItem(dict, key);
    if (item == NULL) {
        /* Handle KeyError only: */
        if (!PyErr_ExceptionMatches(PyExc_KeyError))
            goto error;

        /* Clear the error and use zero: */
        PyErr_Clear();
        item = PyLong_FromLong(0L);
        if (item == NULL)
            goto error;
    }
    const_one = PyLong_FromLong(1L);
    if (const_one == NULL)
        goto error;

    incremented_item = PyNumber_Add(item, const_one);
    if (incremented_item == NULL)
        goto error;

    if (PyObject_SetItem(dict, key, incremented_item) < 0)
        goto error;
    rv = 0; /* Success */
    /* Continue with cleanup code */

 error:
    /* Cleanup code, shared by success and failure path */

    /* Use Py_XDECREF() to ignore NULL references */
    Py_XDECREF(item);
    Py_XDECREF(const_one);
    Py_XDECREF(incremented_item);

    return rv; /* -1 for error, 0 for success */
}
This example represents an endorsed use of the goto statement in C! It illustrates the use of PyErr_ExceptionMatches() and PyErr_Clear() to handle specific exceptions, and the use of Py_XDECREF() to dispose of owned references that may be NULL (note the 'X' in the name; Py_DECREF() would crash when confronted with a NULL reference). It is important that the variables used to hold owned references are initialized to NULL for this to work; likewise, the proposed return value is initialized to -1 (failure) and only set to success after the final call made is successful.

Embedding Python
The one important task that only embedders (as opposed to extension writers) of the Python interpreter have to worry about is the initialization, and possibly the finalization, of the Python interpreter. Most functionality of the interpreter can only be used after the interpreter has been initialized.

The basic initialization function is Py_Initialize(). This initializes the table of loaded modules, and creates the fundamental modules builtins, __main__, and sys. It also initializes the module search path (sys.path).

Py_Initialize() does not set the “script argument list” (sys.argv). If this variable is needed by Python code that will be executed later, it must be set explicitly with a call to PySys_SetArgvEx(argc, argv, updatepath) after the call to Py_Initialize().

On most systems (in particular, on Unix and Windows, although the details are slightly different), Py_Initialize() calculates the module search path based upon its best guess for the location of the standard Python interpreter executable, assuming that the Python library is found in a fixed location relative to the Python interpreter executable. In particular, it looks for a directory named lib/pythonX.Y relative to the parent directory where the executable named python is found on the shell command search path (the environment variable PATH).

For instance, if the Python executable is found in /usr/local/bin/python, it will assume that the libraries are in /usr/local/lib/pythonX.Y. (In fact, this particular path is also the “fallback” location, used when no executable file named python is found along PATH.) The user can override this behavior by setting the environment variable PYTHONHOME, or insert additional directories in front of the standard path by setting PYTHONPATH.

The embedding application can steer the search by calling Py_SetProgramName(file) before calling Py_Initialize(). Note that PYTHONHOME still overrides this and PYTHONPATH is still inserted in front of the standard path. An application that requires total control has to provide its own implementation of Py_GetPath(), Py_GetPrefix(), Py_GetExecPrefix(), and Py_GetProgramFullPath() (all defined in Modules/getpath.c).

Sometimes, it is desirable to “uninitialize” Python. For instance, the application may want to start over (make another call to Py_Initialize()) or the application is simply done with its use of Python and wants to free memory allocated by Python. This can be accomplished by calling Py_FinalizeEx(). The function Py_IsInitialized() returns true if Python is currently in the initialized state. More information about these functions is given in a later chapter. Notice that Py_FinalizeEx() does not free all memory allocated by the Python interpreter, e.g. memory allocated by extension modules currently cannot be released.

Debugging Builds
Python can be built with several macros to enable extra checks of the interpreter and extension modules. These checks tend to add a large amount of overhead to the runtime so they are not enabled by default.

A full list of the various types of debugging builds is in the file Misc/SpecialBuilds.txt in the Python source distribution. Builds are available that support tracing of reference counts, debugging the memory allocator, or low-level profiling of the main interpreter loop. Only the most frequently used builds will be described in the remainder of this section.

Compiling the interpreter with the Py_DEBUG macro defined produces what is generally meant by a debug build of Python. Py_DEBUG is enabled in the Unix build by adding --with-pydebug to the ./configure command. It is also implied by the presence of the not-Python-specific _DEBUG macro. When Py_DEBUG is enabled in the Unix build, compiler optimization is disabled.

In addition to the reference count debugging described below, extra checks are performed, see Python Debug Build.

Defining Py_TRACE_REFS enables reference tracing (see the configure --with-trace-refs option). When defined, a circular doubly linked list of active objects is maintained by adding two extra fields to every PyObject. Total allocations are tracked as well. Upon exit, all existing references are printed. (In interactive mode this happens after every statement run by the interpreter.)

Please refer to Misc/SpecialBuilds.txt in the Python source distribution for more detailed information.

Table of Contents
Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Reference Counts
Reference Count Details
Types
Exceptions
Embedding Python
Debugging Builds
Previous topic
Python/C API Reference Manual

Next topic
C API Stability

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
Introduction
The Application Programmer’s Interface to Python gives C and C++ programmers access to the Python interpreter at a variety of levels. The API is equally usable from C++, but for brevity it is generally referred to as the Python/C API. There are two fundamentally different reasons for using the Python/C API. The first reason is to write extension modules for specific purposes; these are C modules that extend the Python interpreter. This is probably the most common use. The second reason is to use Python as a component in a larger application; this technique is generally referred to as embedding Python in an application.

Writing an extension module is a relatively well-understood process, where a “cookbook” approach works well. There are several tools that automate the process to some extent. While people have embedded Python in other applications since its early existence, the process of embedding Python is less straightforward than writing an extension.

Many API functions are useful independent of whether you’re embedding or extending Python; moreover, most applications that embed Python will need to provide a custom extension as well, so it’s probably a good idea to become familiar with writing an extension before attempting to embed Python in a real application.

Coding standards
If you’re writing C code for inclusion in CPython, you must follow the guidelines and standards defined in PEP 7. These guidelines apply regardless of the version of Python you are contributing to. Following these conventions is not necessary for your own third party extension modules, unless you eventually expect to contribute them to Python.

Include Files
All function, type and macro definitions needed to use the Python/C API are included in your code by the following line:

#define PY_SSIZE_T_CLEAN
#include <Python.h>
This implies inclusion of the following standard headers: <stdio.h>, <string.h>, <errno.h>, <limits.h>, <assert.h> and <stdlib.h> (if available).

Note Since Python may define some pre-processor definitions which affect the standard headers on some systems, you must include Python.h before any standard headers are included.
It is recommended to always define PY_SSIZE_T_CLEAN before including Python.h. See Parsing arguments and building values for a description of this macro.

All user visible names defined by Python.h (except those defined by the included standard headers) have one of the prefixes Py or _Py. Names beginning with _Py are for internal use by the Python implementation and should not be used by extension writers. Structure member names do not have a reserved prefix.

Note User code should never define names that begin with Py or _Py. This confuses the reader, and jeopardizes the portability of the user code to future Python versions, which may define additional names beginning with one of these prefixes.
The header files are typically installed with Python. On Unix, these are located in the directories prefix/include/pythonversion/ and exec_prefix/include/pythonversion/, where prefix and exec_prefix are defined by the corresponding parameters to Python’s configure script and version is '%d.%d' % sys.version_info[:2]. On Windows, the headers are installed in prefix/include, where prefix is the installation directory specified to the installer.

To include the headers, place both directories (if different) on your compiler’s search path for includes. Do not place the parent directories on the search path and then use #include <pythonX.Y/Python.h>; this will break on multi-platform builds since the platform independent headers under prefix include the platform specific headers from exec_prefix.

C++ users should note that although the API is defined entirely using C, the header files properly declare the entry points to be extern "C". As a result, there is no need to do anything special to use the API from C++.

Useful macros
Several useful macros are defined in the Python header files. Many are defined closer to where they are useful (e.g. Py_RETURN_NONE). Others of a more general utility are defined here. This is not necessarily a complete listing.

Py_UNREACHABLE()
Use this when you have a code path that cannot be reached by design. For example, in the default: clause in a switch statement for which all possible values are covered in case statements. Use this in places where you might be tempted to put an assert(0) or abort() call.

In release mode, the macro helps the compiler to optimize the code, and avoids a warning about unreachable code. For example, the macro is implemented with __builtin_unreachable() on GCC in release mode.

A use for Py_UNREACHABLE() is following a call a function that never returns but that is not declared _Py_NO_RETURN.

If a code path is very unlikely code but can be reached under exceptional case, this macro must not be used. For example, under low memory condition or if a system call returns a value out of the expected range. In this case, it’s better to report the error to the caller. If the error cannot be reported to caller, Py_FatalError() can be used.

New in version 3.7.

Py_ABS(x)
Return the absolute value of x.

New in version 3.3.

Py_MIN(x, y)
Return the minimum value between x and y.

New in version 3.3.

Py_MAX(x, y)
Return the maximum value between x and y.

New in version 3.3.

Py_STRINGIFY(x)
Convert x to a C string. E.g. Py_STRINGIFY(123) returns "123".

New in version 3.4.

Py_MEMBER_SIZE(type, member)
Return the size of a structure (type) member in bytes.

New in version 3.6.

Py_CHARMASK(c)
Argument must be a character or an integer in the range [-128, 127] or [0, 255]. This macro returns c cast to an unsigned char.

Py_GETENV(s)
Like getenv(s), but returns NULL if -E was passed on the command line (i.e. if Py_IgnoreEnvironmentFlag is set).

Py_UNUSED(arg)
Use this for unused arguments in a function definition to silence compiler warnings. Example: int func(int a, int Py_UNUSED(b)) { return a; }.

New in version 3.4.

Py_DEPRECATED(version)
Use this for deprecated declarations. The macro must be placed before the symbol name.

Example:

Py_DEPRECATED(3.8) PyAPI_FUNC(int) Py_OldFunction(void);
Changed in version 3.8: MSVC support was added.

PyDoc_STRVAR(name, str)
Creates a variable with name name that can be used in docstrings. If Python is built without docstrings, the value will be empty.

Use PyDoc_STRVAR for docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

PyDoc_STRVAR(pop_doc, "Remove and return the rightmost element.");

static PyMethodDef deque_methods[] = {
    // ...
    {"pop", (PyCFunction)deque_pop, METH_NOARGS, pop_doc},
    // ...
}
PyDoc_STR(str)
Creates a docstring for the given input string or an empty string if docstrings are disabled.

Use PyDoc_STR in specifying docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

static PyMethodDef pysqlite_row_methods[] = {
    {"keys", (PyCFunction)pysqlite_row_keys, METH_NOARGS,
        PyDoc_STR("Returns the keys of the row.")},
    {NULL, NULL}
};
Objects, Types and Reference Counts
Most Python/C API functions have one or more arguments as well as a return value of type PyObject*. This type is a pointer to an opaque data type representing an arbitrary Python object. Since all Python object types are treated the same way by the Python language in most situations (e.g., assignments, scope rules, and argument passing), it is only fitting that they should be represented by a single C type. Almost all Python objects live on the heap: you never declare an automatic or static variable of type PyObject, only pointer variables of type PyObject* can be declared. The sole exception are the type objects; since these must never be deallocated, they are typically static PyTypeObject objects.

All Python objects (even Python integers) have a type and a reference count. An object’s type determines what kind of object it is (e.g., an integer, a list, or a user-defined function; there are many more as explained in The standard type hierarchy). For each of the well-known types there is a macro to check whether an object is of that type; for instance, PyList_Check(a) is true if (and only if) the object pointed to by a is a Python list.

Reference Counts
The reference count is important because today’s computers have a finite (and often severely limited) memory size; it counts how many different places there are that have a reference to an object. Such a place could be another object, or a global (or static) C variable, or a local variable in some C function. When an object’s reference count becomes zero, the object is deallocated. If it contains references to other objects, their reference count is decremented. Those other objects may be deallocated in turn, if this decrement makes their reference count become zero, and so on. (There’s an obvious problem with objects that reference each other here; for now, the solution is “don’t do that.”)

Reference counts are always manipulated explicitly. The normal way is to use the macro Py_INCREF() to increment an object’s reference count by one, and Py_DECREF() to decrement it by one. The Py_DECREF() macro is considerably more complex than the incref one, since it must check whether the reference count becomes zero and then cause the object’s deallocator to be called. The deallocator is a function pointer contained in the object’s type structure. The type-specific deallocator takes care of decrementing the reference counts for other objects contained in the object if this is a compound object type, such as a list, as well as performing any additional finalization that’s needed. There’s no chance that the reference count can overflow; at least as many bits are used to hold the reference count as there are distinct memory locations in virtual memory (assuming sizeof(Py_ssize_t) >= sizeof(void*)). Thus, the reference count increment is a simple operation.

It is not necessary to increment an object’s reference count for every local variable that contains a pointer to an object. In theory, the object’s reference count goes up by one when the variable is made to point to it and it goes down by one when the variable goes out of scope. However, these two cancel each other out, so at the end the reference count hasn’t changed. The only real reason to use the reference count is to prevent the object from being deallocated as long as our variable is pointing to it. If we know that there is at least one other reference to the object that lives at least as long as our variable, there is no need to increment the reference count temporarily. An important situation where this arises is in objects that are passed as arguments to C functions in an extension module that are called from Python; the call mechanism guarantees to hold a reference to every argument for the duration of the call.

However, a common pitfall is to extract an object from a list and hold on to it for a while without incrementing its reference count. Some other operation might conceivably remove the object from the list, decrementing its reference count and possibly deallocating it. The real danger is that innocent-looking operations may invoke arbitrary Python code which could do this; there is a code path which allows control to flow back to the user from a Py_DECREF(), so almost any operation is potentially dangerous.

A safe approach is to always use the generic operations (functions whose name begins with PyObject_, PyNumber_, PySequence_ or PyMapping_). These operations always increment the reference count of the object they return. This leaves the caller with the responsibility to call Py_DECREF() when they are done with the result; this soon becomes second nature.

Reference Count Details
The reference count behavior of functions in the Python/C API is best explained in terms of ownership of references. Ownership pertains to references, never to objects (objects are not owned: they are always shared). “Owning a reference” means being responsible for calling Py_DECREF on it when the reference is no longer needed. Ownership can also be transferred, meaning that the code that receives ownership of the reference then becomes responsible for eventually decref’ing it by calling Py_DECREF() or Py_XDECREF() when it’s no longer needed—or passing on this responsibility (usually to its caller). When a function passes ownership of a reference on to its caller, the caller is said to receive a new reference. When no ownership is transferred, the caller is said to borrow the reference. Nothing needs to be done for a borrowed reference.

Conversely, when a calling function passes in a reference to an object, there are two possibilities: the function steals a reference to the object, or it does not. Stealing a reference means that when you pass a reference to a function, that function assumes that it now owns that reference, and you are not responsible for it any longer.

Few functions steal references; the two notable exceptions are PyList_SetItem() and PyTuple_SetItem(), which steal a reference to the item (but not to the tuple or list into which the item is put!). These functions were designed to steal a reference because of a common idiom for populating a tuple or list with newly created objects; for example, the code to create the tuple (1, 2, "three") could look like this (forgetting about error handling for the moment; a better way to code this is shown below):

PyObject *t;

t = PyTuple_New(3);
PyTuple_SetItem(t, 0, PyLong_FromLong(1L));
PyTuple_SetItem(t, 1, PyLong_FromLong(2L));
PyTuple_SetItem(t, 2, PyUnicode_FromString("three"));
Here, PyLong_FromLong() returns a new reference which is immediately stolen by PyTuple_SetItem(). When you want to keep using an object although the reference to it will be stolen, use Py_INCREF() to grab another reference before calling the reference-stealing function.

Incidentally, PyTuple_SetItem() is the only way to set tuple items; PySequence_SetItem() and PyObject_SetItem() refuse to do this since tuples are an immutable data type. You should only use PyTuple_SetItem() for tuples that you are creating yourself.

Equivalent code for populating a list can be written using PyList_New() and PyList_SetItem().

However, in practice, you will rarely use these ways of creating and populating a tuple or list. There’s a generic function, Py_BuildValue(), that can create most common objects from C values, directed by a format string. For example, the above two blocks of code could be replaced by the following (which also takes care of the error checking):

PyObject *tuple, *list;

tuple = Py_BuildValue("(iis)", 1, 2, "three");
list = Py_BuildValue("[iis]", 1, 2, "three");
It is much more common to use PyObject_SetItem() and friends with items whose references you are only borrowing, like arguments that were passed in to the function you are writing. In that case, their behaviour regarding reference counts is much saner, since you don’t have to increment a reference count so you can give a reference away (“have it be stolen”). For example, this function sets all items of a list (actually, any mutable sequence) to a given item:

int
set_all(PyObject *target, PyObject *item)
{
    Py_ssize_t i, n;

    n = PyObject_Length(target);
    if (n < 0)
        return -1;
    for (i = 0; i < n; i++) {
        PyObject *index = PyLong_FromSsize_t(i);
        if (!index)
            return -1;
        if (PyObject_SetItem(target, index, item) < 0) {
            Py_DECREF(index);
            return -1;
        }
        Py_DECREF(index);
    }
    return 0;
}
The situation is slightly different for function return values. While passing a reference to most functions does not change your ownership responsibilities for that reference, many functions that return a reference to an object give you ownership of the reference. The reason is simple: in many cases, the returned object is created on the fly, and the reference you get is the only reference to the object. Therefore, the generic functions that return object references, like PyObject_GetItem() and PySequence_GetItem(), always return a new reference (the caller becomes the owner of the reference).

It is important to realize that whether you own a reference returned by a function depends on which function you call only — the plumage (the type of the object passed as an argument to the function) doesn’t enter into it! Thus, if you extract an item from a list using PyList_GetItem(), you don’t own the reference — but if you obtain the same item from the same list using PySequence_GetItem() (which happens to take exactly the same arguments), you do own a reference to the returned object.

Here is an example of how you could write a function that computes the sum of the items in a list of integers; once using PyList_GetItem(), and once using PySequence_GetItem().

long
sum_list(PyObject *list)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;

    n = PyList_Size(list);
    if (n < 0)
        return -1; /* Not a list */
    for (i = 0; i < n; i++) {
        item = PyList_GetItem(list, i); /* Can't fail */
        if (!PyLong_Check(item)) continue; /* Skip non-integers */
        value = PyLong_AsLong(item);
        if (value == -1 && PyErr_Occurred())
            /* Integer too big to fit in a C long, bail out */
            return -1;
        total += value;
    }
    return total;
}
long
sum_sequence(PyObject *sequence)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;
    n = PySequence_Length(sequence);
    if (n < 0)
        return -1; /* Has no length */
    for (i = 0; i < n; i++) {
        item = PySequence_GetItem(sequence, i);
        if (item == NULL)
            return -1; /* Not a sequence, or other failure */
        if (PyLong_Check(item)) {
            value = PyLong_AsLong(item);
            Py_DECREF(item);
            if (value == -1 && PyErr_Occurred())
                /* Integer too big to fit in a C long, bail out */
                return -1;
            total += value;
        }
        else {
            Py_DECREF(item); /* Discard reference ownership */
        }
    }
    return total;
}
Types
There are few other data types that play a significant role in the Python/C API; most are simple C types such as int, long, double and char*. A few structure types are used to describe static tables used to list the functions exported by a module or the data attributes of a new object type, and another is used to describe the value of a complex number. These will be discussed together with the functions that use them.

type Py_ssize_t
Part of the Stable ABI.
A signed integral type such that sizeof(Py_ssize_t) == sizeof(size_t). C99 doesn’t define such a thing directly (size_t is an unsigned integral type). See PEP 353 for details. PY_SSIZE_T_MAX is the largest positive value of type Py_ssize_t.

Exceptions
The Python programmer only needs to deal with exceptions if specific error handling is required; unhandled exceptions are automatically propagated to the caller, then to the caller’s caller, and so on, until they reach the top-level interpreter, where they are reported to the user accompanied by a stack traceback.

For C programmers, however, error checking always has to be explicit. All functions in the Python/C API can raise exceptions, unless an explicit claim is made otherwise in a function’s documentation. In general, when a function encounters an error, it sets an exception, discards any object references that it owns, and returns an error indicator. If not documented otherwise, this indicator is either NULL or -1, depending on the function’s return type. A few functions return a Boolean true/false result, with false indicating an error. Very few functions return no explicit error indicator or have an ambiguous return value, and require explicit testing for errors with PyErr_Occurred(). These exceptions are always explicitly documented.

Exception state is maintained in per-thread storage (this is equivalent to using global storage in an unthreaded application). A thread can be in one of two states: an exception has occurred, or not. The function PyErr_Occurred() can be used to check for this: it returns a borrowed reference to the exception type object when an exception has occurred, and NULL otherwise. There are a number of functions to set the exception state: PyErr_SetString() is the most common (though not the most general) function to set the exception state, and PyErr_Clear() clears the exception state.

The full exception state consists of three objects (all of which can be NULL): the exception type, the corresponding exception value, and the traceback. These have the same meanings as the Python result of sys.exc_info(); however, they are not the same: the Python objects represent the last exception being handled by a Python try … except statement, while the C level exception state only exists while an exception is being passed on between C functions until it reaches the Python bytecode interpreter’s main loop, which takes care of transferring it to sys.exc_info() and friends.

Note that starting with Python 1.5, the preferred, thread-safe way to access the exception state from Python code is to call the function sys.exc_info(), which returns the per-thread exception state for Python code. Also, the semantics of both ways to access the exception state have changed so that a function which catches an exception will save and restore its thread’s exception state so as to preserve the exception state of its caller. This prevents common bugs in exception handling code caused by an innocent-looking function overwriting the exception being handled; it also reduces the often unwanted lifetime extension for objects that are referenced by the stack frames in the traceback.

As a general principle, a function that calls another function to perform some task should check whether the called function raised an exception, and if so, pass the exception state on to its caller. It should discard any object references that it owns, and return an error indicator, but it should not set another exception — that would overwrite the exception that was just raised, and lose important information about the exact cause of the error.

A simple example of detecting exceptions and passing them on is shown in the sum_sequence() example above. It so happens that this example doesn’t need to clean up any owned references when it detects an error. The following example function shows some error cleanup. First, to remind you why you like Python, we show the equivalent Python code:

def incr_item(dict, key):
    try:
        item = dict[key]
    except KeyError:
        item = 0
    dict[key] = item + 1
Here is the corresponding C code, in all its glory:

int
incr_item(PyObject *dict, PyObject *key)
{
    /* Objects all initialized to NULL for Py_XDECREF */
    PyObject *item = NULL, *const_one = NULL, *incremented_item = NULL;
    int rv = -1; /* Return value initialized to -1 (failure) */

    item = PyObject_GetItem(dict, key);
    if (item == NULL) {
        /* Handle KeyError only: */
        if (!PyErr_ExceptionMatches(PyExc_KeyError))
            goto error;

        /* Clear the error and use zero: */
        PyErr_Clear();
        item = PyLong_FromLong(0L);
        if (item == NULL)
            goto error;
    }
    const_one = PyLong_FromLong(1L);
    if (const_one == NULL)
        goto error;

    incremented_item = PyNumber_Add(item, const_one);
    if (incremented_item == NULL)
        goto error;

    if (PyObject_SetItem(dict, key, incremented_item) < 0)
        goto error;
    rv = 0; /* Success */
    /* Continue with cleanup code */

 error:
    /* Cleanup code, shared by success and failure path */

    /* Use Py_XDECREF() to ignore NULL references */
    Py_XDECREF(item);
    Py_XDECREF(const_one);
    Py_XDECREF(incremented_item);

    return rv; /* -1 for error, 0 for success */
}
This example represents an endorsed use of the goto statement in C! It illustrates the use of PyErr_ExceptionMatches() and PyErr_Clear() to handle specific exceptions, and the use of Py_XDECREF() to dispose of owned references that may be NULL (note the 'X' in the name; Py_DECREF() would crash when confronted with a NULL reference). It is important that the variables used to hold owned references are initialized to NULL for this to work; likewise, the proposed return value is initialized to -1 (failure) and only set to success after the final call made is successful.

Embedding Python
The one important task that only embedders (as opposed to extension writers) of the Python interpreter have to worry about is the initialization, and possibly the finalization, of the Python interpreter. Most functionality of the interpreter can only be used after the interpreter has been initialized.

The basic initialization function is Py_Initialize(). This initializes the table of loaded modules, and creates the fundamental modules builtins, __main__, and sys. It also initializes the module search path (sys.path).

Py_Initialize() does not set the “script argument list” (sys.argv). If this variable is needed by Python code that will be executed later, it must be set explicitly with a call to PySys_SetArgvEx(argc, argv, updatepath) after the call to Py_Initialize().

On most systems (in particular, on Unix and Windows, although the details are slightly different), Py_Initialize() calculates the module search path based upon its best guess for the location of the standard Python interpreter executable, assuming that the Python library is found in a fixed location relative to the Python interpreter executable. In particular, it looks for a directory named lib/pythonX.Y relative to the parent directory where the executable named python is found on the shell command search path (the environment variable PATH).

For instance, if the Python executable is found in /usr/local/bin/python, it will assume that the libraries are in /usr/local/lib/pythonX.Y. (In fact, this particular path is also the “fallback” location, used when no executable file named python is found along PATH.) The user can override this behavior by setting the environment variable PYTHONHOME, or insert additional directories in front of the standard path by setting PYTHONPATH.

The embedding application can steer the search by calling Py_SetProgramName(file) before calling Py_Initialize(). Note that PYTHONHOME still overrides this and PYTHONPATH is still inserted in front of the standard path. An application that requires total control has to provide its own implementation of Py_GetPath(), Py_GetPrefix(), Py_GetExecPrefix(), and Py_GetProgramFullPath() (all defined in Modules/getpath.c).

Sometimes, it is desirable to “uninitialize” Python. For instance, the application may want to start over (make another call to Py_Initialize()) or the application is simply done with its use of Python and wants to free memory allocated by Python. This can be accomplished by calling Py_FinalizeEx(). The function Py_IsInitialized() returns true if Python is currently in the initialized state. More information about these functions is given in a later chapter. Notice that Py_FinalizeEx() does not free all memory allocated by the Python interpreter, e.g. memory allocated by extension modules currently cannot be released.

Debugging Builds
Python can be built with several macros to enable extra checks of the interpreter and extension modules. These checks tend to add a large amount of overhead to the runtime so they are not enabled by default.

A full list of the various types of debugging builds is in the file Misc/SpecialBuilds.txt in the Python source distribution. Builds are available that support tracing of reference counts, debugging the memory allocator, or low-level profiling of the main interpreter loop. Only the most frequently used builds will be described in the remainder of this section.

Compiling the interpreter with the Py_DEBUG macro defined produces what is generally meant by a debug build of Python. Py_DEBUG is enabled in the Unix build by adding --with-pydebug to the ./configure command. It is also implied by the presence of the not-Python-specific _DEBUG macro. When Py_DEBUG is enabled in the Unix build, compiler optimization is disabled.

In addition to the reference count debugging described below, extra checks are performed, see Python Debug Build.

Defining Py_TRACE_REFS enables reference tracing (see the configure --with-trace-refs option). When defined, a circular doubly linked list of active objects is maintained by adding two extra fields to every PyObject. Total allocations are tracked as well. Upon exit, all existing references are printed. (In interactive mode this happens after every statement run by the interpreter.)

Please refer to Misc/SpecialBuilds.txt in the Python source distribution for more detailed information.

Table of Contents
Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Reference Counts
Reference Count Details
Types
Exceptions
Embedding Python
Debugging Builds
Previous topic
Python/C API Reference Manual

Next topic
C API Stability

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
Introduction
The Application Programmer’s Interface to Python gives C and C++ programmers access to the Python interpreter at a variety of levels. The API is equally usable from C++, but for brevity it is generally referred to as the Python/C API. There are two fundamentally different reasons for using the Python/C API. The first reason is to write extension modules for specific purposes; these are C modules that extend the Python interpreter. This is probably the most common use. The second reason is to use Python as a component in a larger application; this technique is generally referred to as embedding Python in an application.

Writing an extension module is a relatively well-understood process, where a “cookbook” approach works well. There are several tools that automate the process to some extent. While people have embedded Python in other applications since its early existence, the process of embedding Python is less straightforward than writing an extension.

Many API functions are useful independent of whether you’re embedding or extending Python; moreover, most applications that embed Python will need to provide a custom extension as well, so it’s probably a good idea to become familiar with writing an extension before attempting to embed Python in a real application.

Coding standards
If you’re writing C code for inclusion in CPython, you must follow the guidelines and standards defined in PEP 7. These guidelines apply regardless of the version of Python you are contributing to. Following these conventions is not necessary for your own third party extension modules, unless you eventually expect to contribute them to Python.

Include Files
All function, type and macro definitions needed to use the Python/C API are included in your code by the following line:

#define PY_SSIZE_T_CLEAN
#include <Python.h>
This implies inclusion of the following standard headers: <stdio.h>, <string.h>, <errno.h>, <limits.h>, <assert.h> and <stdlib.h> (if available).

Note Since Python may define some pre-processor definitions which affect the standard headers on some systems, you must include Python.h before any standard headers are included.
It is recommended to always define PY_SSIZE_T_CLEAN before including Python.h. See Parsing arguments and building values for a description of this macro.

All user visible names defined by Python.h (except those defined by the included standard headers) have one of the prefixes Py or _Py. Names beginning with _Py are for internal use by the Python implementation and should not be used by extension writers. Structure member names do not have a reserved prefix.

Note User code should never define names that begin with Py or _Py. This confuses the reader, and jeopardizes the portability of the user code to future Python versions, which may define additional names beginning with one of these prefixes.
The header files are typically installed with Python. On Unix, these are located in the directories prefix/include/pythonversion/ and exec_prefix/include/pythonversion/, where prefix and exec_prefix are defined by the corresponding parameters to Python’s configure script and version is '%d.%d' % sys.version_info[:2]. On Windows, the headers are installed in prefix/include, where prefix is the installation directory specified to the installer.

To include the headers, place both directories (if different) on your compiler’s search path for includes. Do not place the parent directories on the search path and then use #include <pythonX.Y/Python.h>; this will break on multi-platform builds since the platform independent headers under prefix include the platform specific headers from exec_prefix.

C++ users should note that although the API is defined entirely using C, the header files properly declare the entry points to be extern "C". As a result, there is no need to do anything special to use the API from C++.

Useful macros
Several useful macros are defined in the Python header files. Many are defined closer to where they are useful (e.g. Py_RETURN_NONE). Others of a more general utility are defined here. This is not necessarily a complete listing.

Py_UNREACHABLE()
Use this when you have a code path that cannot be reached by design. For example, in the default: clause in a switch statement for which all possible values are covered in case statements. Use this in places where you might be tempted to put an assert(0) or abort() call.

In release mode, the macro helps the compiler to optimize the code, and avoids a warning about unreachable code. For example, the macro is implemented with __builtin_unreachable() on GCC in release mode.

A use for Py_UNREACHABLE() is following a call a function that never returns but that is not declared _Py_NO_RETURN.

If a code path is very unlikely code but can be reached under exceptional case, this macro must not be used. For example, under low memory condition or if a system call returns a value out of the expected range. In this case, it’s better to report the error to the caller. If the error cannot be reported to caller, Py_FatalError() can be used.

New in version 3.7.

Py_ABS(x)
Return the absolute value of x.

New in version 3.3.

Py_MIN(x, y)
Return the minimum value between x and y.

New in version 3.3.

Py_MAX(x, y)
Return the maximum value between x and y.

New in version 3.3.

Py_STRINGIFY(x)
Convert x to a C string. E.g. Py_STRINGIFY(123) returns "123".

New in version 3.4.

Py_MEMBER_SIZE(type, member)
Return the size of a structure (type) member in bytes.

New in version 3.6.

Py_CHARMASK(c)
Argument must be a character or an integer in the range [-128, 127] or [0, 255]. This macro returns c cast to an unsigned char.

Py_GETENV(s)
Like getenv(s), but returns NULL if -E was passed on the command line (i.e. if Py_IgnoreEnvironmentFlag is set).

Py_UNUSED(arg)
Use this for unused arguments in a function definition to silence compiler warnings. Example: int func(int a, int Py_UNUSED(b)) { return a; }.

New in version 3.4.

Py_DEPRECATED(version)
Use this for deprecated declarations. The macro must be placed before the symbol name.

Example:

Py_DEPRECATED(3.8) PyAPI_FUNC(int) Py_OldFunction(void);
Changed in version 3.8: MSVC support was added.

PyDoc_STRVAR(name, str)
Creates a variable with name name that can be used in docstrings. If Python is built without docstrings, the value will be empty.

Use PyDoc_STRVAR for docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

PyDoc_STRVAR(pop_doc, "Remove and return the rightmost element.");

static PyMethodDef deque_methods[] = {
    // ...
    {"pop", (PyCFunction)deque_pop, METH_NOARGS, pop_doc},
    // ...
}
PyDoc_STR(str)
Creates a docstring for the given input string or an empty string if docstrings are disabled.

Use PyDoc_STR in specifying docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

static PyMethodDef pysqlite_row_methods[] = {
    {"keys", (PyCFunction)pysqlite_row_keys, METH_NOARGS,
        PyDoc_STR("Returns the keys of the row.")},
    {NULL, NULL}
};
Objects, Types and Reference Counts
Most Python/C API functions have one or more arguments as well as a return value of type PyObject*. This type is a pointer to an opaque data type representing an arbitrary Python object. Since all Python object types are treated the same way by the Python language in most situations (e.g., assignments, scope rules, and argument passing), it is only fitting that they should be represented by a single C type. Almost all Python objects live on the heap: you never declare an automatic or static variable of type PyObject, only pointer variables of type PyObject* can be declared. The sole exception are the type objects; since these must never be deallocated, they are typically static PyTypeObject objects.

All Python objects (even Python integers) have a type and a reference count. An object’s type determines what kind of object it is (e.g., an integer, a list, or a user-defined function; there are many more as explained in The standard type hierarchy). For each of the well-known types there is a macro to check whether an object is of that type; for instance, PyList_Check(a) is true if (and only if) the object pointed to by a is a Python list.

Reference Counts
The reference count is important because today’s computers have a finite (and often severely limited) memory size; it counts how many different places there are that have a reference to an object. Such a place could be another object, or a global (or static) C variable, or a local variable in some C function. When an object’s reference count becomes zero, the object is deallocated. If it contains references to other objects, their reference count is decremented. Those other objects may be deallocated in turn, if this decrement makes their reference count become zero, and so on. (There’s an obvious problem with objects that reference each other here; for now, the solution is “don’t do that.”)

Reference counts are always manipulated explicitly. The normal way is to use the macro Py_INCREF() to increment an object’s reference count by one, and Py_DECREF() to decrement it by one. The Py_DECREF() macro is considerably more complex than the incref one, since it must check whether the reference count becomes zero and then cause the object’s deallocator to be called. The deallocator is a function pointer contained in the object’s type structure. The type-specific deallocator takes care of decrementing the reference counts for other objects contained in the object if this is a compound object type, such as a list, as well as performing any additional finalization that’s needed. There’s no chance that the reference count can overflow; at least as many bits are used to hold the reference count as there are distinct memory locations in virtual memory (assuming sizeof(Py_ssize_t) >= sizeof(void*)). Thus, the reference count increment is a simple operation.

It is not necessary to increment an object’s reference count for every local variable that contains a pointer to an object. In theory, the object’s reference count goes up by one when the variable is made to point to it and it goes down by one when the variable goes out of scope. However, these two cancel each other out, so at the end the reference count hasn’t changed. The only real reason to use the reference count is to prevent the object from being deallocated as long as our variable is pointing to it. If we know that there is at least one other reference to the object that lives at least as long as our variable, there is no need to increment the reference count temporarily. An important situation where this arises is in objects that are passed as arguments to C functions in an extension module that are called from Python; the call mechanism guarantees to hold a reference to every argument for the duration of the call.

However, a common pitfall is to extract an object from a list and hold on to it for a while without incrementing its reference count. Some other operation might conceivably remove the object from the list, decrementing its reference count and possibly deallocating it. The real danger is that innocent-looking operations may invoke arbitrary Python code which could do this; there is a code path which allows control to flow back to the user from a Py_DECREF(), so almost any operation is potentially dangerous.

A safe approach is to always use the generic operations (functions whose name begins with PyObject_, PyNumber_, PySequence_ or PyMapping_). These operations always increment the reference count of the object they return. This leaves the caller with the responsibility to call Py_DECREF() when they are done with the result; this soon becomes second nature.

Reference Count Details
The reference count behavior of functions in the Python/C API is best explained in terms of ownership of references. Ownership pertains to references, never to objects (objects are not owned: they are always shared). “Owning a reference” means being responsible for calling Py_DECREF on it when the reference is no longer needed. Ownership can also be transferred, meaning that the code that receives ownership of the reference then becomes responsible for eventually decref’ing it by calling Py_DECREF() or Py_XDECREF() when it’s no longer needed—or passing on this responsibility (usually to its caller). When a function passes ownership of a reference on to its caller, the caller is said to receive a new reference. When no ownership is transferred, the caller is said to borrow the reference. Nothing needs to be done for a borrowed reference.

Conversely, when a calling function passes in a reference to an object, there are two possibilities: the function steals a reference to the object, or it does not. Stealing a reference means that when you pass a reference to a function, that function assumes that it now owns that reference, and you are not responsible for it any longer.

Few functions steal references; the two notable exceptions are PyList_SetItem() and PyTuple_SetItem(), which steal a reference to the item (but not to the tuple or list into which the item is put!). These functions were designed to steal a reference because of a common idiom for populating a tuple or list with newly created objects; for example, the code to create the tuple (1, 2, "three") could look like this (forgetting about error handling for the moment; a better way to code this is shown below):

PyObject *t;

t = PyTuple_New(3);
PyTuple_SetItem(t, 0, PyLong_FromLong(1L));
PyTuple_SetItem(t, 1, PyLong_FromLong(2L));
PyTuple_SetItem(t, 2, PyUnicode_FromString("three"));
Here, PyLong_FromLong() returns a new reference which is immediately stolen by PyTuple_SetItem(). When you want to keep using an object although the reference to it will be stolen, use Py_INCREF() to grab another reference before calling the reference-stealing function.

Incidentally, PyTuple_SetItem() is the only way to set tuple items; PySequence_SetItem() and PyObject_SetItem() refuse to do this since tuples are an immutable data type. You should only use PyTuple_SetItem() for tuples that you are creating yourself.

Equivalent code for populating a list can be written using PyList_New() and PyList_SetItem().

However, in practice, you will rarely use these ways of creating and populating a tuple or list. There’s a generic function, Py_BuildValue(), that can create most common objects from C values, directed by a format string. For example, the above two blocks of code could be replaced by the following (which also takes care of the error checking):

PyObject *tuple, *list;

tuple = Py_BuildValue("(iis)", 1, 2, "three");
list = Py_BuildValue("[iis]", 1, 2, "three");
It is much more common to use PyObject_SetItem() and friends with items whose references you are only borrowing, like arguments that were passed in to the function you are writing. In that case, their behaviour regarding reference counts is much saner, since you don’t have to increment a reference count so you can give a reference away (“have it be stolen”). For example, this function sets all items of a list (actually, any mutable sequence) to a given item:

int
set_all(PyObject *target, PyObject *item)
{
    Py_ssize_t i, n;

    n = PyObject_Length(target);
    if (n < 0)
        return -1;
    for (i = 0; i < n; i++) {
        PyObject *index = PyLong_FromSsize_t(i);
        if (!index)
            return -1;
        if (PyObject_SetItem(target, index, item) < 0) {
            Py_DECREF(index);
            return -1;
        }
        Py_DECREF(index);
    }
    return 0;
}
The situation is slightly different for function return values. While passing a reference to most functions does not change your ownership responsibilities for that reference, many functions that return a reference to an object give you ownership of the reference. The reason is simple: in many cases, the returned object is created on the fly, and the reference you get is the only reference to the object. Therefore, the generic functions that return object references, like PyObject_GetItem() and PySequence_GetItem(), always return a new reference (the caller becomes the owner of the reference).

It is important to realize that whether you own a reference returned by a function depends on which function you call only — the plumage (the type of the object passed as an argument to the function) doesn’t enter into it! Thus, if you extract an item from a list using PyList_GetItem(), you don’t own the reference — but if you obtain the same item from the same list using PySequence_GetItem() (which happens to take exactly the same arguments), you do own a reference to the returned object.

Here is an example of how you could write a function that computes the sum of the items in a list of integers; once using PyList_GetItem(), and once using PySequence_GetItem().

long
sum_list(PyObject *list)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;

    n = PyList_Size(list);
    if (n < 0)
        return -1; /* Not a list */
    for (i = 0; i < n; i++) {
        item = PyList_GetItem(list, i); /* Can't fail */
        if (!PyLong_Check(item)) continue; /* Skip non-integers */
        value = PyLong_AsLong(item);
        if (value == -1 && PyErr_Occurred())
            /* Integer too big to fit in a C long, bail out */
            return -1;
        total += value;
    }
    return total;
}
long
sum_sequence(PyObject *sequence)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;
    n = PySequence_Length(sequence);
    if (n < 0)
        return -1; /* Has no length */
    for (i = 0; i < n; i++) {
        item = PySequence_GetItem(sequence, i);
        if (item == NULL)
            return -1; /* Not a sequence, or other failure */
        if (PyLong_Check(item)) {
            value = PyLong_AsLong(item);
            Py_DECREF(item);
            if (value == -1 && PyErr_Occurred())
                /* Integer too big to fit in a C long, bail out */
                return -1;
            total += value;
        }
        else {
            Py_DECREF(item); /* Discard reference ownership */
        }
    }
    return total;
}
Types
There are few other data types that play a significant role in the Python/C API; most are simple C types such as int, long, double and char*. A few structure types are used to describe static tables used to list the functions exported by a module or the data attributes of a new object type, and another is used to describe the value of a complex number. These will be discussed together with the functions that use them.

type Py_ssize_t
Part of the Stable ABI.
A signed integral type such that sizeof(Py_ssize_t) == sizeof(size_t). C99 doesn’t define such a thing directly (size_t is an unsigned integral type). See PEP 353 for details. PY_SSIZE_T_MAX is the largest positive value of type Py_ssize_t.

Exceptions
The Python programmer only needs to deal with exceptions if specific error handling is required; unhandled exceptions are automatically propagated to the caller, then to the caller’s caller, and so on, until they reach the top-level interpreter, where they are reported to the user accompanied by a stack traceback.

For C programmers, however, error checking always has to be explicit. All functions in the Python/C API can raise exceptions, unless an explicit claim is made otherwise in a function’s documentation. In general, when a function encounters an error, it sets an exception, discards any object references that it owns, and returns an error indicator. If not documented otherwise, this indicator is either NULL or -1, depending on the function’s return type. A few functions return a Boolean true/false result, with false indicating an error. Very few functions return no explicit error indicator or have an ambiguous return value, and require explicit testing for errors with PyErr_Occurred(). These exceptions are always explicitly documented.

Exception state is maintained in per-thread storage (this is equivalent to using global storage in an unthreaded application). A thread can be in one of two states: an exception has occurred, or not. The function PyErr_Occurred() can be used to check for this: it returns a borrowed reference to the exception type object when an exception has occurred, and NULL otherwise. There are a number of functions to set the exception state: PyErr_SetString() is the most common (though not the most general) function to set the exception state, and PyErr_Clear() clears the exception state.

The full exception state consists of three objects (all of which can be NULL): the exception type, the corresponding exception value, and the traceback. These have the same meanings as the Python result of sys.exc_info(); however, they are not the same: the Python objects represent the last exception being handled by a Python try … except statement, while the C level exception state only exists while an exception is being passed on between C functions until it reaches the Python bytecode interpreter’s main loop, which takes care of transferring it to sys.exc_info() and friends.

Note that starting with Python 1.5, the preferred, thread-safe way to access the exception state from Python code is to call the function sys.exc_info(), which returns the per-thread exception state for Python code. Also, the semantics of both ways to access the exception state have changed so that a function which catches an exception will save and restore its thread’s exception state so as to preserve the exception state of its caller. This prevents common bugs in exception handling code caused by an innocent-looking function overwriting the exception being handled; it also reduces the often unwanted lifetime extension for objects that are referenced by the stack frames in the traceback.

As a general principle, a function that calls another function to perform some task should check whether the called function raised an exception, and if so, pass the exception state on to its caller. It should discard any object references that it owns, and return an error indicator, but it should not set another exception — that would overwrite the exception that was just raised, and lose important information about the exact cause of the error.

A simple example of detecting exceptions and passing them on is shown in the sum_sequence() example above. It so happens that this example doesn’t need to clean up any owned references when it detects an error. The following example function shows some error cleanup. First, to remind you why you like Python, we show the equivalent Python code:

def incr_item(dict, key):
    try:
        item = dict[key]
    except KeyError:
        item = 0
    dict[key] = item + 1
Here is the corresponding C code, in all its glory:

int
incr_item(PyObject *dict, PyObject *key)
{
    /* Objects all initialized to NULL for Py_XDECREF */
    PyObject *item = NULL, *const_one = NULL, *incremented_item = NULL;
    int rv = -1; /* Return value initialized to -1 (failure) */

    item = PyObject_GetItem(dict, key);
    if (item == NULL) {
        /* Handle KeyError only: */
        if (!PyErr_ExceptionMatches(PyExc_KeyError))
            goto error;

        /* Clear the error and use zero: */
        PyErr_Clear();
        item = PyLong_FromLong(0L);
        if (item == NULL)
            goto error;
    }
    const_one = PyLong_FromLong(1L);
    if (const_one == NULL)
        goto error;

    incremented_item = PyNumber_Add(item, const_one);
    if (incremented_item == NULL)
        goto error;

    if (PyObject_SetItem(dict, key, incremented_item) < 0)
        goto error;
    rv = 0; /* Success */
    /* Continue with cleanup code */

 error:
    /* Cleanup code, shared by success and failure path */

    /* Use Py_XDECREF() to ignore NULL references */
    Py_XDECREF(item);
    Py_XDECREF(const_one);
    Py_XDECREF(incremented_item);

    return rv; /* -1 for error, 0 for success */
}
This example represents an endorsed use of the goto statement in C! It illustrates the use of PyErr_ExceptionMatches() and PyErr_Clear() to handle specific exceptions, and the use of Py_XDECREF() to dispose of owned references that may be NULL (note the 'X' in the name; Py_DECREF() would crash when confronted with a NULL reference). It is important that the variables used to hold owned references are initialized to NULL for this to work; likewise, the proposed return value is initialized to -1 (failure) and only set to success after the final call made is successful.

Embedding Python
The one important task that only embedders (as opposed to extension writers) of the Python interpreter have to worry about is the initialization, and possibly the finalization, of the Python interpreter. Most functionality of the interpreter can only be used after the interpreter has been initialized.

The basic initialization function is Py_Initialize(). This initializes the table of loaded modules, and creates the fundamental modules builtins, __main__, and sys. It also initializes the module search path (sys.path).

Py_Initialize() does not set the “script argument list” (sys.argv). If this variable is needed by Python code that will be executed later, it must be set explicitly with a call to PySys_SetArgvEx(argc, argv, updatepath) after the call to Py_Initialize().

On most systems (in particular, on Unix and Windows, although the details are slightly different), Py_Initialize() calculates the module search path based upon its best guess for the location of the standard Python interpreter executable, assuming that the Python library is found in a fixed location relative to the Python interpreter executable. In particular, it looks for a directory named lib/pythonX.Y relative to the parent directory where the executable named python is found on the shell command search path (the environment variable PATH).

For instance, if the Python executable is found in /usr/local/bin/python, it will assume that the libraries are in /usr/local/lib/pythonX.Y. (In fact, this particular path is also the “fallback” location, used when no executable file named python is found along PATH.) The user can override this behavior by setting the environment variable PYTHONHOME, or insert additional directories in front of the standard path by setting PYTHONPATH.

The embedding application can steer the search by calling Py_SetProgramName(file) before calling Py_Initialize(). Note that PYTHONHOME still overrides this and PYTHONPATH is still inserted in front of the standard path. An application that requires total control has to provide its own implementation of Py_GetPath(), Py_GetPrefix(), Py_GetExecPrefix(), and Py_GetProgramFullPath() (all defined in Modules/getpath.c).

Sometimes, it is desirable to “uninitialize” Python. For instance, the application may want to start over (make another call to Py_Initialize()) or the application is simply done with its use of Python and wants to free memory allocated by Python. This can be accomplished by calling Py_FinalizeEx(). The function Py_IsInitialized() returns true if Python is currently in the initialized state. More information about these functions is given in a later chapter. Notice that Py_FinalizeEx() does not free all memory allocated by the Python interpreter, e.g. memory allocated by extension modules currently cannot be released.

Debugging Builds
Python can be built with several macros to enable extra checks of the interpreter and extension modules. These checks tend to add a large amount of overhead to the runtime so they are not enabled by default.

A full list of the various types of debugging builds is in the file Misc/SpecialBuilds.txt in the Python source distribution. Builds are available that support tracing of reference counts, debugging the memory allocator, or low-level profiling of the main interpreter loop. Only the most frequently used builds will be described in the remainder of this section.

Compiling the interpreter with the Py_DEBUG macro defined produces what is generally meant by a debug build of Python. Py_DEBUG is enabled in the Unix build by adding --with-pydebug to the ./configure command. It is also implied by the presence of the not-Python-specific _DEBUG macro. When Py_DEBUG is enabled in the Unix build, compiler optimization is disabled.

In addition to the reference count debugging described below, extra checks are performed, see Python Debug Build.

Defining Py_TRACE_REFS enables reference tracing (see the configure --with-trace-refs option). When defined, a circular doubly linked list of active objects is maintained by adding two extra fields to every PyObject. Total allocations are tracked as well. Upon exit, all existing references are printed. (In interactive mode this happens after every statement run by the interpreter.)

Please refer to Misc/SpecialBuilds.txt in the Python source distribution for more detailed information.

Table of Contents
Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Reference Counts
Reference Count Details
Types
Exceptions
Embedding Python
Debugging Builds
Previous topic
Python/C API Reference Manual

Next topic
C API Stability

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
]indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
Introduction
The Application Programmer’s Interface to Python gives C and C++ programmers access to the Python interpreter at a variety of levels. The API is equally usable from C++, but for brevity it is generally referred to as the Python/C API. There are two fundamentally different reasons for using the Python/C API. The first reason is to write extension modules for specific purposes; these are C modules that extend the Python interpreter. This is probably the most common use. The second reason is to use Python as a component in a larger application; this technique is generally referred to as embedding Python in an application.

Writing an extension module is a relatively well-understood process, where a “cookbook” approach works well. There are several tools that automate the process to some extent. While people have embedded Python in other applications since its early existence, the process of embedding Python is less straightforward than writing an extension.

Many API functions are useful independent of whether you’re embedding or extending Python; moreover, most applications that embed Python will need to provide a custom extension as well, so it’s probably a good idea to become familiar with writing an extension before attempting to embed Python in a real application.

Coding standards
If you’re writing C code for inclusion in CPython, you must follow the guidelines and standards defined in PEP 7. These guidelines apply regardless of the version of Python you are contributing to. Following these conventions is not necessary for your own third party extension modules, unless you eventually expect to contribute them to Python.

Include Files
All function, type and macro definitions needed to use the Python/C API are included in your code by the following line:

#define PY_SSIZE_T_CLEAN
#include <Python.h>
This implies inclusion of the following standard headers: <stdio.h>, <string.h>, <errno.h>, <limits.h>, <assert.h> and <stdlib.h> (if available).

Note Since Python may define some pre-processor definitions which affect the standard headers on some systems, you must include Python.h before any standard headers are included.
It is recommended to always define PY_SSIZE_T_CLEAN before including Python.h. See Parsing arguments and building values for a description of this macro.

All user visible names defined by Python.h (except those defined by the included standard headers) have one of the prefixes Py or _Py. Names beginning with _Py are for internal use by the Python implementation and should not be used by extension writers. Structure member names do not have a reserved prefix.

Note User code should never define names that begin with Py or _Py. This confuses the reader, and jeopardizes the portability of the user code to future Python versions, which may define additional names beginning with one of these prefixes.
The header files are typically installed with Python. On Unix, these are located in the directories prefix/include/pythonversion/ and exec_prefix/include/pythonversion/, where prefix and exec_prefix are defined by the corresponding parameters to Python’s configure script and version is '%d.%d' % sys.version_info[:2]. On Windows, the headers are installed in prefix/include, where prefix is the installation directory specified to the installer.

To include the headers, place both directories (if different) on your compiler’s search path for includes. Do not place the parent directories on the search path and then use #include <pythonX.Y/Python.h>; this will break on multi-platform builds since the platform independent headers under prefix include the platform specific headers from exec_prefix.

C++ users should note that although the API is defined entirely using C, the header files properly declare the entry points to be extern "C". As a result, there is no need to do anything special to use the API from C++.

Useful macros
Several useful macros are defined in the Python header files. Many are defined closer to where they are useful (e.g. Py_RETURN_NONE). Others of a more general utility are defined here. This is not necessarily a complete listing.

Py_UNREACHABLE()
Use this when you have a code path that cannot be reached by design. For example, in the default: clause in a switch statement for which all possible values are covered in case statements. Use this in places where you might be tempted to put an assert(0) or abort() call.

In release mode, the macro helps the compiler to optimize the code, and avoids a warning about unreachable code. For example, the macro is implemented with __builtin_unreachable() on GCC in release mode.

A use for Py_UNREACHABLE() is following a call a function that never returns but that is not declared _Py_NO_RETURN.

If a code path is very unlikely code but can be reached under exceptional case, this macro must not be used. For example, under low memory condition or if a system call returns a value out of the expected range. In this case, it’s better to report the error to the caller. If the error cannot be reported to caller, Py_FatalError() can be used.

New in version 3.7.

Py_ABS(x)
Return the absolute value of x.

New in version 3.3.

Py_MIN(x, y)
Return the minimum value between x and y.

New in version 3.3.

Py_MAX(x, y)
Return the maximum value between x and y.

New in version 3.3.

Py_STRINGIFY(x)
Convert x to a C string. E.g. Py_STRINGIFY(123) returns "123".

New in version 3.4.

Py_MEMBER_SIZE(type, member)
Return the size of a structure (type) member in bytes.

New in version 3.6.

Py_CHARMASK(c)
Argument must be a character or an integer in the range [-128, 127] or [0, 255]. This macro returns c cast to an unsigned char.

Py_GETENV(s)
Like getenv(s), but returns NULL if -E was passed on the command line (i.e. if Py_IgnoreEnvironmentFlag is set).

Py_UNUSED(arg)
Use this for unused arguments in a function definition to silence compiler warnings. Example: int func(int a, int Py_UNUSED(b)) { return a; }.

New in version 3.4.

Py_DEPRECATED(version)
Use this for deprecated declarations. The macro must be placed before the symbol name.

Example:

Py_DEPRECATED(3.8) PyAPI_FUNC(int) Py_OldFunction(void);
Changed in version 3.8: MSVC support was added.

PyDoc_STRVAR(name, str)
Creates a variable with name name that can be used in docstrings. If Python is built without docstrings, the value will be empty.

Use PyDoc_STRVAR for docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

PyDoc_STRVAR(pop_doc, "Remove and return the rightmost element.");

static PyMethodDef deque_methods[] = {
    // ...
    {"pop", (PyCFunction)deque_pop, METH_NOARGS, pop_doc},
    // ...
}
PyDoc_STR(str)
Creates a docstring for the given input string or an empty string if docstrings are disabled.

Use PyDoc_STR in specifying docstrings to support building Python without docstrings, as specified in PEP 7.

Example:

static PyMethodDef pysqlite_row_methods[] = {
    {"keys", (PyCFunction)pysqlite_row_keys, METH_NOARGS,
        PyDoc_STR("Returns the keys of the row.")},
    {NULL, NULL}
};
Objects, Types and Reference Counts
Most Python/C API functions have one or more arguments as well as a return value of type PyObject*. This type is a pointer to an opaque data type representing an arbitrary Python object. Since all Python object types are treated the same way by the Python language in most situations (e.g., assignments, scope rules, and argument passing), it is only fitting that they should be represented by a single C type. Almost all Python objects live on the heap: you never declare an automatic or static variable of type PyObject, only pointer variables of type PyObject* can be declared. The sole exception are the type objects; since these must never be deallocated, they are typically static PyTypeObject objects.

All Python objects (even Python integers) have a type and a reference count. An object’s type determines what kind of object it is (e.g., an integer, a list, or a user-defined function; there are many more as explained in The standard type hierarchy). For each of the well-known types there is a macro to check whether an object is of that type; for instance, PyList_Check(a) is true if (and only if) the object pointed to by a is a Python list.

Reference Counts
The reference count is important because today’s computers have a finite (and often severely limited) memory size; it counts how many different places there are that have a reference to an object. Such a place could be another object, or a global (or static) C variable, or a local variable in some C function. When an object’s reference count becomes zero, the object is deallocated. If it contains references to other objects, their reference count is decremented. Those other objects may be deallocated in turn, if this decrement makes their reference count become zero, and so on. (There’s an obvious problem with objects that reference each other here; for now, the solution is “don’t do that.”)

Reference counts are always manipulated explicitly. The normal way is to use the macro Py_INCREF() to increment an object’s reference count by one, and Py_DECREF() to decrement it by one. The Py_DECREF() macro is considerably more complex than the incref one, since it must check whether the reference count becomes zero and then cause the object’s deallocator to be called. The deallocator is a function pointer contained in the object’s type structure. The type-specific deallocator takes care of decrementing the reference counts for other objects contained in the object if this is a compound object type, such as a list, as well as performing any additional finalization that’s needed. There’s no chance that the reference count can overflow; at least as many bits are used to hold the reference count as there are distinct memory locations in virtual memory (assuming sizeof(Py_ssize_t) >= sizeof(void*)). Thus, the reference count increment is a simple operation.

It is not necessary to increment an object’s reference count for every local variable that contains a pointer to an object. In theory, the object’s reference count goes up by one when the variable is made to point to it and it goes down by one when the variable goes out of scope. However, these two cancel each other out, so at the end the reference count hasn’t changed. The only real reason to use the reference count is to prevent the object from being deallocated as long as our variable is pointing to it. If we know that there is at least one other reference to the object that lives at least as long as our variable, there is no need to increment the reference count temporarily. An important situation where this arises is in objects that are passed as arguments to C functions in an extension module that are called from Python; the call mechanism guarantees to hold a reference to every argument for the duration of the call.

However, a common pitfall is to extract an object from a list and hold on to it for a while without incrementing its reference count. Some other operation might conceivably remove the object from the list, decrementing its reference count and possibly deallocating it. The real danger is that innocent-looking operations may invoke arbitrary Python code which could do this; there is a code path which allows control to flow back to the user from a Py_DECREF(), so almost any operation is potentially dangerous.

A safe approach is to always use the generic operations (functions whose name begins with PyObject_, PyNumber_, PySequence_ or PyMapping_). These operations always increment the reference count of the object they return. This leaves the caller with the responsibility to call Py_DECREF() when they are done with the result; this soon becomes second nature.

Reference Count Details
The reference count behavior of functions in the Python/C API is best explained in terms of ownership of references. Ownership pertains to references, never to objects (objects are not owned: they are always shared). “Owning a reference” means being responsible for calling Py_DECREF on it when the reference is no longer needed. Ownership can also be transferred, meaning that the code that receives ownership of the reference then becomes responsible for eventually decref’ing it by calling Py_DECREF() or Py_XDECREF() when it’s no longer needed—or passing on this responsibility (usually to its caller). When a function passes ownership of a reference on to its caller, the caller is said to receive a new reference. When no ownership is transferred, the caller is said to borrow the reference. Nothing needs to be done for a borrowed reference.

Conversely, when a calling function passes in a reference to an object, there are two possibilities: the function steals a reference to the object, or it does not. Stealing a reference means that when you pass a reference to a function, that function assumes that it now owns that reference, and you are not responsible for it any longer.

Few functions steal references; the two notable exceptions are PyList_SetItem() and PyTuple_SetItem(), which steal a reference to the item (but not to the tuple or list into which the item is put!). These functions were designed to steal a reference because of a common idiom for populating a tuple or list with newly created objects; for example, the code to create the tuple (1, 2, "three") could look like this (forgetting about error handling for the moment; a better way to code this is shown below):

PyObject *t;

t = PyTuple_New(3);
PyTuple_SetItem(t, 0, PyLong_FromLong(1L));
PyTuple_SetItem(t, 1, PyLong_FromLong(2L));
PyTuple_SetItem(t, 2, PyUnicode_FromString("three"));
Here, PyLong_FromLong() returns a new reference which is immediately stolen by PyTuple_SetItem(). When you want to keep using an object although the reference to it will be stolen, use Py_INCREF() to grab another reference before calling the reference-stealing function.

Incidentally, PyTuple_SetItem() is the only way to set tuple items; PySequence_SetItem() and PyObject_SetItem() refuse to do this since tuples are an immutable data type. You should only use PyTuple_SetItem() for tuples that you are creating yourself.

Equivalent code for populating a list can be written using PyList_New() and PyList_SetItem().

However, in practice, you will rarely use these ways of creating and populating a tuple or list. There’s a generic function, Py_BuildValue(), that can create most common objects from C values, directed by a format string. For example, the above two blocks of code could be replaced by the following (which also takes care of the error checking):

PyObject *tuple, *list;

tuple = Py_BuildValue("(iis)", 1, 2, "three");
list = Py_BuildValue("[iis]", 1, 2, "three");
It is much more common to use PyObject_SetItem() and friends with items whose references you are only borrowing, like arguments that were passed in to the function you are writing. In that case, their behaviour regarding reference counts is much saner, since you don’t have to increment a reference count so you can give a reference away (“have it be stolen”). For example, this function sets all items of a list (actually, any mutable sequence) to a given item:

int
set_all(PyObject *target, PyObject *item)
{
    Py_ssize_t i, n;

    n = PyObject_Length(target);
    if (n < 0)
        return -1;
    for (i = 0; i < n; i++) {
        PyObject *index = PyLong_FromSsize_t(i);
        if (!index)
            return -1;
        if (PyObject_SetItem(target, index, item) < 0) {
            Py_DECREF(index);
            return -1;
        }
        Py_DECREF(index);
    }
    return 0;
}
The situation is slightly different for function return values. While passing a reference to most functions does not change your ownership responsibilities for that reference, many functions that return a reference to an object give you ownership of the reference. The reason is simple: in many cases, the returned object is created on the fly, and the reference you get is the only reference to the object. Therefore, the generic functions that return object references, like PyObject_GetItem() and PySequence_GetItem(), always return a new reference (the caller becomes the owner of the reference).

It is important to realize that whether you own a reference returned by a function depends on which function you call only — the plumage (the type of the object passed as an argument to the function) doesn’t enter into it! Thus, if you extract an item from a list using PyList_GetItem(), you don’t own the reference — but if you obtain the same item from the same list using PySequence_GetItem() (which happens to take exactly the same arguments), you do own a reference to the returned object.

Here is an example of how you could write a function that computes the sum of the items in a list of integers; once using PyList_GetItem(), and once using PySequence_GetItem().

long
sum_list(PyObject *list)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;

    n = PyList_Size(list);
    if (n < 0)
        return -1; /* Not a list */
    for (i = 0; i < n; i++) {
        item = PyList_GetItem(list, i); /* Can't fail */
        if (!PyLong_Check(item)) continue; /* Skip non-integers */
        value = PyLong_AsLong(item);
        if (value == -1 && PyErr_Occurred())
            /* Integer too big to fit in a C long, bail out */
            return -1;
        total += value;
    }
    return total;
}
long
sum_sequence(PyObject *sequence)
{
    Py_ssize_t i, n;
    long total = 0, value;
    PyObject *item;
    n = PySequence_Length(sequence);
    if (n < 0)
        return -1; /* Has no length */
    for (i = 0; i < n; i++) {
        item = PySequence_GetItem(sequence, i);
        if (item == NULL)
            return -1; /* Not a sequence, or other failure */
        if (PyLong_Check(item)) {
            value = PyLong_AsLong(item);
            Py_DECREF(item);
            if (value == -1 && PyErr_Occurred())
                /* Integer too big to fit in a C long, bail out */
                return -1;
            total += value;
        }
        else {
            Py_DECREF(item); /* Discard reference ownership */
        }
    }
    return total;
}
Types
There are few other data types that play a significant role in the Python/C API; most are simple C types such as int, long, double and char*. A few structure types are used to describe static tables used to list the functions exported by a module or the data attributes of a new object type, and another is used to describe the value of a complex number. These will be discussed together with the functions that use them.

type Py_ssize_t
Part of the Stable ABI.
A signed integral type such that sizeof(Py_ssize_t) == sizeof(size_t). C99 doesn’t define such a thing directly (size_t is an unsigned integral type). See PEP 353 for details. PY_SSIZE_T_MAX is the largest positive value of type Py_ssize_t.

Exceptions
The Python programmer only needs to deal with exceptions if specific error handling is required; unhandled exceptions are automatically propagated to the caller, then to the caller’s caller, and so on, until they reach the top-level interpreter, where they are reported to the user accompanied by a stack traceback.

For C programmers, however, error checking always has to be explicit. All functions in the Python/C API can raise exceptions, unless an explicit claim is made otherwise in a function’s documentation. In general, when a function encounters an error, it sets an exception, discards any object references that it owns, and returns an error indicator. If not documented otherwise, this indicator is either NULL or -1, depending on the function’s return type. A few functions return a Boolean true/false result, with false indicating an error. Very few functions return no explicit error indicator or have an ambiguous return value, and require explicit testing for errors with PyErr_Occurred(). These exceptions are always explicitly documented.

Exception state is maintained in per-thread storage (this is equivalent to using global storage in an unthreaded application). A thread can be in one of two states: an exception has occurred, or not. The function PyErr_Occurred() can be used to check for this: it returns a borrowed reference to the exception type object when an exception has occurred, and NULL otherwise. There are a number of functions to set the exception state: PyErr_SetString() is the most common (though not the most general) function to set the exception state, and PyErr_Clear() clears the exception state.

The full exception state consists of three objects (all of which can be NULL): the exception type, the corresponding exception value, and the traceback. These have the same meanings as the Python result of sys.exc_info(); however, they are not the same: the Python objects represent the last exception being handled by a Python try … except statement, while the C level exception state only exists while an exception is being passed on between C functions until it reaches the Python bytecode interpreter’s main loop, which takes care of transferring it to sys.exc_info() and friends.

Note that starting with Python 1.5, the preferred, thread-safe way to access the exception state from Python code is to call the function sys.exc_info(), which returns the per-thread exception state for Python code. Also, the semantics of both ways to access the exception state have changed so that a function which catches an exception will save and restore its thread’s exception state so as to preserve the exception state of its caller. This prevents common bugs in exception handling code caused by an innocent-looking function overwriting the exception being handled; it also reduces the often unwanted lifetime extension for objects that are referenced by the stack frames in the traceback.

As a general principle, a function that calls another function to perform some task should check whether the called function raised an exception, and if so, pass the exception state on to its caller. It should discard any object references that it owns, and return an error indicator, but it should not set another exception — that would overwrite the exception that was just raised, and lose important information about the exact cause of the error.

A simple example of detecting exceptions and passing them on is shown in the sum_sequence() example above. It so happens that this example doesn’t need to clean up any owned references when it detects an error. The following example function shows some error cleanup. First, to remind you why you like Python, we show the equivalent Python code:

def incr_item(dict, key):
    try:
        item = dict[key]
    except KeyError:
        item = 0
    dict[key] = item + 1
Here is the corresponding C code, in all its glory:

int
incr_item(PyObject *dict, PyObject *key)
{
    /* Objects all initialized to NULL for Py_XDECREF */
    PyObject *item = NULL, *const_one = NULL, *incremented_item = NULL;
    int rv = -1; /* Return value initialized to -1 (failure) */

    item = PyObject_GetItem(dict, key);
    if (item == NULL) {
        /* Handle KeyError only: */
        if (!PyErr_ExceptionMatches(PyExc_KeyError))
            goto error;

        /* Clear the error and use zero: */
        PyErr_Clear();
        item = PyLong_FromLong(0L);
        if (item == NULL)
            goto error;
    }
    const_one = PyLong_FromLong(1L);
    if (const_one == NULL)
        goto error;

    incremented_item = PyNumber_Add(item, const_one);
    if (incremented_item == NULL)
        goto error;

    if (PyObject_SetItem(dict, key, incremented_item) < 0)
        goto error;
    rv = 0; /* Success */
    /* Continue with cleanup code */

 error:
    /* Cleanup code, shared by success and failure path */

    /* Use Py_XDECREF() to ignore NULL references */
    Py_XDECREF(item);
    Py_XDECREF(const_one);
    Py_XDECREF(incremented_item);

    return rv; /* -1 for error, 0 for success */
}
This example represents an endorsed use of the goto statement in C! It illustrates the use of PyErr_ExceptionMatches() and PyErr_Clear() to handle specific exceptions, and the use of Py_XDECREF() to dispose of owned references that may be NULL (note the 'X' in the name; Py_DECREF() would crash when confronted with a NULL reference). It is important that the variables used to hold owned references are initialized to NULL for this to work; likewise, the proposed return value is initialized to -1 (failure) and only set to success after the final call made is successful.

Embedding Python
The one important task that only embedders (as opposed to extension writers) of the Python interpreter have to worry about is the initialization, and possibly the finalization, of the Python interpreter. Most functionality of the interpreter can only be used after the interpreter has been initialized.

The basic initialization function is Py_Initialize(). This initializes the table of loaded modules, and creates the fundamental modules builtins, __main__, and sys. It also initializes the module search path (sys.path).

Py_Initialize() does not set the “script argument list” (sys.argv). If this variable is needed by Python code that will be executed later, it must be set explicitly with a call to PySys_SetArgvEx(argc, argv, updatepath) after the call to Py_Initialize().

On most systems (in particular, on Unix and Windows, although the details are slightly different), Py_Initialize() calculates the module search path based upon its best guess for the location of the standard Python interpreter executable, assuming that the Python library is found in a fixed location relative to the Python interpreter executable. In particular, it looks for a directory named lib/pythonX.Y relative to the parent directory where the executable named python is found on the shell command search path (the environment variable PATH).

For instance, if the Python executable is found in /usr/local/bin/python, it will assume that the libraries are in /usr/local/lib/pythonX.Y. (In fact, this particular path is also the “fallback” location, used when no executable file named python is found along PATH.) The user can override this behavior by setting the environment variable PYTHONHOME, or insert additional directories in front of the standard path by setting PYTHONPATH.

The embedding application can steer the search by calling Py_SetProgramName(file) before calling Py_Initialize(). Note that PYTHONHOME still overrides this and PYTHONPATH is still inserted in front of the standard path. An application that requires total control has to provide its own implementation of Py_GetPath(), Py_GetPrefix(), Py_GetExecPrefix(), and Py_GetProgramFullPath() (all defined in Modules/getpath.c).

Sometimes, it is desirable to “uninitialize” Python. For instance, the application may want to start over (make another call to Py_Initialize()) or the application is simply done with its use of Python and wants to free memory allocated by Python. This can be accomplished by calling Py_FinalizeEx(). The function Py_IsInitialized() returns true if Python is currently in the initialized state. More information about these functions is given in a later chapter. Notice that Py_FinalizeEx() does not free all memory allocated by the Python interpreter, e.g. memory allocated by extension modules currently cannot be released.

Debugging Builds
Python can be built with several macros to enable extra checks of the interpreter and extension modules. These checks tend to add a large amount of overhead to the runtime so they are not enabled by default.

A full list of the various types of debugging builds is in the file Misc/SpecialBuilds.txt in the Python source distribution. Builds are available that support tracing of reference counts, debugging the memory allocator, or low-level profiling of the main interpreter loop. Only the most frequently used builds will be described in the remainder of this section.

Compiling the interpreter with the Py_DEBUG macro defined produces what is generally meant by a debug build of Python. Py_DEBUG is enabled in the Unix build by adding --with-pydebug to the ./configure command. It is also implied by the presence of the not-Python-specific _DEBUG macro. When Py_DEBUG is enabled in the Unix build, compiler optimization is disabled.

In addition to the reference count debugging described below, extra checks are performed, see Python Debug Build.

Defining Py_TRACE_REFS enables reference tracing (see the configure --with-trace-refs option). When defined, a circular doubly linked list of active objects is maintained by adding two extra fields to every PyObject. Total allocations are tracked as well. Upon exit, all existing references are printed. (In interactive mode this happens after every statement run by the interpreter.)

Please refer to Misc/SpecialBuilds.txt in the Python source distribution for more detailed information.

Table of Contents
Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Reference Counts
Reference Count Details
Types
Exceptions
Embedding Python
Debugging Builds
Previous topic
Python/C API Reference Manual

Next topic
C API Stability

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Introduction
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » C API Stability
Quick search
  |
C API Stability
Python’s C API is covered by the Backwards Compatibility Policy, PEP 387. While the C API will change with every minor release (e.g. from 3.9 to 3.10), most changes will be source-compatible, typically by only adding new API. Changing existing API or removing API is only done after a deprecation period or to fix serious issues.

CPython’s Application Binary Interface (ABI) is forward- and backwards-compatible across a minor release (if these are compiled the same way; see Platform Considerations below). So, code compiled for Python 3.10.0 will work on 3.10.8 and vice versa, but will need to be compiled separately for 3.9.x and 3.10.x.

Names prefixed by an underscore, such as _Py_InternalState, are private API that can change without notice even in patch releases.

Stable Application Binary Interface
Python 3.2 introduced the Limited API, a subset of Python’s C API. Extensions that only use the Limited API can be compiled once and work with multiple versions of Python. Contents of the Limited API are listed below.

To enable this, Python provides a Stable ABI: a set of symbols that will remain compatible across Python 3.x versions. The Stable ABI contains symbols exposed in the Limited API, but also other ones – for example, functions necessary to support older versions of the Limited API.

(For simplicity, this document talks about extensions, but the Limited API and Stable ABI work the same way for all uses of the API – for example, embedding Python.)

Py_LIMITED_API
Define this macro before including Python.h to opt in to only use the Limited API, and to select the Limited API version.

Define Py_LIMITED_API to the value of PY_VERSION_HEX corresponding to the lowest Python version your extension supports. The extension will work without recompilation with all Python 3 releases from the specified one onward, and can use Limited API introduced up to that version.

Rather than using the PY_VERSION_HEX macro directly, hardcode a minimum minor version (e.g. 0x030A0000 for Python 3.10) for stability when compiling with future Python versions.

You can also define Py_LIMITED_API to 3. This works the same as 0x03020000 (Python 3.2, the version that introduced Limited API).

On Windows, extensions that use the Stable ABI should be linked against python3.dll rather than a version-specific library such as python39.dll.

On some platforms, Python will look for and load shared library files named with the abi3 tag (e.g. mymodule.abi3.so). It does not check if such extensions conform to a Stable ABI. The user (or their packaging tools) need to ensure that, for example, extensions built with the 3.10+ Limited API are not installed for lower versions of Python.

All functions in the Stable ABI are present as functions in Python’s shared library, not solely as macros. This makes them usable from languages that don’t use the C preprocessor.

Limited API Scope and Performance
The goal for the Limited API is to allow everything that is possible with the full C API, but possibly with a performance penalty.

For example, while PyList_GetItem() is available, its “unsafe” macro variant PyList_GET_ITEM() is not. The macro can be faster because it can rely on version-specific implementation details of the list object.

Without Py_LIMITED_API defined, some C API functions are inlined or replaced by macros. Defining Py_LIMITED_API disables this inlining, allowing stability as Python’s data structures are improved, but possibly reducing performance.

By leaving out the Py_LIMITED_API definition, it is possible to compile a Limited API extension with a version-specific ABI. This can improve performance for that Python version, but will limit compatibility. Compiling with Py_LIMITED_API will then yield an extension that can be distributed where a version-specific one is not available – for example, for prereleases of an upcoming Python version.

Limited API Caveats
Note that compiling with Py_LIMITED_API is not a complete guarantee that code conforms to the Limited API or the Stable ABI. Py_LIMITED_API only covers definitions, but an API also includes other issues, such as expected semantics.

One issue that Py_LIMITED_API does not guard against is calling a function with arguments that are invalid in a lower Python version. For example, consider a function that starts accepting NULL for an argument. In Python 3.9, NULL now selects a default behavior, but in Python 3.8, the argument will be used directly, causing a NULL dereference and crash. A similar argument works for fields of structs.

Another issue is that some struct fields are currently not hidden when Py_LIMITED_API is defined, even though they’re part of the Limited API.

For these reasons, we recommend testing an extension with all minor Python versions it supports, and preferably to build with the lowest such version.

We also recommend reviewing documentation of all used API to check if it is explicitly part of the Limited API. Even with Py_LIMITED_API defined, a few private declarations are exposed for technical reasons (or even unintentionally, as bugs).

Also note that the Limited API is not necessarily stable: compiling with Py_LIMITED_API with Python 3.8 means that the extension will run with Python 3.12, but it will not necessarily compile with Python 3.12. In particular, parts of the Limited API may be deprecated and removed, provided that the Stable ABI stays stable.

Platform Considerations
ABI stability depends not only on Python, but also on the compiler used, lower-level libraries and compiler options. For the purposes of the Stable ABI, these details define a “platform”. They usually depend on the OS type and processor architecture

It is the responsibility of each particular distributor of Python to ensure that all Python versions on a particular platform are built in a way that does not break the Stable ABI. This is the case with Windows and macOS releases from python.org and many third-party distributors.

Contents of Limited API
Currently, the Limited API includes the following items:

PyAIter_Check()

PyArg_Parse()

PyArg_ParseTuple()

PyArg_ParseTupleAndKeywords()

PyArg_UnpackTuple()

PyArg_VaParse()

PyArg_VaParseTupleAndKeywords()

PyArg_ValidateKeywordArguments()

PyBaseObject_Type

PyBool_FromLong()

PyBool_Type

PyByteArrayIter_Type

PyByteArray_AsString()

PyByteArray_Concat()

PyByteArray_FromObject()

PyByteArray_FromStringAndSize()

PyByteArray_Resize()

PyByteArray_Size()

PyByteArray_Type

PyBytesIter_Type

PyBytes_AsString()

PyBytes_AsStringAndSize()

PyBytes_Concat()

PyBytes_ConcatAndDel()

PyBytes_DecodeEscape()

PyBytes_FromFormat()

PyBytes_FromFormatV()

PyBytes_FromObject()

PyBytes_FromString()

PyBytes_FromStringAndSize()

PyBytes_Repr()

PyBytes_Size()

PyBytes_Type

PyCFunction

PyCFunctionWithKeywords

PyCFunction_Call()

PyCFunction_GetFlags()

PyCFunction_GetFunction()

PyCFunction_GetSelf()

PyCFunction_New()

PyCFunction_NewEx()

PyCFunction_Type

PyCMethod_New()

PyCallIter_New()

PyCallIter_Type

PyCallable_Check()

PyCapsule_Destructor

PyCapsule_GetContext()

PyCapsule_GetDestructor()

PyCapsule_GetName()

PyCapsule_GetPointer()

PyCapsule_Import()

PyCapsule_IsValid()

PyCapsule_New()

PyCapsule_SetContext()

PyCapsule_SetDestructor()

PyCapsule_SetName()

PyCapsule_SetPointer()

PyCapsule_Type

PyClassMethodDescr_Type

PyCodec_BackslashReplaceErrors()

PyCodec_Decode()

PyCodec_Decoder()

PyCodec_Encode()

PyCodec_Encoder()

PyCodec_IgnoreErrors()

PyCodec_IncrementalDecoder()

PyCodec_IncrementalEncoder()

PyCodec_KnownEncoding()

PyCodec_LookupError()

PyCodec_NameReplaceErrors()

PyCodec_Register()

PyCodec_RegisterError()

PyCodec_ReplaceErrors()

PyCodec_StreamReader()

PyCodec_StreamWriter()

PyCodec_StrictErrors()

PyCodec_Unregister()

PyCodec_XMLCharRefReplaceErrors()

PyComplex_FromDoubles()

PyComplex_ImagAsDouble()

PyComplex_RealAsDouble()

PyComplex_Type

PyDescr_NewClassMethod()

PyDescr_NewGetSet()

PyDescr_NewMember()

PyDescr_NewMethod()

PyDictItems_Type

PyDictIterItem_Type

PyDictIterKey_Type

PyDictIterValue_Type

PyDictKeys_Type

PyDictProxy_New()

PyDictProxy_Type

PyDictRevIterItem_Type

PyDictRevIterKey_Type

PyDictRevIterValue_Type

PyDictValues_Type

PyDict_Clear()

PyDict_Contains()

PyDict_Copy()

PyDict_DelItem()

PyDict_DelItemString()

PyDict_GetItem()

PyDict_GetItemString()

PyDict_GetItemWithError()

PyDict_Items()

PyDict_Keys()

PyDict_Merge()

PyDict_MergeFromSeq2()

PyDict_New()

PyDict_Next()

PyDict_SetItem()

PyDict_SetItemString()

PyDict_Size()

PyDict_Type

PyDict_Update()

PyDict_Values()

PyEllipsis_Type

PyEnum_Type

PyErr_BadArgument()

PyErr_BadInternalCall()

PyErr_CheckSignals()

PyErr_Clear()

PyErr_Display()

PyErr_ExceptionMatches()

PyErr_Fetch()

PyErr_Format()

PyErr_FormatV()

PyErr_GetExcInfo()

PyErr_GivenExceptionMatches()

PyErr_NewException()

PyErr_NewExceptionWithDoc()

PyErr_NoMemory()

PyErr_NormalizeException()

PyErr_Occurred()

PyErr_Print()

PyErr_PrintEx()

PyErr_ProgramText()

PyErr_ResourceWarning()

PyErr_Restore()

PyErr_SetExcFromWindowsErr()

PyErr_SetExcFromWindowsErrWithFilename()

PyErr_SetExcFromWindowsErrWithFilenameObject()

PyErr_SetExcFromWindowsErrWithFilenameObjects()

PyErr_SetExcInfo()

PyErr_SetFromErrno()

PyErr_SetFromErrnoWithFilename()

PyErr_SetFromErrnoWithFilenameObject()

PyErr_SetFromErrnoWithFilenameObjects()

PyErr_SetFromWindowsErr()

PyErr_SetFromWindowsErrWithFilename()

PyErr_SetImportError()

PyErr_SetImportErrorSubclass()

PyErr_SetInterrupt()

PyErr_SetInterruptEx()

PyErr_SetNone()

PyErr_SetObject()

PyErr_SetString()

PyErr_SyntaxLocation()

PyErr_SyntaxLocationEx()

PyErr_WarnEx()

PyErr_WarnExplicit()

PyErr_WarnFormat()

PyErr_WriteUnraisable()

PyEval_AcquireLock()

PyEval_AcquireThread()

PyEval_CallFunction()

PyEval_CallMethod()

PyEval_CallObjectWithKeywords()

PyEval_EvalCode()

PyEval_EvalCodeEx()

PyEval_EvalFrame()

PyEval_EvalFrameEx()

PyEval_GetBuiltins()

PyEval_GetFrame()

PyEval_GetFuncDesc()

PyEval_GetFuncName()

PyEval_GetGlobals()

PyEval_GetLocals()

PyEval_InitThreads()

PyEval_ReleaseLock()

PyEval_ReleaseThread()

PyEval_RestoreThread()

PyEval_SaveThread()

PyEval_ThreadsInitialized()

PyExc_ArithmeticError

PyExc_AssertionError

PyExc_AttributeError

PyExc_BaseException

PyExc_BlockingIOError

PyExc_BrokenPipeError

PyExc_BufferError

PyExc_BytesWarning

PyExc_ChildProcessError

PyExc_ConnectionAbortedError

PyExc_ConnectionError

PyExc_ConnectionRefusedError

PyExc_ConnectionResetError

PyExc_DeprecationWarning

PyExc_EOFError

PyExc_EncodingWarning

PyExc_EnvironmentError

PyExc_Exception

PyExc_FileExistsError

PyExc_FileNotFoundError

PyExc_FloatingPointError

PyExc_FutureWarning

PyExc_GeneratorExit

PyExc_IOError

PyExc_ImportError

PyExc_ImportWarning

PyExc_IndentationError

PyExc_IndexError

PyExc_InterruptedError

PyExc_IsADirectoryError

PyExc_KeyError

PyExc_KeyboardInterrupt

PyExc_LookupError

PyExc_MemoryError

PyExc_ModuleNotFoundError

PyExc_NameError

PyExc_NotADirectoryError

PyExc_NotImplementedError

PyExc_OSError

PyExc_OverflowError

PyExc_PendingDeprecationWarning

PyExc_PermissionError

PyExc_ProcessLookupError

PyExc_RecursionError

PyExc_ReferenceError

PyExc_ResourceWarning

PyExc_RuntimeError

PyExc_RuntimeWarning

PyExc_StopAsyncIteration

PyExc_StopIteration

PyExc_SyntaxError

PyExc_SyntaxWarning

PyExc_SystemError

PyExc_SystemExit

PyExc_TabError

PyExc_TimeoutError

PyExc_TypeError

PyExc_UnboundLocalError

PyExc_UnicodeDecodeError

PyExc_UnicodeEncodeError

PyExc_UnicodeError

PyExc_UnicodeTranslateError

PyExc_UnicodeWarning

PyExc_UserWarning

PyExc_ValueError

PyExc_Warning

PyExc_WindowsError

PyExc_ZeroDivisionError

PyExceptionClass_Name()

PyException_GetCause()

PyException_GetContext()

PyException_GetTraceback()

PyException_SetCause()

PyException_SetContext()

PyException_SetTraceback()

PyFile_FromFd()

PyFile_GetLine()

PyFile_WriteObject()

PyFile_WriteString()

PyFilter_Type

PyFloat_AsDouble()

PyFloat_FromDouble()

PyFloat_FromString()

PyFloat_GetInfo()

PyFloat_GetMax()

PyFloat_GetMin()

PyFloat_Type

PyFrameObject

PyFrame_GetCode()

PyFrame_GetLineNumber()

PyFrozenSet_New()

PyFrozenSet_Type

PyGC_Collect()

PyGC_Disable()

PyGC_Enable()

PyGC_IsEnabled()

PyGILState_Ensure()

PyGILState_GetThisThreadState()

PyGILState_Release()

PyGILState_STATE

PyGetSetDef

PyGetSetDescr_Type

PyImport_AddModule()

PyImport_AddModuleObject()

PyImport_AppendInittab()

PyImport_ExecCodeModule()

PyImport_ExecCodeModuleEx()

PyImport_ExecCodeModuleObject()

PyImport_ExecCodeModuleWithPathnames()

PyImport_GetImporter()

PyImport_GetMagicNumber()

PyImport_GetMagicTag()

PyImport_GetModule()

PyImport_GetModuleDict()

PyImport_Import()

PyImport_ImportFrozenModule()

PyImport_ImportFrozenModuleObject()

PyImport_ImportModule()

PyImport_ImportModuleLevel()

PyImport_ImportModuleLevelObject()

PyImport_ImportModuleNoBlock()

PyImport_ReloadModule()

PyIndex_Check()

PyInterpreterState

PyInterpreterState_Clear()

PyInterpreterState_Delete()

PyInterpreterState_Get()

PyInterpreterState_GetDict()

PyInterpreterState_GetID()

PyInterpreterState_New()

PyIter_Check()

PyIter_Next()

PyIter_Send()

PyListIter_Type

PyListRevIter_Type

PyList_Append()

PyList_AsTuple()

PyList_GetItem()

PyList_GetSlice()

PyList_Insert()

PyList_New()

PyList_Reverse()

PyList_SetItem()

PyList_SetSlice()

PyList_Size()

PyList_Sort()

PyList_Type

PyLongObject

PyLongRangeIter_Type

PyLong_AsDouble()

PyLong_AsLong()

PyLong_AsLongAndOverflow()

PyLong_AsLongLong()

PyLong_AsLongLongAndOverflow()

PyLong_AsSize_t()

PyLong_AsSsize_t()

PyLong_AsUnsignedLong()

PyLong_AsUnsignedLongLong()

PyLong_AsUnsignedLongLongMask()

PyLong_AsUnsignedLongMask()

PyLong_AsVoidPtr()

PyLong_FromDouble()

PyLong_FromLong()

PyLong_FromLongLong()

PyLong_FromSize_t()

PyLong_FromSsize_t()

PyLong_FromString()

PyLong_FromUnsignedLong()

PyLong_FromUnsignedLongLong()

PyLong_FromVoidPtr()

PyLong_GetInfo()

PyLong_Type

PyMap_Type

PyMapping_Check()

PyMapping_GetItemString()

PyMapping_HasKey()

PyMapping_HasKeyString()

PyMapping_Items()

PyMapping_Keys()

PyMapping_Length()

PyMapping_SetItemString()

PyMapping_Size()

PyMapping_Values()

PyMem_Calloc()

PyMem_Free()

PyMem_Malloc()

PyMem_Realloc()

PyMemberDef

PyMemberDescr_Type

PyMemoryView_FromMemory()

PyMemoryView_FromObject()

PyMemoryView_GetContiguous()

PyMemoryView_Type

PyMethodDef

PyMethodDescr_Type

PyModuleDef

PyModuleDef_Base

PyModuleDef_Init()

PyModuleDef_Type

PyModule_AddFunctions()

PyModule_AddIntConstant()

PyModule_AddObject()

PyModule_AddObjectRef()

PyModule_AddStringConstant()

PyModule_AddType()

PyModule_Create2()

PyModule_ExecDef()

PyModule_FromDefAndSpec2()

PyModule_GetDef()

PyModule_GetDict()

PyModule_GetFilename()

PyModule_GetFilenameObject()

PyModule_GetName()

PyModule_GetNameObject()

PyModule_GetState()

PyModule_New()

PyModule_NewObject()

PyModule_SetDocString()

PyModule_Type

PyNumber_Absolute()

PyNumber_Add()

PyNumber_And()

PyNumber_AsSsize_t()

PyNumber_Check()

PyNumber_Divmod()

PyNumber_Float()

PyNumber_FloorDivide()

PyNumber_InPlaceAdd()

PyNumber_InPlaceAnd()

PyNumber_InPlaceFloorDivide()

PyNumber_InPlaceLshift()

PyNumber_InPlaceMatrixMultiply()

PyNumber_InPlaceMultiply()

PyNumber_InPlaceOr()

PyNumber_InPlacePower()

PyNumber_InPlaceRemainder()

PyNumber_InPlaceRshift()

PyNumber_InPlaceSubtract()

PyNumber_InPlaceTrueDivide()

PyNumber_InPlaceXor()

PyNumber_Index()

PyNumber_Invert()

PyNumber_Long()

PyNumber_Lshift()

PyNumber_MatrixMultiply()

PyNumber_Multiply()

PyNumber_Negative()

PyNumber_Or()

PyNumber_Positive()

PyNumber_Power()

PyNumber_Remainder()

PyNumber_Rshift()

PyNumber_Subtract()

PyNumber_ToBase()

PyNumber_TrueDivide()

PyNumber_Xor()

PyOS_AfterFork()

PyOS_AfterFork_Child()

PyOS_AfterFork_Parent()

PyOS_BeforeFork()

PyOS_CheckStack()

PyOS_FSPath()

PyOS_InputHook

PyOS_InterruptOccurred()

PyOS_double_to_string()

PyOS_getsig()

PyOS_mystricmp()

PyOS_mystrnicmp()

PyOS_setsig()

PyOS_sighandler_t

PyOS_snprintf()

PyOS_string_to_double()

PyOS_strtol()

PyOS_strtoul()

PyOS_vsnprintf()

PyObject

PyObject.ob_refcnt

PyObject.ob_type

PyObject_ASCII()

PyObject_AsCharBuffer()

PyObject_AsFileDescriptor()

PyObject_AsReadBuffer()

PyObject_AsWriteBuffer()

PyObject_Bytes()

PyObject_Call()

PyObject_CallFunction()

PyObject_CallFunctionObjArgs()

PyObject_CallMethod()

PyObject_CallMethodObjArgs()

PyObject_CallNoArgs()

PyObject_CallObject()

PyObject_Calloc()

PyObject_CheckReadBuffer()

PyObject_ClearWeakRefs()

PyObject_DelItem()

PyObject_DelItemString()

PyObject_Dir()

PyObject_Format()

PyObject_Free()

PyObject_GC_Del()

PyObject_GC_IsFinalized()

PyObject_GC_IsTracked()

PyObject_GC_Track()

PyObject_GC_UnTrack()

PyObject_GenericGetAttr()

PyObject_GenericGetDict()

PyObject_GenericSetAttr()

PyObject_GenericSetDict()

PyObject_GetAIter()

PyObject_GetAttr()

PyObject_GetAttrString()

PyObject_GetItem()

PyObject_GetIter()

PyObject_HasAttr()

PyObject_HasAttrString()

PyObject_Hash()

PyObject_HashNotImplemented()

PyObject_Init()

PyObject_InitVar()

PyObject_IsInstance()

PyObject_IsSubclass()

PyObject_IsTrue()

PyObject_Length()

PyObject_Malloc()

PyObject_Not()

PyObject_Realloc()

PyObject_Repr()

PyObject_RichCompare()

PyObject_RichCompareBool()

PyObject_SelfIter()

PyObject_SetAttr()

PyObject_SetAttrString()

PyObject_SetItem()

PyObject_Size()

PyObject_Str()

PyObject_Type()

PyProperty_Type

PyRangeIter_Type

PyRange_Type

PyReversed_Type

PySeqIter_New()

PySeqIter_Type

PySequence_Check()

PySequence_Concat()

PySequence_Contains()

PySequence_Count()

PySequence_DelItem()

PySequence_DelSlice()

PySequence_Fast()

PySequence_GetItem()

PySequence_GetSlice()

PySequence_In()

PySequence_InPlaceConcat()

PySequence_InPlaceRepeat()

PySequence_Index()

PySequence_Length()

PySequence_List()

PySequence_Repeat()

PySequence_SetItem()

PySequence_SetSlice()

PySequence_Size()

PySequence_Tuple()

PySetIter_Type

PySet_Add()

PySet_Clear()

PySet_Contains()

PySet_Discard()

PySet_New()

PySet_Pop()

PySet_Size()

PySet_Type

PySlice_AdjustIndices()

PySlice_GetIndices()

PySlice_GetIndicesEx()

PySlice_New()

PySlice_Type

PySlice_Unpack()

PyState_AddModule()

PyState_FindModule()

PyState_RemoveModule()

PyStructSequence_Desc

PyStructSequence_Field

PyStructSequence_GetItem()

PyStructSequence_New()

PyStructSequence_NewType()

PyStructSequence_SetItem()

PySuper_Type

PySys_AddWarnOption()

PySys_AddWarnOptionUnicode()

PySys_AddXOption()

PySys_FormatStderr()

PySys_FormatStdout()

PySys_GetObject()

PySys_GetXOptions()

PySys_HasWarnOptions()

PySys_ResetWarnOptions()

PySys_SetArgv()

PySys_SetArgvEx()

PySys_SetObject()

PySys_SetPath()

PySys_WriteStderr()

PySys_WriteStdout()

PyThreadState

PyThreadState_Clear()

PyThreadState_Delete()

PyThreadState_Get()

PyThreadState_GetDict()

PyThreadState_GetFrame()

PyThreadState_GetID()

PyThreadState_GetInterpreter()

PyThreadState_New()

PyThreadState_SetAsyncExc()

PyThreadState_Swap()

PyThread_GetInfo()

PyThread_ReInitTLS()

PyThread_acquire_lock()

PyThread_acquire_lock_timed()

PyThread_allocate_lock()

PyThread_create_key()

PyThread_delete_key()

PyThread_delete_key_value()

PyThread_exit_thread()

PyThread_free_lock()

PyThread_get_key_value()

PyThread_get_stacksize()

PyThread_get_thread_ident()

PyThread_get_thread_native_id()

PyThread_init_thread()

PyThread_release_lock()

PyThread_set_key_value()

PyThread_set_stacksize()

PyThread_start_new_thread()

PyThread_tss_alloc()

PyThread_tss_create()

PyThread_tss_delete()

PyThread_tss_free()

PyThread_tss_get()

PyThread_tss_is_created()

PyThread_tss_set()

PyTraceBack_Here()

PyTraceBack_Print()

PyTraceBack_Type

PyTupleIter_Type

PyTuple_GetItem()

PyTuple_GetSlice()

PyTuple_New()

PyTuple_Pack()

PyTuple_SetItem()

PyTuple_Size()

PyTuple_Type

PyTypeObject

PyType_ClearCache()

PyType_FromModuleAndSpec()

PyType_FromSpec()

PyType_FromSpecWithBases()

PyType_GenericAlloc()

PyType_GenericNew()

PyType_GetFlags()

PyType_GetModule()

PyType_GetModuleState()

PyType_GetSlot()

PyType_IsSubtype()

PyType_Modified()

PyType_Ready()

PyType_Slot

PyType_Spec

PyType_Type

PyUnicodeDecodeError_Create()

PyUnicodeDecodeError_GetEncoding()

PyUnicodeDecodeError_GetEnd()

PyUnicodeDecodeError_GetObject()

PyUnicodeDecodeError_GetReason()

PyUnicodeDecodeError_GetStart()

PyUnicodeDecodeError_SetEnd()

PyUnicodeDecodeError_SetReason()

PyUnicodeDecodeError_SetStart()

PyUnicodeEncodeError_GetEncoding()

PyUnicodeEncodeError_GetEnd()

PyUnicodeEncodeError_GetObject()

PyUnicodeEncodeError_GetReason()

PyUnicodeEncodeError_GetStart()

PyUnicodeEncodeError_SetEnd()

PyUnicodeEncodeError_SetReason()

PyUnicodeEncodeError_SetStart()

PyUnicodeIter_Type

PyUnicodeTranslateError_GetEnd()

PyUnicodeTranslateError_GetObject()

PyUnicodeTranslateError_GetReason()

PyUnicodeTranslateError_GetStart()

PyUnicodeTranslateError_SetEnd()

PyUnicodeTranslateError_SetReason()

PyUnicodeTranslateError_SetStart()

PyUnicode_Append()

PyUnicode_AppendAndDel()

PyUnicode_AsASCIIString()

PyUnicode_AsCharmapString()

PyUnicode_AsDecodedObject()

PyUnicode_AsDecodedUnicode()

PyUnicode_AsEncodedObject()

PyUnicode_AsEncodedString()

PyUnicode_AsEncodedUnicode()

PyUnicode_AsLatin1String()

PyUnicode_AsMBCSString()

PyUnicode_AsRawUnicodeEscapeString()

PyUnicode_AsUCS4()

PyUnicode_AsUCS4Copy()

PyUnicode_AsUTF16String()

PyUnicode_AsUTF32String()

PyUnicode_AsUTF8AndSize()

PyUnicode_AsUTF8String()

PyUnicode_AsUnicodeEscapeString()

PyUnicode_AsWideChar()

PyUnicode_AsWideCharString()

PyUnicode_BuildEncodingMap()

PyUnicode_Compare()

PyUnicode_CompareWithASCIIString()

PyUnicode_Concat()

PyUnicode_Contains()

PyUnicode_Count()

PyUnicode_Decode()

PyUnicode_DecodeASCII()

PyUnicode_DecodeCharmap()

PyUnicode_DecodeCodePageStateful()

PyUnicode_DecodeFSDefault()

PyUnicode_DecodeFSDefaultAndSize()

PyUnicode_DecodeLatin1()

PyUnicode_DecodeLocale()

PyUnicode_DecodeLocaleAndSize()

PyUnicode_DecodeMBCS()

PyUnicode_DecodeMBCSStateful()

PyUnicode_DecodeRawUnicodeEscape()

PyUnicode_DecodeUTF16()

PyUnicode_DecodeUTF16Stateful()

PyUnicode_DecodeUTF32()

PyUnicode_DecodeUTF32Stateful()

PyUnicode_DecodeUTF7()

PyUnicode_DecodeUTF7Stateful()

PyUnicode_DecodeUTF8()

PyUnicode_DecodeUTF8Stateful()

PyUnicode_DecodeUnicodeEscape()

PyUnicode_EncodeCodePage()

PyUnicode_EncodeFSDefault()

PyUnicode_EncodeLocale()

PyUnicode_FSConverter()

PyUnicode_FSDecoder()

PyUnicode_Find()

PyUnicode_FindChar()

PyUnicode_Format()

PyUnicode_FromEncodedObject()

PyUnicode_FromFormat()

PyUnicode_FromFormatV()

PyUnicode_FromObject()

PyUnicode_FromOrdinal()

PyUnicode_FromString()

PyUnicode_FromStringAndSize()

PyUnicode_FromWideChar()

PyUnicode_GetDefaultEncoding()

PyUnicode_GetLength()

PyUnicode_GetSize()

PyUnicode_InternFromString()

PyUnicode_InternImmortal()

PyUnicode_InternInPlace()

PyUnicode_IsIdentifier()

PyUnicode_Join()

PyUnicode_Partition()

PyUnicode_RPartition()

PyUnicode_RSplit()

PyUnicode_ReadChar()

PyUnicode_Replace()

PyUnicode_Resize()

PyUnicode_RichCompare()

PyUnicode_Split()

PyUnicode_Splitlines()

PyUnicode_Substring()

PyUnicode_Tailmatch()

PyUnicode_Translate()

PyUnicode_Type

PyUnicode_WriteChar()

PyVarObject

PyVarObject.ob_base

PyVarObject.ob_size

PyWeakReference

PyWeakref_GetObject()

PyWeakref_NewProxy()

PyWeakref_NewRef()

PyWrapperDescr_Type

PyWrapper_New()

PyZip_Type

Py_AddPendingCall()

Py_AtExit()

Py_BEGIN_ALLOW_THREADS

Py_BLOCK_THREADS

Py_BuildValue()

Py_BytesMain()

Py_CompileString()

Py_DecRef()

Py_DecodeLocale()

Py_END_ALLOW_THREADS

Py_EncodeLocale()

Py_EndInterpreter()

Py_EnterRecursiveCall()

Py_Exit()

Py_FatalError()

Py_FileSystemDefaultEncodeErrors

Py_FileSystemDefaultEncoding

Py_Finalize()

Py_FinalizeEx()

Py_GenericAlias()

Py_GenericAliasType

Py_GetBuildInfo()

Py_GetCompiler()

Py_GetCopyright()

Py_GetExecPrefix()

Py_GetPath()

Py_GetPlatform()

Py_GetPrefix()

Py_GetProgramFullPath()

Py_GetProgramName()

Py_GetPythonHome()

Py_GetRecursionLimit()

Py_GetVersion()

Py_HasFileSystemDefaultEncoding

Py_IncRef()

Py_Initialize()

Py_InitializeEx()

Py_Is()

Py_IsFalse()

Py_IsInitialized()

Py_IsNone()

Py_IsTrue()

Py_LeaveRecursiveCall()

Py_Main()

Py_MakePendingCalls()

Py_NewInterpreter()

Py_NewRef()

Py_ReprEnter()

Py_ReprLeave()

Py_SetPath()

Py_SetProgramName()

Py_SetPythonHome()

Py_SetRecursionLimit()

Py_UCS4

Py_UNBLOCK_THREADS

Py_UTF8Mode

Py_VaBuildValue()

Py_XNewRef()

Py_intptr_t

Py_ssize_t

Py_uintptr_t

allocfunc

binaryfunc

descrgetfunc

descrsetfunc

destructor

getattrfunc

getattrofunc

getiterfunc

getter

hashfunc

initproc

inquiry

iternextfunc

lenfunc

newfunc

objobjargproc

objobjproc

reprfunc

richcmpfunc

setattrfunc

setattrofunc

setter

ssizeargfunc

ssizeobjargproc

ssizessizeargfunc

ssizessizeobjargproc

symtable

ternaryfunc

traverseproc

unaryfunc

visitproc

Table of Contents
C API Stability
Stable Application Binary Interface
Limited API Scope and Performance
Limited API Caveats
Platform Considerations
Contents of Limited API
Previous topic
Introduction

Next topic
The Very High Level Layer

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » C API Stability
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » C API Stability
Quick search
  |
C API Stability
Python’s C API is covered by the Backwards Compatibility Policy, PEP 387. While the C API will change with every minor release (e.g. from 3.9 to 3.10), most changes will be source-compatible, typically by only adding new API. Changing existing API or removing API is only done after a deprecation period or to fix serious issues.

CPython’s Application Binary Interface (ABI) is forward- and backwards-compatible across a minor release (if these are compiled the same way; see Platform Considerations below). So, code compiled for Python 3.10.0 will work on 3.10.8 and vice versa, but will need to be compiled separately for 3.9.x and 3.10.x.

Names prefixed by an underscore, such as _Py_InternalState, are private API that can change without notice even in patch releases.

Stable Application Binary Interface
Python 3.2 introduced the Limited API, a subset of Python’s C API. Extensions that only use the Limited API can be compiled once and work with multiple versions of Python. Contents of the Limited API are listed below.

To enable this, Python provides a Stable ABI: a set of symbols that will remain compatible across Python 3.x versions. The Stable ABI contains symbols exposed in the Limited API, but also other ones – for example, functions necessary to support older versions of the Limited API.

(For simplicity, this document talks about extensions, but the Limited API and Stable ABI work the same way for all uses of the API – for example, embedding Python.)

Py_LIMITED_API
Define this macro before including Python.h to opt in to only use the Limited API, and to select the Limited API version.

Define Py_LIMITED_API to the value of PY_VERSION_HEX corresponding to the lowest Python version your extension supports. The extension will work without recompilation with all Python 3 releases from the specified one onward, and can use Limited API introduced up to that version.

Rather than using the PY_VERSION_HEX macro directly, hardcode a minimum minor version (e.g. 0x030A0000 for Python 3.10) for stability when compiling with future Python versions.

You can also define Py_LIMITED_API to 3. This works the same as 0x03020000 (Python 3.2, the version that introduced Limited API).

On Windows, extensions that use the Stable ABI should be linked against python3.dll rather than a version-specific library such as python39.dll.

On some platforms, Python will look for and load shared library files named with the abi3 tag (e.g. mymodule.abi3.so). It does not check if such extensions conform to a Stable ABI. The user (or their packaging tools) need to ensure that, for example, extensions built with the 3.10+ Limited API are not installed for lower versions of Python.

All functions in the Stable ABI are present as functions in Python’s shared library, not solely as macros. This makes them usable from languages that don’t use the C preprocessor.

Limited API Scope and Performance
The goal for the Limited API is to allow everything that is possible with the full C API, but possibly with a performance penalty.

For example, while PyList_GetItem() is available, its “unsafe” macro variant PyList_GET_ITEM() is not. The macro can be faster because it can rely on version-specific implementation details of the list object.

Without Py_LIMITED_API defined, some C API functions are inlined or replaced by macros. Defining Py_LIMITED_API disables this inlining, allowing stability as Python’s data structures are improved, but possibly reducing performance.

By leaving out the Py_LIMITED_API definition, it is possible to compile a Limited API extension with a version-specific ABI. This can improve performance for that Python version, but will limit compatibility. Compiling with Py_LIMITED_API will then yield an extension that can be distributed where a version-specific one is not available – for example, for prereleases of an upcoming Python version.

Limited API Caveats
Note that compiling with Py_LIMITED_API is not a complete guarantee that code conforms to the Limited API or the Stable ABI. Py_LIMITED_API only covers definitions, but an API also includes other issues, such as expected semantics.

One issue that Py_LIMITED_API does not guard against is calling a function with arguments that are invalid in a lower Python version. For example, consider a function that starts accepting NULL for an argument. In Python 3.9, NULL now selects a default behavior, but in Python 3.8, the argument will be used directly, causing a NULL dereference and crash. A similar argument works for fields of structs.

Another issue is that some struct fields are currently not hidden when Py_LIMITED_API is defined, even though they’re part of the Limited API.

For these reasons, we recommend testing an extension with all minor Python versions it supports, and preferably to build with the lowest such version.

We also recommend reviewing documentation of all used API to check if it is explicitly part of the Limited API. Even with Py_LIMITED_API defined, a few private declarations are exposed for technical reasons (or even unintentionally, as bugs).

Also note that the Limited API is not necessarily stable: compiling with Py_LIMITED_API with Python 3.8 means that the extension will run with Python 3.12, but it will not necessarily compile with Python 3.12. In particular, parts of the Limited API may be deprecated and removed, provided that the Stable ABI stays stable.

Platform Considerations
ABI stability depends not only on Python, but also on the compiler used, lower-level libraries and compiler options. For the purposes of the Stable ABI, these details define a “platform”. They usually depend on the OS type and processor architecture

It is the responsibility of each particular distributor of Python to ensure that all Python versions on a particular platform are built in a way that does not break the Stable ABI. This is the case with Windows and macOS releases from python.org and many third-party distributors.

Contents of Limited API
Currently, the Limited API includes the following items:

PyAIter_Check()

PyArg_Parse()

PyArg_ParseTuple()

PyArg_ParseTupleAndKeywords()

PyArg_UnpackTuple()

PyArg_VaParse()

PyArg_VaParseTupleAndKeywords()

PyArg_ValidateKeywordArguments()

PyBaseObject_Type

PyBool_FromLong()

PyBool_Type

PyByteArrayIter_Type

PyByteArray_AsString()

PyByteArray_Concat()

PyByteArray_FromObject()

PyByteArray_FromStringAndSize()

PyByteArray_Resize()

PyByteArray_Size()

PyByteArray_Type

PyBytesIter_Type

PyBytes_AsString()

PyBytes_AsStringAndSize()

PyBytes_Concat()

PyBytes_ConcatAndDel()

PyBytes_DecodeEscape()

PyBytes_FromFormat()

PyBytes_FromFormatV()

PyBytes_FromObject()

PyBytes_FromString()

PyBytes_FromStringAndSize()

PyBytes_Repr()

PyBytes_Size()

PyBytes_Type

PyCFunction

PyCFunctionWithKeywords

PyCFunction_Call()

PyCFunction_GetFlags()

PyCFunction_GetFunction()

PyCFunction_GetSelf()

PyCFunction_New()

PyCFunction_NewEx()

PyCFunction_Type

PyCMethod_New()

PyCallIter_New()

PyCallIter_Type

PyCallable_Check()

PyCapsule_Destructor

PyCapsule_GetContext()

PyCapsule_GetDestructor()

PyCapsule_GetName()

PyCapsule_GetPointer()

PyCapsule_Import()

PyCapsule_IsValid()

PyCapsule_New()

PyCapsule_SetContext()

PyCapsule_SetDestructor()

PyCapsule_SetName()

PyCapsule_SetPointer()

PyCapsule_Type

PyClassMethodDescr_Type

PyCodec_BackslashReplaceErrors()

PyCodec_Decode()

PyCodec_Decoder()

PyCodec_Encode()

PyCodec_Encoder()

PyCodec_IgnoreErrors()

PyCodec_IncrementalDecoder()

PyCodec_IncrementalEncoder()

PyCodec_KnownEncoding()

PyCodec_LookupError()

PyCodec_NameReplaceErrors()

PyCodec_Register()

PyCodec_RegisterError()

PyCodec_ReplaceErrors()

PyCodec_StreamReader()

PyCodec_StreamWriter()

PyCodec_StrictErrors()

PyCodec_Unregister()

PyCodec_XMLCharRefReplaceErrors()

PyComplex_FromDoubles()

PyComplex_ImagAsDouble()

PyComplex_RealAsDouble()

PyComplex_Type

PyDescr_NewClassMethod()

PyDescr_NewGetSet()

PyDescr_NewMember()

PyDescr_NewMethod()

PyDictItems_Type

PyDictIterItem_Type

PyDictIterKey_Type

PyDictIterValue_Type

PyDictKeys_Type

PyDictProxy_New()

PyDictProxy_Type

PyDictRevIterItem_Type

PyDictRevIterKey_Type

PyDictRevIterValue_Type

PyDictValues_Type

PyDict_Clear()

PyDict_Contains()

PyDict_Copy()

PyDict_DelItem()

PyDict_DelItemString()

PyDict_GetItem()

PyDict_GetItemString()

PyDict_GetItemWithError()

PyDict_Items()

PyDict_Keys()

PyDict_Merge()

PyDict_MergeFromSeq2()

PyDict_New()

PyDict_Next()

PyDict_SetItem()

PyDict_SetItemString()

PyDict_Size()

PyDict_Type

PyDict_Update()

PyDict_Values()

PyEllipsis_Type

PyEnum_Type

PyErr_BadArgument()

PyErr_BadInternalCall()

PyErr_CheckSignals()

PyErr_Clear()

PyErr_Display()

PyErr_ExceptionMatches()

PyErr_Fetch()

PyErr_Format()

PyErr_FormatV()

PyErr_GetExcInfo()

PyErr_GivenExceptionMatches()

PyErr_NewException()

PyErr_NewExceptionWithDoc()

PyErr_NoMemory()

PyErr_NormalizeException()

PyErr_Occurred()

PyErr_Print()

PyErr_PrintEx()

PyErr_ProgramText()

PyErr_ResourceWarning()

PyErr_Restore()

PyErr_SetExcFromWindowsErr()

PyErr_SetExcFromWindowsErrWithFilename()

PyErr_SetExcFromWindowsErrWithFilenameObject()

PyErr_SetExcFromWindowsErrWithFilenameObjects()

PyErr_SetExcInfo()

PyErr_SetFromErrno()

PyErr_SetFromErrnoWithFilename()

PyErr_SetFromErrnoWithFilenameObject()

PyErr_SetFromErrnoWithFilenameObjects()

PyErr_SetFromWindowsErr()

PyErr_SetFromWindowsErrWithFilename()

PyErr_SetImportError()

PyErr_SetImportErrorSubclass()

PyErr_SetInterrupt()

PyErr_SetInterruptEx()

PyErr_SetNone()

PyErr_SetObject()

PyErr_SetString()

PyErr_SyntaxLocation()

PyErr_SyntaxLocationEx()

PyErr_WarnEx()

PyErr_WarnExplicit()

PyErr_WarnFormat()

PyErr_WriteUnraisable()

PyEval_AcquireLock()

PyEval_AcquireThread()

PyEval_CallFunction()

PyEval_CallMethod()

PyEval_CallObjectWithKeywords()

PyEval_EvalCode()

PyEval_EvalCodeEx()

PyEval_EvalFrame()

PyEval_EvalFrameEx()

PyEval_GetBuiltins()

PyEval_GetFrame()

PyEval_GetFuncDesc()

PyEval_GetFuncName()

PyEval_GetGlobals()

PyEval_GetLocals()

PyEval_InitThreads()

PyEval_ReleaseLock()

PyEval_ReleaseThread()

PyEval_RestoreThread()

PyEval_SaveThread()

PyEval_ThreadsInitialized()

PyExc_ArithmeticError

PyExc_AssertionError

PyExc_AttributeError

PyExc_BaseException

PyExc_BlockingIOError

PyExc_BrokenPipeError

PyExc_BufferError

PyExc_BytesWarning

PyExc_ChildProcessError

PyExc_ConnectionAbortedError

PyExc_ConnectionError

PyExc_ConnectionRefusedError

PyExc_ConnectionResetError

PyExc_DeprecationWarning

PyExc_EOFError

PyExc_EncodingWarning

PyExc_EnvironmentError

PyExc_Exception

PyExc_FileExistsError

PyExc_FileNotFoundError

PyExc_FloatingPointError

PyExc_FutureWarning

PyExc_GeneratorExit

PyExc_IOError

PyExc_ImportError

PyExc_ImportWarning

PyExc_IndentationError

PyExc_IndexError

PyExc_InterruptedError

PyExc_IsADirectoryError

PyExc_KeyError

PyExc_KeyboardInterrupt

PyExc_LookupError

PyExc_MemoryError

PyExc_ModuleNotFoundError

PyExc_NameError

PyExc_NotADirectoryError

PyExc_NotImplementedError

PyExc_OSError

PyExc_OverflowError

PyExc_PendingDeprecationWarning

PyExc_PermissionError

PyExc_ProcessLookupError

PyExc_RecursionError

PyExc_ReferenceError

PyExc_ResourceWarning

PyExc_RuntimeError

PyExc_RuntimeWarning

PyExc_StopAsyncIteration

PyExc_StopIteration

PyExc_SyntaxError

PyExc_SyntaxWarning

PyExc_SystemError

PyExc_SystemExit

PyExc_TabError

PyExc_TimeoutError

PyExc_TypeError

PyExc_UnboundLocalError

PyExc_UnicodeDecodeError

PyExc_UnicodeEncodeError

PyExc_UnicodeError

PyExc_UnicodeTranslateError

PyExc_UnicodeWarning

PyExc_UserWarning

PyExc_ValueError

PyExc_Warning

PyExc_WindowsError

PyExc_ZeroDivisionError

PyExceptionClass_Name()

PyException_GetCause()

PyException_GetContext()

PyException_GetTraceback()

PyException_SetCause()

PyException_SetContext()

PyException_SetTraceback()

PyFile_FromFd()

PyFile_GetLine()

PyFile_WriteObject()

PyFile_WriteString()

PyFilter_Type

PyFloat_AsDouble()

PyFloat_FromDouble()

PyFloat_FromString()

PyFloat_GetInfo()

PyFloat_GetMax()

PyFloat_GetMin()

PyFloat_Type

PyFrameObject

PyFrame_GetCode()

PyFrame_GetLineNumber()

PyFrozenSet_New()

PyFrozenSet_Type

PyGC_Collect()

PyGC_Disable()

PyGC_Enable()

PyGC_IsEnabled()

PyGILState_Ensure()

PyGILState_GetThisThreadState()

PyGILState_Release()

PyGILState_STATE

PyGetSetDef

PyGetSetDescr_Type

PyImport_AddModule()

PyImport_AddModuleObject()

PyImport_AppendInittab()

PyImport_ExecCodeModule()

PyImport_ExecCodeModuleEx()

PyImport_ExecCodeModuleObject()

PyImport_ExecCodeModuleWithPathnames()

PyImport_GetImporter()

PyImport_GetMagicNumber()

PyImport_GetMagicTag()

PyImport_GetModule()

PyImport_GetModuleDict()

PyImport_Import()

PyImport_ImportFrozenModule()

PyImport_ImportFrozenModuleObject()

PyImport_ImportModule()

PyImport_ImportModuleLevel()

PyImport_ImportModuleLevelObject()

PyImport_ImportModuleNoBlock()

PyImport_ReloadModule()

PyIndex_Check()

PyInterpreterState

PyInterpreterState_Clear()

PyInterpreterState_Delete()

PyInterpreterState_Get()

PyInterpreterState_GetDict()

PyInterpreterState_GetID()

PyInterpreterState_New()

PyIter_Check()

PyIter_Next()

PyIter_Send()

PyListIter_Type

PyListRevIter_Type

PyList_Append()

PyList_AsTuple()

PyList_GetItem()

PyList_GetSlice()

PyList_Insert()

PyList_New()

PyList_Reverse()

PyList_SetItem()

PyList_SetSlice()

PyList_Size()

PyList_Sort()

PyList_Type

PyLongObject

PyLongRangeIter_Type

PyLong_AsDouble()

PyLong_AsLong()

PyLong_AsLongAndOverflow()

PyLong_AsLongLong()

PyLong_AsLongLongAndOverflow()

PyLong_AsSize_t()

PyLong_AsSsize_t()

PyLong_AsUnsignedLong()

PyLong_AsUnsignedLongLong()

PyLong_AsUnsignedLongLongMask()

PyLong_AsUnsignedLongMask()

PyLong_AsVoidPtr()

PyLong_FromDouble()

PyLong_FromLong()

PyLong_FromLongLong()

PyLong_FromSize_t()

PyLong_FromSsize_t()

PyLong_FromString()

PyLong_FromUnsignedLong()

PyLong_FromUnsignedLongLong()

PyLong_FromVoidPtr()

PyLong_GetInfo()

PyLong_Type

PyMap_Type

PyMapping_Check()

PyMapping_GetItemString()

PyMapping_HasKey()

PyMapping_HasKeyString()

PyMapping_Items()

PyMapping_Keys()

PyMapping_Length()

PyMapping_SetItemString()

PyMapping_Size()

PyMapping_Values()

PyMem_Calloc()

PyMem_Free()

PyMem_Malloc()

PyMem_Realloc()

PyMemberDef

PyMemberDescr_Type

PyMemoryView_FromMemory()

PyMemoryView_FromObject()

PyMemoryView_GetContiguous()

PyMemoryView_Type

PyMethodDef

PyMethodDescr_Type

PyModuleDef

PyModuleDef_Base

PyModuleDef_Init()

PyModuleDef_Type

PyModule_AddFunctions()

PyModule_AddIntConstant()

PyModule_AddObject()

PyModule_AddObjectRef()

PyModule_AddStringConstant()

PyModule_AddType()

PyModule_Create2()

PyModule_ExecDef()

PyModule_FromDefAndSpec2()

PyModule_GetDef()

PyModule_GetDict()

PyModule_GetFilename()

PyModule_GetFilenameObject()

PyModule_GetName()

PyModule_GetNameObject()

PyModule_GetState()

PyModule_New()

PyModule_NewObject()

PyModule_SetDocString()

PyModule_Type

PyNumber_Absolute()

PyNumber_Add()

PyNumber_And()

PyNumber_AsSsize_t()

PyNumber_Check()

PyNumber_Divmod()

PyNumber_Float()

PyNumber_FloorDivide()

PyNumber_InPlaceAdd()

PyNumber_InPlaceAnd()

PyNumber_InPlaceFloorDivide()

PyNumber_InPlaceLshift()

PyNumber_InPlaceMatrixMultiply()

PyNumber_InPlaceMultiply()

PyNumber_InPlaceOr()

PyNumber_InPlacePower()

PyNumber_InPlaceRemainder()

PyNumber_InPlaceRshift()

PyNumber_InPlaceSubtract()

PyNumber_InPlaceTrueDivide()

PyNumber_InPlaceXor()

PyNumber_Index()

PyNumber_Invert()

PyNumber_Long()

PyNumber_Lshift()

PyNumber_MatrixMultiply()

PyNumber_Multiply()

PyNumber_Negative()

PyNumber_Or()

PyNumber_Positive()

PyNumber_Power()

PyNumber_Remainder()

PyNumber_Rshift()

PyNumber_Subtract()

PyNumber_ToBase()

PyNumber_TrueDivide()

PyNumber_Xor()

PyOS_AfterFork()

PyOS_AfterFork_Child()

PyOS_AfterFork_Parent()

PyOS_BeforeFork()

PyOS_CheckStack()

PyOS_FSPath()

PyOS_InputHook

PyOS_InterruptOccurred()

PyOS_double_to_string()

PyOS_getsig()

PyOS_mystricmp()

PyOS_mystrnicmp()

PyOS_setsig()

PyOS_sighandler_t

PyOS_snprintf()

PyOS_string_to_double()

PyOS_strtol()

PyOS_strtoul()

PyOS_vsnprintf()

PyObject

PyObject.ob_refcnt

PyObject.ob_type

PyObject_ASCII()

PyObject_AsCharBuffer()

PyObject_AsFileDescriptor()

PyObject_AsReadBuffer()

PyObject_AsWriteBuffer()

PyObject_Bytes()

PyObject_Call()

PyObject_CallFunction()

PyObject_CallFunctionObjArgs()

PyObject_CallMethod()

PyObject_CallMethodObjArgs()

PyObject_CallNoArgs()

PyObject_CallObject()

PyObject_Calloc()

PyObject_CheckReadBuffer()

PyObject_ClearWeakRefs()

PyObject_DelItem()

PyObject_DelItemString()

PyObject_Dir()

PyObject_Format()

PyObject_Free()

PyObject_GC_Del()

PyObject_GC_IsFinalized()

PyObject_GC_IsTracked()

PyObject_GC_Track()

PyObject_GC_UnTrack()

PyObject_GenericGetAttr()

PyObject_GenericGetDict()

PyObject_GenericSetAttr()

PyObject_GenericSetDict()

PyObject_GetAIter()

PyObject_GetAttr()

PyObject_GetAttrString()

PyObject_GetItem()

PyObject_GetIter()

PyObject_HasAttr()

PyObject_HasAttrString()

PyObject_Hash()

PyObject_HashNotImplemented()

PyObject_Init()

PyObject_InitVar()

PyObject_IsInstance()

PyObject_IsSubclass()

PyObject_IsTrue()

PyObject_Length()

PyObject_Malloc()

PyObject_Not()

PyObject_Realloc()

PyObject_Repr()

PyObject_RichCompare()

PyObject_RichCompareBool()

PyObject_SelfIter()

PyObject_SetAttr()

PyObject_SetAttrString()

PyObject_SetItem()

PyObject_Size()

PyObject_Str()

PyObject_Type()

PyProperty_Type

PyRangeIter_Type

PyRange_Type

PyReversed_Type

PySeqIter_New()

PySeqIter_Type

PySequence_Check()

PySequence_Concat()

PySequence_Contains()

PySequence_Count()

PySequence_DelItem()

PySequence_DelSlice()

PySequence_Fast()

PySequence_GetItem()

PySequence_GetSlice()

PySequence_In()

PySequence_InPlaceConcat()

PySequence_InPlaceRepeat()

PySequence_Index()

PySequence_Length()

PySequence_List()

PySequence_Repeat()

PySequence_SetItem()

PySequence_SetSlice()

PySequence_Size()

PySequence_Tuple()

PySetIter_Type

PySet_Add()

PySet_Clear()

PySet_Contains()

PySet_Discard()

PySet_New()

PySet_Pop()

PySet_Size()

PySet_Type

PySlice_AdjustIndices()

PySlice_GetIndices()

PySlice_GetIndicesEx()

PySlice_New()

PySlice_Type

PySlice_Unpack()

PyState_AddModule()

PyState_FindModule()

PyState_RemoveModule()

PyStructSequence_Desc

PyStructSequence_Field

PyStructSequence_GetItem()

PyStructSequence_New()

PyStructSequence_NewType()

PyStructSequence_SetItem()

PySuper_Type

PySys_AddWarnOption()

PySys_AddWarnOptionUnicode()

PySys_AddXOption()

PySys_FormatStderr()

PySys_FormatStdout()

PySys_GetObject()

PySys_GetXOptions()

PySys_HasWarnOptions()

PySys_ResetWarnOptions()

PySys_SetArgv()

PySys_SetArgvEx()

PySys_SetObject()

PySys_SetPath()

PySys_WriteStderr()

PySys_WriteStdout()

PyThreadState

PyThreadState_Clear()

PyThreadState_Delete()

PyThreadState_Get()

PyThreadState_GetDict()

PyThreadState_GetFrame()

PyThreadState_GetID()

PyThreadState_GetInterpreter()

PyThreadState_New()

PyThreadState_SetAsyncExc()

PyThreadState_Swap()

PyThread_GetInfo()

PyThread_ReInitTLS()

PyThread_acquire_lock()

PyThread_acquire_lock_timed()

PyThread_allocate_lock()

PyThread_create_key()

PyThread_delete_key()

PyThread_delete_key_value()

PyThread_exit_thread()

PyThread_free_lock()

PyThread_get_key_value()

PyThread_get_stacksize()

PyThread_get_thread_ident()

PyThread_get_thread_native_id()

PyThread_init_thread()

PyThread_release_lock()

PyThread_set_key_value()

PyThread_set_stacksize()

PyThread_start_new_thread()

PyThread_tss_alloc()

PyThread_tss_create()

PyThread_tss_delete()

PyThread_tss_free()

PyThread_tss_get()

PyThread_tss_is_created()

PyThread_tss_set()

PyTraceBack_Here()

PyTraceBack_Print()

PyTraceBack_Type

PyTupleIter_Type

PyTuple_GetItem()

PyTuple_GetSlice()

PyTuple_New()

PyTuple_Pack()

PyTuple_SetItem()

PyTuple_Size()

PyTuple_Type

PyTypeObject

PyType_ClearCache()

PyType_FromModuleAndSpec()

PyType_FromSpec()

PyType_FromSpecWithBases()

PyType_GenericAlloc()

PyType_GenericNew()

PyType_GetFlags()

PyType_GetModule()

PyType_GetModuleState()

PyType_GetSlot()

PyType_IsSubtype()

PyType_Modified()

PyType_Ready()

PyType_Slot

PyType_Spec

PyType_Type

PyUnicodeDecodeError_Create()

PyUnicodeDecodeError_GetEncoding()

PyUnicodeDecodeError_GetEnd()

PyUnicodeDecodeError_GetObject()

PyUnicodeDecodeError_GetReason()

PyUnicodeDecodeError_GetStart()

PyUnicodeDecodeError_SetEnd()

PyUnicodeDecodeError_SetReason()

PyUnicodeDecodeError_SetStart()

PyUnicodeEncodeError_GetEncoding()

PyUnicodeEncodeError_GetEnd()

PyUnicodeEncodeError_GetObject()

PyUnicodeEncodeError_GetReason()

PyUnicodeEncodeError_GetStart()

PyUnicodeEncodeError_SetEnd()

PyUnicodeEncodeError_SetReason()

PyUnicodeEncodeError_SetStart()

PyUnicodeIter_Type

PyUnicodeTranslateError_GetEnd()

PyUnicodeTranslateError_GetObject()

PyUnicodeTranslateError_GetReason()

PyUnicodeTranslateError_GetStart()

PyUnicodeTranslateError_SetEnd()

PyUnicodeTranslateError_SetReason()

PyUnicodeTranslateError_SetStart()

PyUnicode_Append()

PyUnicode_AppendAndDel()

PyUnicode_AsASCIIString()

PyUnicode_AsCharmapString()

PyUnicode_AsDecodedObject()

PyUnicode_AsDecodedUnicode()

PyUnicode_AsEncodedObject()

PyUnicode_AsEncodedString()

PyUnicode_AsEncodedUnicode()

PyUnicode_AsLatin1String()

PyUnicode_AsMBCSString()

PyUnicode_AsRawUnicodeEscapeString()

PyUnicode_AsUCS4()

PyUnicode_AsUCS4Copy()

PyUnicode_AsUTF16String()

PyUnicode_AsUTF32String()

PyUnicode_AsUTF8AndSize()

PyUnicode_AsUTF8String()

PyUnicode_AsUnicodeEscapeString()

PyUnicode_AsWideChar()

PyUnicode_AsWideCharString()

PyUnicode_BuildEncodingMap()

PyUnicode_Compare()

PyUnicode_CompareWithASCIIString()

PyUnicode_Concat()

PyUnicode_Contains()

PyUnicode_Count()

PyUnicode_Decode()

PyUnicode_DecodeASCII()

PyUnicode_DecodeCharmap()

PyUnicode_DecodeCodePageStateful()

PyUnicode_DecodeFSDefault()

PyUnicode_DecodeFSDefaultAndSize()

PyUnicode_DecodeLatin1()

PyUnicode_DecodeLocale()

PyUnicode_DecodeLocaleAndSize()

PyUnicode_DecodeMBCS()

PyUnicode_DecodeMBCSStateful()

PyUnicode_DecodeRawUnicodeEscape()

PyUnicode_DecodeUTF16()

PyUnicode_DecodeUTF16Stateful()

PyUnicode_DecodeUTF32()

PyUnicode_DecodeUTF32Stateful()

PyUnicode_DecodeUTF7()

PyUnicode_DecodeUTF7Stateful()

PyUnicode_DecodeUTF8()

PyUnicode_DecodeUTF8Stateful()

PyUnicode_DecodeUnicodeEscape()

PyUnicode_EncodeCodePage()

PyUnicode_EncodeFSDefault()

PyUnicode_EncodeLocale()

PyUnicode_FSConverter()

PyUnicode_FSDecoder()

PyUnicode_Find()

PyUnicode_FindChar()

PyUnicode_Format()

PyUnicode_FromEncodedObject()

PyUnicode_FromFormat()

PyUnicode_FromFormatV()

PyUnicode_FromObject()

PyUnicode_FromOrdinal()

PyUnicode_FromString()

PyUnicode_FromStringAndSize()

PyUnicode_FromWideChar()

PyUnicode_GetDefaultEncoding()

PyUnicode_GetLength()

PyUnicode_GetSize()

PyUnicode_InternFromString()

PyUnicode_InternImmortal()

PyUnicode_InternInPlace()

PyUnicode_IsIdentifier()

PyUnicode_Join()

PyUnicode_Partition()

PyUnicode_RPartition()

PyUnicode_RSplit()

PyUnicode_ReadChar()

PyUnicode_Replace()

PyUnicode_Resize()

PyUnicode_RichCompare()

PyUnicode_Split()

PyUnicode_Splitlines()

PyUnicode_Substring()

PyUnicode_Tailmatch()

PyUnicode_Translate()

PyUnicode_Type

PyUnicode_WriteChar()

PyVarObject

PyVarObject.ob_base

PyVarObject.ob_size

PyWeakReference

PyWeakref_GetObject()

PyWeakref_NewProxy()

PyWeakref_NewRef()

PyWrapperDescr_Type

PyWrapper_New()

PyZip_Type

Py_AddPendingCall()

Py_AtExit()

Py_BEGIN_ALLOW_THREADS

Py_BLOCK_THREADS

Py_BuildValue()

Py_BytesMain()

Py_CompileString()

Py_DecRef()

Py_DecodeLocale()

Py_END_ALLOW_THREADS

Py_EncodeLocale()

Py_EndInterpreter()

Py_EnterRecursiveCall()

Py_Exit()

Py_FatalError()

Py_FileSystemDefaultEncodeErrors

Py_FileSystemDefaultEncoding

Py_Finalize()

Py_FinalizeEx()

Py_GenericAlias()

Py_GenericAliasType

Py_GetBuildInfo()

Py_GetCompiler()

Py_GetCopyright()

Py_GetExecPrefix()

Py_GetPath()

Py_GetPlatform()

Py_GetPrefix()

Py_GetProgramFullPath()

Py_GetProgramName()

Py_GetPythonHome()

Py_GetRecursionLimit()

Py_GetVersion()

Py_HasFileSystemDefaultEncoding

Py_IncRef()

Py_Initialize()

Py_InitializeEx()

Py_Is()

Py_IsFalse()

Py_IsInitialized()

Py_IsNone()

Py_IsTrue()

Py_LeaveRecursiveCall()

Py_Main()

Py_MakePendingCalls()

Py_NewInterpreter()

Py_NewRef()

Py_ReprEnter()

Py_ReprLeave()

Py_SetPath()

Py_SetProgramName()

Py_SetPythonHome()

Py_SetRecursionLimit()

Py_UCS4

Py_UNBLOCK_THREADS

Py_UTF8Mode

Py_VaBuildValue()

Py_XNewRef()

Py_intptr_t

Py_ssize_t

Py_uintptr_t

allocfunc

binaryfunc

descrgetfunc

descrsetfunc

destructor

getattrfunc

getattrofunc

getiterfunc

getter

hashfunc

initproc

inquiry

iternextfunc

lenfunc

newfunc

objobjargproc

objobjproc

reprfunc

richcmpfunc

setattrfunc

setattrofunc

setter

ssizeargfunc

ssizeobjargproc

ssizessizeargfunc

ssizessizeobjargproc

symtable

ternaryfunc

traverseproc

unaryfunc

visitproc

Table of Contents
C API Stability
Stable Application Binary Interface
Limited API Scope and Performance
Limited API Caveats
Platform Considerations
Contents of Limited API
Previous topic
Introduction

Next topic
The Very High Level Layer

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » C API Stability
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » C API Stability
Quick search
  |
C API Stability
Python’s C API is covered by the Backwards Compatibility Policy, PEP 387. While the C API will change with every minor release (e.g. from 3.9 to 3.10), most changes will be source-compatible, typically by only adding new API. Changing existing API or removing API is only done after a deprecation period or to fix serious issues.

CPython’s Application Binary Interface (ABI) is forward- and backwards-compatible across a minor release (if these are compiled the same way; see Platform Considerations below). So, code compiled for Python 3.10.0 will work on 3.10.8 and vice versa, but will need to be compiled separately for 3.9.x and 3.10.x.

Names prefixed by an underscore, such as _Py_InternalState, are private API that can change without notice even in patch releases.

Stable Application Binary Interface
Python 3.2 introduced the Limited API, a subset of Python’s C API. Extensions that only use the Limited API can be compiled once and work with multiple versions of Python. Contents of the Limited API are listed below.

To enable this, Python provides a Stable ABI: a set of symbols that will remain compatible across Python 3.x versions. The Stable ABI contains symbols exposed in the Limited API, but also other ones – for example, functions necessary to support older versions of the Limited API.

(For simplicity, this document talks about extensions, but the Limited API and Stable ABI work the same way for all uses of the API – for example, embedding Python.)

Py_LIMITED_API
Define this macro before including Python.h to opt in to only use the Limited API, and to select the Limited API version.

Define Py_LIMITED_API to the value of PY_VERSION_HEX corresponding to the lowest Python version your extension supports. The extension will work without recompilation with all Python 3 releases from the specified one onward, and can use Limited API introduced up to that version.

Rather than using the PY_VERSION_HEX macro directly, hardcode a minimum minor version (e.g. 0x030A0000 for Python 3.10) for stability when compiling with future Python versions.

You can also define Py_LIMITED_API to 3. This works the same as 0x03020000 (Python 3.2, the version that introduced Limited API).

On Windows, extensions that use the Stable ABI should be linked against python3.dll rather than a version-specific library such as python39.dll.

On some platforms, Python will look for and load shared library files named with the abi3 tag (e.g. mymodule.abi3.so). It does not check if such extensions conform to a Stable ABI. The user (or their packaging tools) need to ensure that, for example, extensions built with the 3.10+ Limited API are not installed for lower versions of Python.

All functions in the Stable ABI are present as functions in Python’s shared library, not solely as macros. This makes them usable from languages that don’t use the C preprocessor.

Limited API Scope and Performance
The goal for the Limited API is to allow everything that is possible with the full C API, but possibly with a performance penalty.

For example, while PyList_GetItem() is available, its “unsafe” macro variant PyList_GET_ITEM() is not. The macro can be faster because it can rely on version-specific implementation details of the list object.

Without Py_LIMITED_API defined, some C API functions are inlined or replaced by macros. Defining Py_LIMITED_API disables this inlining, allowing stability as Python’s data structures are improved, but possibly reducing performance.

By leaving out the Py_LIMITED_API definition, it is possible to compile a Limited API extension with a version-specific ABI. This can improve performance for that Python version, but will limit compatibility. Compiling with Py_LIMITED_API will then yield an extension that can be distributed where a version-specific one is not available – for example, for prereleases of an upcoming Python version.

Limited API Caveats
Note that compiling with Py_LIMITED_API is not a complete guarantee that code conforms to the Limited API or the Stable ABI. Py_LIMITED_API only covers definitions, but an API also includes other issues, such as expected semantics.

One issue that Py_LIMITED_API does not guard against is calling a function with arguments that are invalid in a lower Python version. For example, consider a function that starts accepting NULL for an argument. In Python 3.9, NULL now selects a default behavior, but in Python 3.8, the argument will be used directly, causing a NULL dereference and crash. A similar argument works for fields of structs.

Another issue is that some struct fields are currently not hidden when Py_LIMITED_API is defined, even though they’re part of the Limited API.

For these reasons, we recommend testing an extension with all minor Python versions it supports, and preferably to build with the lowest such version.

We also recommend reviewing documentation of all used API to check if it is explicitly part of the Limited API. Even with Py_LIMITED_API defined, a few private declarations are exposed for technical reasons (or even unintentionally, as bugs).

Also note that the Limited API is not necessarily stable: compiling with Py_LIMITED_API with Python 3.8 means that the extension will run with Python 3.12, but it will not necessarily compile with Python 3.12. In particular, parts of the Limited API may be deprecated and removed, provided that the Stable ABI stays stable.

Platform Considerations
ABI stability depends not only on Python, but also on the compiler used, lower-level libraries and compiler options. For the purposes of the Stable ABI, these details define a “platform”. They usually depend on the OS type and processor architecture

It is the responsibility of each particular distributor of Python to ensure that all Python versions on a particular platform are built in a way that does not break the Stable ABI. This is the case with Windows and macOS releases from python.org and many third-party distributors.

Contents of Limited API¶
Currently, the Limited API includes the following items:

PyAIter_Check()

PyArg_Parse()

PyArg_ParseTuple()

PyArg_ParseTupleAndKeywords()

PyArg_UnpackTuple()

PyArg_VaParse()

PyArg_VaParseTupleAndKeywords()

PyArg_ValidateKeywordArguments()

PyBaseObject_Type

PyBool_FromLong()

PyBool_Type

PyByteArrayIter_Type

PyByteArray_AsString()

PyByteArray_Concat()

PyByteArray_FromObject()

PyByteArray_FromStringAndSize()

PyByteArray_Resize()

PyByteArray_Size()

PyByteArray_Type

PyBytesIter_Type

PyBytes_AsString()

PyBytes_AsStringAndSize()

PyBytes_Concat()

PyBytes_ConcatAndDel()

PyBytes_DecodeEscape()

PyBytes_FromFormat()

PyBytes_FromFormatV()

PyBytes_FromObject()

PyBytes_FromString()

PyBytes_FromStringAndSize()

PyBytes_Repr()

PyBytes_Size()

PyBytes_Type

PyCFunction

PyCFunctionWithKeywords

PyCFunction_Call()

PyCFunction_GetFlags()

PyCFunction_GetFunction()

PyCFunction_GetSelf()

PyCFunction_New()

PyCFunction_NewEx()

PyCFunction_Type

PyCMethod_New()

PyCallIter_New()

PyCallIter_Type

PyCallable_Check()

PyCapsule_Destructor

PyCapsule_GetContext()

PyCapsule_GetDestructor()

PyCapsule_GetName()

PyCapsule_GetPointer()

PyCapsule_Import()

PyCapsule_IsValid()

PyCapsule_New()

PyCapsule_SetContext()

PyCapsule_SetDestructor()

PyCapsule_SetName()

PyCapsule_SetPointer()

PyCapsule_Type

PyClassMethodDescr_Type

PyCodec_BackslashReplaceErrors()

PyCodec_Decode()

PyCodec_Decoder()

PyCodec_Encode()

PyCodec_Encoder()

PyCodec_IgnoreErrors()

PyCodec_IncrementalDecoder()

PyCodec_IncrementalEncoder()

PyCodec_KnownEncoding()

PyCodec_LookupError()

PyCodec_NameReplaceErrors()

PyCodec_Register()

PyCodec_RegisterError()

PyCodec_ReplaceErrors()

PyCodec_StreamReader()

PyCodec_StreamWriter()

PyCodec_StrictErrors()

PyCodec_Unregister()

PyCodec_XMLCharRefReplaceErrors()

PyComplex_FromDoubles()

PyComplex_ImagAsDouble()

PyComplex_RealAsDouble()

PyComplex_Type

PyDescr_NewClassMethod()

PyDescr_NewGetSet()

PyDescr_NewMember()

PyDescr_NewMethod()

PyDictItems_Type

PyDictIterItem_Type

PyDictIterKey_Type

PyDictIterValue_Type

PyDictKeys_Type

PyDictProxy_New()

PyDictProxy_Type

PyDictRevIterItem_Type

PyDictRevIterKey_Type

PyDictRevIterValue_Type

PyDictValues_Type

PyDict_Clear()

PyDict_Contains()

PyDict_Copy()

PyDict_DelItem()

PyDict_DelItemString()

PyDict_GetItem()

PyDict_GetItemString()

PyDict_GetItemWithError()

PyDict_Items()

PyDict_Keys()

PyDict_Merge()

PyDict_MergeFromSeq2()

PyDict_New()

PyDict_Next()

PyDict_SetItem()

PyDict_SetItemString()

PyDict_Size()

PyDict_Type

PyDict_Update()

PyDict_Values()

PyEllipsis_Type

PyEnum_Type

PyErr_BadArgument()

PyErr_BadInternalCall()

PyErr_CheckSignals()

PyErr_Clear()

PyErr_Display()

PyErr_ExceptionMatches()

PyErr_Fetch()

PyErr_Format()

PyErr_FormatV()

PyErr_GetExcInfo()

PyErr_GivenExceptionMatches()

PyErr_NewException()

PyErr_NewExceptionWithDoc()

PyErr_NoMemory()

PyErr_NormalizeException()

PyErr_Occurred()

PyErr_Print()

PyErr_PrintEx()

PyErr_ProgramText()

PyErr_ResourceWarning()

PyErr_Restore()

PyErr_SetExcFromWindowsErr()

PyErr_SetExcFromWindowsErrWithFilename()

PyErr_SetExcFromWindowsErrWithFilenameObject()

PyErr_SetExcFromWindowsErrWithFilenameObjects()

PyErr_SetExcInfo()

PyErr_SetFromErrno()

PyErr_SetFromErrnoWithFilename()

PyErr_SetFromErrnoWithFilenameObject()

PyErr_SetFromErrnoWithFilenameObjects()

PyErr_SetFromWindowsErr()

PyErr_SetFromWindowsErrWithFilename()

PyErr_SetImportError()

PyErr_SetImportErrorSubclass()

PyErr_SetInterrupt()

PyErr_SetInterruptEx()

PyErr_SetNone()

PyErr_SetObject()

PyErr_SetString()

PyErr_SyntaxLocation()

PyErr_SyntaxLocationEx()

PyErr_WarnEx()

PyErr_WarnExplicit()

PyErr_WarnFormat()

PyErr_WriteUnraisable()

PyEval_AcquireLock()

PyEval_AcquireThread()

PyEval_CallFunction()

PyEval_CallMethod()

PyEval_CallObjectWithKeywords()

PyEval_EvalCode()

PyEval_EvalCodeEx()

PyEval_EvalFrame()

PyEval_EvalFrameEx()

PyEval_GetBuiltins()

PyEval_GetFrame()

PyEval_GetFuncDesc()

PyEval_GetFuncName()

PyEval_GetGlobals()

PyEval_GetLocals()

PyEval_InitThreads()

PyEval_ReleaseLock()

PyEval_ReleaseThread()

PyEval_RestoreThread()

PyEval_SaveThread()

PyEval_ThreadsInitialized()

PyExc_ArithmeticError

PyExc_AssertionError

PyExc_AttributeError

PyExc_BaseException

PyExc_BlockingIOError

PyExc_BrokenPipeError

PyExc_BufferError

PyExc_BytesWarning

PyExc_ChildProcessError

PyExc_ConnectionAbortedError

PyExc_ConnectionError

PyExc_ConnectionRefusedError

PyExc_ConnectionResetError

PyExc_DeprecationWarning

PyExc_EOFError

PyExc_EncodingWarning

PyExc_EnvironmentError

PyExc_Exception

PyExc_FileExistsError

PyExc_FileNotFoundError

PyExc_FloatingPointError

PyExc_FutureWarning

PyExc_GeneratorExit

PyExc_IOError

PyExc_ImportError

PyExc_ImportWarning

PyExc_IndentationError

PyExc_IndexError

PyExc_InterruptedError

PyExc_IsADirectoryError

PyExc_KeyError

PyExc_KeyboardInterrupt

PyExc_LookupError

PyExc_MemoryError

PyExc_ModuleNotFoundError

PyExc_NameError

PyExc_NotADirectoryError

PyExc_NotImplementedError

PyExc_OSError

PyExc_OverflowError

PyExc_PendingDeprecationWarning

PyExc_PermissionError

PyExc_ProcessLookupError

PyExc_RecursionError

PyExc_ReferenceError

PyExc_ResourceWarning

PyExc_RuntimeError

PyExc_RuntimeWarning

PyExc_StopAsyncIteration

PyExc_StopIteration

PyExc_SyntaxError

PyExc_SyntaxWarning

PyExc_SystemError

PyExc_SystemExit

PyExc_TabError

PyExc_TimeoutError

PyExc_TypeError

PyExc_UnboundLocalError

PyExc_UnicodeDecodeError

PyExc_UnicodeEncodeError

PyExc_UnicodeError

PyExc_UnicodeTranslateError

PyExc_UnicodeWarning

PyExc_UserWarning

PyExc_ValueError

PyExc_Warning

PyExc_WindowsError

PyExc_ZeroDivisionError

PyExceptionClass_Name()

PyException_GetCause()

PyException_GetContext()

PyException_GetTraceback()

PyException_SetCause()

PyException_SetContext()

PyException_SetTraceback()

PyFile_FromFd()

PyFile_GetLine()

PyFile_WriteObject()

PyFile_WriteString()

PyFilter_Type

PyFloat_AsDouble()

PyFloat_FromDouble()

PyFloat_FromString()

PyFloat_GetInfo()

PyFloat_GetMax()

PyFloat_GetMin()

PyFloat_Type

PyFrameObject

PyFrame_GetCode()

PyFrame_GetLineNumber()

PyFrozenSet_New()

PyFrozenSet_Type

PyGC_Collect()

PyGC_Disable()

PyGC_Enable()

PyGC_IsEnabled()

PyGILState_Ensure()

PyGILState_GetThisThreadState()

PyGILState_Release()

PyGILState_STATE

PyGetSetDef

PyGetSetDescr_Type

PyImport_AddModule()

PyImport_AddModuleObject()

PyImport_AppendInittab()

PyImport_ExecCodeModule()

PyImport_ExecCodeModuleEx()

PyImport_ExecCodeModuleObject()

PyImport_ExecCodeModuleWithPathnames()

PyImport_GetImporter()

PyImport_GetMagicNumber()

PyImport_GetMagicTag()

PyImport_GetModule()

PyImport_GetModuleDict()

PyImport_Import()

PyImport_ImportFrozenModule()

PyImport_ImportFrozenModuleObject()

PyImport_ImportModule()

PyImport_ImportModuleLevel()

PyImport_ImportModuleLevelObject()

PyImport_ImportModuleNoBlock()

PyImport_ReloadModule()

PyIndex_Check()

PyInterpreterState

PyInterpreterState_Clear()

PyInterpreterState_Delete()

PyInterpreterState_Get()

PyInterpreterState_GetDict()

PyInterpreterState_GetID()

PyInterpreterState_New()

PyIter_Check()

PyIter_Next()

PyIter_Send()

PyListIter_Type

PyListRevIter_Type

PyList_Append()

PyList_AsTuple()

PyList_GetItem()

PyList_GetSlice()

PyList_Insert()

PyList_New()

PyList_Reverse()

PyList_SetItem()

PyList_SetSlice()

PyList_Size()

PyList_Sort()

PyList_Type

PyLongObject

PyLongRangeIter_Type

PyLong_AsDouble()

PyLong_AsLong()

PyLong_AsLongAndOverflow()

PyLong_AsLongLong()

PyLong_AsLongLongAndOverflow()

PyLong_AsSize_t()

PyLong_AsSsize_t()

PyLong_AsUnsignedLong()

PyLong_AsUnsignedLongLong()

PyLong_AsUnsignedLongLongMask()

PyLong_AsUnsignedLongMask()

PyLong_AsVoidPtr()

PyLong_FromDouble()

PyLong_FromLong()

PyLong_FromLongLong()

PyLong_FromSize_t()

PyLong_FromSsize_t()

PyLong_FromString()

PyLong_FromUnsignedLong()

PyLong_FromUnsignedLongLong()

PyLong_FromVoidPtr()

PyLong_GetInfo()

PyLong_Type

PyMap_Type

PyMapping_Check()

PyMapping_GetItemString()

PyMapping_HasKey()

PyMapping_HasKeyString()

PyMapping_Items()

PyMapping_Keys()

PyMapping_Length()

PyMapping_SetItemString()

PyMapping_Size()

PyMapping_Values()

PyMem_Calloc()

PyMem_Free()

PyMem_Malloc()

PyMem_Realloc()

PyMemberDef

PyMemberDescr_Type

PyMemoryView_FromMemory()

PyMemoryView_FromObject()

PyMemoryView_GetContiguous()

PyMemoryView_Type

PyMethodDef

PyMethodDescr_Type

PyModuleDef

PyModuleDef_Base

PyModuleDef_Init()

PyModuleDef_Type

PyModule_AddFunctions()

PyModule_AddIntConstant()

PyModule_AddObject()

PyModule_AddObjectRef()

PyModule_AddStringConstant()

PyModule_AddType()

PyModule_Create2()

PyModule_ExecDef()

PyModule_FromDefAndSpec2()

PyModule_GetDef()

PyModule_GetDict()

PyModule_GetFilename()

PyModule_GetFilenameObject()

PyModule_GetName()

PyModule_GetNameObject()

PyModule_GetState()

PyModule_New()

PyModule_NewObject()

PyModule_SetDocString()

PyModule_Type

PyNumber_Absolute()

PyNumber_Add()

PyNumber_And()

PyNumber_AsSsize_t()

PyNumber_Check()

PyNumber_Divmod()

PyNumber_Float()

PyNumber_FloorDivide()

PyNumber_InPlaceAdd()

PyNumber_InPlaceAnd()

PyNumber_InPlaceFloorDivide()

PyNumber_InPlaceLshift()

PyNumber_InPlaceMatrixMultiply()

PyNumber_InPlaceMultiply()

PyNumber_InPlaceOr()

PyNumber_InPlacePower()

PyNumber_InPlaceRemainder()

PyNumber_InPlaceRshift()

PyNumber_InPlaceSubtract()

PyNumber_InPlaceTrueDivide()

PyNumber_InPlaceXor()

PyNumber_Index()

PyNumber_Invert()

PyNumber_Long()

PyNumber_Lshift()

PyNumber_MatrixMultiply()

PyNumber_Multiply()

PyNumber_Negative()

PyNumber_Or()

PyNumber_Positive()

PyNumber_Power()

PyNumber_Remainder()

PyNumber_Rshift()

PyNumber_Subtract()

PyNumber_ToBase()

PyNumber_TrueDivide()

PyNumber_Xor()

PyOS_AfterFork()

PyOS_AfterFork_Child()

PyOS_AfterFork_Parent()

PyOS_BeforeFork()

PyOS_CheckStack()

PyOS_FSPath()

PyOS_InputHook

PyOS_InterruptOccurred()

PyOS_double_to_string()

PyOS_getsig()

PyOS_mystricmp()

PyOS_mystrnicmp()

PyOS_setsig()

PyOS_sighandler_t

PyOS_snprintf()

PyOS_string_to_double()

PyOS_strtol()

PyOS_strtoul()

PyOS_vsnprintf()

PyObject

PyObject.ob_refcnt

PyObject.ob_type

PyObject_ASCII()

PyObject_AsCharBuffer()

PyObject_AsFileDescriptor()

PyObject_AsReadBuffer()

PyObject_AsWriteBuffer()

PyObject_Bytes()

PyObject_Call()

PyObject_CallFunction()

PyObject_CallFunctionObjArgs()

PyObject_CallMethod()

PyObject_CallMethodObjArgs()

PyObject_CallNoArgs()

PyObject_CallObject()

PyObject_Calloc()

PyObject_CheckReadBuffer()

PyObject_ClearWeakRefs()

PyObject_DelItem()

PyObject_DelItemString()

PyObject_Dir()

PyObject_Format()

PyObject_Free()

PyObject_GC_Del()

PyObject_GC_IsFinalized()

PyObject_GC_IsTracked()

PyObject_GC_Track()

PyObject_GC_UnTrack()

PyObject_GenericGetAttr()

PyObject_GenericGetDict()

PyObject_GenericSetAttr()

PyObject_GenericSetDict()

PyObject_GetAIter()

PyObject_GetAttr()

PyObject_GetAttrString()

PyObject_GetItem()

PyObject_GetIter()

PyObject_HasAttr()

PyObject_HasAttrString()

PyObject_Hash()

PyObject_HashNotImplemented()

PyObject_Init()

PyObject_InitVar()

PyObject_IsInstance()

PyObject_IsSubclass()

PyObject_IsTrue()

PyObject_Length()

PyObject_Malloc()

PyObject_Not()

PyObject_Realloc()

PyObject_Repr()

PyObject_RichCompare()

PyObject_RichCompareBool()

PyObject_SelfIter()

PyObject_SetAttr()

PyObject_SetAttrString()

PyObject_SetItem()

PyObject_Size()

PyObject_Str()

PyObject_Type()

PyProperty_Type

PyRangeIter_Type

PyRange_Type

PyReversed_Type

PySeqIter_New()

PySeqIter_Type

PySequence_Check()

PySequence_Concat()

PySequence_Contains()

PySequence_Count()

PySequence_DelItem()

PySequence_DelSlice()

PySequence_Fast()

PySequence_GetItem()

PySequence_GetSlice()

PySequence_In()

PySequence_InPlaceConcat()

PySequence_InPlaceRepeat()

PySequence_Index()

PySequence_Length()

PySequence_List()

PySequence_Repeat()

PySequence_SetItem()

PySequence_SetSlice()

PySequence_Size()

PySequence_Tuple()

PySetIter_Type

PySet_Add()

PySet_Clear()

PySet_Contains()

PySet_Discard()

PySet_New()

PySet_Pop()

PySet_Size()

PySet_Type

PySlice_AdjustIndices()

PySlice_GetIndices()

PySlice_GetIndicesEx()

PySlice_New()

PySlice_Type

PySlice_Unpack()

PyState_AddModule()

PyState_FindModule()

PyState_RemoveModule()

PyStructSequence_Desc

PyStructSequence_Field

PyStructSequence_GetItem()

PyStructSequence_New()

PyStructSequence_NewType()

PyStructSequence_SetItem()

PySuper_Type

PySys_AddWarnOption()

PySys_AddWarnOptionUnicode()

PySys_AddXOption()

PySys_FormatStderr()

PySys_FormatStdout()

PySys_GetObject()

PySys_GetXOptions()

PySys_HasWarnOptions()

PySys_ResetWarnOptions()

PySys_SetArgv()

PySys_SetArgvEx()

PySys_SetObject()

PySys_SetPath()

PySys_WriteStderr()

PySys_WriteStdout()

PyThreadState

PyThreadState_Clear()

PyThreadState_Delete()

PyThreadState_Get()

PyThreadState_GetDict()

PyThreadState_GetFrame()

PyThreadState_GetID()

PyThreadState_GetInterpreter()

PyThreadState_New()

PyThreadState_SetAsyncExc()

PyThreadState_Swap()

PyThread_GetInfo()

PyThread_ReInitTLS()

PyThread_acquire_lock()

PyThread_acquire_lock_timed()

PyThread_allocate_lock()

PyThread_create_key()

PyThread_delete_key()

PyThread_delete_key_value()

PyThread_exit_thread()

PyThread_free_lock()

PyThread_get_key_value()

PyThread_get_stacksize()

PyThread_get_thread_ident()

PyThread_get_thread_native_id()

PyThread_init_thread()

PyThread_release_lock()

PyThread_set_key_value()

PyThread_set_stacksize()

PyThread_start_new_thread()

PyThread_tss_alloc()

PyThread_tss_create()

PyThread_tss_delete()

PyThread_tss_free()

PyThread_tss_get()

PyThread_tss_is_created()

PyThread_tss_set()

PyTraceBack_Here()

PyTraceBack_Print()

PyTraceBack_Type

PyTupleIter_Type

PyTuple_GetItem()

PyTuple_GetSlice()

PyTuple_New()

PyTuple_Pack()

PyTuple_SetItem()

PyTuple_Size()

PyTuple_Type

PyTypeObject

PyType_ClearCache()

PyType_FromModuleAndSpec()

PyType_FromSpec()

PyType_FromSpecWithBases()

PyType_GenericAlloc()

PyType_GenericNew()

PyType_GetFlags()

PyType_GetModule()

PyType_GetModuleState()

PyType_GetSlot()

PyType_IsSubtype()

PyType_Modified()

PyType_Ready()

PyType_Slot

PyType_Spec

PyType_Type

PyUnicodeDecodeError_Create()

PyUnicodeDecodeError_GetEncoding()

PyUnicodeDecodeError_GetEnd()

PyUnicodeDecodeError_GetObject()

PyUnicodeDecodeError_GetReason()

PyUnicodeDecodeError_GetStart()

PyUnicodeDecodeError_SetEnd()

PyUnicodeDecodeError_SetReason()

PyUnicodeDecodeError_SetStart()

PyUnicodeEncodeError_GetEncoding()

PyUnicodeEncodeError_GetEnd()

PyUnicodeEncodeError_GetObject()

PyUnicodeEncodeError_GetReason()

PyUnicodeEncodeError_GetStart()

PyUnicodeEncodeError_SetEnd()

PyUnicodeEncodeError_SetReason()

PyUnicodeEncodeError_SetStart()

PyUnicodeIter_Type

PyUnicodeTranslateError_GetEnd()

PyUnicodeTranslateError_GetObject()

PyUnicodeTranslateError_GetReason()

PyUnicodeTranslateError_GetStart()

PyUnicodeTranslateError_SetEnd()

PyUnicodeTranslateError_SetReason()

PyUnicodeTranslateError_SetStart()

PyUnicode_Append()

PyUnicode_AppendAndDel()

PyUnicode_AsASCIIString()

PyUnicode_AsCharmapString()

PyUnicode_AsDecodedObject()

PyUnicode_AsDecodedUnicode()

PyUnicode_AsEncodedObject()

PyUnicode_AsEncodedString()

PyUnicode_AsEncodedUnicode()

PyUnicode_AsLatin1String()

PyUnicode_AsMBCSString()

PyUnicode_AsRawUnicodeEscapeString()

PyUnicode_AsUCS4()

PyUnicode_AsUCS4Copy()

PyUnicode_AsUTF16String()

PyUnicode_AsUTF32String()

PyUnicode_AsUTF8AndSize()

PyUnicode_AsUTF8String()

PyUnicode_AsUnicodeEscapeString()

PyUnicode_AsWideChar()

PyUnicode_AsWideCharString()

PyUnicode_BuildEncodingMap()

PyUnicode_Compare()

PyUnicode_CompareWithASCIIString()

PyUnicode_Concat()

PyUnicode_Contains()

PyUnicode_Count()

PyUnicode_Decode()

PyUnicode_DecodeASCII()

PyUnicode_DecodeCharmap()

PyUnicode_DecodeCodePageStateful()

PyUnicode_DecodeFSDefault()

PyUnicode_DecodeFSDefaultAndSize()

PyUnicode_DecodeLatin1()

PyUnicode_DecodeLocale()

PyUnicode_DecodeLocaleAndSize()

PyUnicode_DecodeMBCS()

PyUnicode_DecodeMBCSStateful()

PyUnicode_DecodeRawUnicodeEscape()

PyUnicode_DecodeUTF16()

PyUnicode_DecodeUTF16Stateful()

PyUnicode_DecodeUTF32()

PyUnicode_DecodeUTF32Stateful()

PyUnicode_DecodeUTF7()

PyUnicode_DecodeUTF7Stateful()

PyUnicode_DecodeUTF8()

PyUnicode_DecodeUTF8Stateful()

PyUnicode_DecodeUnicodeEscape()

PyUnicode_EncodeCodePage()

PyUnicode_EncodeFSDefault()

PyUnicode_EncodeLocale()

PyUnicode_FSConverter()

PyUnicode_FSDecoder()

PyUnicode_Find()

PyUnicode_FindChar()

PyUnicode_Format()

PyUnicode_FromEncodedObject()

PyUnicode_FromFormat()

PyUnicode_FromFormatV()

PyUnicode_FromObject()

PyUnicode_FromOrdinal()

PyUnicode_FromString()

PyUnicode_FromStringAndSize()

PyUnicode_FromWideChar()

PyUnicode_GetDefaultEncoding()

PyUnicode_GetLength()

PyUnicode_GetSize()

PyUnicode_InternFromString()

PyUnicode_InternImmortal()

PyUnicode_InternInPlace()

PyUnicode_IsIdentifier()

PyUnicode_Join()

PyUnicode_Partition()

PyUnicode_RPartition()

PyUnicode_RSplit()

PyUnicode_ReadChar()

PyUnicode_Replace()

PyUnicode_Resize()

PyUnicode_RichCompare()

PyUnicode_Split()

PyUnicode_Splitlines()

PyUnicode_Substring()

PyUnicode_Tailmatch()

PyUnicode_Translate()

PyUnicode_Type

PyUnicode_WriteChar()

PyVarObject

PyVarObject.ob_base

PyVarObject.ob_size

PyWeakReference

PyWeakref_GetObject()

PyWeakref_NewProxy()

PyWeakref_NewRef()

PyWrapperDescr_Type

PyWrapper_New()

PyZip_Type

Py_AddPendingCall()

Py_AtExit()

Py_BEGIN_ALLOW_THREADS

Py_BLOCK_THREADS

Py_BuildValue()

Py_BytesMain()

Py_CompileString()

Py_DecRef()

Py_DecodeLocale()

Py_END_ALLOW_THREADS

Py_EncodeLocale()

Py_EndInterpreter()

Py_EnterRecursiveCall()

Py_Exit()

Py_FatalError()

Py_FileSystemDefaultEncodeErrors

Py_FileSystemDefaultEncoding

Py_Finalize()

Py_FinalizeEx()

Py_GenericAlias()

Py_GenericAliasType

Py_GetBuildInfo()

Py_GetCompiler()

Py_GetCopyright()

Py_GetExecPrefix()

Py_GetPath()

Py_GetPlatform()

Py_GetPrefix()

Py_GetProgramFullPath()

Py_GetProgramName()

Py_GetPythonHome()

Py_GetRecursionLimit()

Py_GetVersion()

Py_HasFileSystemDefaultEncoding

Py_IncRef()

Py_Initialize()

Py_InitializeEx()

Py_Is()

Py_IsFalse()

Py_IsInitialized()

Py_IsNone()

Py_IsTrue()

Py_LeaveRecursiveCall()

Py_Main()

Py_MakePendingCalls()

Py_NewInterpreter()

Py_NewRef()

Py_ReprEnter()

Py_ReprLeave()

Py_SetPath()

Py_SetProgramName()

Py_SetPythonHome()

Py_SetRecursionLimit()

Py_UCS4

Py_UNBLOCK_THREADS

Py_UTF8Mode

Py_VaBuildValue()

Py_XNewRef()

Py_intptr_t

Py_ssize_t

Py_uintptr_t

allocfunc

binaryfunc

descrgetfunc

descrsetfunc

destructor

getattrfunc

getattrofunc

getiterfunc

getter

hashfunc

initproc

inquiry

iternextfunc

lenfunc

newfunc

objobjargproc

objobjproc

reprfunc

richcmpfunc

setattrfunc

setattrofunc

setter

ssizeargfunc

ssizeobjargproc

ssizessizeargfunc

ssizessizeobjargproc

symtable

ternaryfunc

traverseproc

unaryfunc

visitproc

Table of Contents
C API Stability
Stable Application Binary Interface
Limited API Scope and Performance
Limited API Caveats
Platform Considerations
Contents of Limited API
Previous topic
Introduction

Next topic
The Very High Level Layer

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » C API Stability
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » C API Stability
Quick search
  |
C API Stability
Python’s C API is covered by the Backwards Compatibility Policy, PEP 387. While the C API will change with every minor release (e.g. from 3.9 to 3.10), most changes will be source-compatible, typically by only adding new API. Changing existing API or removing API is only done after a deprecation period or to fix serious issues.

CPython’s Application Binary Interface (ABI) is forward- and backwards-compatible across a minor release (if these are compiled the same way; see Platform Considerations below). So, code compiled for Python 3.10.0 will work on 3.10.8 and vice versa, but will need to be compiled separately for 3.9.x and 3.10.x.

Names prefixed by an underscore, such as _Py_InternalState, are private API that can change without notice even in patch releases.

Stable Application Binary Interface
Python 3.2 introduced the Limited API, a subset of Python’s C API. Extensions that only use the Limited API can be compiled once and work with multiple versions of Python. Contents of the Limited API are listed below.

To enable this, Python provides a Stable ABI: a set of symbols that will remain compatible across Python 3.x versions. The Stable ABI contains symbols exposed in the Limited API, but also other ones – for example, functions necessary to support older versions of the Limited API.

(For simplicity, this document talks about extensions, but the Limited API and Stable ABI work the same way for all uses of the API – for example, embedding Python.)

Py_LIMITED_API
Define this macro before including Python.h to opt in to only use the Limited API, and to select the Limited API version.

Define Py_LIMITED_API to the value of PY_VERSION_HEX corresponding to the lowest Python version your extension supports. The extension will work without recompilation with all Python 3 releases from the specified one onward, and can use Limited API introduced up to that version.

Rather than using the PY_VERSION_HEX macro directly, hardcode a minimum minor version (e.g. 0x030A0000 for Python 3.10) for stability when compiling with future Python versions.

You can also define Py_LIMITED_API to 3. This works the same as 0x03020000 (Python 3.2, the version that introduced Limited API).

On Windows, extensions that use the Stable ABI should be linked against python3.dll rather than a version-specific library such as python39.dll.

On some platforms, Python will look for and load shared library files named with the abi3 tag (e.g. mymodule.abi3.so). It does not check if such extensions conform to a Stable ABI. The user (or their packaging tools) need to ensure that, for example, extensions built with the 3.10+ Limited API are not installed for lower versions of Python.

All functions in the Stable ABI are present as functions in Python’s shared library, not solely as macros. This makes them usable from languages that don’t use the C preprocessor.

Limited API Scope and Performance
The goal for the Limited API is to allow everything that is possible with the full C API, but possibly with a performance penalty.

For example, while PyList_GetItem() is available, its “unsafe” macro variant PyList_GET_ITEM() is not. The macro can be faster because it can rely on version-specific implementation details of the list object.

Without Py_LIMITED_API defined, some C API functions are inlined or replaced by macros. Defining Py_LIMITED_API disables this inlining, allowing stability as Python’s data structures are improved, but possibly reducing performance.

By leaving out the Py_LIMITED_API definition, it is possible to compile a Limited API extension with a version-specific ABI. This can improve performance for that Python version, but will limit compatibility. Compiling with Py_LIMITED_API will then yield an extension that can be distributed where a version-specific one is not available – for example, for prereleases of an upcoming Python version.

Limited API Caveats
Note that compiling with Py_LIMITED_API is not a complete guarantee that code conforms to the Limited API or the Stable ABI. Py_LIMITED_API only covers definitions, but an API also includes other issues, such as expected semantics.

One issue that Py_LIMITED_API does not guard against is calling a function with arguments that are invalid in a lower Python version. For example, consider a function that starts accepting NULL for an argument. In Python 3.9, NULL now selects a default behavior, but in Python 3.8, the argument will be used directly, causing a NULL dereference and crash. A similar argument works for fields of structs.

Another issue is that some struct fields are currently not hidden when Py_LIMITED_API is defined, even though they’re part of the Limited API.

For these reasons, we recommend testing an extension with all minor Python versions it supports, and preferably to build with the lowest such version.

We also recommend reviewing documentation of all used API to check if it is explicitly part of the Limited API. Even with Py_LIMITED_API defined, a few private declarations are exposed for technical reasons (or even unintentionally, as bugs).

Also note that the Limited API is not necessarily stable: compiling with Py_LIMITED_API with Python 3.8 means that the extension will run with Python 3.12, but it will not necessarily compile with Python 3.12. In particular, parts of the Limited API may be deprecated and removed, provided that the Stable ABI stays stable.

Platform Considerations
ABI stability depends not only on Python, but also on the compiler used, lower-level libraries and compiler options. For the purposes of the Stable ABI, these details define a “platform”. They usually depend on the OS type and processor architecture

It is the responsibility of each particular distributor of Python to ensure that all Python versions on a particular platform are built in a way that does not break the Stable ABI. This is the case with Windows and macOS releases from python.org and many third-party distributors.

Contents of Limited API
Currently, the Limited API includes the following items:

PyAIter_Check()

PyArg_Parse()

PyArg_ParseTuple()

PyArg_ParseTupleAndKeywords()

PyArg_UnpackTuple()

PyArg_VaParse()

PyArg_VaParseTupleAndKeywords()

PyArg_ValidateKeywordArguments()

PyBaseObject_Type

PyBool_FromLong()

PyBool_Type

PyByteArrayIter_Type

PyByteArray_AsString()

PyByteArray_Concat()

PyByteArray_FromObject()

PyByteArray_FromStringAndSize()

PyByteArray_Resize()

PyByteArray_Size()

PyByteArray_Type

PyBytesIter_Type

PyBytes_AsString()

PyBytes_AsStringAndSize()

PyBytes_Concat()

PyBytes_ConcatAndDel()

PyBytes_DecodeEscape()

PyBytes_FromFormat()

PyBytes_FromFormatV()

PyBytes_FromObject()

PyBytes_FromString()

PyBytes_FromStringAndSize()

PyBytes_Repr()

PyBytes_Size()

PyBytes_Type

PyCFunction

PyCFunctionWithKeywords

PyCFunction_Call()

PyCFunction_GetFlags()

PyCFunction_GetFunction()

PyCFunction_GetSelf()

PyCFunction_New()

PyCFunction_NewEx()

PyCFunction_Type

PyCMethod_New()

PyCallIter_New()

PyCallIter_Type

PyCallable_Check()

PyCapsule_Destructor

PyCapsule_GetContext()

PyCapsule_GetDestructor()

PyCapsule_GetName()

PyCapsule_GetPointer()

PyCapsule_Import()

PyCapsule_IsValid()

PyCapsule_New()

PyCapsule_SetContext()

PyCapsule_SetDestructor()

PyCapsule_SetName()

PyCapsule_SetPointer()

PyCapsule_Type

PyClassMethodDescr_Type

PyCodec_BackslashReplaceErrors()

PyCodec_Decode()

PyCodec_Decoder()

PyCodec_Encode()

PyCodec_Encoder()

PyCodec_IgnoreErrors()

PyCodec_IncrementalDecoder()

PyCodec_IncrementalEncoder()

PyCodec_KnownEncoding()

PyCodec_LookupError()

PyCodec_NameReplaceErrors()

PyCodec_Register()

PyCodec_RegisterError()

PyCodec_ReplaceErrors()

PyCodec_StreamReader()

PyCodec_StreamWriter()

PyCodec_StrictErrors()

PyCodec_Unregister()

PyCodec_XMLCharRefReplaceErrors()

PyComplex_FromDoubles()

PyComplex_ImagAsDouble()

PyComplex_RealAsDouble()

PyComplex_Type

PyDescr_NewClassMethod()

PyDescr_NewGetSet()

PyDescr_NewMember()

PyDescr_NewMethod()

PyDictItems_Type

PyDictIterItem_Type

PyDictIterKey_Type

PyDictIterValue_Type

PyDictKeys_Type

PyDictProxy_New()

PyDictProxy_Type

PyDictRevIterItem_Type

PyDictRevIterKey_Type

PyDictRevIterValue_Type

PyDictValues_Type

PyDict_Clear()

PyDict_Contains()

PyDict_Copy()

PyDict_DelItem()

PyDict_DelItemString()

PyDict_GetItem()

PyDict_GetItemString()

PyDict_GetItemWithError()

PyDict_Items()

PyDict_Keys()

PyDict_Merge()

PyDict_MergeFromSeq2()

PyDict_New()

PyDict_Next()

PyDict_SetItem()

PyDict_SetItemString()

PyDict_Size()

PyDict_Type

PyDict_Update()

PyDict_Values()

PyEllipsis_Type

PyEnum_Type

PyErr_BadArgument()

PyErr_BadInternalCall()

PyErr_CheckSignals()

PyErr_Clear()

PyErr_Display()

PyErr_ExceptionMatches()

PyErr_Fetch()

PyErr_Format()

PyErr_FormatV()

PyErr_GetExcInfo()

PyErr_GivenExceptionMatches()

PyErr_NewException()

PyErr_NewExceptionWithDoc()

PyErr_NoMemory()

PyErr_NormalizeException()

PyErr_Occurred()

PyErr_Print()

PyErr_PrintEx()

PyErr_ProgramText()

PyErr_ResourceWarning()

PyErr_Restore()

PyErr_SetExcFromWindowsErr()

PyErr_SetExcFromWindowsErrWithFilename()

PyErr_SetExcFromWindowsErrWithFilenameObject()

PyErr_SetExcFromWindowsErrWithFilenameObjects()

PyErr_SetExcInfo()

PyErr_SetFromErrno()

PyErr_SetFromErrnoWithFilename()

PyErr_SetFromErrnoWithFilenameObject()

PyErr_SetFromErrnoWithFilenameObjects()

PyErr_SetFromWindowsErr()

PyErr_SetFromWindowsErrWithFilename()

PyErr_SetImportError()

PyErr_SetImportErrorSubclass()

PyErr_SetInterrupt()

PyErr_SetInterruptEx()

PyErr_SetNone()

PyErr_SetObject()

PyErr_SetString()

PyErr_SyntaxLocation()

PyErr_SyntaxLocationEx()

PyErr_WarnEx()

PyErr_WarnExplicit()

PyErr_WarnFormat()

PyErr_WriteUnraisable()

PyEval_AcquireLock()

PyEval_AcquireThread()

PyEval_CallFunction()

PyEval_CallMethod()

PyEval_CallObjectWithKeywords()

PyEval_EvalCode()

PyEval_EvalCodeEx()

PyEval_EvalFrame()

PyEval_EvalFrameEx()

PyEval_GetBuiltins()

PyEval_GetFrame()

PyEval_GetFuncDesc()

PyEval_GetFuncName()

PyEval_GetGlobals()

PyEval_GetLocals()

PyEval_InitThreads()

PyEval_ReleaseLock()

PyEval_ReleaseThread()

PyEval_RestoreThread()

PyEval_SaveThread()

PyEval_ThreadsInitialized()

PyExc_ArithmeticError

PyExc_AssertionError

PyExc_AttributeError

PyExc_BaseException

PyExc_BlockingIOError

PyExc_BrokenPipeError

PyExc_BufferError

PyExc_BytesWarning

PyExc_ChildProcessError

PyExc_ConnectionAbortedError

PyExc_ConnectionError

PyExc_ConnectionRefusedError

PyExc_ConnectionResetError

PyExc_DeprecationWarning

PyExc_EOFError

PyExc_EncodingWarning

PyExc_EnvironmentError

PyExc_Exception

PyExc_FileExistsError

PyExc_FileNotFoundError

PyExc_FloatingPointError

PyExc_FutureWarning

PyExc_GeneratorExit

PyExc_IOError

PyExc_ImportError

PyExc_ImportWarning

PyExc_IndentationError

PyExc_IndexError

PyExc_InterruptedError

PyExc_IsADirectoryError

PyExc_KeyError

PyExc_KeyboardInterrupt

PyExc_LookupError

PyExc_MemoryError

PyExc_ModuleNotFoundError

PyExc_NameError

PyExc_NotADirectoryError

PyExc_NotImplementedError

PyExc_OSError

PyExc_OverflowError

PyExc_PendingDeprecationWarning

PyExc_PermissionError

PyExc_ProcessLookupError

PyExc_RecursionError

PyExc_ReferenceError

PyExc_ResourceWarning

PyExc_RuntimeError

PyExc_RuntimeWarning

PyExc_StopAsyncIteration

PyExc_StopIteration

PyExc_SyntaxError

PyExc_SyntaxWarning

PyExc_SystemError

PyExc_SystemExit

PyExc_TabError

PyExc_TimeoutError

PyExc_TypeError

PyExc_UnboundLocalError

PyExc_UnicodeDecodeError

PyExc_UnicodeEncodeError

PyExc_UnicodeError

PyExc_UnicodeTranslateError

PyExc_UnicodeWarning

PyExc_UserWarning

PyExc_ValueError

PyExc_Warning

PyExc_WindowsError

PyExc_ZeroDivisionError

PyExceptionClass_Name()

PyException_GetCause()

PyException_GetContext()

PyException_GetTraceback()

PyException_SetCause()

PyException_SetContext()

PyException_SetTraceback()

PyFile_FromFd()

PyFile_GetLine()

PyFile_WriteObject()

PyFile_WriteString()

PyFilter_Type

PyFloat_AsDouble()

PyFloat_FromDouble()

PyFloat_FromString()

PyFloat_GetInfo()

PyFloat_GetMax()

PyFloat_GetMin()

PyFloat_Type

PyFrameObject

PyFrame_GetCode()

PyFrame_GetLineNumber()

PyFrozenSet_New()

PyFrozenSet_Type

PyGC_Collect()

PyGC_Disable()

PyGC_Enable()

PyGC_IsEnabled()

PyGILState_Ensure()

PyGILState_GetThisThreadState()

PyGILState_Release()

PyGILState_STATE

PyGetSetDef

PyGetSetDescr_Type

PyImport_AddModule()

PyImport_AddModuleObject()

PyImport_AppendInittab()

PyImport_ExecCodeModule()

PyImport_ExecCodeModuleEx()

PyImport_ExecCodeModuleObject()

PyImport_ExecCodeModuleWithPathnames()

PyImport_GetImporter()

PyImport_GetMagicNumber()

PyImport_GetMagicTag()

PyImport_GetModule()

PyImport_GetModuleDict()

PyImport_Import()

PyImport_ImportFrozenModule()

PyImport_ImportFrozenModuleObject()

PyImport_ImportModule()

PyImport_ImportModuleLevel()

PyImport_ImportModuleLevelObject()

PyImport_ImportModuleNoBlock()

PyImport_ReloadModule()

PyIndex_Check()

PyInterpreterState

PyInterpreterState_Clear()

PyInterpreterState_Delete()

PyInterpreterState_Get()

PyInterpreterState_GetDict()

PyInterpreterState_GetID()

PyInterpreterState_New()

PyIter_Check()

PyIter_Next()

PyIter_Send()

PyListIter_Type

PyListRevIter_Type

PyList_Append()

PyList_AsTuple()

PyList_GetItem()

PyList_GetSlice()

PyList_Insert()

PyList_New()

PyList_Reverse()

PyList_SetItem()

PyList_SetSlice()

PyList_Size()

PyList_Sort()

PyList_Type

PyLongObject

PyLongRangeIter_Type

PyLong_AsDouble()

PyLong_AsLong()

PyLong_AsLongAndOverflow()

PyLong_AsLongLong()

PyLong_AsLongLongAndOverflow()

PyLong_AsSize_t()

PyLong_AsSsize_t()

PyLong_AsUnsignedLong()

PyLong_AsUnsignedLongLong()

PyLong_AsUnsignedLongLongMask()

PyLong_AsUnsignedLongMask()

PyLong_AsVoidPtr()

PyLong_FromDouble()

PyLong_FromLong()

PyLong_FromLongLong()

PyLong_FromSize_t()

PyLong_FromSsize_t()

PyLong_FromString()

PyLong_FromUnsignedLong()

PyLong_FromUnsignedLongLong()

PyLong_FromVoidPtr()

PyLong_GetInfo()

PyLong_Type

PyMap_Type

PyMapping_Check()

PyMapping_GetItemString()

PyMapping_HasKey()

PyMapping_HasKeyString()

PyMapping_Items()

PyMapping_Keys()

PyMapping_Length()

PyMapping_SetItemString()

PyMapping_Size()

PyMapping_Values()

PyMem_Calloc()

PyMem_Free()

PyMem_Malloc()

PyMem_Realloc()

PyMemberDef

PyMemberDescr_Type

PyMemoryView_FromMemory()

PyMemoryView_FromObject()

PyMemoryView_GetContiguous()

PyMemoryView_Type

PyMethodDef

PyMethodDescr_Type

PyModuleDef

PyModuleDef_Base

PyModuleDef_Init()

PyModuleDef_Type

PyModule_AddFunctions()

PyModule_AddIntConstant()

PyModule_AddObject()

PyModule_AddObjectRef()

PyModule_AddStringConstant()

PyModule_AddType()

PyModule_Create2()

PyModule_ExecDef()

PyModule_FromDefAndSpec2()

PyModule_GetDef()

PyModule_GetDict()

PyModule_GetFilename()

PyModule_GetFilenameObject()

PyModule_GetName()

PyModule_GetNameObject()

PyModule_GetState()

PyModule_New()

PyModule_NewObject()

PyModule_SetDocString()

PyModule_Type

PyNumber_Absolute()

PyNumber_Add()

PyNumber_And()

PyNumber_AsSsize_t()

PyNumber_Check()

PyNumber_Divmod()

PyNumber_Float()

PyNumber_FloorDivide()

PyNumber_InPlaceAdd()

PyNumber_InPlaceAnd()

PyNumber_InPlaceFloorDivide()

PyNumber_InPlaceLshift()

PyNumber_InPlaceMatrixMultiply()

PyNumber_InPlaceMultiply()

PyNumber_InPlaceOr()

PyNumber_InPlacePower()

PyNumber_InPlaceRemainder()

PyNumber_InPlaceRshift()

PyNumber_InPlaceSubtract()

PyNumber_InPlaceTrueDivide()

PyNumber_InPlaceXor()

PyNumber_Index()

PyNumber_Invert()

PyNumber_Long()

PyNumber_Lshift()

PyNumber_MatrixMultiply()

PyNumber_Multiply()

PyNumber_Negative()

PyNumber_Or()

PyNumber_Positive()

PyNumber_Power()

PyNumber_Remainder()

PyNumber_Rshift()

PyNumber_Subtract()

PyNumber_ToBase()

PyNumber_TrueDivide()

PyNumber_Xor()

PyOS_AfterFork()

PyOS_AfterFork_Child()

PyOS_AfterFork_Parent()

PyOS_BeforeFork()

PyOS_CheckStack()

PyOS_FSPath()

PyOS_InputHook

PyOS_InterruptOccurred()

PyOS_double_to_string()

PyOS_getsig()

PyOS_mystricmp()

PyOS_mystrnicmp()

PyOS_setsig()

PyOS_sighandler_t

PyOS_snprintf()

PyOS_string_to_double()

PyOS_strtol()

PyOS_strtoul()

PyOS_vsnprintf()

PyObject

PyObject.ob_refcnt

PyObject.ob_type

PyObject_ASCII()

PyObject_AsCharBuffer()

PyObject_AsFileDescriptor()

PyObject_AsReadBuffer()

PyObject_AsWriteBuffer()

PyObject_Bytes()

PyObject_Call()

PyObject_CallFunction()

PyObject_CallFunctionObjArgs()

PyObject_CallMethod()

PyObject_CallMethodObjArgs()

PyObject_CallNoArgs()

PyObject_CallObject()

PyObject_Calloc()

PyObject_CheckReadBuffer()

PyObject_ClearWeakRefs()

PyObject_DelItem()

PyObject_DelItemString()

PyObject_Dir()

PyObject_Format()

PyObject_Free()

PyObject_GC_Del()

PyObject_GC_IsFinalized()

PyObject_GC_IsTracked()

PyObject_GC_Track()

PyObject_GC_UnTrack()

PyObject_GenericGetAttr()

PyObject_GenericGetDict()

PyObject_GenericSetAttr()

PyObject_GenericSetDict()

PyObject_GetAIter()

PyObject_GetAttr()

PyObject_GetAttrString()

PyObject_GetItem()

PyObject_GetIter()

PyObject_HasAttr()

PyObject_HasAttrString()

PyObject_Hash()

PyObject_HashNotImplemented()

PyObject_Init()

PyObject_InitVar()

PyObject_IsInstance()

PyObject_IsSubclass()

PyObject_IsTrue()

PyObject_Length()

PyObject_Malloc()

PyObject_Not()

PyObject_Realloc()

PyObject_Repr()

PyObject_RichCompare()

PyObject_RichCompareBool()

PyObject_SelfIter()

PyObject_SetAttr()

PyObject_SetAttrString()

PyObject_SetItem()

PyObject_Size()

PyObject_Str()

PyObject_Type()

PyProperty_Type

PyRangeIter_Type

PyRange_Type

PyReversed_Type

PySeqIter_New()

PySeqIter_Type

PySequence_Check()

PySequence_Concat()

PySequence_Contains()

PySequence_Count()

PySequence_DelItem()

PySequence_DelSlice()

PySequence_Fast()

PySequence_GetItem()

PySequence_GetSlice()

PySequence_In()

PySequence_InPlaceConcat()

PySequence_InPlaceRepeat()

PySequence_Index()

PySequence_Length()

PySequence_List()

PySequence_Repeat()

PySequence_SetItem()

PySequence_SetSlice()

PySequence_Size()

PySequence_Tuple()

PySetIter_Type

PySet_Add()

PySet_Clear()

PySet_Contains()

PySet_Discard()

PySet_New()

PySet_Pop()

PySet_Size()

PySet_Type

PySlice_AdjustIndices()

PySlice_GetIndices()

PySlice_GetIndicesEx()

PySlice_New()

PySlice_Type

PySlice_Unpack()

PyState_AddModule()

PyState_FindModule()

PyState_RemoveModule()

PyStructSequence_Desc

PyStructSequence_Field

PyStructSequence_GetItem()

PyStructSequence_New()

PyStructSequence_NewType()

PyStructSequence_SetItem()

PySuper_Type

PySys_AddWarnOption()

PySys_AddWarnOptionUnicode()

PySys_AddXOption()

PySys_FormatStderr()

PySys_FormatStdout()

PySys_GetObject()

PySys_GetXOptions()

PySys_HasWarnOptions()

PySys_ResetWarnOptions()

PySys_SetArgv()

PySys_SetArgvEx()

PySys_SetObject()

PySys_SetPath()

PySys_WriteStderr()

PySys_WriteStdout()

PyThreadState

PyThreadState_Clear()

PyThreadState_Delete()

PyThreadState_Get()

PyThreadState_GetDict()

PyThreadState_GetFrame()

PyThreadState_GetID()

PyThreadState_GetInterpreter()

PyThreadState_New()

PyThreadState_SetAsyncExc()

PyThreadState_Swap()

PyThread_GetInfo()

PyThread_ReInitTLS()

PyThread_acquire_lock()

PyThread_acquire_lock_timed()

PyThread_allocate_lock()

PyThread_create_key()

PyThread_delete_key()

PyThread_delete_key_value()

PyThread_exit_thread()

PyThread_free_lock()

PyThread_get_key_value()

PyThread_get_stacksize()

PyThread_get_thread_ident()

PyThread_get_thread_native_id()

PyThread_init_thread()

PyThread_release_lock()

PyThread_set_key_value()

PyThread_set_stacksize()

PyThread_start_new_thread()

PyThread_tss_alloc()

PyThread_tss_create()

PyThread_tss_delete()

PyThread_tss_free()

PyThread_tss_get()

PyThread_tss_is_created()

PyThread_tss_set()

PyTraceBack_Here()

PyTraceBack_Print()

PyTraceBack_Type

PyTupleIter_Type

PyTuple_GetItem()

PyTuple_GetSlice()

PyTuple_New()

PyTuple_Pack()

PyTuple_SetItem()

PyTuple_Size()

PyTuple_Type

PyTypeObject

PyType_ClearCache()

PyType_FromModuleAndSpec()

PyType_FromSpec()

PyType_FromSpecWithBases()

PyType_GenericAlloc()

PyType_GenericNew()

PyType_GetFlags()

PyType_GetModule()

PyType_GetModuleState()

PyType_GetSlot()

PyType_IsSubtype()

PyType_Modified()

PyType_Ready()

PyType_Slot

PyType_Spec

PyType_Type

PyUnicodeDecodeError_Create()

PyUnicodeDecodeError_GetEncoding()

PyUnicodeDecodeError_GetEnd()

PyUnicodeDecodeError_GetObject()

PyUnicodeDecodeError_GetReason()

PyUnicodeDecodeError_GetStart()

PyUnicodeDecodeError_SetEnd()

PyUnicodeDecodeError_SetReason()

PyUnicodeDecodeError_SetStart()

PyUnicodeEncodeError_GetEncoding()

PyUnicodeEncodeError_GetEnd()

PyUnicodeEncodeError_GetObject()

PyUnicodeEncodeError_GetReason()

PyUnicodeEncodeError_GetStart()

PyUnicodeEncodeError_SetEnd()

PyUnicodeEncodeError_SetReason()

PyUnicodeEncodeError_SetStart()

PyUnicodeIter_Type

PyUnicodeTranslateError_GetEnd()

PyUnicodeTranslateError_GetObject()

PyUnicodeTranslateError_GetReason()

PyUnicodeTranslateError_GetStart()

PyUnicodeTranslateError_SetEnd()

PyUnicodeTranslateError_SetReason()

PyUnicodeTranslateError_SetStart()

PyUnicode_Append()

PyUnicode_AppendAndDel()

PyUnicode_AsASCIIString()

PyUnicode_AsCharmapString()

PyUnicode_AsDecodedObject()

PyUnicode_AsDecodedUnicode()

PyUnicode_AsEncodedObject()

PyUnicode_AsEncodedString()

PyUnicode_AsEncodedUnicode()

PyUnicode_AsLatin1String()

PyUnicode_AsMBCSString()

PyUnicode_AsRawUnicodeEscapeString()

PyUnicode_AsUCS4()

PyUnicode_AsUCS4Copy()

PyUnicode_AsUTF16String()

PyUnicode_AsUTF32String()

PyUnicode_AsUTF8AndSize()

PyUnicode_AsUTF8String()

PyUnicode_AsUnicodeEscapeString()

PyUnicode_AsWideChar()

PyUnicode_AsWideCharString()

PyUnicode_BuildEncodingMap()

PyUnicode_Compare()

PyUnicode_CompareWithASCIIString()

PyUnicode_Concat()

PyUnicode_Contains()

PyUnicode_Count()

PyUnicode_Decode()

PyUnicode_DecodeASCII()

PyUnicode_DecodeCharmap()

PyUnicode_DecodeCodePageStateful()

PyUnicode_DecodeFSDefault()

PyUnicode_DecodeFSDefaultAndSize()

PyUnicode_DecodeLatin1()

PyUnicode_DecodeLocale()

PyUnicode_DecodeLocaleAndSize()

PyUnicode_DecodeMBCS()

PyUnicode_DecodeMBCSStateful()

PyUnicode_DecodeRawUnicodeEscape()

PyUnicode_DecodeUTF16()

PyUnicode_DecodeUTF16Stateful()

PyUnicode_DecodeUTF32()

PyUnicode_DecodeUTF32Stateful()

PyUnicode_DecodeUTF7()

PyUnicode_DecodeUTF7Stateful()

PyUnicode_DecodeUTF8()

PyUnicode_DecodeUTF8Stateful()

PyUnicode_DecodeUnicodeEscape()

PyUnicode_EncodeCodePage()

PyUnicode_EncodeFSDefault()

PyUnicode_EncodeLocale()

PyUnicode_FSConverter()

PyUnicode_FSDecoder()

PyUnicode_Find()

PyUnicode_FindChar()

PyUnicode_Format()

PyUnicode_FromEncodedObject()

PyUnicode_FromFormat()

PyUnicode_FromFormatV()

PyUnicode_FromObject()

PyUnicode_FromOrdinal()

PyUnicode_FromString()

PyUnicode_FromStringAndSize()

PyUnicode_FromWideChar()

PyUnicode_GetDefaultEncoding()

PyUnicode_GetLength()

PyUnicode_GetSize()

PyUnicode_InternFromString()

PyUnicode_InternImmortal()

PyUnicode_InternInPlace()

PyUnicode_IsIdentifier()

PyUnicode_Join()

PyUnicode_Partition()

PyUnicode_RPartition()

PyUnicode_RSplit()

PyUnicode_ReadChar()

PyUnicode_Replace()

PyUnicode_Resize()

PyUnicode_RichCompare()

PyUnicode_Split()

PyUnicode_Splitlines()

PyUnicode_Substring()

PyUnicode_Tailmatch()

PyUnicode_Translate()

PyUnicode_Type

PyUnicode_WriteChar()

PyVarObject

PyVarObject.ob_base

PyVarObject.ob_size

PyWeakReference

PyWeakref_GetObject()

PyWeakref_NewProxy()

PyWeakref_NewRef()

PyWrapperDescr_Type

PyWrapper_New()

PyZip_Type

Py_AddPendingCall()

Py_AtExit()

Py_BEGIN_ALLOW_THREADS

Py_BLOCK_THREADS

Py_BuildValue()

Py_BytesMain()

Py_CompileString()

Py_DecRef()

Py_DecodeLocale()

Py_END_ALLOW_THREADS

Py_EncodeLocale()

Py_EndInterpreter()

Py_EnterRecursiveCall()

Py_Exit()

Py_FatalError()

Py_FileSystemDefaultEncodeErrors

Py_FileSystemDefaultEncoding

Py_Finalize()

Py_FinalizeEx()

Py_GenericAlias()

Py_GenericAliasType

Py_GetBuildInfo()

Py_GetCompiler()

Py_GetCopyright()

Py_GetExecPrefix()

Py_GetPath()

Py_GetPlatform()

Py_GetPrefix()

Py_GetProgramFullPath()

Py_GetProgramName()

Py_GetPythonHome()

Py_GetRecursionLimit()

Py_GetVersion()

Py_HasFileSystemDefaultEncoding

Py_IncRef()

Py_Initialize()

Py_InitializeEx()

Py_Is()

Py_IsFalse()

Py_IsInitialized()

Py_IsNone()

Py_IsTrue()

Py_LeaveRecursiveCall()

Py_Main()

Py_MakePendingCalls()

Py_NewInterpreter()

Py_NewRef()

Py_ReprEnter()

Py_ReprLeave()

Py_SetPath()

Py_SetProgramName()

Py_SetPythonHome()

Py_SetRecursionLimit()

Py_UCS4

Py_UNBLOCK_THREADS

Py_UTF8Mode

Py_VaBuildValue()

Py_XNewRef()

Py_intptr_t

Py_ssize_t

Py_uintptr_t

allocfunc

binaryfunc

descrgetfunc

descrsetfunc

destructor

getattrfunc

getattrofunc

getiterfunc

getter

hashfunc

initproc

inquiry

iternextfunc

lenfunc

newfunc

objobjargproc

objobjproc

reprfunc

richcmpfunc

setattrfunc

setattrofunc

setter

ssizeargfunc

ssizeobjargproc

ssizessizeargfunc

ssizessizeobjargproc

symtable

ternaryfunc

traverseproc

unaryfunc

visitproc

Table of Contents
C API Stability
Stable Application Binary Interface
Limited API Scope and Performance
Limited API Caveats
Platform Considerations
Contents of Limited API
Previous topic
Introduction

Next topic
The Very High Level Layer

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » C API Stability
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » The Very High Level Layer
Quick search
  |
The Very High Level Layer
The functions in this chapter will let you execute Python source code given in a file or a buffer, but they will not let you interact in a more detailed way with the interpreter.

Several of these functions accept a start symbol from the grammar as a parameter. The available start symbols are Py_eval_input, Py_file_input, and Py_single_input. These are described following the functions which accept them as parameters.

Note also that several of these functions take FILE* parameters. One particular issue which needs to be handled carefully is that the FILE structure for different C libraries can be different and incompatible. Under Windows (at least), it is possible for dynamically linked extensions to actually use different libraries, so care should be taken that FILE* parameters are only passed to these functions if it is certain that they were created by the same library that the Python runtime is using.

int Py_Main(int argc, wchar_t **argv)
Part of the Stable ABI.
The main program for the standard interpreter. This is made available for programs which embed Python. The argc and argv parameters should be prepared exactly as those which are passed to a C program’s main() function (converted to wchar_t according to the user’s locale). It is important to note that the argument list may be modified (but the contents of the strings pointed to by the argument list are not). The return value will be 0 if the interpreter exits normally (i.e., without an exception), 1 if the interpreter exits due to an exception, or 2 if the parameter list does not represent a valid Python command line.

Note that if an otherwise unhandled SystemExit is raised, this function will not return 1, but exit the process, as long as Py_InspectFlag is not set.

int Py_BytesMain(int argc, char **argv)
Part of the Stable ABI since version 3.8.
Similar to Py_Main() but argv is an array of bytes strings.

New in version 3.8.

int PyRun_AnyFile(FILE *fp, const char *filename)
This is a simplified interface to PyRun_AnyFileExFlags() below, leaving closeit set to 0 and flags set to NULL.

int PyRun_AnyFileFlags(FILE *fp, const char *filename, PyCompilerFlags *flags)
This is a simplified interface to PyRun_AnyFileExFlags() below, leaving the closeit argument set to 0.

int PyRun_AnyFileEx(FILE *fp, const char *filename, int closeit)
This is a simplified interface to PyRun_AnyFileExFlags() below, leaving the flags argument set to NULL.

int PyRun_AnyFileExFlags(FILE *fp, const char *filename, int closeit, PyCompilerFlags *flags)
If fp refers to a file associated with an interactive device (console or terminal input or Unix pseudo-terminal), return the value of PyRun_InteractiveLoop(), otherwise return the result of PyRun_SimpleFile(). filename is decoded from the filesystem encoding (sys.getfilesystemencoding()). If filename is NULL, this function uses "???" as the filename. If closeit is true, the file is closed before PyRun_SimpleFileExFlags() returns.

int PyRun_SimpleString(const char *command)
This is a simplified interface to PyRun_SimpleStringFlags() below, leaving the PyCompilerFlags* argument set to NULL.

int PyRun_SimpleStringFlags(const char *command, PyCompilerFlags *flags)
Executes the Python source code from command in the __main__ module according to the flags argument. If __main__ does not already exist, it is created. Returns 0 on success or -1 if an exception was raised. If there was an error, there is no way to get the exception information. For the meaning of flags, see below.

Note that if an otherwise unhandled SystemExit is raised, this function will not return -1, but exit the process, as long as Py_InspectFlag is not set.

int PyRun_SimpleFile(FILE *fp, const char *filename)
This is a simplified interface to PyRun_SimpleFileExFlags() below, leaving closeit set to 0 and flags set to NULL.

int PyRun_SimpleFileEx(FILE *fp, const char *filename, int closeit)
This is a simplified interface to PyRun_SimpleFileExFlags() below, leaving flags set to NULL.

int PyRun_SimpleFileExFlags(FILE *fp, const char *filename, int closeit, PyCompilerFlags *flags)
Similar to PyRun_SimpleStringFlags(), but the Python source code is read from fp instead of an in-memory string. filename should be the name of the file, it is decoded from filesystem encoding and error handler. If closeit is true, the file is closed before PyRun_SimpleFileExFlags() returns.

Note On Windows, fp should be opened as binary mode (e.g. fopen(filename, "rb")). Otherwise, Python may not handle script file with LF line ending correctly.
int PyRun_InteractiveOne(FILE *fp, const char *filename)
This is a simplified interface to PyRun_InteractiveOneFlags() below, leaving flags set to NULL.

int PyRun_InteractiveOneFlags(FILE *fp, const char *filename, PyCompilerFlags *flags)
Read and execute a single statement from a file associated with an interactive device according to the flags argument. The user will be prompted using sys.ps1 and sys.ps2. filename is decoded from the filesystem encoding and error handler.

Returns 0 when the input was executed successfully, -1 if there was an exception, or an error code from the errcode.h include file distributed as part of Python if there was a parse error. (Note that errcode.h is not included by Python.h, so must be included specifically if needed.)

int PyRun_InteractiveLoop(FILE *fp, const char *filename)
This is a simplified interface to PyRun_InteractiveLoopFlags() below, leaving flags set to NULL.

int PyRun_InteractiveLoopFlags(FILE *fp, const char *filename, PyCompilerFlags *flags)
Read and execute statements from a file associated with an interactive device until EOF is reached. The user will be prompted using sys.ps1 and sys.ps2. filename is decoded from the filesystem encoding and error handler. Returns 0 at EOF or a negative number upon failure.

int (*PyOS_InputHook)(void)
Part of the Stable ABI.
Can be set to point to a function with the prototype int func(void). The function will be called when Python’s interpreter prompt is about to become idle and wait for user input from the terminal. The return value is ignored. Overriding this hook can be used to integrate the interpreter’s prompt with other event loops, as done in the Modules/_tkinter.c in the Python source code.

char *(*PyOS_ReadlineFunctionPointer)(FILE*, FILE*, const char*)
Can be set to point to a function with the prototype char *func(FILE *stdin, FILE *stdout, char *prompt), overriding the default function used to read a single line of input at the interpreter’s prompt. The function is expected to output the string prompt if it’s not NULL, and then read a line of input from the provided standard input file, returning the resulting string. For example, The readline module sets this hook to provide line-editing and tab-completion features.

The result must be a string allocated by PyMem_RawMalloc() or PyMem_RawRealloc(), or NULL if an error occurred.

Changed in version 3.4: The result must be allocated by PyMem_RawMalloc() or PyMem_RawRealloc(), instead of being allocated by PyMem_Malloc() or PyMem_Realloc().

PyObject *PyRun_String(const char *str, int start, PyObject *globals, PyObject *locals)
Return value: New reference.
This is a simplified interface to PyRun_StringFlags() below, leaving flags set to NULL.

PyObject *PyRun_StringFlags(const char *str, int start, PyObject *globals, PyObject *locals, PyCompilerFlags *flags)
Return value: New reference.
Execute Python source code from str in the context specified by the objects globals and locals with the compiler flags specified by flags. globals must be a dictionary; locals can be any object that implements the mapping protocol. The parameter start specifies the start token that should be used to parse the source code.

Returns the result of executing the code as a Python object, or NULL if an exception was raised.

PyObject *PyRun_File(FILE *fp, const char *filename, int start, PyObject *globals, PyObject *locals)
Return value: New reference.
This is a simplified interface to PyRun_FileExFlags() below, leaving closeit set to 0 and flags set to NULL.

PyObject *PyRun_FileEx(FILE *fp, const char *filename, int start, PyObject *globals, PyObject *locals, int closeit)
Return value: New reference.
This is a simplified interface to PyRun_FileExFlags() below, leaving flags set to NULL.

PyObject *PyRun_FileFlags(FILE *fp, const char *filename, int start, PyObject *globals, PyObject *locals, PyCompilerFlags *flags)
Return value: New reference.
This is a simplified interface to PyRun_FileExFlags() below, leaving closeit set to 0.

PyObject *PyRun_FileExFlags(FILE *fp, const char *filename, int start, PyObject *globals, PyObject *locals, int closeit, PyCompilerFlags *flags)
Return value: New reference.
Similar to PyRun_StringFlags(), but the Python source code is read from fp instead of an in-memory string. filename should be the name of the file, it is decoded from the filesystem encoding and error handler. If closeit is true, the file is closed before PyRun_FileExFlags() returns.

PyObject *Py_CompileString(const char *str, const char *filename, int start)
Return value: New reference. Part of the Stable ABI.
This is a simplified interface to Py_CompileStringFlags() below, leaving flags set to NULL.

PyObject *Py_CompileStringFlags(const char *str, const char *filename, int start, PyCompilerFlags *flags)
Return value: New reference.
This is a simplified interface to Py_CompileStringExFlags() below, with optimize set to -1.

PyObject *Py_CompileStringObject(const char *str, PyObject *filename, int start, PyCompilerFlags *flags, int optimize)
Return value: New reference.
Parse and compile the Python source code in str, returning the resulting code object. The start token is given by start; this can be used to constrain the code which can be compiled and should be Py_eval_input, Py_file_input, or Py_single_input. The filename specified by filename is used to construct the code object and may appear in tracebacks or SyntaxError exception messages. This returns NULL if the code cannot be parsed or compiled.

The integer optimize specifies the optimization level of the compiler; a value of -1 selects the optimization level of the interpreter as given by -O options. Explicit levels are 0 (no optimization; __debug__ is true), 1 (asserts are removed, __debug__ is false) or 2 (docstrings are removed too).

New in version 3.4.

PyObject *Py_CompileStringExFlags(const char *str, const char *filename, int start, PyCompilerFlags *flags, int optimize)
Return value: New reference.
Like Py_CompileStringObject(), but filename is a byte string decoded from the filesystem encoding and error handler.

New in version 3.2.

PyObject *PyEval_EvalCode(PyObject *co, PyObject *globals, PyObject *locals)
Return value: New reference. Part of the Stable ABI.
This is a simplified interface to PyEval_EvalCodeEx(), with just the code object, and global and local variables. The other arguments are set to NULL.

PyObject *PyEval_EvalCodeEx(PyObject *co, PyObject *globals, PyObject *locals, PyObject *const *args, int argcount, PyObject *const *kws, int kwcount, PyObject *const *defs, int defcount, PyObject *kwdefs, PyObject *closure)
Return value: New reference. Part of the Stable ABI.
Evaluate a precompiled code object, given a particular environment for its evaluation. This environment consists of a dictionary of global variables, a mapping object of local variables, arrays of arguments, keywords and defaults, a dictionary of default values for keyword-only arguments and a closure tuple of cells.

type PyFrameObject
Part of the Limited API (as an opaque struct).
The C structure of the objects used to describe frame objects. The fields of this type are subject to change at any time.

PyObject *PyEval_EvalFrame(PyFrameObject *f)
Return value: New reference. Part of the Stable ABI.
Evaluate an execution frame. This is a simplified interface to PyEval_EvalFrameEx(), for backward compatibility.

PyObject *PyEval_EvalFrameEx(PyFrameObject *f, int throwflag)
Return value: New reference. Part of the Stable ABI.
This is the main, unvarnished function of Python interpretation. The code object associated with the execution frame f is executed, interpreting bytecode and executing calls as needed. The additional throwflag parameter can mostly be ignored - if true, then it causes an exception to immediately be thrown; this is used for the throw() methods of generator objects.

Changed in version 3.4: This function now includes a debug assertion to help ensure that it does not silently discard an active exception.

int PyEval_MergeCompilerFlags(PyCompilerFlags *cf)
This function changes the flags of the current evaluation frame, and returns true on success, false on failure.

int Py_eval_input
The start symbol from the Python grammar for isolated expressions; for use with Py_CompileString().

int Py_file_input
The start symbol from the Python grammar for sequences of statements as read from a file or other source; for use with Py_CompileString(). This is the symbol to use when compiling arbitrarily long Python source code.

int Py_single_input
The start symbol from the Python grammar for a single statement; for use with Py_CompileString(). This is the symbol used for the interactive interpreter loop.

struct PyCompilerFlags
This is the structure used to hold compiler flags. In cases where code is only being compiled, it is passed as int flags, and in cases where code is being executed, it is passed as PyCompilerFlags *flags. In this case, from __future__ import can modify flags.

Whenever PyCompilerFlags *flags is NULL, cf_flags is treated as equal to 0, and any modification due to from __future__ import is discarded.

int cf_flags
Compiler flags.

int cf_feature_version
cf_feature_version is the minor Python version. It should be initialized to PY_MINOR_VERSION.

The field is ignored by default, it is used if and only if PyCF_ONLY_AST flag is set in cf_flags.

Changed in version 3.8: Added cf_feature_version field.

int CO_FUTURE_DIVISION
This bit can be set in flags to cause division operator / to be interpreted as “true division” according to PEP 238.

Previous topic
C API Stability

Next topic
Reference Counting

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » The Very High Level Layer
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Reference Counting
Quick search
  |
Reference Counting
The macros in this section are used for managing reference counts of Python objects.

void Py_INCREF(PyObject *o)¶
Increment the reference count for object o.

This function is usually used to convert a borrowed reference to a strong reference in-place. The Py_NewRef() function can be used to create a new strong reference.

The object must not be NULL; if you aren’t sure that it isn’t NULL, use Py_XINCREF().

void Py_XINCREF(PyObject *o)
Increment the reference count for object o. The object may be NULL, in which case the macro has no effect.

See also Py_XNewRef().

PyObject *Py_NewRef(PyObject *o)
Part of the Stable ABI since version 3.10.
Create a new strong reference to an object: increment the reference count of the object o and return the object o.

When the strong reference is no longer needed, Py_DECREF() should be called on it to decrement the object reference count.

The object o must not be NULL; use Py_XNewRef() if o can be NULL.

For example:

Py_INCREF(obj);
self->attr = obj;
can be written as:

self->attr = Py_NewRef(obj);
See also Py_INCREF().

New in version 3.10.

PyObject *Py_XNewRef(PyObject *o)
Part of the Stable ABI since version 3.10.
Similar to Py_NewRef(), but the object o can be NULL.

If the object o is NULL, the function just returns NULL.

New in version 3.10.

void Py_DECREF(PyObject *o)
Decrement the reference count for object o.

If the reference count reaches zero, the object’s type’s deallocation function (which must not be NULL) is invoked.

This function is usually used to delete a strong reference before exiting its scope.

The object must not be NULL; if you aren’t sure that it isn’t NULL, use Py_XDECREF().

Warning The deallocation function can cause arbitrary Python code to be invoked (e.g. when a class instance with a __del__() method is deallocated). While exceptions in such code are not propagated, the executed code has free access to all Python global variables. This means that any object that is reachable from a global variable should be in a consistent state before Py_DECREF() is invoked. For example, code to delete an object from a list should copy a reference to the deleted object in a temporary variable, update the list data structure, and then call Py_DECREF() for the temporary variable.
void Py_XDECREF(PyObject *o)
Decrement the reference count for object o. The object may be NULL, in which case the macro has no effect; otherwise the effect is the same as for Py_DECREF(), and the same warning applies.

void Py_CLEAR(PyObject *o)
Decrement the reference count for object o. The object may be NULL, in which case the macro has no effect; otherwise the effect is the same as for Py_DECREF(), except that the argument is also set to NULL. The warning for Py_DECREF() does not apply with respect to the object passed because the macro carefully uses a temporary variable and sets the argument to NULL before decrementing its reference count.

It is a good idea to use this macro whenever decrementing the reference count of an object that might be traversed during garbage collection.

void Py_IncRef(PyObject *o)
Part of the Stable ABI.
Increment the reference count for object o. A function version of Py_XINCREF(). It can be used for runtime dynamic embedding of Python.

void Py_DecRef(PyObject *o)
Part of the Stable ABI.
Decrement the reference count for object o. A function version of Py_XDECREF(). It can be used for runtime dynamic embedding of Python.

The following functions or macros are only for use within the interpreter core: _Py_Dealloc(), _Py_ForgetReference(), _Py_NewReference(), as well as the global variable _Py_RefTotal.

Previous topic
The Very High Level Layer

Next topic
Exception Handling

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Reference Counting
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
Exception Handling
The functions described in this chapter will let you handle and raise Python exceptions. It is important to understand some of the basics of Python exception handling. It works somewhat like the POSIX errno variable: there is a global indicator (per thread) of the last error that occurred. Most C API functions don’t clear this on success, but will set it to indicate the cause of the error on failure. Most C API functions also return an error indicator, usually NULL if they are supposed to return a pointer, or -1 if they return an integer (exception: the PyArg_* functions return 1 for success and 0 for failure).

Concretely, the error indicator consists of three object pointers: the exception’s type, the exception’s value, and the traceback object. Any of those pointers can be NULL if non-set (although some combinations are forbidden, for example you can’t have a non-NULL traceback if the exception type is NULL).

When a function must fail because some function it called failed, it generally doesn’t set the error indicator; the function it called already set it. It is responsible for either handling the error and clearing the exception or returning after cleaning up any resources it holds (such as object references or memory allocations); it should not continue normally if it is not prepared to handle the error. If returning due to an error, it is important to indicate to the caller that an error has been set. If the error is not handled or carefully propagated, additional calls into the Python/C API may not behave as intended and may fail in mysterious ways.

Note The error indicator is not the result of sys.exc_info(). The former corresponds to an exception that is not yet caught (and is therefore still propagating), while the latter returns an exception after it is caught (and has therefore stopped propagating).
Printing and clearing
void PyErr_Clear()
Part of the Stable ABI.
Clear the error indicator. If the error indicator is not set, there is no effect.

void PyErr_PrintEx(int set_sys_last_vars)
Part of the Stable ABI.
Print a standard traceback to sys.stderr and clear the error indicator. Unless the error is a SystemExit, in that case no traceback is printed and the Python process will exit with the error code specified by the SystemExit instance.

Call this function only when the error indicator is set. Otherwise it will cause a fatal error!

If set_sys_last_vars is nonzero, the variables sys.last_type, sys.last_value and sys.last_traceback will be set to the type, value and traceback of the printed exception, respectively.

void PyErr_Print()
Part of the Stable ABI.
Alias for PyErr_PrintEx(1).

void PyErr_WriteUnraisable(PyObject *obj)
Part of the Stable ABI.
Call sys.unraisablehook() using the current exception and obj argument.

This utility function prints a warning message to sys.stderr when an exception has been set but it is impossible for the interpreter to actually raise the exception. It is used, for example, when an exception occurs in an __del__() method.

The function is called with a single argument obj that identifies the context in which the unraisable exception occurred. If possible, the repr of obj will be printed in the warning message.

An exception must be set when calling this function.

Raising exceptions
These functions help you set the current thread’s error indicator. For convenience, some of these functions will always return a NULL pointer for use in a return statement.

void PyErr_SetString(PyObject *type, const char *message)
Part of the Stable ABI.
This is the most common way to set the error indicator. The first argument specifies the exception type; it is normally one of the standard exceptions, e.g. PyExc_RuntimeError. You need not increment its reference count. The second argument is an error message; it is decoded from 'utf-8'.

void PyErr_SetObject(PyObject *type, PyObject *value)
Part of the Stable ABI.
This function is similar to PyErr_SetString() but lets you specify an arbitrary Python object for the “value” of the exception.

PyObject *PyErr_Format(PyObject *exception, const char *format, ...)
Return value: Always NULL. Part of the Stable ABI.
This function sets the error indicator and returns NULL. exception should be a Python exception class. The format and subsequent parameters help format the error message; they have the same meaning and values as in PyUnicode_FromFormat(). format is an ASCII-encoded string.

PyObject *PyErr_FormatV(PyObject *exception, const char *format, va_list vargs)
Return value: Always NULL. Part of the Stable ABI since version 3.5.
Same as PyErr_Format(), but taking a va_list argument rather than a variable number of arguments.

New in version 3.5.

void PyErr_SetNone(PyObject *type)
Part of the Stable ABI.
This is a shorthand for PyErr_SetObject(type, Py_None).

int PyErr_BadArgument()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_TypeError, message), where message indicates that a built-in operation was invoked with an illegal argument. It is mostly for internal use.

PyObject *PyErr_NoMemory()
Return value: Always NULL. Part of the Stable ABI.
This is a shorthand for PyErr_SetNone(PyExc_MemoryError); it returns NULL so an object allocation function can write return PyErr_NoMemory(); when it runs out of memory.

PyObject *PyErr_SetFromErrno(PyObject *type)
Return value: Always NULL. Part of the Stable ABI.
This is a convenience function to raise an exception when a C library function has returned an error and set the C variable errno. It constructs a tuple object whose first item is the integer errno value and whose second item is the corresponding error message (gotten from strerror()), and then calls PyErr_SetObject(type, object). On Unix, when the errno value is EINTR, indicating an interrupted system call, this calls PyErr_CheckSignals(), and if that set the error indicator, leaves it set to that. The function always returns NULL, so a wrapper function around a system call can write return PyErr_SetFromErrno(type); when the system call returns an error.

PyObject *PyErr_SetFromErrnoWithFilenameObject(PyObject *type, PyObject *filenameObject)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrno(), with the additional behavior that if filenameObject is not NULL, it is passed to the constructor of type as a third parameter. In the case of OSError exception, this is used to define the filename attribute of the exception instance.

PyObject *PyErr_SetFromErrnoWithFilenameObjects(PyObject *type, PyObject *filenameObject, PyObject *filenameObject2)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but takes a second filename object, for raising errors when a function that takes two filenames fails.

New in version 3.4.

PyObject *PyErr_SetFromErrnoWithFilename(PyObject *type, const char *filename)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding and error handler.

PyObject *PyErr_SetFromWindowsErr(int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
This is a convenience function to raise WindowsError. If called with ierr of 0, the error code returned by a call to GetLastError() is used instead. It calls the Win32 function FormatMessage() to retrieve the Windows description of error code given by ierr or GetLastError(), then it constructs a tuple object whose first item is the ierr value and whose second item is the corresponding error message (gotten from FormatMessage()), and then calls PyErr_SetObject(PyExc_WindowsError, object). This function always returns NULL.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErr(PyObject *type, int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErr(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetFromWindowsErrWithFilename(int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding (os.fsdecode()).

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObject(PyObject *type, int ierr, PyObject *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObjects(PyObject *type, int ierr, PyObject *filename, PyObject *filename2)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetExcFromWindowsErrWithFilenameObject(), but accepts a second filename object.

Availability: Windows.

New in version 3.4.

PyObject *PyErr_SetExcFromWindowsErrWithFilename(PyObject *type, int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilename(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetImportError(PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
This is a convenience function to raise ImportError. msg will be set as the exception’s message string. name and path, both of which can be NULL, will be set as the ImportError’s respective name and path attributes.

New in version 3.3.

PyObject *PyErr_SetImportErrorSubclass(PyObject *exception, PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.6.
Much like PyErr_SetImportError() but this function allows for specifying a subclass of ImportError to raise.

New in version 3.6.

void PyErr_SyntaxLocationObject(PyObject *filename, int lineno, int col_offset)
Set file, line, and offset information for the current exception. If the current exception is not a SyntaxError, then it sets additional attributes, which make the exception printing subsystem think the exception is a SyntaxError.

New in version 3.4.

void PyErr_SyntaxLocationEx(const char *filename, int lineno, int col_offset)
Part of the Stable ABI since version 3.7.
Like PyErr_SyntaxLocationObject(), but filename is a byte string decoded from the filesystem encoding and error handler.

New in version 3.2.

void PyErr_SyntaxLocation(const char *filename, int lineno)
Part of the Stable ABI.
Like PyErr_SyntaxLocationEx(), but the col_offset parameter is omitted.

void PyErr_BadInternalCall()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_SystemError, message), where message indicates that an internal operation (e.g. a Python/C API function) was invoked with an illegal argument. It is mostly for internal use.

Issuing warnings
Use these functions to issue warnings from C code. They mirror similar functions exported by the Python warnings module. They normally print a warning message to sys.stderr; however, it is also possible that the user has specified that warnings are to be turned into errors, and in that case they will raise an exception. It is also possible that the functions raise an exception because of a problem with the warning machinery. The return value is 0 if no exception is raised, or -1 if an exception is raised. (It is not possible to determine whether a warning message is actually printed, nor what the reason is for the exception; this is intentional.) If an exception is raised, the caller should do its normal exception handling (for example, Py_DECREF() owned references and return an error value).

int PyErr_WarnEx(PyObject *category, const char *message, Py_ssize_t stack_level)
Part of the Stable ABI.
Issue a warning message. The category argument is a warning category (see below) or NULL; the message argument is a UTF-8 encoded string. stack_level is a positive number giving a number of stack frames; the warning will be issued from the currently executing line of code in that stack frame. A stack_level of 1 is the function calling PyErr_WarnEx(), 2 is the function above that, and so forth.

Warning categories must be subclasses of PyExc_Warning; PyExc_Warning is a subclass of PyExc_Exception; the default warning category is PyExc_RuntimeWarning. The standard Python warning categories are available as global variables whose names are enumerated at Standard Warning Categories.

For information about warning control, see the documentation for the warnings module and the -W option in the command line documentation. There is no C API for warning control.

int PyErr_WarnExplicitObject(PyObject *category, PyObject *message, PyObject *filename, int lineno, PyObject *module, PyObject *registry)
Issue a warning message with explicit control over all warning attributes. This is a straightforward wrapper around the Python function warnings.warn_explicit(); see there for more information. The module and registry arguments may be set to NULL to get the default effect described there.

New in version 3.4.

int PyErr_WarnExplicit(PyObject *category, const char *message, const char *filename, int lineno, const char *module, PyObject *registry)
Part of the Stable ABI.
Similar to PyErr_WarnExplicitObject() except that message and module are UTF-8 encoded strings, and filename is decoded from the filesystem encoding and error handler.

int PyErr_WarnFormat(PyObject *category, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI.
Function similar to PyErr_WarnEx(), but use PyUnicode_FromFormat() to format the warning message. format is an ASCII-encoded string.

New in version 3.2.

int PyErr_ResourceWarning(PyObject *source, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI since version 3.6.
Function similar to PyErr_WarnFormat(), but category is ResourceWarning and it passes source to warnings.WarningMessage().

New in version 3.6.

Querying the error indicator
PyObject *PyErr_Occurred()
Return value: Borrowed reference. Part of the Stable ABI.
Test whether the error indicator is set. If set, return the exception type (the first argument to the last call to one of the PyErr_Set* functions or to PyErr_Restore()). If not set, return NULL. You do not own a reference to the return value, so you do not need to Py_DECREF() it.

The caller must hold the GIL.

Note Do not compare the return value to a specific exception; use PyErr_ExceptionMatches() instead, shown below. (The comparison could easily fail since the exception may be an instance instead of a class, in the case of a class exception, or it may be a subclass of the expected exception.)
int PyErr_ExceptionMatches(PyObject *exc)
Part of the Stable ABI.
Equivalent to PyErr_GivenExceptionMatches(PyErr_Occurred(), exc). This should only be called when an exception is actually set; a memory access violation will occur if no exception has been raised.

int PyErr_GivenExceptionMatches(PyObject *given, PyObject *exc)
Part of the Stable ABI.
Return true if the given exception matches the exception type in exc. If exc is a class object, this also returns true when given is an instance of a subclass. If exc is a tuple, all exception types in the tuple (and recursively in subtuples) are searched for a match.

void PyErr_Fetch(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI.
Retrieve the error indicator into three variables whose addresses are passed. If the error indicator is not set, set all three variables to NULL. If it is set, it will be cleared and you own a reference to each object retrieved. The value and traceback object may be NULL even when the type object is not.

Note This function is normally only used by code that needs to catch exceptions or by code that needs to save and restore the error indicator temporarily, e.g.:
{
   PyObject *type, *value, *traceback;
   PyErr_Fetch(&type, &value, &traceback);

   /* ... code that might produce other errors ... */

   PyErr_Restore(type, value, traceback);
}
void PyErr_Restore(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI.
Set the error indicator from the three objects. If the error indicator is already set, it is cleared first. If the objects are NULL, the error indicator is cleared. Do not pass a NULL type and non-NULL value or traceback. The exception type should be a class. Do not pass an invalid exception type or value. (Violating these rules will cause subtle problems later.) This call takes away a reference to each object: you must own a reference to each object before the call and after the call you no longer own these references. (If you don’t understand this, don’t use this function. I warned you.)

Note This function is normally only used by code that needs to save and restore the error indicator temporarily. Use PyErr_Fetch() to save the current error indicator.
void PyErr_NormalizeException(PyObject **exc, PyObject **val, PyObject **tb)
Part of the Stable ABI.
Under certain circumstances, the values returned by PyErr_Fetch() below can be “unnormalized”, meaning that *exc is a class object but *val is not an instance of the same class. This function can be used to instantiate the class in that case. If the values are already normalized, nothing happens. The delayed normalization is implemented to improve performance.

Note This function does not implicitly set the __traceback__ attribute on the exception value. If setting the traceback appropriately is desired, the following additional snippet is needed:
if (tb != NULL) {
  PyException_SetTraceback(val, tb);
}
void PyErr_GetExcInfo(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI since version 3.7.
Retrieve the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. Returns new references for the three objects, any of which may be NULL. Does not modify the exception info state.

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_SetExcInfo() to restore or clear the exception state.
New in version 3.3.

void PyErr_SetExcInfo(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI since version 3.7.
Set the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. This function steals the references of the arguments. To clear the exception state, pass NULL for all three arguments. For general rules about the three arguments, see PyErr_Restore().

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_GetExcInfo() to read the exception state.
New in version 3.3.

Signal Handling
int PyErr_CheckSignals()
Part of the Stable ABI.
This function interacts with Python’s signal handling.

If the function is called from the main thread and under the main Python interpreter, it checks whether a signal has been sent to the processes and if so, invokes the corresponding signal handler. If the signal module is supported, this can invoke a signal handler written in Python.

The function attempts to handle all pending signals, and then returns 0. However, if a Python signal handler raises an exception, the error indicator is set and the function returns -1 immediately (such that other pending signals may not have been handled yet: they will be on the next PyErr_CheckSignals() invocation).

If the function is called from a non-main thread, or under a non-main Python interpreter, it does nothing and returns 0.

This function can be called by long-running C code that wants to be interruptible by user requests (such as by pressing Ctrl-C).

Note The default Python signal handler for SIGINT raises the KeyboardInterrupt exception.
void PyErr_SetInterrupt()
Part of the Stable ABI.
Simulate the effect of a SIGINT signal arriving. This is equivalent to PyErr_SetInterruptEx(SIGINT).

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
int PyErr_SetInterruptEx(int signum)
Part of the Stable ABI since version 3.10.
Simulate the effect of a signal arriving. The next time PyErr_CheckSignals() is called, the Python signal handler for the given signal number will be called.

This function can be called by C code that sets up its own signal handling and wants Python signal handlers to be invoked as expected when an interruption is requested (for example when the user presses Ctrl-C to interrupt an operation).

If the given signal isn’t handled by Python (it was set to signal.SIG_DFL or signal.SIG_IGN), it will be ignored.

If signum is outside of the allowed range of signal numbers, -1 is returned. Otherwise, 0 is returned. The error indicator is never changed by this function.

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
New in version 3.10.

int PySignal_SetWakeupFd(int fd)
This utility function specifies a file descriptor to which the signal number is written as a single byte whenever a signal is received. fd must be non-blocking. It returns the previous such file descriptor.

The value -1 disables the feature; this is the initial state. This is equivalent to signal.set_wakeup_fd() in Python, but without any error checking. fd should be a valid file descriptor. The function should only be called from the main thread.

Changed in version 3.5: On Windows, the function now also supports socket handles.

Exception Classes
PyObject *PyErr_NewException(const char *name, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
This utility function creates and returns a new exception class. The name argument must be the name of the new exception, a C string of the form module.classname. The base and dict arguments are normally NULL. This creates a class object derived from Exception (accessible in C as PyExc_Exception).

The __module__ attribute of the new class is set to the first part (up to the last dot) of the name argument, and the class name is set to the last part (after the last dot). The base argument can be used to specify alternate base classes; it can either be only one class or a tuple of classes. The dict argument can be used to specify a dictionary of class variables and methods.

PyObject *PyErr_NewExceptionWithDoc(const char *name, const char *doc, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
Same as PyErr_NewException(), except that the new exception class can easily be given a docstring: If doc is non-NULL, it will be used as the docstring for the exception class.

New in version 3.2.

Exception Objects
PyObject *PyException_GetTraceback(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the traceback associated with the exception as a new reference, as accessible from Python through __traceback__. If there is no traceback associated, this returns NULL.

int PyException_SetTraceback(PyObject *ex, PyObject *tb)
Part of the Stable ABI.
Set the traceback associated with the exception to tb. Use Py_None to clear it.

PyObject *PyException_GetContext(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the context (another exception instance during whose handling ex was raised) associated with the exception as a new reference, as accessible from Python through __context__. If there is no context associated, this returns NULL.

void PyException_SetContext(PyObject *ex, PyObject *ctx)
Part of the Stable ABI.
Set the context associated with the exception to ctx. Use NULL to clear it. There is no type check to make sure that ctx is an exception instance. This steals a reference to ctx.

PyObject *PyException_GetCause(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the cause (either an exception instance, or None, set by raise ... from ...) associated with the exception as a new reference, as accessible from Python through __cause__.

void PyException_SetCause(PyObject *ex, PyObject *cause)
Part of the Stable ABI.
Set the cause associated with the exception to cause. Use NULL to clear it. There is no type check to make sure that cause is either an exception instance or None. This steals a reference to cause.

__suppress_context__ is implicitly set to True by this function.

Unicode Exception Objects
The following functions are used to create and modify Unicode exceptions from C.

PyObject *PyUnicodeDecodeError_Create(const char *encoding, const char *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference. Part of the Stable ABI.
Create a UnicodeDecodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

PyObject *PyUnicodeEncodeError_Create(const char *encoding, const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeEncodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeEncodeError, "sOnns", ...).

PyObject *PyUnicodeTranslateError_Create(const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeTranslateError object with the attributes object, length, start, end and reason. reason is a UTF-8 encoded string.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeTranslateError, "Onns", ...).

PyObject *PyUnicodeDecodeError_GetEncoding(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetEncoding(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the encoding attribute of the given exception object.

PyObject *PyUnicodeDecodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetObject(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the object attribute of the given exception object.

int PyUnicodeDecodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeEncodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeTranslateError_GetStart(PyObject *exc, Py_ssize_t *start)
Part of the Stable ABI.
Get the start attribute of the given exception object and place it into *start. start must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeEncodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeTranslateError_SetStart(PyObject *exc, Py_ssize_t start)
Part of the Stable ABI.
Set the start attribute of the given exception object to start. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeEncodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeTranslateError_GetEnd(PyObject *exc, Py_ssize_t *end)
Part of the Stable ABI.
Get the end attribute of the given exception object and place it into *end. end must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeEncodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeTranslateError_SetEnd(PyObject *exc, Py_ssize_t end)
Part of the Stable ABI.
Set the end attribute of the given exception object to end. Return 0 on success, -1 on failure.

PyObject *PyUnicodeDecodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetReason(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the reason attribute of the given exception object.

int PyUnicodeDecodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeEncodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeTranslateError_SetReason(PyObject *exc, const char *reason)
Part of the Stable ABI.
Set the reason attribute of the given exception object to reason. Return 0 on success, -1 on failure.

Recursion Control
These two functions provide a way to perform safe recursive calls at the C level, both in the core and in extension modules. They are needed if the recursive code does not necessarily invoke Python code (which tracks its recursion depth automatically). They are also not needed for tp_call implementations because the call protocol takes care of recursion handling.

int Py_EnterRecursiveCall(const char *where)
Part of the Stable ABI since version 3.9.
Marks a point where a recursive C-level call is about to be performed.

If USE_STACKCHECK is defined, this function checks if the OS stack overflowed using PyOS_CheckStack(). In this is the case, it sets a MemoryError and returns a nonzero value.

The function then checks if the recursion limit is reached. If this is the case, a RecursionError is set and a nonzero value is returned. Otherwise, zero is returned.

where should be a UTF-8 encoded string such as " in instance check" to be concatenated to the RecursionError message caused by the recursion depth limit.

Changed in version 3.9: This function is now also available in the limited API.

void Py_LeaveRecursiveCall(void)
Part of the Stable ABI since version 3.9.
Ends a Py_EnterRecursiveCall(). Must be called once for each successful invocation of Py_EnterRecursiveCall().

Changed in version 3.9: This function is now also available in the limited API.

Properly implementing tp_repr for container types requires special recursion handling. In addition to protecting the stack, tp_repr also needs to track objects to prevent cycles. The following two functions facilitate this functionality. Effectively, these are the C equivalent to reprlib.recursive_repr().

int Py_ReprEnter(PyObject *object)
Part of the Stable ABI.
Called at the beginning of the tp_repr implementation to detect cycles.

If the object has already been processed, the function returns a positive integer. In that case the tp_repr implementation should return a string object indicating a cycle. As examples, dict objects return {...} and list objects return [...].

The function will return a negative integer if the recursion limit is reached. In that case the tp_repr implementation should typically return NULL.

Otherwise, the function returns zero and the tp_repr implementation can continue normally.

void Py_ReprLeave(PyObject *object)
Part of the Stable ABI.
Ends a Py_ReprEnter(). Must be called once for each invocation of Py_ReprEnter() that returns zero.

Standard Exceptions
All standard Python exceptions are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_BaseException

BaseException

1

PyExc_Exception

Exception

1

PyExc_ArithmeticError

ArithmeticError

1

PyExc_AssertionError

AssertionError

PyExc_AttributeError

AttributeError

PyExc_BlockingIOError

BlockingIOError

PyExc_BrokenPipeError

BrokenPipeError

PyExc_BufferError

BufferError

PyExc_ChildProcessError

ChildProcessError

PyExc_ConnectionAbortedError

ConnectionAbortedError

PyExc_ConnectionError

ConnectionError

PyExc_ConnectionRefusedError

ConnectionRefusedError

PyExc_ConnectionResetError

ConnectionResetError

PyExc_EOFError

EOFError

PyExc_FileExistsError

FileExistsError

PyExc_FileNotFoundError

FileNotFoundError

PyExc_FloatingPointError

FloatingPointError

PyExc_GeneratorExit

GeneratorExit

PyExc_ImportError

ImportError

PyExc_IndentationError

IndentationError

PyExc_IndexError

IndexError

PyExc_InterruptedError

InterruptedError

PyExc_IsADirectoryError

IsADirectoryError

PyExc_KeyError

KeyError

PyExc_KeyboardInterrupt

KeyboardInterrupt

PyExc_LookupError

LookupError

1

PyExc_MemoryError

MemoryError

PyExc_ModuleNotFoundError

ModuleNotFoundError

PyExc_NameError

NameError

PyExc_NotADirectoryError

NotADirectoryError

PyExc_NotImplementedError

NotImplementedError

PyExc_OSError

OSError

1

PyExc_OverflowError

OverflowError

PyExc_PermissionError

PermissionError

PyExc_ProcessLookupError

ProcessLookupError

PyExc_RecursionError

RecursionError

PyExc_ReferenceError

ReferenceError

PyExc_RuntimeError

RuntimeError

PyExc_StopAsyncIteration

StopAsyncIteration

PyExc_StopIteration

StopIteration

PyExc_SyntaxError

SyntaxError

PyExc_SystemError

SystemError

PyExc_SystemExit

SystemExit

PyExc_TabError

TabError

PyExc_TimeoutError

TimeoutError

PyExc_TypeError

TypeError

PyExc_UnboundLocalError

UnboundLocalError

PyExc_UnicodeDecodeError

UnicodeDecodeError

PyExc_UnicodeEncodeError

UnicodeEncodeError

PyExc_UnicodeError

UnicodeError

PyExc_UnicodeTranslateError

UnicodeTranslateError

PyExc_ValueError

ValueError

PyExc_ZeroDivisionError

ZeroDivisionError

New in version 3.3: PyExc_BlockingIOError, PyExc_BrokenPipeError, PyExc_ChildProcessError, PyExc_ConnectionError, PyExc_ConnectionAbortedError, PyExc_ConnectionRefusedError, PyExc_ConnectionResetError, PyExc_FileExistsError, PyExc_FileNotFoundError, PyExc_InterruptedError, PyExc_IsADirectoryError, PyExc_NotADirectoryError, PyExc_PermissionError, PyExc_ProcessLookupError and PyExc_TimeoutError were introduced following PEP 3151.

New in version 3.5: PyExc_StopAsyncIteration and PyExc_RecursionError.

New in version 3.6: PyExc_ModuleNotFoundError.

These are compatibility aliases to PyExc_OSError:

C Name

Notes

PyExc_EnvironmentError

PyExc_IOError

PyExc_WindowsError

2

Changed in version 3.3: These aliases used to be separate exception types.

Notes:

1(1,2,3,4,5)
This is a base class for other standard exceptions.

2
Only defined on Windows; protect code that uses this by testing that the preprocessor macro MS_WINDOWS is defined.

Standard Warning Categories
All standard Python warning categories are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_Warning

Warning

3

PyExc_BytesWarning

BytesWarning

PyExc_DeprecationWarning

DeprecationWarning

PyExc_FutureWarning

FutureWarning

PyExc_ImportWarning

ImportWarning

PyExc_PendingDeprecationWarning

PendingDeprecationWarning

PyExc_ResourceWarning

ResourceWarning

PyExc_RuntimeWarning

RuntimeWarning

PyExc_SyntaxWarning

SyntaxWarning

PyExc_UnicodeWarning

UnicodeWarning

PyExc_UserWarning

UserWarning

New in version 3.2: PyExc_ResourceWarning.

Notes:

3
This is a base class for other standard warning categories.

Table of Contents
Exception Handling
Printing and clearing
Raising exceptions
Issuing warnings
Querying the error indicator
Signal Handling
Exception Classes
Exception Objects
Unicode Exception Objects
Recursion Control
Standard Exceptions
Standard Warning Categories
Previous topic
Reference Counting

Next topic
Utilities

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
Exception Handling
The functions described in this chapter will let you handle and raise Python exceptions. It is important to understand some of the basics of Python exception handling. It works somewhat like the POSIX errno variable: there is a global indicator (per thread) of the last error that occurred. Most C API functions don’t clear this on success, but will set it to indicate the cause of the error on failure. Most C API functions also return an error indicator, usually NULL if they are supposed to return a pointer, or -1 if they return an integer (exception: the PyArg_* functions return 1 for success and 0 for failure).

Concretely, the error indicator consists of three object pointers: the exception’s type, the exception’s value, and the traceback object. Any of those pointers can be NULL if non-set (although some combinations are forbidden, for example you can’t have a non-NULL traceback if the exception type is NULL).

When a function must fail because some function it called failed, it generally doesn’t set the error indicator; the function it called already set it. It is responsible for either handling the error and clearing the exception or returning after cleaning up any resources it holds (such as object references or memory allocations); it should not continue normally if it is not prepared to handle the error. If returning due to an error, it is important to indicate to the caller that an error has been set. If the error is not handled or carefully propagated, additional calls into the Python/C API may not behave as intended and may fail in mysterious ways.

Note The error indicator is not the result of sys.exc_info(). The former corresponds to an exception that is not yet caught (and is therefore still propagating), while the latter returns an exception after it is caught (and has therefore stopped propagating).
Printing and clearing
void PyErr_Clear()
Part of the Stable ABI.
Clear the error indicator. If the error indicator is not set, there is no effect.

void PyErr_PrintEx(int set_sys_last_vars)
Part of the Stable ABI.
Print a standard traceback to sys.stderr and clear the error indicator. Unless the error is a SystemExit, in that case no traceback is printed and the Python process will exit with the error code specified by the SystemExit instance.

Call this function only when the error indicator is set. Otherwise it will cause a fatal error!

If set_sys_last_vars is nonzero, the variables sys.last_type, sys.last_value and sys.last_traceback will be set to the type, value and traceback of the printed exception, respectively.

void PyErr_Print()
Part of the Stable ABI.
Alias for PyErr_PrintEx(1).

void PyErr_WriteUnraisable(PyObject *obj)
Part of the Stable ABI.
Call sys.unraisablehook() using the current exception and obj argument.

This utility function prints a warning message to sys.stderr when an exception has been set but it is impossible for the interpreter to actually raise the exception. It is used, for example, when an exception occurs in an __del__() method.

The function is called with a single argument obj that identifies the context in which the unraisable exception occurred. If possible, the repr of obj will be printed in the warning message.

An exception must be set when calling this function.

Raising exceptions
These functions help you set the current thread’s error indicator. For convenience, some of these functions will always return a NULL pointer for use in a return statement.

void PyErr_SetString(PyObject *type, const char *message)
Part of the Stable ABI.
This is the most common way to set the error indicator. The first argument specifies the exception type; it is normally one of the standard exceptions, e.g. PyExc_RuntimeError. You need not increment its reference count. The second argument is an error message; it is decoded from 'utf-8'.

void PyErr_SetObject(PyObject *type, PyObject *value)
Part of the Stable ABI.
This function is similar to PyErr_SetString() but lets you specify an arbitrary Python object for the “value” of the exception.

PyObject *PyErr_Format(PyObject *exception, const char *format, ...)
Return value: Always NULL. Part of the Stable ABI.
This function sets the error indicator and returns NULL. exception should be a Python exception class. The format and subsequent parameters help format the error message; they have the same meaning and values as in PyUnicode_FromFormat(). format is an ASCII-encoded string.

PyObject *PyErr_FormatV(PyObject *exception, const char *format, va_list vargs)
Return value: Always NULL. Part of the Stable ABI since version 3.5.
Same as PyErr_Format(), but taking a va_list argument rather than a variable number of arguments.

New in version 3.5.

void PyErr_SetNone(PyObject *type)
Part of the Stable ABI.
This is a shorthand for PyErr_SetObject(type, Py_None).

int PyErr_BadArgument()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_TypeError, message), where message indicates that a built-in operation was invoked with an illegal argument. It is mostly for internal use.

PyObject *PyErr_NoMemory()
Return value: Always NULL. Part of the Stable ABI.
This is a shorthand for PyErr_SetNone(PyExc_MemoryError); it returns NULL so an object allocation function can write return PyErr_NoMemory(); when it runs out of memory.

PyObject *PyErr_SetFromErrno(PyObject *type)
Return value: Always NULL. Part of the Stable ABI.
This is a convenience function to raise an exception when a C library function has returned an error and set the C variable errno. It constructs a tuple object whose first item is the integer errno value and whose second item is the corresponding error message (gotten from strerror()), and then calls PyErr_SetObject(type, object). On Unix, when the errno value is EINTR, indicating an interrupted system call, this calls PyErr_CheckSignals(), and if that set the error indicator, leaves it set to that. The function always returns NULL, so a wrapper function around a system call can write return PyErr_SetFromErrno(type); when the system call returns an error.

PyObject *PyErr_SetFromErrnoWithFilenameObject(PyObject *type, PyObject *filenameObject)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrno(), with the additional behavior that if filenameObject is not NULL, it is passed to the constructor of type as a third parameter. In the case of OSError exception, this is used to define the filename attribute of the exception instance.

PyObject *PyErr_SetFromErrnoWithFilenameObjects(PyObject *type, PyObject *filenameObject, PyObject *filenameObject2)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but takes a second filename object, for raising errors when a function that takes two filenames fails.

New in version 3.4.

PyObject *PyErr_SetFromErrnoWithFilename(PyObject *type, const char *filename)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding and error handler.

PyObject *PyErr_SetFromWindowsErr(int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
This is a convenience function to raise WindowsError. If called with ierr of 0, the error code returned by a call to GetLastError() is used instead. It calls the Win32 function FormatMessage() to retrieve the Windows description of error code given by ierr or GetLastError(), then it constructs a tuple object whose first item is the ierr value and whose second item is the corresponding error message (gotten from FormatMessage()), and then calls PyErr_SetObject(PyExc_WindowsError, object). This function always returns NULL.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErr(PyObject *type, int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErr(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetFromWindowsErrWithFilename(int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding (os.fsdecode()).

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObject(PyObject *type, int ierr, PyObject *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObjects(PyObject *type, int ierr, PyObject *filename, PyObject *filename2)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetExcFromWindowsErrWithFilenameObject(), but accepts a second filename object.

Availability: Windows.

New in version 3.4.

PyObject *PyErr_SetExcFromWindowsErrWithFilename(PyObject *type, int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilename(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetImportError(PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
This is a convenience function to raise ImportError. msg will be set as the exception’s message string. name and path, both of which can be NULL, will be set as the ImportError’s respective name and path attributes.

New in version 3.3.

PyObject *PyErr_SetImportErrorSubclass(PyObject *exception, PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.6.
Much like PyErr_SetImportError() but this function allows for specifying a subclass of ImportError to raise.

New in version 3.6.

void PyErr_SyntaxLocationObject(PyObject *filename, int lineno, int col_offset)
Set file, line, and offset information for the current exception. If the current exception is not a SyntaxError, then it sets additional attributes, which make the exception printing subsystem think the exception is a SyntaxError.

New in version 3.4.

void PyErr_SyntaxLocationEx(const char *filename, int lineno, int col_offset)
Part of the Stable ABI since version 3.7.
Like PyErr_SyntaxLocationObject(), but filename is a byte string decoded from the filesystem encoding and error handler.

New in version 3.2.

void PyErr_SyntaxLocation(const char *filename, int lineno)
Part of the Stable ABI.
Like PyErr_SyntaxLocationEx(), but the col_offset parameter is omitted.

void PyErr_BadInternalCall()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_SystemError, message), where message indicates that an internal operation (e.g. a Python/C API function) was invoked with an illegal argument. It is mostly for internal use.

Issuing warnings
Use these functions to issue warnings from C code. They mirror similar functions exported by the Python warnings module. They normally print a warning message to sys.stderr; however, it is also possible that the user has specified that warnings are to be turned into errors, and in that case they will raise an exception. It is also possible that the functions raise an exception because of a problem with the warning machinery. The return value is 0 if no exception is raised, or -1 if an exception is raised. (It is not possible to determine whether a warning message is actually printed, nor what the reason is for the exception; this is intentional.) If an exception is raised, the caller should do its normal exception handling (for example, Py_DECREF() owned references and return an error value).

int PyErr_WarnEx(PyObject *category, const char *message, Py_ssize_t stack_level)
Part of the Stable ABI.
Issue a warning message. The category argument is a warning category (see below) or NULL; the message argument is a UTF-8 encoded string. stack_level is a positive number giving a number of stack frames; the warning will be issued from the currently executing line of code in that stack frame. A stack_level of 1 is the function calling PyErr_WarnEx(), 2 is the function above that, and so forth.

Warning categories must be subclasses of PyExc_Warning; PyExc_Warning is a subclass of PyExc_Exception; the default warning category is PyExc_RuntimeWarning. The standard Python warning categories are available as global variables whose names are enumerated at Standard Warning Categories.

For information about warning control, see the documentation for the warnings module and the -W option in the command line documentation. There is no C API for warning control.

int PyErr_WarnExplicitObject(PyObject *category, PyObject *message, PyObject *filename, int lineno, PyObject *module, PyObject *registry)
Issue a warning message with explicit control over all warning attributes. This is a straightforward wrapper around the Python function warnings.warn_explicit(); see there for more information. The module and registry arguments may be set to NULL to get the default effect described there.

New in version 3.4.

int PyErr_WarnExplicit(PyObject *category, const char *message, const char *filename, int lineno, const char *module, PyObject *registry)
Part of the Stable ABI.
Similar to PyErr_WarnExplicitObject() except that message and module are UTF-8 encoded strings, and filename is decoded from the filesystem encoding and error handler.

int PyErr_WarnFormat(PyObject *category, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI.
Function similar to PyErr_WarnEx(), but use PyUnicode_FromFormat() to format the warning message. format is an ASCII-encoded string.

New in version 3.2.

int PyErr_ResourceWarning(PyObject *source, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI since version 3.6.
Function similar to PyErr_WarnFormat(), but category is ResourceWarning and it passes source to warnings.WarningMessage().

New in version 3.6.

Querying the error indicator
PyObject *PyErr_Occurred()
Return value: Borrowed reference. Part of the Stable ABI.
Test whether the error indicator is set. If set, return the exception type (the first argument to the last call to one of the PyErr_Set* functions or to PyErr_Restore()). If not set, return NULL. You do not own a reference to the return value, so you do not need to Py_DECREF() it.

The caller must hold the GIL.

Note Do not compare the return value to a specific exception; use PyErr_ExceptionMatches() instead, shown below. (The comparison could easily fail since the exception may be an instance instead of a class, in the case of a class exception, or it may be a subclass of the expected exception.)
int PyErr_ExceptionMatches(PyObject *exc)
Part of the Stable ABI.
Equivalent to PyErr_GivenExceptionMatches(PyErr_Occurred(), exc). This should only be called when an exception is actually set; a memory access violation will occur if no exception has been raised.

int PyErr_GivenExceptionMatches(PyObject *given, PyObject *exc)
Part of the Stable ABI.
Return true if the given exception matches the exception type in exc. If exc is a class object, this also returns true when given is an instance of a subclass. If exc is a tuple, all exception types in the tuple (and recursively in subtuples) are searched for a match.

void PyErr_Fetch(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI.
Retrieve the error indicator into three variables whose addresses are passed. If the error indicator is not set, set all three variables to NULL. If it is set, it will be cleared and you own a reference to each object retrieved. The value and traceback object may be NULL even when the type object is not.

Note This function is normally only used by code that needs to catch exceptions or by code that needs to save and restore the error indicator temporarily, e.g.:
{
   PyObject *type, *value, *traceback;
   PyErr_Fetch(&type, &value, &traceback);

   /* ... code that might produce other errors ... */

   PyErr_Restore(type, value, traceback);
}
void PyErr_Restore(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI.
Set the error indicator from the three objects. If the error indicator is already set, it is cleared first. If the objects are NULL, the error indicator is cleared. Do not pass a NULL type and non-NULL value or traceback. The exception type should be a class. Do not pass an invalid exception type or value. (Violating these rules will cause subtle problems later.) This call takes away a reference to each object: you must own a reference to each object before the call and after the call you no longer own these references. (If you don’t understand this, don’t use this function. I warned you.)

Note This function is normally only used by code that needs to save and restore the error indicator temporarily. Use PyErr_Fetch() to save the current error indicator.
void PyErr_NormalizeException(PyObject **exc, PyObject **val, PyObject **tb)
Part of the Stable ABI.
Under certain circumstances, the values returned by PyErr_Fetch() below can be “unnormalized”, meaning that *exc is a class object but *val is not an instance of the same class. This function can be used to instantiate the class in that case. If the values are already normalized, nothing happens. The delayed normalization is implemented to improve performance.

Note This function does not implicitly set the __traceback__ attribute on the exception value. If setting the traceback appropriately is desired, the following additional snippet is needed:
if (tb != NULL) {
  PyException_SetTraceback(val, tb);
}
void PyErr_GetExcInfo(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI since version 3.7.
Retrieve the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. Returns new references for the three objects, any of which may be NULL. Does not modify the exception info state.

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_SetExcInfo() to restore or clear the exception state.
New in version 3.3.

void PyErr_SetExcInfo(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI since version 3.7.
Set the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. This function steals the references of the arguments. To clear the exception state, pass NULL for all three arguments. For general rules about the three arguments, see PyErr_Restore().

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_GetExcInfo() to read the exception state.
New in version 3.3.

Signal Handling
int PyErr_CheckSignals()
Part of the Stable ABI.
This function interacts with Python’s signal handling.

If the function is called from the main thread and under the main Python interpreter, it checks whether a signal has been sent to the processes and if so, invokes the corresponding signal handler. If the signal module is supported, this can invoke a signal handler written in Python.

The function attempts to handle all pending signals, and then returns 0. However, if a Python signal handler raises an exception, the error indicator is set and the function returns -1 immediately (such that other pending signals may not have been handled yet: they will be on the next PyErr_CheckSignals() invocation).

If the function is called from a non-main thread, or under a non-main Python interpreter, it does nothing and returns 0.

This function can be called by long-running C code that wants to be interruptible by user requests (such as by pressing Ctrl-C).

Note The default Python signal handler for SIGINT raises the KeyboardInterrupt exception.
void PyErr_SetInterrupt()
Part of the Stable ABI.
Simulate the effect of a SIGINT signal arriving. This is equivalent to PyErr_SetInterruptEx(SIGINT).

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
int PyErr_SetInterruptEx(int signum)
Part of the Stable ABI since version 3.10.
Simulate the effect of a signal arriving. The next time PyErr_CheckSignals() is called, the Python signal handler for the given signal number will be called.

This function can be called by C code that sets up its own signal handling and wants Python signal handlers to be invoked as expected when an interruption is requested (for example when the user presses Ctrl-C to interrupt an operation).

If the given signal isn’t handled by Python (it was set to signal.SIG_DFL or signal.SIG_IGN), it will be ignored.

If signum is outside of the allowed range of signal numbers, -1 is returned. Otherwise, 0 is returned. The error indicator is never changed by this function.

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
New in version 3.10.

int PySignal_SetWakeupFd(int fd)
This utility function specifies a file descriptor to which the signal number is written as a single byte whenever a signal is received. fd must be non-blocking. It returns the previous such file descriptor.

The value -1 disables the feature; this is the initial state. This is equivalent to signal.set_wakeup_fd() in Python, but without any error checking. fd should be a valid file descriptor. The function should only be called from the main thread.

Changed in version 3.5: On Windows, the function now also supports socket handles.

Exception Classes
PyObject *PyErr_NewException(const char *name, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
This utility function creates and returns a new exception class. The name argument must be the name of the new exception, a C string of the form module.classname. The base and dict arguments are normally NULL. This creates a class object derived from Exception (accessible in C as PyExc_Exception).

The __module__ attribute of the new class is set to the first part (up to the last dot) of the name argument, and the class name is set to the last part (after the last dot). The base argument can be used to specify alternate base classes; it can either be only one class or a tuple of classes. The dict argument can be used to specify a dictionary of class variables and methods.

PyObject *PyErr_NewExceptionWithDoc(const char *name, const char *doc, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
Same as PyErr_NewException(), except that the new exception class can easily be given a docstring: If doc is non-NULL, it will be used as the docstring for the exception class.

New in version 3.2.

Exception Objects
PyObject *PyException_GetTraceback(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the traceback associated with the exception as a new reference, as accessible from Python through __traceback__. If there is no traceback associated, this returns NULL.

int PyException_SetTraceback(PyObject *ex, PyObject *tb)
Part of the Stable ABI.
Set the traceback associated with the exception to tb. Use Py_None to clear it.

PyObject *PyException_GetContext(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the context (another exception instance during whose handling ex was raised) associated with the exception as a new reference, as accessible from Python through __context__. If there is no context associated, this returns NULL.

void PyException_SetContext(PyObject *ex, PyObject *ctx)
Part of the Stable ABI.
Set the context associated with the exception to ctx. Use NULL to clear it. There is no type check to make sure that ctx is an exception instance. This steals a reference to ctx.

PyObject *PyException_GetCause(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the cause (either an exception instance, or None, set by raise ... from ...) associated with the exception as a new reference, as accessible from Python through __cause__.

void PyException_SetCause(PyObject *ex, PyObject *cause)
Part of the Stable ABI.
Set the cause associated with the exception to cause. Use NULL to clear it. There is no type check to make sure that cause is either an exception instance or None. This steals a reference to cause.

__suppress_context__ is implicitly set to True by this function.

Unicode Exception Objects
The following functions are used to create and modify Unicode exceptions from C.

PyObject *PyUnicodeDecodeError_Create(const char *encoding, const char *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference. Part of the Stable ABI.
Create a UnicodeDecodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

PyObject *PyUnicodeEncodeError_Create(const char *encoding, const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeEncodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeEncodeError, "sOnns", ...).

PyObject *PyUnicodeTranslateError_Create(const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeTranslateError object with the attributes object, length, start, end and reason. reason is a UTF-8 encoded string.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeTranslateError, "Onns", ...).

PyObject *PyUnicodeDecodeError_GetEncoding(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetEncoding(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the encoding attribute of the given exception object.

PyObject *PyUnicodeDecodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetObject(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the object attribute of the given exception object.

int PyUnicodeDecodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeEncodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeTranslateError_GetStart(PyObject *exc, Py_ssize_t *start)
Part of the Stable ABI.
Get the start attribute of the given exception object and place it into *start. start must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeEncodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeTranslateError_SetStart(PyObject *exc, Py_ssize_t start)
Part of the Stable ABI.
Set the start attribute of the given exception object to start. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeEncodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeTranslateError_GetEnd(PyObject *exc, Py_ssize_t *end)
Part of the Stable ABI.
Get the end attribute of the given exception object and place it into *end. end must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeEncodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeTranslateError_SetEnd(PyObject *exc, Py_ssize_t end)
Part of the Stable ABI.
Set the end attribute of the given exception object to end. Return 0 on success, -1 on failure.

PyObject *PyUnicodeDecodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetReason(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the reason attribute of the given exception object.

int PyUnicodeDecodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeEncodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeTranslateError_SetReason(PyObject *exc, const char *reason)
Part of the Stable ABI.
Set the reason attribute of the given exception object to reason. Return 0 on success, -1 on failure.

Recursion Control
These two functions provide a way to perform safe recursive calls at the C level, both in the core and in extension modules. They are needed if the recursive code does not necessarily invoke Python code (which tracks its recursion depth automatically). They are also not needed for tp_call implementations because the call protocol takes care of recursion handling.

int Py_EnterRecursiveCall(const char *where)
Part of the Stable ABI since version 3.9.
Marks a point where a recursive C-level call is about to be performed.

If USE_STACKCHECK is defined, this function checks if the OS stack overflowed using PyOS_CheckStack(). In this is the case, it sets a MemoryError and returns a nonzero value.

The function then checks if the recursion limit is reached. If this is the case, a RecursionError is set and a nonzero value is returned. Otherwise, zero is returned.

where should be a UTF-8 encoded string such as " in instance check" to be concatenated to the RecursionError message caused by the recursion depth limit.

Changed in version 3.9: This function is now also available in the limited API.

void Py_LeaveRecursiveCall(void)
Part of the Stable ABI since version 3.9.
Ends a Py_EnterRecursiveCall(). Must be called once for each successful invocation of Py_EnterRecursiveCall().

Changed in version 3.9: This function is now also available in the limited API.

Properly implementing tp_repr for container types requires special recursion handling. In addition to protecting the stack, tp_repr also needs to track objects to prevent cycles. The following two functions facilitate this functionality. Effectively, these are the C equivalent to reprlib.recursive_repr().

int Py_ReprEnter(PyObject *object)
Part of the Stable ABI.
Called at the beginning of the tp_repr implementation to detect cycles.

If the object has already been processed, the function returns a positive integer. In that case the tp_repr implementation should return a string object indicating a cycle. As examples, dict objects return {...} and list objects return [...].

The function will return a negative integer if the recursion limit is reached. In that case the tp_repr implementation should typically return NULL.

Otherwise, the function returns zero and the tp_repr implementation can continue normally.

void Py_ReprLeave(PyObject *object)
Part of the Stable ABI.
Ends a Py_ReprEnter(). Must be called once for each invocation of Py_ReprEnter() that returns zero.

Standard Exceptions
All standard Python exceptions are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_BaseException

BaseException

1

PyExc_Exception

Exception

1

PyExc_ArithmeticError

ArithmeticError

1

PyExc_AssertionError

AssertionError

PyExc_AttributeError

AttributeError

PyExc_BlockingIOError

BlockingIOError

PyExc_BrokenPipeError

BrokenPipeError

PyExc_BufferError

BufferError

PyExc_ChildProcessError

ChildProcessError

PyExc_ConnectionAbortedError

ConnectionAbortedError

PyExc_ConnectionError

ConnectionError

PyExc_ConnectionRefusedError

ConnectionRefusedError

PyExc_ConnectionResetError

ConnectionResetError

PyExc_EOFError

EOFError

PyExc_FileExistsError

FileExistsError

PyExc_FileNotFoundError

FileNotFoundError

PyExc_FloatingPointError

FloatingPointError

PyExc_GeneratorExit

GeneratorExit

PyExc_ImportError

ImportError

PyExc_IndentationError

IndentationError

PyExc_IndexError

IndexError

PyExc_InterruptedError

InterruptedError

PyExc_IsADirectoryError

IsADirectoryError

PyExc_KeyError

KeyError

PyExc_KeyboardInterrupt

KeyboardInterrupt

PyExc_LookupError

LookupError

1

PyExc_MemoryError

MemoryError

PyExc_ModuleNotFoundError

ModuleNotFoundError

PyExc_NameError

NameError

PyExc_NotADirectoryError

NotADirectoryError

PyExc_NotImplementedError

NotImplementedError

PyExc_OSError

OSError

1

PyExc_OverflowError

OverflowError

PyExc_PermissionError

PermissionError

PyExc_ProcessLookupError

ProcessLookupError

PyExc_RecursionError

RecursionError

PyExc_ReferenceError

ReferenceError

PyExc_RuntimeError

RuntimeError

PyExc_StopAsyncIteration

StopAsyncIteration

PyExc_StopIteration

StopIteration

PyExc_SyntaxError

SyntaxError

PyExc_SystemError

SystemError

PyExc_SystemExit

SystemExit

PyExc_TabError

TabError

PyExc_TimeoutError

TimeoutError

PyExc_TypeError

TypeError

PyExc_UnboundLocalError

UnboundLocalError

PyExc_UnicodeDecodeError

UnicodeDecodeError

PyExc_UnicodeEncodeError

UnicodeEncodeError

PyExc_UnicodeError

UnicodeError

PyExc_UnicodeTranslateError

UnicodeTranslateError

PyExc_ValueError

ValueError

PyExc_ZeroDivisionError

ZeroDivisionError

New in version 3.3: PyExc_BlockingIOError, PyExc_BrokenPipeError, PyExc_ChildProcessError, PyExc_ConnectionError, PyExc_ConnectionAbortedError, PyExc_ConnectionRefusedError, PyExc_ConnectionResetError, PyExc_FileExistsError, PyExc_FileNotFoundError, PyExc_InterruptedError, PyExc_IsADirectoryError, PyExc_NotADirectoryError, PyExc_PermissionError, PyExc_ProcessLookupError and PyExc_TimeoutError were introduced following PEP 3151.

New in version 3.5: PyExc_StopAsyncIteration and PyExc_RecursionError.

New in version 3.6: PyExc_ModuleNotFoundError.

These are compatibility aliases to PyExc_OSError:

C Name

Notes

PyExc_EnvironmentError

PyExc_IOError

PyExc_WindowsError

2

Changed in version 3.3: These aliases used to be separate exception types.

Notes:

1(1,2,3,4,5)
This is a base class for other standard exceptions.

2
Only defined on Windows; protect code that uses this by testing that the preprocessor macro MS_WINDOWS is defined.

Standard Warning Categories
All standard Python warning categories are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_Warning

Warning

3

PyExc_BytesWarning

BytesWarning

PyExc_DeprecationWarning

DeprecationWarning

PyExc_FutureWarning

FutureWarning

PyExc_ImportWarning

ImportWarning

PyExc_PendingDeprecationWarning

PendingDeprecationWarning

PyExc_ResourceWarning

ResourceWarning

PyExc_RuntimeWarning

RuntimeWarning

PyExc_SyntaxWarning

SyntaxWarning

PyExc_UnicodeWarning

UnicodeWarning

PyExc_UserWarning

UserWarning

New in version 3.2: PyExc_ResourceWarning.

Notes:

3
This is a base class for other standard warning categories.

Table of Contents
Exception Handling
Printing and clearing
Raising exceptions
Issuing warnings
Querying the error indicator
Signal Handling
Exception Classes
Exception Objects
Unicode Exception Objects
Recursion Control
Standard Exceptions
Standard Warning Categories
Previous topic
Reference Counting

Next topic
Utilities

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
Exception Handling
The functions described in this chapter will let you handle and raise Python exceptions. It is important to understand some of the basics of Python exception handling. It works somewhat like the POSIX errno variable: there is a global indicator (per thread) of the last error that occurred. Most C API functions don’t clear this on success, but will set it to indicate the cause of the error on failure. Most C API functions also return an error indicator, usually NULL if they are supposed to return a pointer, or -1 if they return an integer (exception: the PyArg_* functions return 1 for success and 0 for failure).

Concretely, the error indicator consists of three object pointers: the exception’s type, the exception’s value, and the traceback object. Any of those pointers can be NULL if non-set (although some combinations are forbidden, for example you can’t have a non-NULL traceback if the exception type is NULL).

When a function must fail because some function it called failed, it generally doesn’t set the error indicator; the function it called already set it. It is responsible for either handling the error and clearing the exception or returning after cleaning up any resources it holds (such as object references or memory allocations); it should not continue normally if it is not prepared to handle the error. If returning due to an error, it is important to indicate to the caller that an error has been set. If the error is not handled or carefully propagated, additional calls into the Python/C API may not behave as intended and may fail in mysterious ways.

Note The error indicator is not the result of sys.exc_info(). The former corresponds to an exception that is not yet caught (and is therefore still propagating), while the latter returns an exception after it is caught (and has therefore stopped propagating).
Printing and clearing
void PyErr_Clear()
Part of the Stable ABI.
Clear the error indicator. If the error indicator is not set, there is no effect.

void PyErr_PrintEx(int set_sys_last_vars)
Part of the Stable ABI.
Print a standard traceback to sys.stderr and clear the error indicator. Unless the error is a SystemExit, in that case no traceback is printed and the Python process will exit with the error code specified by the SystemExit instance.

Call this function only when the error indicator is set. Otherwise it will cause a fatal error!

If set_sys_last_vars is nonzero, the variables sys.last_type, sys.last_value and sys.last_traceback will be set to the type, value and traceback of the printed exception, respectively.

void PyErr_Print()
Part of the Stable ABI.
Alias for PyErr_PrintEx(1).

void PyErr_WriteUnraisable(PyObject *obj)
Part of the Stable ABI.
Call sys.unraisablehook() using the current exception and obj argument.

This utility function prints a warning message to sys.stderr when an exception has been set but it is impossible for the interpreter to actually raise the exception. It is used, for example, when an exception occurs in an __del__() method.

The function is called with a single argument obj that identifies the context in which the unraisable exception occurred. If possible, the repr of obj will be printed in the warning message.

An exception must be set when calling this function.

Raising exceptions
These functions help you set the current thread’s error indicator. For convenience, some of these functions will always return a NULL pointer for use in a return statement.

void PyErr_SetString(PyObject *type, const char *message)
Part of the Stable ABI.
This is the most common way to set the error indicator. The first argument specifies the exception type; it is normally one of the standard exceptions, e.g. PyExc_RuntimeError. You need not increment its reference count. The second argument is an error message; it is decoded from 'utf-8'.

void PyErr_SetObject(PyObject *type, PyObject *value)
Part of the Stable ABI.
This function is similar to PyErr_SetString() but lets you specify an arbitrary Python object for the “value” of the exception.

PyObject *PyErr_Format(PyObject *exception, const char *format, ...)
Return value: Always NULL. Part of the Stable ABI.
This function sets the error indicator and returns NULL. exception should be a Python exception class. The format and subsequent parameters help format the error message; they have the same meaning and values as in PyUnicode_FromFormat(). format is an ASCII-encoded string.

PyObject *PyErr_FormatV(PyObject *exception, const char *format, va_list vargs)
Return value: Always NULL. Part of the Stable ABI since version 3.5.
Same as PyErr_Format(), but taking a va_list argument rather than a variable number of arguments.

New in version 3.5.

void PyErr_SetNone(PyObject *type)
Part of the Stable ABI.
This is a shorthand for PyErr_SetObject(type, Py_None).

int PyErr_BadArgument()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_TypeError, message), where message indicates that a built-in operation was invoked with an illegal argument. It is mostly for internal use.

PyObject *PyErr_NoMemory()
Return value: Always NULL. Part of the Stable ABI.
This is a shorthand for PyErr_SetNone(PyExc_MemoryError); it returns NULL so an object allocation function can write return PyErr_NoMemory(); when it runs out of memory.

PyObject *PyErr_SetFromErrno(PyObject *type)
Return value: Always NULL. Part of the Stable ABI.
This is a convenience function to raise an exception when a C library function has returned an error and set the C variable errno. It constructs a tuple object whose first item is the integer errno value and whose second item is the corresponding error message (gotten from strerror()), and then calls PyErr_SetObject(type, object). On Unix, when the errno value is EINTR, indicating an interrupted system call, this calls PyErr_CheckSignals(), and if that set the error indicator, leaves it set to that. The function always returns NULL, so a wrapper function around a system call can write return PyErr_SetFromErrno(type); when the system call returns an error.

PyObject *PyErr_SetFromErrnoWithFilenameObject(PyObject *type, PyObject *filenameObject)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrno(), with the additional behavior that if filenameObject is not NULL, it is passed to the constructor of type as a third parameter. In the case of OSError exception, this is used to define the filename attribute of the exception instance.

PyObject *PyErr_SetFromErrnoWithFilenameObjects(PyObject *type, PyObject *filenameObject, PyObject *filenameObject2)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but takes a second filename object, for raising errors when a function that takes two filenames fails.

New in version 3.4.

PyObject *PyErr_SetFromErrnoWithFilename(PyObject *type, const char *filename)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding and error handler.

PyObject *PyErr_SetFromWindowsErr(int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
This is a convenience function to raise WindowsError. If called with ierr of 0, the error code returned by a call to GetLastError() is used instead. It calls the Win32 function FormatMessage() to retrieve the Windows description of error code given by ierr or GetLastError(), then it constructs a tuple object whose first item is the ierr value and whose second item is the corresponding error message (gotten from FormatMessage()), and then calls PyErr_SetObject(PyExc_WindowsError, object). This function always returns NULL.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErr(PyObject *type, int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErr(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetFromWindowsErrWithFilename(int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding (os.fsdecode()).

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObject(PyObject *type, int ierr, PyObject *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObjects(PyObject *type, int ierr, PyObject *filename, PyObject *filename2)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetExcFromWindowsErrWithFilenameObject(), but accepts a second filename object.

Availability: Windows.

New in version 3.4.

PyObject *PyErr_SetExcFromWindowsErrWithFilename(PyObject *type, int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilename(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetImportError(PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
This is a convenience function to raise ImportError. msg will be set as the exception’s message string. name and path, both of which can be NULL, will be set as the ImportError’s respective name and path attributes.

New in version 3.3.

PyObject *PyErr_SetImportErrorSubclass(PyObject *exception, PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.6.
Much like PyErr_SetImportError() but this function allows for specifying a subclass of ImportError to raise.

New in version 3.6.

void PyErr_SyntaxLocationObject(PyObject *filename, int lineno, int col_offset)
Set file, line, and offset information for the current exception. If the current exception is not a SyntaxError, then it sets additional attributes, which make the exception printing subsystem think the exception is a SyntaxError.

New in version 3.4.

void PyErr_SyntaxLocationEx(const char *filename, int lineno, int col_offset)
Part of the Stable ABI since version 3.7.
Like PyErr_SyntaxLocationObject(), but filename is a byte string decoded from the filesystem encoding and error handler.

New in version 3.2.

void PyErr_SyntaxLocation(const char *filename, int lineno)
Part of the Stable ABI.
Like PyErr_SyntaxLocationEx(), but the col_offset parameter is omitted.

void PyErr_BadInternalCall()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_SystemError, message), where message indicates that an internal operation (e.g. a Python/C API function) was invoked with an illegal argument. It is mostly for internal use.

Issuing warnings
Use these functions to issue warnings from C code. They mirror similar functions exported by the Python warnings module. They normally print a warning message to sys.stderr; however, it is also possible that the user has specified that warnings are to be turned into errors, and in that case they will raise an exception. It is also possible that the functions raise an exception because of a problem with the warning machinery. The return value is 0 if no exception is raised, or -1 if an exception is raised. (It is not possible to determine whether a warning message is actually printed, nor what the reason is for the exception; this is intentional.) If an exception is raised, the caller should do its normal exception handling (for example, Py_DECREF() owned references and return an error value).

int PyErr_WarnEx(PyObject *category, const char *message, Py_ssize_t stack_level)
Part of the Stable ABI.
Issue a warning message. The category argument is a warning category (see below) or NULL; the message argument is a UTF-8 encoded string. stack_level is a positive number giving a number of stack frames; the warning will be issued from the currently executing line of code in that stack frame. A stack_level of 1 is the function calling PyErr_WarnEx(), 2 is the function above that, and so forth.

Warning categories must be subclasses of PyExc_Warning; PyExc_Warning is a subclass of PyExc_Exception; the default warning category is PyExc_RuntimeWarning. The standard Python warning categories are available as global variables whose names are enumerated at Standard Warning Categories.

For information about warning control, see the documentation for the warnings module and the -W option in the command line documentation. There is no C API for warning control.

int PyErr_WarnExplicitObject(PyObject *category, PyObject *message, PyObject *filename, int lineno, PyObject *module, PyObject *registry)
Issue a warning message with explicit control over all warning attributes. This is a straightforward wrapper around the Python function warnings.warn_explicit(); see there for more information. The module and registry arguments may be set to NULL to get the default effect described there.

New in version 3.4.

int PyErr_WarnExplicit(PyObject *category, const char *message, const char *filename, int lineno, const char *module, PyObject *registry)
Part of the Stable ABI.
Similar to PyErr_WarnExplicitObject() except that message and module are UTF-8 encoded strings, and filename is decoded from the filesystem encoding and error handler.

int PyErr_WarnFormat(PyObject *category, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI.
Function similar to PyErr_WarnEx(), but use PyUnicode_FromFormat() to format the warning message. format is an ASCII-encoded string.

New in version 3.2.

int PyErr_ResourceWarning(PyObject *source, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI since version 3.6.
Function similar to PyErr_WarnFormat(), but category is ResourceWarning and it passes source to warnings.WarningMessage().

New in version 3.6.

Querying the error indicator
PyObject *PyErr_Occurred()
Return value: Borrowed reference. Part of the Stable ABI.
Test whether the error indicator is set. If set, return the exception type (the first argument to the last call to one of the PyErr_Set* functions or to PyErr_Restore()). If not set, return NULL. You do not own a reference to the return value, so you do not need to Py_DECREF() it.

The caller must hold the GIL.

Note Do not compare the return value to a specific exception; use PyErr_ExceptionMatches() instead, shown below. (The comparison could easily fail since the exception may be an instance instead of a class, in the case of a class exception, or it may be a subclass of the expected exception.)
int PyErr_ExceptionMatches(PyObject *exc)
Part of the Stable ABI.
Equivalent to PyErr_GivenExceptionMatches(PyErr_Occurred(), exc). This should only be called when an exception is actually set; a memory access violation will occur if no exception has been raised.

int PyErr_GivenExceptionMatches(PyObject *given, PyObject *exc)
Part of the Stable ABI.
Return true if the given exception matches the exception type in exc. If exc is a class object, this also returns true when given is an instance of a subclass. If exc is a tuple, all exception types in the tuple (and recursively in subtuples) are searched for a match.

void PyErr_Fetch(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI.
Retrieve the error indicator into three variables whose addresses are passed. If the error indicator is not set, set all three variables to NULL. If it is set, it will be cleared and you own a reference to each object retrieved. The value and traceback object may be NULL even when the type object is not.

Note This function is normally only used by code that needs to catch exceptions or by code that needs to save and restore the error indicator temporarily, e.g.:
{
   PyObject *type, *value, *traceback;
   PyErr_Fetch(&type, &value, &traceback);

   /* ... code that might produce other errors ... */

   PyErr_Restore(type, value, traceback);
}
void PyErr_Restore(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI.
Set the error indicator from the three objects. If the error indicator is already set, it is cleared first. If the objects are NULL, the error indicator is cleared. Do not pass a NULL type and non-NULL value or traceback. The exception type should be a class. Do not pass an invalid exception type or value. (Violating these rules will cause subtle problems later.) This call takes away a reference to each object: you must own a reference to each object before the call and after the call you no longer own these references. (If you don’t understand this, don’t use this function. I warned you.)

Note This function is normally only used by code that needs to save and restore the error indicator temporarily. Use PyErr_Fetch() to save the current error indicator.
void PyErr_NormalizeException(PyObject **exc, PyObject **val, PyObject **tb)
Part of the Stable ABI.
Under certain circumstances, the values returned by PyErr_Fetch() below can be “unnormalized”, meaning that *exc is a class object but *val is not an instance of the same class. This function can be used to instantiate the class in that case. If the values are already normalized, nothing happens. The delayed normalization is implemented to improve performance.

Note This function does not implicitly set the __traceback__ attribute on the exception value. If setting the traceback appropriately is desired, the following additional snippet is needed:
if (tb != NULL) {
  PyException_SetTraceback(val, tb);
}
void PyErr_GetExcInfo(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI since version 3.7.
Retrieve the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. Returns new references for the three objects, any of which may be NULL. Does not modify the exception info state.

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_SetExcInfo() to restore or clear the exception state.
New in version 3.3.

void PyErr_SetExcInfo(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI since version 3.7.
Set the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. This function steals the references of the arguments. To clear the exception state, pass NULL for all three arguments. For general rules about the three arguments, see PyErr_Restore().

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_GetExcInfo() to read the exception state.
New in version 3.3.

Signal Handling
int PyErr_CheckSignals()
Part of the Stable ABI.
This function interacts with Python’s signal handling.

If the function is called from the main thread and under the main Python interpreter, it checks whether a signal has been sent to the processes and if so, invokes the corresponding signal handler. If the signal module is supported, this can invoke a signal handler written in Python.

The function attempts to handle all pending signals, and then returns 0. However, if a Python signal handler raises an exception, the error indicator is set and the function returns -1 immediately (such that other pending signals may not have been handled yet: they will be on the next PyErr_CheckSignals() invocation).

If the function is called from a non-main thread, or under a non-main Python interpreter, it does nothing and returns 0.

This function can be called by long-running C code that wants to be interruptible by user requests (such as by pressing Ctrl-C).

Note The default Python signal handler for SIGINT raises the KeyboardInterrupt exception.
void PyErr_SetInterrupt()
Part of the Stable ABI.
Simulate the effect of a SIGINT signal arriving. This is equivalent to PyErr_SetInterruptEx(SIGINT).

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
int PyErr_SetInterruptEx(int signum)
Part of the Stable ABI since version 3.10.
Simulate the effect of a signal arriving. The next time PyErr_CheckSignals() is called, the Python signal handler for the given signal number will be called.

This function can be called by C code that sets up its own signal handling and wants Python signal handlers to be invoked as expected when an interruption is requested (for example when the user presses Ctrl-C to interrupt an operation).

If the given signal isn’t handled by Python (it was set to signal.SIG_DFL or signal.SIG_IGN), it will be ignored.

If signum is outside of the allowed range of signal numbers, -1 is returned. Otherwise, 0 is returned. The error indicator is never changed by this function.

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
New in version 3.10.

int PySignal_SetWakeupFd(int fd)
This utility function specifies a file descriptor to which the signal number is written as a single byte whenever a signal is received. fd must be non-blocking. It returns the previous such file descriptor.

The value -1 disables the feature; this is the initial state. This is equivalent to signal.set_wakeup_fd() in Python, but without any error checking. fd should be a valid file descriptor. The function should only be called from the main thread.

Changed in version 3.5: On Windows, the function now also supports socket handles.

Exception Classes
PyObject *PyErr_NewException(const char *name, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
This utility function creates and returns a new exception class. The name argument must be the name of the new exception, a C string of the form module.classname. The base and dict arguments are normally NULL. This creates a class object derived from Exception (accessible in C as PyExc_Exception).

The __module__ attribute of the new class is set to the first part (up to the last dot) of the name argument, and the class name is set to the last part (after the last dot). The base argument can be used to specify alternate base classes; it can either be only one class or a tuple of classes. The dict argument can be used to specify a dictionary of class variables and methods.

PyObject *PyErr_NewExceptionWithDoc(const char *name, const char *doc, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
Same as PyErr_NewException(), except that the new exception class can easily be given a docstring: If doc is non-NULL, it will be used as the docstring for the exception class.

New in version 3.2.

Exception Objects
PyObject *PyException_GetTraceback(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the traceback associated with the exception as a new reference, as accessible from Python through __traceback__. If there is no traceback associated, this returns NULL.

int PyException_SetTraceback(PyObject *ex, PyObject *tb)
Part of the Stable ABI.
Set the traceback associated with the exception to tb. Use Py_None to clear it.

PyObject *PyException_GetContext(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the context (another exception instance during whose handling ex was raised) associated with the exception as a new reference, as accessible from Python through __context__. If there is no context associated, this returns NULL.

void PyException_SetContext(PyObject *ex, PyObject *ctx)
Part of the Stable ABI.
Set the context associated with the exception to ctx. Use NULL to clear it. There is no type check to make sure that ctx is an exception instance. This steals a reference to ctx.

PyObject *PyException_GetCause(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the cause (either an exception instance, or None, set by raise ... from ...) associated with the exception as a new reference, as accessible from Python through __cause__.

void PyException_SetCause(PyObject *ex, PyObject *cause)
Part of the Stable ABI.
Set the cause associated with the exception to cause. Use NULL to clear it. There is no type check to make sure that cause is either an exception instance or None. This steals a reference to cause.

__suppress_context__ is implicitly set to True by this function.

Unicode Exception Objects
The following functions are used to create and modify Unicode exceptions from C.

PyObject *PyUnicodeDecodeError_Create(const char *encoding, const char *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference. Part of the Stable ABI.
Create a UnicodeDecodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

PyObject *PyUnicodeEncodeError_Create(const char *encoding, const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeEncodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeEncodeError, "sOnns", ...).

PyObject *PyUnicodeTranslateError_Create(const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeTranslateError object with the attributes object, length, start, end and reason. reason is a UTF-8 encoded string.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeTranslateError, "Onns", ...).

PyObject *PyUnicodeDecodeError_GetEncoding(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetEncoding(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the encoding attribute of the given exception object.

PyObject *PyUnicodeDecodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetObject(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the object attribute of the given exception object.

int PyUnicodeDecodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeEncodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeTranslateError_GetStart(PyObject *exc, Py_ssize_t *start)
Part of the Stable ABI.
Get the start attribute of the given exception object and place it into *start. start must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeEncodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeTranslateError_SetStart(PyObject *exc, Py_ssize_t start)
Part of the Stable ABI.
Set the start attribute of the given exception object to start. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeEncodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeTranslateError_GetEnd(PyObject *exc, Py_ssize_t *end)
Part of the Stable ABI.
Get the end attribute of the given exception object and place it into *end. end must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeEncodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeTranslateError_SetEnd(PyObject *exc, Py_ssize_t end)
Part of the Stable ABI.
Set the end attribute of the given exception object to end. Return 0 on success, -1 on failure.

PyObject *PyUnicodeDecodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetReason(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the reason attribute of the given exception object.

int PyUnicodeDecodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeEncodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeTranslateError_SetReason(PyObject *exc, const char *reason)
Part of the Stable ABI.
Set the reason attribute of the given exception object to reason. Return 0 on success, -1 on failure.

Recursion Control
These two functions provide a way to perform safe recursive calls at the C level, both in the core and in extension modules. They are needed if the recursive code does not necessarily invoke Python code (which tracks its recursion depth automatically). They are also not needed for tp_call implementations because the call protocol takes care of recursion handling.

int Py_EnterRecursiveCall(const char *where)
Part of the Stable ABI since version 3.9.
Marks a point where a recursive C-level call is about to be performed.

If USE_STACKCHECK is defined, this function checks if the OS stack overflowed using PyOS_CheckStack(). In this is the case, it sets a MemoryError and returns a nonzero value.

The function then checks if the recursion limit is reached. If this is the case, a RecursionError is set and a nonzero value is returned. Otherwise, zero is returned.

where should be a UTF-8 encoded string such as " in instance check" to be concatenated to the RecursionError message caused by the recursion depth limit.

Changed in version 3.9: This function is now also available in the limited API.

void Py_LeaveRecursiveCall(void)
Part of the Stable ABI since version 3.9.
Ends a Py_EnterRecursiveCall(). Must be called once for each successful invocation of Py_EnterRecursiveCall().

Changed in version 3.9: This function is now also available in the limited API.

Properly implementing tp_repr for container types requires special recursion handling. In addition to protecting the stack, tp_repr also needs to track objects to prevent cycles. The following two functions facilitate this functionality. Effectively, these are the C equivalent to reprlib.recursive_repr().

int Py_ReprEnter(PyObject *object)
Part of the Stable ABI.
Called at the beginning of the tp_repr implementation to detect cycles.

If the object has already been processed, the function returns a positive integer. In that case the tp_repr implementation should return a string object indicating a cycle. As examples, dict objects return {...} and list objects return [...].

The function will return a negative integer if the recursion limit is reached. In that case the tp_repr implementation should typically return NULL.

Otherwise, the function returns zero and the tp_repr implementation can continue normally.

void Py_ReprLeave(PyObject *object)
Part of the Stable ABI.
Ends a Py_ReprEnter(). Must be called once for each invocation of Py_ReprEnter() that returns zero.

Standard Exceptions
All standard Python exceptions are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_BaseException

BaseException

1

PyExc_Exception

Exception

1

PyExc_ArithmeticError

ArithmeticError

1

PyExc_AssertionError

AssertionError

PyExc_AttributeError

AttributeError

PyExc_BlockingIOError

BlockingIOError

PyExc_BrokenPipeError

BrokenPipeError

PyExc_BufferError

BufferError

PyExc_ChildProcessError

ChildProcessError

PyExc_ConnectionAbortedError

ConnectionAbortedError

PyExc_ConnectionError

ConnectionError

PyExc_ConnectionRefusedError

ConnectionRefusedError

PyExc_ConnectionResetError

ConnectionResetError

PyExc_EOFError

EOFError

PyExc_FileExistsError

FileExistsError

PyExc_FileNotFoundError

FileNotFoundError

PyExc_FloatingPointError

FloatingPointError

PyExc_GeneratorExit

GeneratorExit

PyExc_ImportError

ImportError

PyExc_IndentationError

IndentationError

PyExc_IndexError

IndexError

PyExc_InterruptedError

InterruptedError

PyExc_IsADirectoryError

IsADirectoryError

PyExc_KeyError

KeyError

PyExc_KeyboardInterrupt

KeyboardInterrupt

PyExc_LookupError

LookupError

1

PyExc_MemoryError

MemoryError

PyExc_ModuleNotFoundError

ModuleNotFoundError

PyExc_NameError

NameError

PyExc_NotADirectoryError

NotADirectoryError

PyExc_NotImplementedError

NotImplementedError

PyExc_OSError

OSError

1

PyExc_OverflowError

OverflowError

PyExc_PermissionError

PermissionError

PyExc_ProcessLookupError

ProcessLookupError

PyExc_RecursionError

RecursionError

PyExc_ReferenceError

ReferenceError

PyExc_RuntimeError

RuntimeError

PyExc_StopAsyncIteration

StopAsyncIteration

PyExc_StopIteration

StopIteration

PyExc_SyntaxError

SyntaxError

PyExc_SystemError

SystemError

PyExc_SystemExit

SystemExit

PyExc_TabError

TabError

PyExc_TimeoutError

TimeoutError

PyExc_TypeError

TypeError

PyExc_UnboundLocalError

UnboundLocalError

PyExc_UnicodeDecodeError

UnicodeDecodeError

PyExc_UnicodeEncodeError

UnicodeEncodeError

PyExc_UnicodeError

UnicodeError

PyExc_UnicodeTranslateError

UnicodeTranslateError

PyExc_ValueError

ValueError

PyExc_ZeroDivisionError

ZeroDivisionError

New in version 3.3: PyExc_BlockingIOError, PyExc_BrokenPipeError, PyExc_ChildProcessError, PyExc_ConnectionError, PyExc_ConnectionAbortedError, PyExc_ConnectionRefusedError, PyExc_ConnectionResetError, PyExc_FileExistsError, PyExc_FileNotFoundError, PyExc_InterruptedError, PyExc_IsADirectoryError, PyExc_NotADirectoryError, PyExc_PermissionError, PyExc_ProcessLookupError and PyExc_TimeoutError were introduced following PEP 3151.

New in version 3.5: PyExc_StopAsyncIteration and PyExc_RecursionError.

New in version 3.6: PyExc_ModuleNotFoundError.

These are compatibility aliases to PyExc_OSError:

C Name

Notes

PyExc_EnvironmentError

PyExc_IOError

PyExc_WindowsError

2

Changed in version 3.3: These aliases used to be separate exception types.

Notes:

1(1,2,3,4,5)
This is a base class for other standard exceptions.

2
Only defined on Windows; protect code that uses this by testing that the preprocessor macro MS_WINDOWS is defined.

Standard Warning Categories
All standard Python warning categories are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_Warning

Warning

3

PyExc_BytesWarning

BytesWarning

PyExc_DeprecationWarning

DeprecationWarning

PyExc_FutureWarning

FutureWarning

PyExc_ImportWarning

ImportWarning

PyExc_PendingDeprecationWarning

PendingDeprecationWarning

PyExc_ResourceWarning

ResourceWarning

PyExc_RuntimeWarning

RuntimeWarning

PyExc_SyntaxWarning

SyntaxWarning

PyExc_UnicodeWarning

UnicodeWarning

PyExc_UserWarning

UserWarning

New in version 3.2: PyExc_ResourceWarning.

Notes:

3
This is a base class for other standard warning categories.

Table of Contents
Exception Handling
Printing and clearing
Raising exceptions
Issuing warnings
Querying the error indicator
Signal Handling
Exception Classes
Exception Objects
Unicode Exception Objects
Recursion Control
Standard Exceptions
Standard Warning Categories
Previous topic
Reference Counting

Next topic
Utilities

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.

We use technology such as cookies on our site to collect and use personal data to personalise content and ads, to provide social media features and to analyse our traffic.

Manage Options
Agree and proceed
Powered by
UniConsent
60%

OFF

PRO SALE — Get 60% discount on Programiz PRO for a limited time. Claim Your Discount

9d : 19hrs : 48mins : 42s
Programiz
Courses
Tutorials
Examples

Search tutorials and examples
Learn Python Interactively
Python Introduction
Python Flow Control
Python Functions
Python Datatypes
Python Files
Python Object & Class
Python Advanced Topics
Python Date and time


Related Topics
Python Global, Local and Nonlocal variables
Python Keywords and Identifiers
Python Global Keyword
Python Exception Handling Using try, except and finally statement
Python Assert Statement
Python if...else Statement



List of Keywords in Python
This tutorial provides brief information on all keywords used in Python.

Keywords are the reserved words in Python. We cannot use a keyword as a variable name, function name or any other identifier.

Here's a list of all keywords in Python Programming

Keywords in Python programming language
False	await	else	import	pass
None	break	except	in	raise
True	class	finally	is	return
and	continue	for	lambda	try
as	def	from	nonlocal	while
assert	del	global	not	with
async	elif	if	or	yield
The above keywords may get altered in different versions of Python. Some extra might get added or some might be removed. You can always get the list of keywords in your current version by typing the following in the prompt.


>>> import keyword
>>> print(keyword.kwlist)
['False', 'None', 'True', 'and', 'as', 'assert', 'async', 'await', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
Description of Keywords in Python with examples
True, False
True and False are truth values in Python. They are the results of comparison operations or logical (Boolean) operations in Python. For example:


>>> 1 == 1
True
>>> 5 > 3
True
>>> True or False
True
>>> 10 <= 1
False
>>> 3 > 7
False
>>> True and False
False
Here we can see that the first three statements are true so the interpreter returns True and returns False for the remaining three statements. True and False in python is same as 1 and 0. This can be justified with the following example:

>>> True == 1
True
>>> False == 0
True
>>> True + True
2
None
None is a special constant in Python that represents the absence of a value or a null value.

It is an object of its own datatype, the NoneType. We cannot create multiple None objects but can assign it to variables. These variables will be equal to one another.


We must take special care that None does not imply False, 0 or any empty list, dictionary, string etc. For example:

>>> None == 0
False
>>> None == []
False
>>> None == False
False
>>> x = None
>>> y = None
>>> x == y
True
Void functions that do not return anything will return a None object automatically. None is also returned by functions in which the program flow does not encounter a return statement. For example:


def a_void_function():
    a = 1
    b = 2
    c = a + b

x = a_void_function()
print(x)
Output


None
This program has a function that does not return a value, although it does some operations inside. So when we print x, we get None which is returned automatically (implicitly). Similarly, here is another example:

def improper_return_function(a):
    if (a % 2) == 0:
        return True

x = improper_return_function(3)
print(x)
Output

None
Although this function has a return statement, it is not reached in every case. The function will return True only when the input is even.

If we give the function an odd number, None is returned implicitly.

and, or , not
and, or, not are the logical operators in Python. and will result into True only if both the operands are True. The truth table for and is given below:

Truth table for and
A	B	A and B
True	True	True
True	False	False
False	True	False
False	False	False
or will result into True if any of the operands is True. The truth table for or is given below:

Truth table for or
A	B	A or B
True	True	True
True	False	True
False	True	True
False	False	False
not operator is used to invert the truth value. The truth table for not is given below:

Truth tabel for not
A	not A
True	False
False	True
some example of their usage are given below

>>> True and False
False
>>> True or False
True
>>> not False
True
as
as is used to create an alias while importing a module. It means giving a different name (user-defined) to a module while importing it.

As for example, Python has a standard module called math. Suppose we want to calculate what cosine pi is using an alias. We can do it as follows using as:

>>> import math as myAlias
>>>myAlias.cos(myAlias.pi)
-1.0
Here we imported the math module by giving it the name myAlias. Now we can refer to the math module with this name. Using this name we calculated cos(pi) and got -1.0 as the answer.

assert
assert is used for debugging purposes.

While programming, sometimes we wish to know the internal state or check if our assumptions are true. assert helps us do this and find bugs more conveniently. assert is followed by a condition.

If the condition is true, nothing happens. But if the condition is false, AssertionError is raised. For example:

>>> a = 4
>>> assert a < 5
>>> assert a > 5
Traceback (most recent call last):
  File "<string>", line 301, in runcode
  File "<interactive input>", line 1, in <module>
AssertionError
For our better understanding, we can also provide a message to be printed with the AssertionError.

>>> a = 4
>>> assert a > 5, "The value of a is too small"
Traceback (most recent call last):
  File "<string>", line 301, in runcode
  File "<interactive input>", line 1, in <module>
AssertionError: The value of a is too small
At this point we can note that,

assert condition, message
is equivalent to,

if not condition:
    raise AssertionError(message)
async, await
The async and await keywords are provided by the asyncio library in Python. They are used to write concurrent code in Python. For example,

import asyncio

async def main():
    print('Hello')
    await asyncio.sleep(1)
    print('world')
To run the program, we use

asyncio.run(main())
In the above program, the async keyword specifies that the function will be executed asynchronously.

Here, first Hello is printed. The await keyword makes the program wait for 1 second. And then the world is printed.

break, continue
break and continue are used inside for and while loops to alter their normal behavior.

break will end the smallest loop it is in and control flows to the statement immediately below the loop. continue causes to end the current iteration of the loop, but not the whole loop.

This can be illustrated with the following two examples:

for i in range(1,11):
    if i == 5:
        break
    print(i)
Output

1
2
3
4
Here, the for loop intends to print numbers from 1 to 10. But the if condition is met when i is equal to 5 and we break from the loop. Thus, only the range 1 to 4 is printed.

for i in range(1,11):
    if i == 5:
        continue
    print(i)
Output

1
2
3
4
6
7
8
9
10
Here we use continue for the same program. So, when the condition is met, that iteration is skipped. But we do not exit the loop. Hence, all the values except 5 are printed out.

Learn more about Python break and continue statement.

class
class is used to define a new user-defined class in Python.

Class is a collection of related attributes and methods that try to represent a real-world situation. This idea of putting data and functions together in a class is central to the concept of object-oriented programming (OOP).

Classes can be defined anywhere in a program. But it is a good practice to define a single class in a module. Following is a sample usage:

class ExampleClass:
    def function1(parameters):
        …
    def function2(parameters):
        …
Learn more about Python Objects and Class.

def
def is used to define a user-defined function.

Function is a block of related statements, which together does some specific task. It helps us organize code into manageable chunks and also to do some repetitive task.

The usage of def is shown below:

def function_name(parameters):
    …
Learn more about Python functions.

del
del is used to delete the reference to an object. Everything is object in Python. We can delete a variable reference using del

>>> a = b = 5
>>> del a
>>> a
Traceback (most recent call last):
  File "<string>", line 301, in runcode
  File "<interactive input>", line 1, in <module>
NameError: name 'a' is not defined
>>> b
5
Here we can see that the reference of the variable a was deleted. So, it is no longer defined. But b still exists.

del is also used to delete items from a list or a dictionary:


>>> a = ['x','y','z']
>>> del a[1]
>>> a
['x', 'z']
if, else, elif
if, else, elif are used for conditional branching or decision making.

When we want to test some condition and execute a block only if the condition is true, then we use if and elif. elif is short for else if. else is the block which is executed if the condition is false. This will be clear with the following example:

def if_example(a):
    if a == 1:
        print('One')
    elif a == 2:
        print('Two')
    else:
        print('Something else')

if_example(2)
if_example(4)
if_example(1)
Output

Two
Something else
One
Here, the function checks the input number and prints the result if it is 1 or 2. Any input other than this will cause the else part of the code to execute.

Learn more about Python if and if...else Statement.

except, raise, try
except, raise, try are used with exceptions in Python.

Exceptions are basically errors that suggests something went wrong while executing our program. IOError, ValueError, ZeroDivisionError, ImportError, NameError, TypeError etc. are few examples of exception in Python. try...except blocks are used to catch exceptions in Python.

We can raise an exception explicitly with the raise keyword. Following is an example:

def reciprocal(num):
    try:
        r = 1/num
    except:
        print('Exception caught')
        return
    return r

print(reciprocal(10))
print(reciprocal(0))
Output

0.1
Exception caught
None
Here, the function reciprocal() returns the reciprocal of the input number.

When we enter 10, we get the normal output of 0.1. But when we input 0, a ZeroDivisionError is raised automatically.

This is caught by our try…except block and we return None. We could have also raised the ZeroDivisionError explicitly by checking the input and handled it elsewhere as follows:

if num == 0:
    raise ZeroDivisionError('cannot divide')
finally
finally is used with try…except block to close up resources or file streams.

Using finally ensures that the block of code inside it gets executed even if there is an unhandled exception. For example:

try:
    Try-block
except exception1:
    Exception1-block
except exception2:
    Exception2-block
else:
    Else-block
finally:
    Finally-block
Here if there is an exception in the Try-block, it is handled in the except or else block. But no matter in what order the execution flows, we can rest assured that the Finally-block is executed even if there is an error. This is useful in cleaning up the resources.

Learn more about exception handling in Python programming.

for
for is used for looping. Generally we use for when we know the number of times we want to loop.

In Python we can use it with any type of sequences like a list or a string. Here is an example in which for is used to traverse through a list of names:

names = ['John','Monica','Steven','Robin']
for i in names:
    print('Hello '+i)
Output

Hello John
Hello Monica
Hello Steven
Hello Robin
Learn more about Python for loop.

from, import
import keyword is used to import modules into the current namespace. from…import is used to import specific attributes or functions into the current namespace. For example:

import math
will import the math module. Now we can use the cos() function inside it as math.cos(). But if we wanted to import just the cos() function, this can done using from as

from math import cos
now we can use the function simply as cos(), no need to write math.cos().

Learn more on Python modules and import statement.

global
global is used to declare that a variable inside the function is global (outside the function).

If we need to read the value of a global variable, it is not necessary to define it as global. This is understood.

If we need to modify the value of a global variable inside a function, then we must declare it with global. Otherwise, a local variable with that name is created.

Following example will help us clarify this.

globvar = 10
def read1():
    print(globvar)
def write1():
    global globvar
    globvar = 5
def write2():
    globvar = 15

read1()
write1()
read1()
write2()
read1()
Output

10
5
5
Here, the read1() function is just reading the value of globvar. So, we do not need to declare it as global. But the write1() function is modifying the value, so we need to declare the variable as global.

We can see in our output that the modification did take place (10 is changed to 5). The write2() also tries to modify this value. But we have not declared it as global.

Hence, a new local variable globvar is created which is not visible outside this function. Although we modify this local variable to 15, the global variable remains unchanged. This is clearly visible in our output.

in
in is used to test if a sequence (list, tuple, string etc.) contains a value. It returns True if the value is present, else it returns False. For example:

>>> a = [1, 2, 3, 4, 5]
>>> 5 in a
True
>>> 10 in a
False
The secondary use of in is to traverse through a sequence in a for loop.

for i in 'hello':
    print(i)
Output

h
e
l
l
o
is
is is used in Python for testing object identity. While the == operator is used to test if two variables are equal or not, is is used to test if the two variables refer to the same object.

It returns True if the objects are identical and False if not.

>>> True is True
True
>>> False is False
True
>>> None is None
True
We know that there is only one instance of True, False and None in Python, so they are identical.

>>> [] == []
True
>>> [] is []
False
>>> {} == {}
True
>>> {} is {}
False
An empty list or dictionary is equal to another empty one. But they are not identical objects as they are located separately in memory. This is because list and dictionary are mutable (value can be changed).

>>> '' == ''
True
>>> '' is ''
True
>>> () == ()
True
>>> () is ()
True
Unlike list and dictionary, string and tuple are immutable (value cannot be altered once defined). Hence, two equal string or tuple are identical as well. They refer to the same memory location.

lambda
lambda is used to create an anonymous function (function with no name). It is an inline function that does not contain a return statement. It consists of an expression that is evaluated and returned. For example:

a = lambda x: x*2
for i in range(1,6):
    print(a(i))
Output

2
4
6
8
10
Here, we have created an inline function that doubles the value, using the lambda statement. We used this to double the values in a list containing 1 to 5.

Learn more about Python lamda function.

nonlocal
The use of nonlocal keyword is very much similar to the global keyword. nonlocal is used to declare that a variable inside a nested function (function inside a function) is not local to it, meaning it lies in the outer inclosing function. If we need to modify the value of a non-local variable inside a nested function, then we must declare it with nonlocal. Otherwise a local variable with that name is created inside the nested function. Following example will help us clarify this.

def outer_function():
    a = 5
    def inner_function():
        nonlocal a
        a = 10
        print("Inner function: ",a)
    inner_function()
    print("Outer function: ",a)

outer_function()
Output

Inner function:  10
Outer function:  10
Here, the inner_function() is nested within the outer_function.

The variable a is in the outer_function(). So, if we want to modify it in the inner_function(), we must declare it as nonlocal. Notice that a is not a global variable.

Hence, we see from the output that the variable was successfully modified inside the nested inner_function(). The result of not using the nonlocal keyword is as follows:

def outer_function():
    a = 5
    def inner_function():
        a = 10
        print("Inner function: ",a)
    inner_function()
    print("Outer function: ",a)

outer_function()
Output

Inner function:  10
Outer function:  5
Here, we do not declare that the variable a inside the nested function is nonlocal. Hence, a new local variable with the same name is created, but the non-local a is not modified as seen in our output.

pass
pass is a null statement in Python. Nothing happens when it is executed. It is used as a placeholder.

Suppose we have a function that is not implemented yet, but we want to implement it in the future. Simply writing,

def function(args):
in the middle of a program will give us IndentationError. Instead of this, we construct a blank body with the pass statement.

def function(args):
    pass
We can do the same thing in an empty class as well.

class example:
    pass
return
return statement is used inside a function to exit it and return a value.

If we do not return a value explicitly, None is returned automatically. This is verified with the following example.

def func_return():
    a = 10
    return a

def no_return():
    a = 10

print(func_return())
print(no_return())
Output

10
None
while
while is used for looping in Python.

The statements inside a while loop continue to execute until the condition for the while loop evaluates to False or a break statement is encountered. Following program illustrates this.

i = 5
while(i):
    print(i)
    i = i – 1
Output

5
4
3
2
1
Note that 0 is equal to False.

Learn more about Python while loop.

with
with statement is used to wrap the execution of a block of code within methods defined by the context manager.

Context manager is a class that implements __enter__ and __exit__ methods. Use of with statement ensures that the __exit__ method is called at the end of the nested block. This concept is similar to the use of try…finally block. Here, is an example.

with open('example.txt', 'w') as my_file:
    my_file.write('Hello world!')
This example writes the text Hello world! to the file example.txt. File objects have __enter__ and __exit__ method defined within them, so they act as their own context manager.

First the __enter__ method is called, then the code within with statement is executed and finally the __exit__ method is called. __exit__ method is called even if there is an error. It basically closes the file stream.

yield
yield is used inside a function like a return statement. But yield returns a generator.

Generator is an iterator that generates one item at a time. A large list of values will take up a lot of memory. Generators are useful in this situation as it generates only one value at a time instead of storing all the values in memory. For example,

>>> g = (2**x for x in range(100))
will create a generator g which generates powers of 2 up to the number two raised to the power 99. We can generate the numbers using the next() function as shown below.

>>> next(g)
1
>>> next(g)
2
>>> next(g)
4
>>> next(g)
8
>>> next(g)
16
And so on… This type of generator is returned by the yield statement from a function. Here is an example.

def generator():
    for i in range(6):
        yield i*i

g = generator()
for i in g:
    print(i)
Output

0
1
4
9
16
25
Here, the function generator() returns a generator that generates square of numbers from 0 to 5. This is printed in the for loop.

Share on:
Did you find this article helpful?
Related Tutorials
Python Tutorial

Python Keywords and Identifiers

Python Tutorial

Python Global, Local and Nonlocal variables

Python Tutorial

Python Global Keyword

Python Tutorial

Python Exception Handling Using try, except and finally statement


Learn Python Interactively



Join our newsletter for the latest updates.
Enter Email Address*
Join


Tutorials
Python 3 Tutorial
JavaScript Tutorial
SQL Tutorial
C Tutorial
Java Tutorial
Kotlin Tutorial
C++ Tutorial
Swift Tutorial
C# Tutorial
Go Tutorial
DSA Tutorial
Examples
Python Examples
JavaScript Examples
C Examples
Java Examples
Kotlin Examples
C++ Examples
Company
Change Consent
About
Advertising
Privacy Policy
Terms & Conditions
Contact
Blog
Youtube
Apps
Learn Python
Learn C Programming
Learn Java
© Parewa Labs Pvt. Ltd. All rights reserved.
Real Python
Start Here
 Learn Python 
More 
Search
Python Keywords: An Introduction
Python Keywords: An Introduction
by Chad Hansen 3 Comments  basics python
Tweet Share Email
Table of Contents

Python Keywords
How to Identify Python Keywords
Use an IDE With Syntax Highlighting
Use Code in a REPL to Check Keywords
Look for a SyntaxError
Python Keywords and Their Usage
Value Keywords: True, False, None
Operator Keywords: and, or, not, in, is
Control Flow Keywords: if, elif, else
Iteration Keywords: for, while, break, continue, else
Structure Keywords: def, class, with, as, pass, lambda
Returning Keywords: return, yield
Import Keywords: import, from, as
Exception-Handling Keywords: try, except, raise, finally, else, assert
Asynchronous Programming Keywords: async, await
Variable Handling Keywords: del, global, nonlocal
Deprecated Python Keywords
The Former print Keyword
The Former exec Keyword
Conclusion
Remove ads
 Watch Now This tutorial has a related video course created by the Real Python team. Watch it together with the written tutorial to deepen your understanding: Exploring Keywords in Python

Every programming language has special reserved words, or keywords, that have specific meanings and restrictions around how they should be used. Python is no different. Python keywords are the fundamental building blocks of any Python program.

In this article, you’ll find a basic introduction to all Python keywords along with other resources that will be helpful for learning more about each keyword.

By the end of this article, you’ll be able to:

Identify Python keywords
Understand what each keyword is used for
Work with keywords programmatically using the keyword module
Free Bonus: 5 Thoughts On Python Mastery, a free course for Python developers that shows you the roadmap and the mindset you’ll need to take your Python skills to the next level.

Python Keywords
Python keywords are special reserved words that have specific meanings and purposes and can’t be used for anything but those specific purposes. These keywords are always available—you’ll never have to import them into your code.

Python keywords are different from Python’s built-in functions and types. The built-in functions and types are also always available, but they aren’t as restrictive as the keywords in their usage.

An example of something you can’t do with Python keywords is assign something to them. If you try, then you’ll get a SyntaxError. You won’t get a SyntaxError if you try to assign something to a built-in function or type, but it still isn’t a good idea. For a more in-depth explanation of ways keywords can be misused, check out Invalid Syntax in Python: Common Reasons for SyntaxError.

As of Python 3.8, there are thirty-five keywords in Python. Here they are with links to the relevant sections throughout the rest of this article:

False	await	else	import	pass
None	break	except	in	raise
True	class	finally	is	return
and	continue	for	lambda	try
as	def	from	nonlocal	while
assert	del	global	not	with
async	elif	if	or	yield
You can use these links to jump to the keywords you’d like to read about, or you can continue reading for a guided tour.

Note: Two keywords have additional uses beyond their initial use cases. The else keyword is also used with loops as well as with try and except. The as keyword is also used with the with keyword.


Remove ads
How to Identify Python Keywords
The list of Python keywords has changed over time. For example, the await and async keywords weren’t added until Python 3.7. Also, both print and exec were keywords in Python 2.7 but have been turned into built-in functions in Python 3+ and no longer appear in the list of keywords.

In the sections below, you’ll learn several ways to know or find out which words are keywords in Python.

Use an IDE With Syntax Highlighting
There are a lot of good Python IDEs out there. All of them will highlight keywords to differentiate them from other words in your code. This will help you quickly identify Python keywords while you’re programming so you don’t use them incorrectly.

Use Code in a REPL to Check Keywords
In the Python REPL, there are a number of ways you can identify valid Python keywords and learn more about them.

Note: Code examples in this article use Python 3.8 unless otherwise indicated.

You can get a list of available keywords by using help():

>>> help("keywords")

Here is a list of the Python keywords.  Enter any keyword to get more help.

False               class               from                or
None                continue            global              pass
True                def                 if                  raise
and                 del                 import              return
as                  elif                in                  try
assert              else                is                  while
async               except              lambda              with
await               finally             nonlocal            yield
break               for                 not
Next, as indicated in the output above, you can use help() again by passing in the specific keyword that you need more information about. You can do this, for example, with the pass keyword:

>>> help("pass")
The "pass" statement
********************

   pass_stmt ::= "pass"

"pass" is a null operation — when it is executed, nothing happens. It
is useful as a placeholder when a statement is required syntactically,
but no code needs to be executed, for example:

   def f(arg): pass    # a function that does nothing (yet)

   class C: pass       # a class with no methods (yet)
Python also provides a keyword module for working with Python keywords in a programmatic way. The keyword module in Python provides two helpful members for dealing with keywords:

kwlist provides a list of all the Python keywords for the version of Python you’re running.
iskeyword() provides a handy way to determine if a string is also a keyword.
To get a list of all the keywords in the version of Python you’re running, and to quickly determine how many keywords are defined, use keyword.kwlist:

>>> import keyword
>>> keyword.kwlist
['False', 'None', 'True', 'and', 'as', 'assert', 'async', ...
>>> len(keyword.kwlist)
35
If you need to know more about a keyword or need to work with keywords in a programmatic way, then Python provides this documentation and tooling for you.

Look for a SyntaxError
Finally, another indicator that a word you’re using is actually a keyword is if you get a SyntaxError while trying to assign to it, name a function with it, or do something else that isn’t allowed with it. This one is a little harder to spot, but it’s a way that Python will let you know you’re using a keyword incorrectly.

Python Keywords and Their Usage
The sections below organize the Python keywords into groups based on their usage. For example, the first group is all the keywords that are used as values, and the second group is the keywords that are used as operators. These groupings will help you better understand how keywords are used and provide a nice way to organize the long list of Python keywords.

There are a few terms used in the sections below that may be new to you. They’re defined here, and you should be aware of their meaning before proceeding:

Truthiness refers to the Boolean evaluation of a value. The truthiness of a value indicates whether the value is truthy or falsy.

Truthy means any value that evaluates to true in the Boolean context. To determine if a value is truthy, pass it as the argument to bool(). If it returns True, then the value is truthy. Examples of truthy values are non-empty strings, any numbers that aren’t 0, non-empty lists, and many more.

Falsy means any value that evaluates to false in the Boolean context. To determine if a value is falsy, pass it as the argument to bool(). If it returns False, then the value is falsy. Examples of falsy values are "", 0, [], {}, and set().

For more on these terms and concepts, check out Operators and Expressions in Python.


Remove ads
Value Keywords: True, False, None
There are three Python keywords that are used as values. These values are singleton values that can be used over and over again and always reference the exact same object. You’ll most likely see and use these values a lot.

The True and False Keywords
The True keyword is used as the Boolean true value in Python code. The Python keyword False is similar to the True keyword, but with the opposite Boolean value of false. In other programming languages, you’ll see these keywords written in lowercase (true and false), but in Python they are always written in uppercase.

The Python keywords True and False can be assigned to variables and compared to directly:

>>> x = True
>>> x is True
True

>>> y = False
>>> y is False
True
Most values in Python will evaluate to True when passed to bool(). There are only a few values in Python that will evaluate to False when passed to bool(): 0, "", [], and {} to name a few. Passing a value to bool() indicates the value’s truthiness, or the equivalent Boolean value. You can compare a value’s truthiness to True or False by passing the value to bool():

>>> x = "this is a truthy value"
>>> x is True
False
>>> bool(x) is True
True

>>> y = ""  # This is falsy
>>> y is False
False
>>> bool(y) is False
True
Notice that comparing a truthy value directly to True or False using is doesn’t work. You should directly compare a value to True or False only if you want to know whether it is actually the values True or False.

When writing conditional statements that are based on the truthiness of a value, you should not compare directly to True or False. You can rely on Python to do the truthiness check in conditionals for you:

>>> x = "this is a truthy value"
>>> if x is True:  # Don't do this
...     print("x is True")
...
>>> if x:  # Do this
...     print("x is truthy")
...
x is truthy
In Python, you generally don’t need to convert values to be explicitly True or False. Python will implicitly determine the truthiness of the value for you.

The None Keyword
The Python keyword None represents no value. In other programming languages, None is represented as null, nil, none, undef, or undefined.

None is also the default value returned by a function if it doesn’t have a return statement:

>>> def func():
...     print("hello")
...
>>> x = func()
hello
>>> print(x)
None
To go more in depth on this very important and useful Python keyword, check out Null in Python: Understanding Python’s NoneType Object.

Operator Keywords: and, or, not, in, is
Several Python keywords are used as operators. In other programming languages, these operators use symbols like &, |, and !. The Python operators for these are all keywords:

Math Operator	Other Languages	Python Keyword
AND, ∧	&&	and
OR, ∨	||	or
NOT, ¬	!	not
CONTAINS, ∈		in
IDENTITY	===	is
Python code was designed for readability. That’s why many of the operators that use symbols in other programming languages are keywords in Python.

The and Keyword
The Python keyword and is used to determine if both the left and right operands are truthy or falsy. If both operands are truthy, then the result will be truthy. If one is falsy, then the result will be falsy:

<expr1> and <expr2>
Note that the results of an and statement will not necessarily be True or False. This is because of the quirky behavior of and. Rather than evaluating the operands to their Boolean values, and simply returns <expr1> if it is falsy or else it returns <expr2>. The results of an and statement could be passed to bool() to get the explicit True or False value, or they could be used in a conditional if statement.

If you wanted to define an expression that did the same thing as an and expression, but without using the and keyword, then you could use the Python ternary operator:

left if not left else right
The above statement will produce the same result as left and right.

Because and returns the first operand if it’s falsy and otherwise returns the last operand, you can also use and in an assignment:

x = y and z
If y is falsy, then this would result in x being assigned the value of y. Otherwise, x would be assigned the value of z. However, this makes for confusing code. A more verbose and clear alternative would be:

x = y if not y else z
This code is longer, but it more clearly indicates what you’re trying to accomplish.

The or Keyword
Python’s or keyword is used to determine if at least one of the operands is truthy. An or statement returns the first operand if it is truthy and otherwise returns the second operand:

<expr1> or <expr2>
Just like the and keyword, or doesn’t convert its operands to their Boolean values. Instead, it relies on their truthiness to determine the results.

If you wanted to write something like an or expression without the use of or, then you could do so with a ternary expression:

left if left else right
This expression will produce the same result as left or right. To take advantage of this behavior, you’ll also sometimes see or used in assignments. This is generally discouraged in favor of a more explicit assignment.

For a more in-depth look at or, you can read about how to use the Python or operator.

The not Keyword
Python’s not keyword is used to get the opposite Boolean value of a variable:

>>> val = ""  # Truthiness value is `False`
>>> not val
True

>>> val = 5  # Truthiness value is `True`
>>> not val
False
The not keyword is used in conditional statements or other Boolean expressions to flip the Boolean meaning or result. Unlike and and or, not will determine the explicit Boolean value, True or False, and then return the opposite.

If you wanted to get the same behavior without using not, then you could do so with the following ternary expression:

True if bool(<expr>) is False else False
This statement would return the same result as not <expr>.

The in Keyword
Python’s in keyword is a powerful containment check, or membership operator. Given an element to find and a container or sequence to search, in will return True or False indicating whether the element was found in the container:

<element> in <container>
A good example of using the in keyword is checking for a specific letter in a string:

>>> name = "Chad"
>>> "c" in name
False
>>> "C" in name
True
The in keyword works with all types of containers: lists, dicts, sets, strings, and anything else that defines __contains__() or can be iterated over.

The is Keyword
Python’s is keyword is an identity check. This is different from the == operator, which checks for equality. Sometimes two things can be considered equal but not be the exact same object in memory. The is keyword determines whether two objects are exactly the same object:

<obj1> is <obj2>
This will return True if <obj1> is the exact same object in memory as <obj2>, or else it will return False.

Most of the time you’ll see is used to check if an object is None. Since None is a singleton, only one instance of None that can exist, so all None values are the exact same object in memory.

If these concepts are new to you, then you can get a more in-depth explanation by checking out Python ‘!=’ Is Not ‘is not’: Comparing Objects in Python. For a deeper dive into how is works, check out Operators and Expressions in Python.


Remove ads
Control Flow Keywords: if, elif, else
Three Python keywords are used for control flow: if, elif, and else. These Python keywords allow you to use conditional logic and execute code given certain conditions. These keywords are very common—they’ll be used in almost every program you see or write in Python.

The if Keyword
The if keyword is used to start a conditional statement. An if statement allows you to write a block of code that gets executed only if the expression after if is truthy.

The syntax for an if statement starts with the keyword if at the beginning of the line, followed by a valid expression that will be evaluated for its truthiness value:

if <expr>:
    <statements>
The if statement is a crucial component of most programs. For more information about the if statement, check out Conditional Statements in Python.

Another use of the if keyword is as part of Python’s ternary operator:

<var> = <expr1> if <expr2> else <expr3>
This is a one-line version of the if...else statement below:

if <expr2>:
    <var> = <expr1>
else:
    <var> = <expr3>
If your expressions are uncomplicated statements, then using the ternary expression provides a nice way to simplify your code a bit. Once the conditions get a little complex, it’s often better to rely on the standard if statement.

The elif Keyword
The elif statement looks and functions like the if statement, with two major differences:

Using elif is only valid after an if statement or another elif.
You can use as many elif statements as you need.
In other programming languages, elif is either else if (two separate words) or elseif (both words mashed together). When you see elif in Python, think else if:

if <expr1>:
    <statements>
elif <expr2>:
    <statements>
elif <expr3>:
    <statements>
Python doesn’t have a switch statement. One way to get the same functionality that other programming languages provide with switch statements is by using if and elif. For other ways of reproducing the switch statement in Python, check out Emulating switch/case Statements in Python.

The else Keyword
The else statement, in conjunction with the Python keywords if and elif, denotes a block of code that should be executed only if the other conditional blocks, if and elif, are all falsy:

if <expr>:
    <statements>
else:
    <statements>
Notice that the else statement doesn’t take a conditional expression. Knowledge of the elif and else keywords and their proper usage is critical for Python programmers. Together with if, they make up some of the most frequently used components in any Python program.


Remove ads
Iteration Keywords: for, while, break, continue, else
Looping and iteration are hugely important programming concepts. Several Python keywords are used to create and work with loops. These, like the Python keywords used for conditionals above, will be used and seen in just about every Python program you come across. Understanding them and their proper usage will help you improve as a Python programmer.

The for Keyword
The most common loop in Python is the for loop. It’s constructed by combining the Python keywords for and in explained earlier. The basic syntax for a for loop is as follows:

for <element> in <container>:
    <statements>
A common example is looping over the numbers one through five and printing them to the screen:

>>> for num in range(1, 6):
...     print(num)
...
1
2
3
4
5
In other programming languages, the syntax for a for loop will look a little different. You’ll often need to specify the variable, the condition for continuing, and the way to increment that variable (for (int i = 0; i < 5; i++)).

In Python, the for loop is like a for-each loop in other programming languages. Given the object to iterate over, it assigns the value of each iteration to the variable:

>>> people = ["Kevin", "Creed", "Jim"]
>>> for person in people:
...     print(f"{person} was in The Office.")
...
Kevin was in The Office.
Creed was in The Office.
Jim was in The Office.
In this example, you start with the list (container) of people’s names. The for loop starts with the for keyword at the beginning of the line, followed by the variable to assign each element of the list to, then the in keyword, and finally the container (people).

Python’s for loop is another major ingredient in any Python program. To learn more about for loops, check out Python “for” Loops (Definite Iteration).

The while Keyword
Python’s while loop uses the keyword while and works like a while loop in other programming languages. As long as the condition that follows the while keyword is truthy, the block following the while statement will continue to be executed over and over again:

while <expr>:
    <statements>
Note: For the infinite loop example below, be prepared to use Ctrl+C to stop the process if you decide to try it on your own machine.

The easiest way to specify an infinite loop in Python is to use the while keyword with an expression that is always truthy:

>>> while True:
...     print("working...")
...
For more examples of infinite loops in action, check out Socket Programming in Python (Guide). To learn more about while loops, check out Python “while” Loops (Indefinite Iteration).

The break Keyword
If you need to exit a loop early, then you can use the break keyword. This keyword will work in both for and while loops:

for <element> in <container>:
    if <expr>:
        break
An example of using the break keyword would be if you were summing the integers in a list of numbers and wanted to quit when the total went above a given value:

>>> nums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>> total_sum = 0
>>> for num in nums:
...     total_sum += num
...     if total_sum > 10:
...         break
...
>>> total_sum
15
Both the Python keywords break and continue can be useful tools when working with loops. For a deeper discussion of their uses, check out Python “while” Loops (Indefinite Iteration). If you’d like to explore another use case for the break keyword, then you can learn how to emulate do-while loops in Python.

The continue Keyword
Python also has a continue keyword for when you want to skip to the next loop iteration. Like in most other programming languages, the continue keyword allows you to stop executing the current loop iteration and move on to the next iteration:

for <element> in <container>:
    if <expr>:
        continue
The continue keyword also works in while loops. If the continue keyword is reached in a loop, then the current iteration is stopped, and the next iteration of the loop is started.

The else Keyword Used With Loops
In addition to using the else keyword with conditional if statements, you can also use it as part of a loop. When used with a loop, the else keyword specifies code that should be run if the loop exits normally, meaning break was not called to exit the loop early.

The syntax for using else with a for loop looks like the following:

for <element> in <container>:
    <statements>
else:
    <statements>
This is very similar to using else with an if statement. Using else with a while loop looks similar:

while <expr>:
    <statements>
else:
    <statements>
The Python standard documentation has a section on using break and else with a for loop that you should really check out. It uses a great example to illustrate the usefulness of the else block.

The task it shows is looping over the numbers two through nine to find the prime numbers. One way you could do this is with a standard for loop with a flag variable:

>>> for n in range(2, 10):
...     prime = True
...     for x in range(2, n):
...         if n % x == 0:
...             prime = False
...             print(f"{n} is not prime")
...             break
...     if prime:
...         print(f"{n} is prime!")
...
2 is prime!
3 is prime!
4 is not prime
5 is prime!
6 is not prime
7 is prime!
8 is not prime
9 is not prime
You can use the prime flag to indicate how the loop was exited. If it exited normally, then the prime flag stays True. If it exited with break, then the prime flag will be set to False. Once outside the inner for loop, you can check the flag to determine if prime is True and, if so, print that the number is prime.

The else block provides more straightforward syntax. If you find yourself having to set a flag in a loop, then consider the next example as a way to potentially simplify your code:

>>> for n in range(2, 10):
...     for x in range(2, n):
...         if n % x == 0:
...             print(f"{n} is not prime")
...             break
...     else:
...         print(f"{n} is prime!")
...
2 is prime!
3 is prime!
4 is not prime
5 is prime!
6 is not prime
7 is prime!
8 is not prime
9 is not prime
The only thing that you need to do to use the else block in this example is to remove the prime flag and replace the final if statement with the else block. This ends up producing the same result as the example before, only with clearer code.

Sometimes using an else keyword with a loop can seem a little strange, but once you understand that it allows you to avoid using flags in your loops, it can be a powerful tool.


Remove ads
Structure Keywords: def, class, with, as, pass, lambda
In order to define functions and classes or use context managers, you’ll need to use one of the Python keywords in this section. They’re an essential part of the Python language, and understanding when to use them will help you become a better Python programmer.

The def Keyword
Python’s keyword def is used to define a function or method of a class. This is equivalent to function in JavaScript and PHP. The basic syntax for defining a function with def looks like this:

def <function>(<params>):
    <body>
Functions and methods can be very helpful structures in any Python program. To learn more about defining them and all their ins and outs, check out Defining Your Own Python Function.

The class Keyword
To define a class in Python, you use the class keyword. The general syntax for defining a class with class is as follows:

class MyClass(<extends>):
    <body>
Classes are powerful tools in object-oriented programming, and you should know about them and how to define them. To learn more, check out Object-Oriented Programming (OOP) in Python 3.

The with Keyword
Context managers are a really helpful structure in Python. Each context manager executes specific code before and after the statements you specify. To use one, you use the with keyword:

with <context manager> as <var>:
    <statements>
Using with gives you a way to define code to be executed within the context manager’s scope. The most basic example of this is when you’re working with file I/O in Python.

If you wanted to open a file, do something with that file, and then make sure that the file was closed correctly, then you would use a context manager. Consider this example in which names.txt contains a list of names, one per line:

>>> with open("names.txt") as input_file:
...    for name in input_file:
...        print(name.strip())
...
Jim
Pam
Cece
Philip
The file I/O context manager provided by open() and initiated with the with keyword opens the file for reading, assigns the open file pointer to input_file, then executes whatever code you specify in the with block. Then, after the block is executed, the file pointer closes. Even if your code in the with block raises an exception, the file pointer would still close.

For a great example of using with and context managers, check out Python Timer Functions: Three Ways to Monitor Your Code.

The as Keyword Used With with
If you want access to the results of the expression or context manager passed to with, you’ll need to alias it using as. You may have also seen as used to alias imports and exceptions, and this is no different. The alias is available in the with block:

with <expr> as <alias>:
    <statements>
Most of the time, you’ll see these two Python keywords, with and as, used together.

The pass Keyword
Since Python doesn’t have block indicators to specify the end of a block, the pass keyword is used to specify that the block is intentionally left blank. It’s the equivalent of a no-op, or no operation. Here are a few examples of using pass to specify that the block is blank:

def my_function():
    pass

class MyClass:
    pass

if True:
    pass
For more on pass, check out The pass Statement: How to Do Nothing in Python.

The lambda Keyword
The lambda keyword is used to define a function that doesn’t have a name and has only one statement, the results of which are returned. Functions defined with lambda are referred to as lambda functions:

lambda <args>: <statement>
A basic example of a lambda function that computes the argument raised to the power of 10 would look like this:

p10 = lambda x: x**10
This is equivalent to defining a function with def:

def p10(x):
    return x**10
One common use for a lambda function is specifying a different behavior for another function. For example, imagine you wanted to sort a list of strings by their integer values. The default behavior of sorted() would sort the strings alphabetically. But with sorted(), you can specify which key the list should be sorted on.

A lambda function provides a nice way to do so:

>>> ids = ["id1", "id2", "id30", "id3", "id20", "id10"]
>>> sorted(ids)
['id1', 'id10', 'id2', 'id20', 'id3', 'id30']

>>> sorted(ids, key=lambda x: int(x[2:]))
['id1', 'id2', 'id3', 'id10', 'id20', 'id30']
This example sorts the list based not on alphabetical order but on the numerical order of the last characters of the strings after converting them to integers. Without lambda, you would have had to define a function, give it a name, and then pass it to sorted(). lambda made this code cleaner.

For comparison, this is what the example above would look like without using lambda:

>>> def sort_by_int(x):
...     return int(x[2:])
...
>>> ids = ["id1", "id2", "id30", "id3", "id20", "id10"]
>>> sorted(ids, key=sort_by_int)
['id1', 'id2', 'id3', 'id10', 'id20', 'id30']
This code produces the same result as the lambda example, but you need to define the function before using it.

For a lot more information about lambda, check out How to Use Python Lambda Functions.


Remove ads
Returning Keywords: return, yield
There are two Python keywords used to specify what gets returned from functions or methods: return and yield. Understanding when and where to use return is vital to becoming a better Python programmer. The yield keyword is a more advanced feature of Python, but it can also be a useful tool to understand.

The return Keyword
Python’s return keyword is valid only as part of a function defined with def. When Python encounters this keyword, it will exit the function at that point and return the results of whatever comes after the return keyword:

def <function>():
    return <expr>
When given no expression, return will return None by default:

>>> def return_none():
...     return
...
>>> return_none()
>>> r = return_none()
>>> print(r)
None
Most of the time, however, you want to return the results of an expression or a specific value:

>>> def plus_1(num):
...    return num + 1
...
>>> plus_1(9)
10
>>> r = plus_1(9)
>>> print(r)
10
You can even use the return keyword multiple times in a function. This allows you to have multiple exit points in your function. A classic example of when you would want to have multiple return statements is the following recursive solution to calculating factorial:

def factorial(n):
    if n == 1:
        return 1
    else:
        return n * factorial(n - 1)
In the factorial function above, there are two cases in which you would want to return from the function. The first is the base case, when the number is 1, and the second is the regular case, when you want to multiply the current number by the next number’s factorial value.

To learn more about the return keyword, check out Defining Your Own Python Function.

The yield Keyword
Python’s yield keyword is kind of like the return keyword in that it specifies what gets returned from a function. However, when a function has a yield statement, what gets returned is a generator. The generator can then be passed to Python’s built-in next() to get the next value returned from the function.

When you call a function with yield statements, Python executes the function until it reaches the first yield keyword and then returns a generator. These are known as generator functions:

def <function>():
    yield <expr>
The most straightforward example of this would be a generator function that returns the same set of values:

>>> def family():
...     yield "Pam"
...     yield "Jim"
...     yield "Cece"
...     yield "Philip"
...
>>> names = family()
>>> names
<generator object family at 0x7f47a43577d8>
>>> next(names)
'Pam'
>>> next(names)
'Jim'
>>> next(names)
'Cece'
>>> next(names)
'Philip'
>>> next(names)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
Once the StopIteration exception is raised, the generator is done returning values. In order to go through the names again, you would need to call family() again and get a new generator. Most of the time, a generator function will be called as part of a for loop, which does the next() calls for you.

For much more on the yield keyword and using generators and generator functions, check out How to Use Generators and yield in Python and Python Generators 101.


Remove ads
Import Keywords: import, from, as
For those tools that, unlike Python keywords and built-ins, are not already available to your Python program, you’ll need to import them into your program. There are many useful modules available in Python’s standard library that are only an import away. There are also many other useful libraries and tools available in PyPI that, once you’ve installed them into your environment, you’ll need to import into your programs.

The following are brief descriptions of the three Python keywords used for importing modules into your program. For more information about these keywords, check out Python Modules and Packages – An Introduction and Python import: Advanced Techniques and Tips.

The import Keyword
Python’s import keyword is used to import, or include, a module for use in your Python program. Basic usage syntax looks like this:

import <module>
After that statement runs, the <module> will be available to your program.

For example, if you want to use the Counter class from the collections module in the standard library, then you can use the following code:

>>> import collections
>>> collections.Counter()
Counter()
Importing collections in this way makes the whole collections module, including the Counter class, available to your program. By using the module name, you have access to all the tools available in that module. To get access to Counter, you reference it from the module: collections.Counter.

The from Keyword
The from keyword is used together with import to import something specific from a module:

from <module> import <thing>
This will import whatever <thing> is inside <module> to be used inside your program. These two Python keywords, from and import, are used together.

If you want to use Counter from the collections module in the standard library, then you can import it specifically:

>>> from collections import Counter
>>> Counter()
Counter()
Importing Counter like this makes the Counter class available, but nothing else from the collections module is available. Counter is now available without you having to reference it from the collections module.

The as Keyword
The as keyword is used to alias an imported module or tool. It’s used together with the Python keywords import and from to change the name of the thing being imported:

import <module> as <alias>
from <module> import <thing> as <alias>
For modules that have really long names or a commonly used import alias, as can be helpful in creating the alias.

If you want to import the Counter class from the collections module but name it something different, you can alias it by using as:

>>> from collections import Counter as C
>>> C()
Counter()
Now Counter is available to be used in your program, but it’s referenced by C instead. A more common use of as import aliases is with NumPy or Pandas packages. These are commonly imported with standard aliases:

import numpy as np
import pandas as pd
This is a better alternative to just importing everything from a module, and it allows you to shorten the name of the module being imported.


Remove ads
Exception-Handling Keywords: try, except, raise, finally, else, assert
One of the most common aspects of any Python program is the raising and catching of exceptions. Because this is such a fundamental aspect of all Python code, there are several Python keywords available to help make this part of your code clear and concise.

The sections below go over these Python keywords and their basic usage. For a more in-depth tutorial on these keywords, check out Python Exceptions: An Introduction.

The try Keyword
Any exception-handling block begins with Python’s try keyword. This is the same in most other programming languages that have exception handling.

The code in the try block is code that might raise an exception. Several other Python keywords are associated with try and are used to define what should be done if different exceptions are raised or in different situations. These are except, else, and finally:

try:
    <statements>
<except|else|finally>:
    <statements>
A try block isn’t valid unless it has at least one of the other Python keywords used for exception handling as part of the overall try statement.

If you wanted to calculate and return the miles per gallon of gas (mpg) given the miles driven and the gallons of gas used, then you could write a function like the following:

def mpg(miles, gallons):
    return miles / gallons
The first problem you might see is that your code could raise a ZeroDivisionError if the gallons parameter is passed in as 0. The try keyword allows you to modify the code above to handle that situation appropriately:

def mpg(miles, gallons):
    try:
        mpg = miles / gallons
    except ZeroDivisionError:
        mpg = None
    return mpg
Now if gallons = 0, then mpg() won’t raise an exception and will return None instead. This might be better, or you might decide that you want to raise a different type of exception or handle this situation differently. You’ll see an expanded version of this example below to illustrate the other keywords used for exception handling.

The except Keyword
Python’s except keyword is used with try to define what to do when specific exceptions are raised. You can have one or more except blocks with a single try. The basic usage looks like this:

try:
    <statements>
except <exception>:
    <statements>
Taking the mpg() example from before, you could also do something specific in the event that someone passes types that won’t work with the / operator. Having defined mpg() in a previous example, now try to call it with strings instead of numbers:

>>> mpg("lots", "many")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in mpg
TypeError: unsupported operand type(s) for /: 'str' and 'str'
You could revise mpg() and use multiple except blocks to handle this situation, too:

def mpg(miles, gallons):
    try:
        mpg = miles / gallons
    except ZeroDivisionError:
        mpg = None
    except TypeError as ex:
        print("you need to provide numbers")
        raise ex
    return mpg
Here, you modify mpg() to raise the TypeError exception only after you’ve printed a helpful reminder to the screen.

Notice that the except keyword can also be used in conjunction with the as keyword. This has the same effect as the other uses of as, giving the raised exception an alias so you can work with it in the except block.

Even though it’s syntactically allowed, try not to use except statements as implicit catchalls. It’s better practice to always explicitly catch something, even if it’s just Exception:

try:
    1 / 0
except:  # Don't do this
    pass

try:
    1 / 0
except Exception:  # This is better
    pass

try:
    1 / 0
except ZeroDivisionError:  # This is best
    pass
If you really do want to catch a broad range of exceptions, then specify the parent Exception. This is more explicitly a catchall, and it won’t also catch exceptions you probably don’t want to catch, like RuntimeError or KeyboardInterrupt.

The raise Keyword
The raise keyword raises an exception. If you find you need to raise an exception, then you can use raise followed by the exception to be raised:

raise <exception>
You used raise previously, in the mpg() example. When you catch the TypeError, you re-raise the exception after printing a message to the screen.

The finally Keyword
Python’s finally keyword is helpful for specifying code that should be run no matter what happens in the try, except, or else blocks. To use finally, use it as part of a try block and specify the statements that should be run no matter what:

try:
    <statements>
finally:
    <statements>
Using the example from before, it might be helpful to specify that, no matter what happens, you want to know what arguments the function was called with. You could modify mpg() to include a finally block that does just that:

def mpg(miles, gallons):
    try:
        mpg = miles / gallons
    except ZeroDivisionError:
        mpg = None
    except TypeError as ex:
        print("you need to provide numbers")
        raise ex
    finally:
        print(f"mpg({miles}, {gallons})")
    return mpg
Now, no matter how mpg() is called or what the result is, you print the arguments supplied by the user:

>>> mpg(10, 1)
mpg(10, 1)
10.0

>>> mpg("lots", "many")
you need to provide numbers
mpg(lots, many)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 8, in mpg
  File "<stdin>", line 3, in mpg
TypeError: unsupported operand type(s) for /: 'str' and 'str'
The finally keyword can be a very useful part of your exception-handling code.

The else Keyword Used With try and except
You’ve learned that the else keyword can be used with both the if keyword and loops in Python, but it has one more use. It can be combined with the try and except Python keywords. You can use else in this way only if you also use at least one except block:

try:
    <statements>
except <exception>:
    <statements>
else:
    <statements>
In this context, the code in the else block is executed only if an exception was not raised in the try block. In other words, if the try block executed all the code successfully, then the else block code would be executed.

In the mpg() example, imagine you want to make sure that the mpg result is always returned as a float no matter what number combination is passed in. One of the ways you could do this is to use an else block. If the try block calculation of mpg is successful, then you convert the result to a float in the else block before returning:

def mpg(miles, gallons):
    try:
        mpg = miles / gallons
    except ZeroDivisionError:
        mpg = None
    except TypeError as ex:
        print("you need to provide numbers")
        raise ex
    else:
        mpg = float(mpg) if mpg is not None else mpg
    finally:
        print(f"mpg({miles}, {gallons})")
    return mpg
Now the results of a call to mpg(), if successful, will always be a float.

For more on using the else block as part of a try and except block, check out Python Exceptions: An Introduction.

The assert Keyword
The assert keyword in Python is used to specify an assert statement, or an assertion about an expression. An assert statement will result in a no-op if the expression (<expr>) is truthy, and it will raise an AssertionError if the expression is falsy. To define an assertion, use assert followed by an expression:

assert <expr>
Generally, assert statements will be used to make sure something that needs to be true is. You shouldn’t rely on them, however, as they can be ignored depending on how your Python program is executed.


Remove ads
Asynchronous Programming Keywords: async, await
Asynchronous programming is a complex topic. There are two Python keywords defined to help make asynchronous code more readable and cleaner: async and await.

The sections below introduce the two asynchronous keywords and their basic syntax, but they won’t go into depth on asynchronous programming. To learn more about asynchronous programming, check out Async IO in Python: A Complete Walkthrough and Getting Started With Async Features in Python.

The async Keyword
The async keyword is used with def to define an asynchronous function, or coroutine. The syntax is just like defining a function, with the addition of async at the beginning:

async def <function>(<params>):
    <statements>
You can make a function asynchronous by adding the async keyword before the function’s regular definition.

The await Keyword
Python’s await keyword is used in asynchronous functions to specify a point in the function where control is given back to the event loop for other functions to run. You can use it by placing the await keyword in front of a call to any async function:

await <some async function call>
# OR
<var> = await <some async function call>
When using await, you can either call the asynchronous function and ignore the results, or you can store the results in a variable when the function eventually returns.

Variable Handling Keywords: del, global, nonlocal
Three Python keywords are used to work with variables. The del keyword is much more commonly used than the global and nonlocal keywords. But it’s still helpful to know and understand all three keywords so you can identify when and how to use them.

The del Keyword
del is used in Python to unset a variable or name. You can use it on variable names, but a more common use is to remove indexes from a list or dictionary. To unset a variable, use del followed by the variable you want to unset:

del <variable>
Let’s assume you want to clean up a dictionary that you got from an API response by throwing out keys you know you won’t use. You can do so with the del keyword:

>>> del response["headers"]
>>> del response["errors"]
This will remove the "headers" and "errors" keys from the dictionary response.

The global Keyword
If you need to modify a variable that isn’t defined in a function but is defined in the global scope, then you’ll need to use the global keyword. This works by specifying in the function which variables need to be pulled into the function from the global scope:

global <variable>
A basic example is incrementing a global variable with a function call. You can do that with the global keyword:

>>> x = 0
>>> def inc():
...     global x
...     x += 1
...
>>> inc()
>>> x
1
>>> inc()
>>> x
2
This is generally not considered good practice, but it does have its uses. To learn much more on the global keyword, check out Python Scope & the LEGB Rule: Resolving Names in Your Code.

The nonlocal Keyword
The nonlocal keyword is similar to global in that it allows you to modify variables from a different scope. With global, the scope you’re pulling from is the global scope. With nonlocal, the scope you’re pulling from is the parent scope. The syntax is similar to global:

nonlocal <variable>
This keyword isn’t used very often, but it can be handy at times. For more on scoping and the nonlocal keyword, check out Python Scope & the LEGB Rule: Resolving Names in Your Code.


Remove ads
Deprecated Python Keywords
Sometimes a Python keyword becomes a built-in function. That was the case with both print and exec. These used to be Python keywords in version 2.7, but they’ve since been changed to built-in functions.

The Former print Keyword
When print was a keyword, the syntax to print something to the screen looked like this:

print "Hello, World"
Notice that it looks like a lot of the other keyword statements, with the keyword followed by the arguments.

Now print is no longer a keyword, and printing is accomplished with the built-in print(). To print something to the screen, you now use the following syntax:

print("Hello, World")
For more on printing, check out Your Guide to the Python print() Function.

The Former exec Keyword
In Python 2.7, the exec keyword took Python code as a string and executed it. This was done with the following syntax:

exec "<statements>"
You can get the same behavior in Python 3+, only with the built-in exec(). For example, if you wanted to execute "x = 12 * 7" in your Python code, then you could do the following:

>>> exec("x = 12 * 7")
>>> x == 84
True
For more on exec() and its uses, check out How to Run Your Python Scripts and Python’s exec(): Execute Dynamically Generated Code.

Conclusion
Python keywords are the fundamental building blocks of any Python program. Understanding their proper use is key to improving your skills and knowledge of Python.

Throughout this article, you’ve seen a few things to solidify your understanding Python keywords and to help you write more efficient and readable code.

In this article, you’ve learned:

The Python keywords in version 3.8 and their basic usage
Several resources to help deepen your understanding of many of the keywords
How to use Python’s keyword module to work with keywords in a programmatic way
If you understand most of these keywords and feel comfortable using them, then you might be interested to learn more about Python’s grammar and how the statements that use these keywords are specified and constructed.

 
 Watch Now This tutorial has a related video course created by the Real Python team. Watch it together with the written tutorial to deepen your understanding: Exploring Keywords in Python

🐍 Python Tricks 💌

Get a short & sweet Python Trick delivered to your inbox every couple of days. No spam ever. Unsubscribe any time. Curated by the Real Python team.

Python Tricks Dictionary Merge
Email Address
About Chad Hansen

Chad Hansen
Chad is an avid Pythonista and does web development with Django fulltime. Chad lives in Utah with his wife and six kids.

» More about Chad
Each tutorial at Real Python is created by a team of developers so that it meets our high quality standards. The team members who worked on this tutorial are:

Aldren Santos
Aldren

Geir Arne Hjelle
Geir Arne

Jim Anderson
Jim

Joanna Jablonski
Joanna

Jacob Schmitt
Jacob

Master Real-World Python Skills
With Unlimited Access to Real Python



Join us and get access to thousands of tutorials, hands-on video courses, and a community of expert Pythonistas:


What Do You Think?

Rate this article: 
Tweet Share Share Email
What’s your #1 takeaway or favorite thing you learned? How are you going to put your newfound skills to use? Leave a comment below and let us know.

Commenting Tips: The most useful comments are those written with the goal of learning from or helping out other students. Get tips for asking good questions and get answers to common questions in our support portal.

Looking for a real-time conversation? Visit the Real Python Community Chat or join the next “Office Hours” Live Q&A Session. Happy Pythoning!
Keep Learning

Related Tutorial Categories: basics python

Recommended Video Course: Exploring Keywords in Python

— FREE Email Series —

🐍 Python Tricks 💌

Python Tricks Dictionary Merge

Email…
🔒 No spam. Unsubscribe any time.

All Tutorial Topics

advanced api basics best-practices community databases data-science devops django docker flask front-end gamedev gui intermediate machine-learning projects python testing tools web-dev web-scraping

Table of Contents

Python Keywords
How to Identify Python Keywords
Python Keywords and Their Usage
Deprecated Python Keywords
Conclusion
Tweet Share Email
 Recommended Video Course
Exploring Keywords in Python


Remove ads
© 2012–2022 Real Python ⋅ Newsletter ⋅ Podcast ⋅ YouTube ⋅ Twitter ⋅ Facebook ⋅ Instagram ⋅ Python Tutorials ⋅ Search ⋅ Privacy Policy ⋅ Energy Policy ⋅ Advertise ⋅ Contact
❤️ Happy Pythoning!

Improve Your Python

Improve Your Python
...with a fresh 🐍 Python Trick 💌  
code snippet every couple of days:
Email Address

Receive the Real Python newsletter and get notified about new tutorials we publish on the site, as well as occasional special offers.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
Exception Handling
The functions described in this chapter will let you handle and raise Python exceptions. It is important to understand some of the basics of Python exception handling. It works somewhat like the POSIX errno variable: there is a global indicator (per thread) of the last error that occurred. Most C API functions don’t clear this on success, but will set it to indicate the cause of the error on failure. Most C API functions also return an error indicator, usually NULL if they are supposed to return a pointer, or -1 if they return an integer (exception: the PyArg_* functions return 1 for success and 0 for failure).

Concretely, the error indicator consists of three object pointers: the exception’s type, the exception’s value, and the traceback object. Any of those pointers can be NULL if non-set (although some combinations are forbidden, for example you can’t have a non-NULL traceback if the exception type is NULL).

When a function must fail because some function it called failed, it generally doesn’t set the error indicator; the function it called already set it. It is responsible for either handling the error and clearing the exception or returning after cleaning up any resources it holds (such as object references or memory allocations); it should not continue normally if it is not prepared to handle the error. If returning due to an error, it is important to indicate to the caller that an error has been set. If the error is not handled or carefully propagated, additional calls into the Python/C API may not behave as intended and may fail in mysterious ways.

Note The error indicator is not the result of sys.exc_info(). The former corresponds to an exception that is not yet caught (and is therefore still propagating), while the latter returns an exception after it is caught (and has therefore stopped propagating).
Printing and clearing
void PyErr_Clear()
Part of the Stable ABI.
Clear the error indicator. If the error indicator is not set, there is no effect.

void PyErr_PrintEx(int set_sys_last_vars)
Part of the Stable ABI.
Print a standard traceback to sys.stderr and clear the error indicator. Unless the error is a SystemExit, in that case no traceback is printed and the Python process will exit with the error code specified by the SystemExit instance.

Call this function only when the error indicator is set. Otherwise it will cause a fatal error!

If set_sys_last_vars is nonzero, the variables sys.last_type, sys.last_value and sys.last_traceback will be set to the type, value and traceback of the printed exception, respectively.

void PyErr_Print()
Part of the Stable ABI.
Alias for PyErr_PrintEx(1).

void PyErr_WriteUnraisable(PyObject *obj)
Part of the Stable ABI.
Call sys.unraisablehook() using the current exception and obj argument.

This utility function prints a warning message to sys.stderr when an exception has been set but it is impossible for the interpreter to actually raise the exception. It is used, for example, when an exception occurs in an __del__() method.

The function is called with a single argument obj that identifies the context in which the unraisable exception occurred. If possible, the repr of obj will be printed in the warning message.

An exception must be set when calling this function.

Raising exceptions
These functions help you set the current thread’s error indicator. For convenience, some of these functions will always return a NULL pointer for use in a return statement.

void PyErr_SetString(PyObject *type, const char *message)
Part of the Stable ABI.
This is the most common way to set the error indicator. The first argument specifies the exception type; it is normally one of the standard exceptions, e.g. PyExc_RuntimeError. You need not increment its reference count. The second argument is an error message; it is decoded from 'utf-8'.

void PyErr_SetObject(PyObject *type, PyObject *value)
Part of the Stable ABI.
This function is similar to PyErr_SetString() but lets you specify an arbitrary Python object for the “value” of the exception.

PyObject *PyErr_Format(PyObject *exception, const char *format, ...)
Return value: Always NULL. Part of the Stable ABI.
This function sets the error indicator and returns NULL. exception should be a Python exception class. The format and subsequent parameters help format the error message; they have the same meaning and values as in PyUnicode_FromFormat(). format is an ASCII-encoded string.

PyObject *PyErr_FormatV(PyObject *exception, const char *format, va_list vargs)
Return value: Always NULL. Part of the Stable ABI since version 3.5.
Same as PyErr_Format(), but taking a va_list argument rather than a variable number of arguments.

New in version 3.5.

void PyErr_SetNone(PyObject *type)
Part of the Stable ABI.
This is a shorthand for PyErr_SetObject(type, Py_None).

int PyErr_BadArgument()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_TypeError, message), where message indicates that a built-in operation was invoked with an illegal argument. It is mostly for internal use.

PyObject *PyErr_NoMemory()
Return value: Always NULL. Part of the Stable ABI.
This is a shorthand for PyErr_SetNone(PyExc_MemoryError); it returns NULL so an object allocation function can write return PyErr_NoMemory(); when it runs out of memory.

PyObject *PyErr_SetFromErrno(PyObject *type)
Return value: Always NULL. Part of the Stable ABI.
This is a convenience function to raise an exception when a C library function has returned an error and set the C variable errno. It constructs a tuple object whose first item is the integer errno value and whose second item is the corresponding error message (gotten from strerror()), and then calls PyErr_SetObject(type, object). On Unix, when the errno value is EINTR, indicating an interrupted system call, this calls PyErr_CheckSignals(), and if that set the error indicator, leaves it set to that. The function always returns NULL, so a wrapper function around a system call can write return PyErr_SetFromErrno(type); when the system call returns an error.

PyObject *PyErr_SetFromErrnoWithFilenameObject(PyObject *type, PyObject *filenameObject)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrno(), with the additional behavior that if filenameObject is not NULL, it is passed to the constructor of type as a third parameter. In the case of OSError exception, this is used to define the filename attribute of the exception instance.

PyObject *PyErr_SetFromErrnoWithFilenameObjects(PyObject *type, PyObject *filenameObject, PyObject *filenameObject2)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but takes a second filename object, for raising errors when a function that takes two filenames fails.

New in version 3.4.

PyObject *PyErr_SetFromErrnoWithFilename(PyObject *type, const char *filename)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding and error handler.

PyObject *PyErr_SetFromWindowsErr(int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
This is a convenience function to raise WindowsError. If called with ierr of 0, the error code returned by a call to GetLastError() is used instead. It calls the Win32 function FormatMessage() to retrieve the Windows description of error code given by ierr or GetLastError(), then it constructs a tuple object whose first item is the ierr value and whose second item is the corresponding error message (gotten from FormatMessage()), and then calls PyErr_SetObject(PyExc_WindowsError, object). This function always returns NULL.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErr(PyObject *type, int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErr(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetFromWindowsErrWithFilename(int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding (os.fsdecode()).

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObject(PyObject *type, int ierr, PyObject *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObjects(PyObject *type, int ierr, PyObject *filename, PyObject *filename2)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetExcFromWindowsErrWithFilenameObject(), but accepts a second filename object.

Availability: Windows.

New in version 3.4.

PyObject *PyErr_SetExcFromWindowsErrWithFilename(PyObject *type, int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilename(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetImportError(PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
This is a convenience function to raise ImportError. msg will be set as the exception’s message string. name and path, both of which can be NULL, will be set as the ImportError’s respective name and path attributes.

New in version 3.3.

PyObject *PyErr_SetImportErrorSubclass(PyObject *exception, PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.6.
Much like PyErr_SetImportError() but this function allows for specifying a subclass of ImportError to raise.

New in version 3.6.

void PyErr_SyntaxLocationObject(PyObject *filename, int lineno, int col_offset)
Set file, line, and offset information for the current exception. If the current exception is not a SyntaxError, then it sets additional attributes, which make the exception printing subsystem think the exception is a SyntaxError.

New in version 3.4.

void PyErr_SyntaxLocationEx(const char *filename, int lineno, int col_offset)
Part of the Stable ABI since version 3.7.
Like PyErr_SyntaxLocationObject(), but filename is a byte string decoded from the filesystem encoding and error handler.

New in version 3.2.

void PyErr_SyntaxLocation(const char *filename, int lineno)
Part of the Stable ABI.
Like PyErr_SyntaxLocationEx(), but the col_offset parameter is omitted.

void PyErr_BadInternalCall()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_SystemError, message), where message indicates that an internal operation (e.g. a Python/C API function) was invoked with an illegal argument. It is mostly for internal use.

Issuing warnings
Use these functions to issue warnings from C code. They mirror similar functions exported by the Python warnings module. They normally print a warning message to sys.stderr; however, it is also possible that the user has specified that warnings are to be turned into errors, and in that case they will raise an exception. It is also possible that the functions raise an exception because of a problem with the warning machinery. The return value is 0 if no exception is raised, or -1 if an exception is raised. (It is not possible to determine whether a warning message is actually printed, nor what the reason is for the exception; this is intentional.) If an exception is raised, the caller should do its normal exception handling (for example, Py_DECREF() owned references and return an error value).

int PyErr_WarnEx(PyObject *category, const char *message, Py_ssize_t stack_level)
Part of the Stable ABI.
Issue a warning message. The category argument is a warning category (see below) or NULL; the message argument is a UTF-8 encoded string. stack_level is a positive number giving a number of stack frames; the warning will be issued from the currently executing line of code in that stack frame. A stack_level of 1 is the function calling PyErr_WarnEx(), 2 is the function above that, and so forth.

Warning categories must be subclasses of PyExc_Warning; PyExc_Warning is a subclass of PyExc_Exception; the default warning category is PyExc_RuntimeWarning. The standard Python warning categories are available as global variables whose names are enumerated at Standard Warning Categories.

For information about warning control, see the documentation for the warnings module and the -W option in the command line documentation. There is no C API for warning control.

int PyErr_WarnExplicitObject(PyObject *category, PyObject *message, PyObject *filename, int lineno, PyObject *module, PyObject *registry)
Issue a warning message with explicit control over all warning attributes. This is a straightforward wrapper around the Python function warnings.warn_explicit(); see there for more information. The module and registry arguments may be set to NULL to get the default effect described there.

New in version 3.4.

int PyErr_WarnExplicit(PyObject *category, const char *message, const char *filename, int lineno, const char *module, PyObject *registry)
Part of the Stable ABI.
Similar to PyErr_WarnExplicitObject() except that message and module are UTF-8 encoded strings, and filename is decoded from the filesystem encoding and error handler.

int PyErr_WarnFormat(PyObject *category, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI.
Function similar to PyErr_WarnEx(), but use PyUnicode_FromFormat() to format the warning message. format is an ASCII-encoded string.

New in version 3.2.

int PyErr_ResourceWarning(PyObject *source, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI since version 3.6.
Function similar to PyErr_WarnFormat(), but category is ResourceWarning and it passes source to warnings.WarningMessage().

New in version 3.6.

Querying the error indicator
PyObject *PyErr_Occurred()
Return value: Borrowed reference. Part of the Stable ABI.
Test whether the error indicator is set. If set, return the exception type (the first argument to the last call to one of the PyErr_Set* functions or to PyErr_Restore()). If not set, return NULL. You do not own a reference to the return value, so you do not need to Py_DECREF() it.

The caller must hold the GIL.

Note Do not compare the return value to a specific exception; use PyErr_ExceptionMatches() instead, shown below. (The comparison could easily fail since the exception may be an instance instead of a class, in the case of a class exception, or it may be a subclass of the expected exception.)
int PyErr_ExceptionMatches(PyObject *exc)
Part of the Stable ABI.
Equivalent to PyErr_GivenExceptionMatches(PyErr_Occurred(), exc). This should only be called when an exception is actually set; a memory access violation will occur if no exception has been raised.

int PyErr_GivenExceptionMatches(PyObject *given, PyObject *exc)
Part of the Stable ABI.
Return true if the given exception matches the exception type in exc. If exc is a class object, this also returns true when given is an instance of a subclass. If exc is a tuple, all exception types in the tuple (and recursively in subtuples) are searched for a match.

void PyErr_Fetch(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI.
Retrieve the error indicator into three variables whose addresses are passed. If the error indicator is not set, set all three variables to NULL. If it is set, it will be cleared and you own a reference to each object retrieved. The value and traceback object may be NULL even when the type object is not.

Note This function is normally only used by code that needs to catch exceptions or by code that needs to save and restore the error indicator temporarily, e.g.:
{
   PyObject *type, *value, *traceback;
   PyErr_Fetch(&type, &value, &traceback);

   /* ... code that might produce other errors ... */

   PyErr_Restore(type, value, traceback);
}
void PyErr_Restore(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI.
Set the error indicator from the three objects. If the error indicator is already set, it is cleared first. If the objects are NULL, the error indicator is cleared. Do not pass a NULL type and non-NULL value or traceback. The exception type should be a class. Do not pass an invalid exception type or value. (Violating these rules will cause subtle problems later.) This call takes away a reference to each object: you must own a reference to each object before the call and after the call you no longer own these references. (If you don’t understand this, don’t use this function. I warned you.)

Note This function is normally only used by code that needs to save and restore the error indicator temporarily. Use PyErr_Fetch() to save the current error indicator.
void PyErr_NormalizeException(PyObject **exc, PyObject **val, PyObject **tb)
Part of the Stable ABI.
Under certain circumstances, the values returned by PyErr_Fetch() below can be “unnormalized”, meaning that *exc is a class object but *val is not an instance of the same class. This function can be used to instantiate the class in that case. If the values are already normalized, nothing happens. The delayed normalization is implemented to improve performance.

Note This function does not implicitly set the __traceback__ attribute on the exception value. If setting the traceback appropriately is desired, the following additional snippet is needed:
if (tb != NULL) {
  PyException_SetTraceback(val, tb);
}
void PyErr_GetExcInfo(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI since version 3.7.
Retrieve the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. Returns new references for the three objects, any of which may be NULL. Does not modify the exception info state.

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_SetExcInfo() to restore or clear the exception state.
New in version 3.3.

void PyErr_SetExcInfo(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI since version 3.7.
Set the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. This function steals the references of the arguments. To clear the exception state, pass NULL for all three arguments. For general rules about the three arguments, see PyErr_Restore().

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_GetExcInfo() to read the exception state.
New in version 3.3.

Signal Handling
int PyErr_CheckSignals()
Part of the Stable ABI.
This function interacts with Python’s signal handling.

If the function is called from the main thread and under the main Python interpreter, it checks whether a signal has been sent to the processes and if so, invokes the corresponding signal handler. If the signal module is supported, this can invoke a signal handler written in Python.

The function attempts to handle all pending signals, and then returns 0. However, if a Python signal handler raises an exception, the error indicator is set and the function returns -1 immediately (such that other pending signals may not have been handled yet: they will be on the next PyErr_CheckSignals() invocation).

If the function is called from a non-main thread, or under a non-main Python interpreter, it does nothing and returns 0.

This function can be called by long-running C code that wants to be interruptible by user requests (such as by pressing Ctrl-C).

Note The default Python signal handler for SIGINT raises the KeyboardInterrupt exception.
void PyErr_SetInterrupt()
Part of the Stable ABI.
Simulate the effect of a SIGINT signal arriving. This is equivalent to PyErr_SetInterruptEx(SIGINT).

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
int PyErr_SetInterruptEx(int signum)
Part of the Stable ABI since version 3.10.
Simulate the effect of a signal arriving. The next time PyErr_CheckSignals() is called, the Python signal handler for the given signal number will be called.

This function can be called by C code that sets up its own signal handling and wants Python signal handlers to be invoked as expected when an interruption is requested (for example when the user presses Ctrl-C to interrupt an operation).

If the given signal isn’t handled by Python (it was set to signal.SIG_DFL or signal.SIG_IGN), it will be ignored.

If signum is outside of the allowed range of signal numbers, -1 is returned. Otherwise, 0 is returned. The error indicator is never changed by this function.

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
New in version 3.10.

int PySignal_SetWakeupFd(int fd)
This utility function specifies a file descriptor to which the signal number is written as a single byte whenever a signal is received. fd must be non-blocking. It returns the previous such file descriptor.

The value -1 disables the feature; this is the initial state. This is equivalent to signal.set_wakeup_fd() in Python, but without any error checking. fd should be a valid file descriptor. The function should only be called from the main thread.

Changed in version 3.5: On Windows, the function now also supports socket handles.

Exception Classes
PyObject *PyErr_NewException(const char *name, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
This utility function creates and returns a new exception class. The name argument must be the name of the new exception, a C string of the form module.classname. The base and dict arguments are normally NULL. This creates a class object derived from Exception (accessible in C as PyExc_Exception).

The __module__ attribute of the new class is set to the first part (up to the last dot) of the name argument, and the class name is set to the last part (after the last dot). The base argument can be used to specify alternate base classes; it can either be only one class or a tuple of classes. The dict argument can be used to specify a dictionary of class variables and methods.

PyObject *PyErr_NewExceptionWithDoc(const char *name, const char *doc, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
Same as PyErr_NewException(), except that the new exception class can easily be given a docstring: If doc is non-NULL, it will be used as the docstring for the exception class.

New in version 3.2.

Exception Objects
PyObject *PyException_GetTraceback(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the traceback associated with the exception as a new reference, as accessible from Python through __traceback__. If there is no traceback associated, this returns NULL.

int PyException_SetTraceback(PyObject *ex, PyObject *tb)
Part of the Stable ABI.
Set the traceback associated with the exception to tb. Use Py_None to clear it.

PyObject *PyException_GetContext(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the context (another exception instance during whose handling ex was raised) associated with the exception as a new reference, as accessible from Python through __context__. If there is no context associated, this returns NULL.

void PyException_SetContext(PyObject *ex, PyObject *ctx)
Part of the Stable ABI.
Set the context associated with the exception to ctx. Use NULL to clear it. There is no type check to make sure that ctx is an exception instance. This steals a reference to ctx.

PyObject *PyException_GetCause(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the cause (either an exception instance, or None, set by raise ... from ...) associated with the exception as a new reference, as accessible from Python through __cause__.

void PyException_SetCause(PyObject *ex, PyObject *cause)
Part of the Stable ABI.
Set the cause associated with the exception to cause. Use NULL to clear it. There is no type check to make sure that cause is either an exception instance or None. This steals a reference to cause.

__suppress_context__ is implicitly set to True by this function.

Unicode Exception Objects
The following functions are used to create and modify Unicode exceptions from C.

PyObject *PyUnicodeDecodeError_Create(const char *encoding, const char *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference. Part of the Stable ABI.
Create a UnicodeDecodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

PyObject *PyUnicodeEncodeError_Create(const char *encoding, const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeEncodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeEncodeError, "sOnns", ...).

PyObject *PyUnicodeTranslateError_Create(const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeTranslateError object with the attributes object, length, start, end and reason. reason is a UTF-8 encoded string.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeTranslateError, "Onns", ...).

PyObject *PyUnicodeDecodeError_GetEncoding(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetEncoding(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the encoding attribute of the given exception object.

PyObject *PyUnicodeDecodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetObject(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the object attribute of the given exception object.

int PyUnicodeDecodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeEncodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeTranslateError_GetStart(PyObject *exc, Py_ssize_t *start)
Part of the Stable ABI.
Get the start attribute of the given exception object and place it into *start. start must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeEncodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeTranslateError_SetStart(PyObject *exc, Py_ssize_t start)
Part of the Stable ABI.
Set the start attribute of the given exception object to start. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeEncodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeTranslateError_GetEnd(PyObject *exc, Py_ssize_t *end)
Part of the Stable ABI.
Get the end attribute of the given exception object and place it into *end. end must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeEncodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeTranslateError_SetEnd(PyObject *exc, Py_ssize_t end)
Part of the Stable ABI.
Set the end attribute of the given exception object to end. Return 0 on success, -1 on failure.

PyObject *PyUnicodeDecodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetReason(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the reason attribute of the given exception object.

int PyUnicodeDecodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeEncodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeTranslateError_SetReason(PyObject *exc, const char *reason)
Part of the Stable ABI.
Set the reason attribute of the given exception object to reason. Return 0 on success, -1 on failure.

Recursion Control
These two functions provide a way to perform safe recursive calls at the C level, both in the core and in extension modules. They are needed if the recursive code does not necessarily invoke Python code (which tracks its recursion depth automatically). They are also not needed for tp_call implementations because the call protocol takes care of recursion handling.

int Py_EnterRecursiveCall(const char *where)
Part of the Stable ABI since version 3.9.
Marks a point where a recursive C-level call is about to be performed.

If USE_STACKCHECK is defined, this function checks if the OS stack overflowed using PyOS_CheckStack(). In this is the case, it sets a MemoryError and returns a nonzero value.

The function then checks if the recursion limit is reached. If this is the case, a RecursionError is set and a nonzero value is returned. Otherwise, zero is returned.

where should be a UTF-8 encoded string such as " in instance check" to be concatenated to the RecursionError message caused by the recursion depth limit.

Changed in version 3.9: This function is now also available in the limited API.

void Py_LeaveRecursiveCall(void)
Part of the Stable ABI since version 3.9.
Ends a Py_EnterRecursiveCall(). Must be called once for each successful invocation of Py_EnterRecursiveCall().

Changed in version 3.9: This function is now also available in the limited API.

Properly implementing tp_repr for container types requires special recursion handling. In addition to protecting the stack, tp_repr also needs to track objects to prevent cycles. The following two functions facilitate this functionality. Effectively, these are the C equivalent to reprlib.recursive_repr().

int Py_ReprEnter(PyObject *object)
Part of the Stable ABI.
Called at the beginning of the tp_repr implementation to detect cycles.

If the object has already been processed, the function returns a positive integer. In that case the tp_repr implementation should return a string object indicating a cycle. As examples, dict objects return {...} and list objects return [...].

The function will return a negative integer if the recursion limit is reached. In that case the tp_repr implementation should typically return NULL.

Otherwise, the function returns zero and the tp_repr implementation can continue normally.

void Py_ReprLeave(PyObject *object)
Part of the Stable ABI.
Ends a Py_ReprEnter(). Must be called once for each invocation of Py_ReprEnter() that returns zero.

Standard Exceptions
All standard Python exceptions are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_BaseException

BaseException

1

PyExc_Exception

Exception

1

PyExc_ArithmeticError

ArithmeticError

1

PyExc_AssertionError

AssertionError

PyExc_AttributeError

AttributeError

PyExc_BlockingIOError

BlockingIOError

PyExc_BrokenPipeError

BrokenPipeError

PyExc_BufferError

BufferError

PyExc_ChildProcessError

ChildProcessError

PyExc_ConnectionAbortedError

ConnectionAbortedError

PyExc_ConnectionError

ConnectionError

PyExc_ConnectionRefusedError

ConnectionRefusedError

PyExc_ConnectionResetError

ConnectionResetError

PyExc_EOFError

EOFError

PyExc_FileExistsError

FileExistsError

PyExc_FileNotFoundError

FileNotFoundError

PyExc_FloatingPointError

FloatingPointError

PyExc_GeneratorExit

GeneratorExit

PyExc_ImportError

ImportError

PyExc_IndentationError

IndentationError

PyExc_IndexError

IndexError

PyExc_InterruptedError

InterruptedError

PyExc_IsADirectoryError

IsADirectoryError

PyExc_KeyError

KeyError

PyExc_KeyboardInterrupt

KeyboardInterrupt

PyExc_LookupError

LookupError

1

PyExc_MemoryError

MemoryError

PyExc_ModuleNotFoundError

ModuleNotFoundError

PyExc_NameError

NameError

PyExc_NotADirectoryError

NotADirectoryError

PyExc_NotImplementedError

NotImplementedError

PyExc_OSError

OSError

1

PyExc_OverflowError

OverflowError

PyExc_PermissionError

PermissionError

PyExc_ProcessLookupError

ProcessLookupError

PyExc_RecursionError

RecursionError

PyExc_ReferenceError

ReferenceError

PyExc_RuntimeError

RuntimeError

PyExc_StopAsyncIteration

StopAsyncIteration

PyExc_StopIteration

StopIteration

PyExc_SyntaxError

SyntaxError

PyExc_SystemError

SystemError

PyExc_SystemExit

SystemExit

PyExc_TabError

TabError

PyExc_TimeoutError

TimeoutError

PyExc_TypeError

TypeError

PyExc_UnboundLocalError

UnboundLocalError

PyExc_UnicodeDecodeError

UnicodeDecodeError

PyExc_UnicodeEncodeError

UnicodeEncodeError

PyExc_UnicodeError

UnicodeError

PyExc_UnicodeTranslateError

UnicodeTranslateError

PyExc_ValueError

ValueError

PyExc_ZeroDivisionError

ZeroDivisionError

New in version 3.3: PyExc_BlockingIOError, PyExc_BrokenPipeError, PyExc_ChildProcessError, PyExc_ConnectionError, PyExc_ConnectionAbortedError, PyExc_ConnectionRefusedError, PyExc_ConnectionResetError, PyExc_FileExistsError, PyExc_FileNotFoundError, PyExc_InterruptedError, PyExc_IsADirectoryError, PyExc_NotADirectoryError, PyExc_PermissionError, PyExc_ProcessLookupError and PyExc_TimeoutError were introduced following PEP 3151.

New in version 3.5: PyExc_StopAsyncIteration and PyExc_RecursionError.

New in version 3.6: PyExc_ModuleNotFoundError.

These are compatibility aliases to PyExc_OSError:

C Name

Notes

PyExc_EnvironmentError

PyExc_IOError

PyExc_WindowsError

2

Changed in version 3.3: These aliases used to be separate exception types.

Notes:

1(1,2,3,4,5)
This is a base class for other standard exceptions.

2
Only defined on Windows; protect code that uses this by testing that the preprocessor macro MS_WINDOWS is defined.

Standard Warning Categories
All standard Python warning categories are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_Warning

Warning

3

PyExc_BytesWarning

BytesWarning

PyExc_DeprecationWarning

DeprecationWarning

PyExc_FutureWarning

FutureWarning

PyExc_ImportWarning

ImportWarning

PyExc_PendingDeprecationWarning

PendingDeprecationWarning

PyExc_ResourceWarning

ResourceWarning

PyExc_RuntimeWarning

RuntimeWarning

PyExc_SyntaxWarning

SyntaxWarning

PyExc_UnicodeWarning

UnicodeWarning

PyExc_UserWarning

UserWarning

New in version 3.2: PyExc_ResourceWarning.

Notes:

3
This is a base class for other standard warning categories.

Table of Contents
Exception Handling
Printing and clearing
Raising exceptions
Issuing warnings
Querying the error indicator
Signal Handling
Exception Classes
Exception Objects
Unicode Exception Objects
Recursion Control
Standard Exceptions
Standard Warning Categories
Previous topic
Reference Counting

Next topic
Utilities

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
Exception Handling
The functions described in this chapter will let you handle and raise Python exceptions. It is important to understand some of the basics of Python exception handling. It works somewhat like the POSIX errno variable: there is a global indicator (per thread) of the last error that occurred. Most C API functions don’t clear this on success, but will set it to indicate the cause of the error on failure. Most C API functions also return an error indicator, usually NULL if they are supposed to return a pointer, or -1 if they return an integer (exception: the PyArg_* functions return 1 for success and 0 for failure).

Concretely, the error indicator consists of three object pointers: the exception’s type, the exception’s value, and the traceback object. Any of those pointers can be NULL if non-set (although some combinations are forbidden, for example you can’t have a non-NULL traceback if the exception type is NULL).

When a function must fail because some function it called failed, it generally doesn’t set the error indicator; the function it called already set it. It is responsible for either handling the error and clearing the exception or returning after cleaning up any resources it holds (such as object references or memory allocations); it should not continue normally if it is not prepared to handle the error. If returning due to an error, it is important to indicate to the caller that an error has been set. If the error is not handled or carefully propagated, additional calls into the Python/C API may not behave as intended and may fail in mysterious ways.

Note The error indicator is not the result of sys.exc_info(). The former corresponds to an exception that is not yet caught (and is therefore still propagating), while the latter returns an exception after it is caught (and has therefore stopped propagating).
Printing and clearing
void PyErr_Clear()
Part of the Stable ABI.
Clear the error indicator. If the error indicator is not set, there is no effect.

void PyErr_PrintEx(int set_sys_last_vars)
Part of the Stable ABI.
Print a standard traceback to sys.stderr and clear the error indicator. Unless the error is a SystemExit, in that case no traceback is printed and the Python process will exit with the error code specified by the SystemExit instance.

Call this function only when the error indicator is set. Otherwise it will cause a fatal error!

If set_sys_last_vars is nonzero, the variables sys.last_type, sys.last_value and sys.last_traceback will be set to the type, value and traceback of the printed exception, respectively.

void PyErr_Print()
Part of the Stable ABI.
Alias for PyErr_PrintEx(1).

void PyErr_WriteUnraisable(PyObject *obj)
Part of the Stable ABI.
Call sys.unraisablehook() using the current exception and obj argument.

This utility function prints a warning message to sys.stderr when an exception has been set but it is impossible for the interpreter to actually raise the exception. It is used, for example, when an exception occurs in an __del__() method.

The function is called with a single argument obj that identifies the context in which the unraisable exception occurred. If possible, the repr of obj will be printed in the warning message.

An exception must be set when calling this function.

Raising exceptions
These functions help you set the current thread’s error indicator. For convenience, some of these functions will always return a NULL pointer for use in a return statement.

void PyErr_SetString(PyObject *type, const char *message)
Part of the Stable ABI.
This is the most common way to set the error indicator. The first argument specifies the exception type; it is normally one of the standard exceptions, e.g. PyExc_RuntimeError. You need not increment its reference count. The second argument is an error message; it is decoded from 'utf-8'.

void PyErr_SetObject(PyObject *type, PyObject *value)
Part of the Stable ABI.
This function is similar to PyErr_SetString() but lets you specify an arbitrary Python object for the “value” of the exception.

PyObject *PyErr_Format(PyObject *exception, const char *format, ...)
Return value: Always NULL. Part of the Stable ABI.
This function sets the error indicator and returns NULL. exception should be a Python exception class. The format and subsequent parameters help format the error message; they have the same meaning and values as in PyUnicode_FromFormat(). format is an ASCII-encoded string.

PyObject *PyErr_FormatV(PyObject *exception, const char *format, va_list vargs)
Return value: Always NULL. Part of the Stable ABI since version 3.5.
Same as PyErr_Format(), but taking a va_list argument rather than a variable number of arguments.

New in version 3.5.

void PyErr_SetNone(PyObject *type)
Part of the Stable ABI.
This is a shorthand for PyErr_SetObject(type, Py_None).

int PyErr_BadArgument()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_TypeError, message), where message indicates that a built-in operation was invoked with an illegal argument. It is mostly for internal use.

PyObject *PyErr_NoMemory()
Return value: Always NULL. Part of the Stable ABI.
This is a shorthand for PyErr_SetNone(PyExc_MemoryError); it returns NULL so an object allocation function can write return PyErr_NoMemory(); when it runs out of memory.

PyObject *PyErr_SetFromErrno(PyObject *type)
Return value: Always NULL. Part of the Stable ABI.
This is a convenience function to raise an exception when a C library function has returned an error and set the C variable errno. It constructs a tuple object whose first item is the integer errno value and whose second item is the corresponding error message (gotten from strerror()), and then calls PyErr_SetObject(type, object). On Unix, when the errno value is EINTR, indicating an interrupted system call, this calls PyErr_CheckSignals(), and if that set the error indicator, leaves it set to that. The function always returns NULL, so a wrapper function around a system call can write return PyErr_SetFromErrno(type); when the system call returns an error.

PyObject *PyErr_SetFromErrnoWithFilenameObject(PyObject *type, PyObject *filenameObject)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrno(), with the additional behavior that if filenameObject is not NULL, it is passed to the constructor of type as a third parameter. In the case of OSError exception, this is used to define the filename attribute of the exception instance.

PyObject *PyErr_SetFromErrnoWithFilenameObjects(PyObject *type, PyObject *filenameObject, PyObject *filenameObject2)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but takes a second filename object, for raising errors when a function that takes two filenames fails.

New in version 3.4.

PyObject *PyErr_SetFromErrnoWithFilename(PyObject *type, const char *filename)
Return value: Always NULL. Part of the Stable ABI.
Similar to PyErr_SetFromErrnoWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding and error handler.

PyObject *PyErr_SetFromWindowsErr(int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
This is a convenience function to raise WindowsError. If called with ierr of 0, the error code returned by a call to GetLastError() is used instead. It calls the Win32 function FormatMessage() to retrieve the Windows description of error code given by ierr or GetLastError(), then it constructs a tuple object whose first item is the ierr value and whose second item is the corresponding error message (gotten from FormatMessage()), and then calls PyErr_SetObject(PyExc_WindowsError, object). This function always returns NULL.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErr(PyObject *type, int ierr)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErr(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetFromWindowsErrWithFilename(int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), but the filename is given as a C string. filename is decoded from the filesystem encoding (os.fsdecode()).

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObject(PyObject *type, int ierr, PyObject *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilenameObject(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetExcFromWindowsErrWithFilenameObjects(PyObject *type, int ierr, PyObject *filename, PyObject *filename2)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetExcFromWindowsErrWithFilenameObject(), but accepts a second filename object.

Availability: Windows.

New in version 3.4.

PyObject *PyErr_SetExcFromWindowsErrWithFilename(PyObject *type, int ierr, const char *filename)
Return value: Always NULL. Part of the Stable ABI on Windows since version 3.7.
Similar to PyErr_SetFromWindowsErrWithFilename(), with an additional parameter specifying the exception type to be raised.

Availability: Windows.

PyObject *PyErr_SetImportError(PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.7.
This is a convenience function to raise ImportError. msg will be set as the exception’s message string. name and path, both of which can be NULL, will be set as the ImportError’s respective name and path attributes.

New in version 3.3.

PyObject *PyErr_SetImportErrorSubclass(PyObject *exception, PyObject *msg, PyObject *name, PyObject *path)
Return value: Always NULL. Part of the Stable ABI since version 3.6.
Much like PyErr_SetImportError() but this function allows for specifying a subclass of ImportError to raise.

New in version 3.6.

void PyErr_SyntaxLocationObject(PyObject *filename, int lineno, int col_offset)
Set file, line, and offset information for the current exception. If the current exception is not a SyntaxError, then it sets additional attributes, which make the exception printing subsystem think the exception is a SyntaxError.

New in version 3.4.

void PyErr_SyntaxLocationEx(const char *filename, int lineno, int col_offset)
Part of the Stable ABI since version 3.7.
Like PyErr_SyntaxLocationObject(), but filename is a byte string decoded from the filesystem encoding and error handler.

New in version 3.2.

void PyErr_SyntaxLocation(const char *filename, int lineno)
Part of the Stable ABI.
Like PyErr_SyntaxLocationEx(), but the col_offset parameter is omitted.

void PyErr_BadInternalCall()
Part of the Stable ABI.
This is a shorthand for PyErr_SetString(PyExc_SystemError, message), where message indicates that an internal operation (e.g. a Python/C API function) was invoked with an illegal argument. It is mostly for internal use.

Issuing warnings
Use these functions to issue warnings from C code. They mirror similar functions exported by the Python warnings module. They normally print a warning message to sys.stderr; however, it is also possible that the user has specified that warnings are to be turned into errors, and in that case they will raise an exception. It is also possible that the functions raise an exception because of a problem with the warning machinery. The return value is 0 if no exception is raised, or -1 if an exception is raised. (It is not possible to determine whether a warning message is actually printed, nor what the reason is for the exception; this is intentional.) If an exception is raised, the caller should do its normal exception handling (for example, Py_DECREF() owned references and return an error value).

int PyErr_WarnEx(PyObject *category, const char *message, Py_ssize_t stack_level)
Part of the Stable ABI.
Issue a warning message. The category argument is a warning category (see below) or NULL; the message argument is a UTF-8 encoded string. stack_level is a positive number giving a number of stack frames; the warning will be issued from the currently executing line of code in that stack frame. A stack_level of 1 is the function calling PyErr_WarnEx(), 2 is the function above that, and so forth.

Warning categories must be subclasses of PyExc_Warning; PyExc_Warning is a subclass of PyExc_Exception; the default warning category is PyExc_RuntimeWarning. The standard Python warning categories are available as global variables whose names are enumerated at Standard Warning Categories.

For information about warning control, see the documentation for the warnings module and the -W option in the command line documentation. There is no C API for warning control.

int PyErr_WarnExplicitObject(PyObject *category, PyObject *message, PyObject *filename, int lineno, PyObject *module, PyObject *registry)
Issue a warning message with explicit control over all warning attributes. This is a straightforward wrapper around the Python function warnings.warn_explicit(); see there for more information. The module and registry arguments may be set to NULL to get the default effect described there.

New in version 3.4.

int PyErr_WarnExplicit(PyObject *category, const char *message, const char *filename, int lineno, const char *module, PyObject *registry)
Part of the Stable ABI.
Similar to PyErr_WarnExplicitObject() except that message and module are UTF-8 encoded strings, and filename is decoded from the filesystem encoding and error handler.

int PyErr_WarnFormat(PyObject *category, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI.
Function similar to PyErr_WarnEx(), but use PyUnicode_FromFormat() to format the warning message. format is an ASCII-encoded string.

New in version 3.2.

int PyErr_ResourceWarning(PyObject *source, Py_ssize_t stack_level, const char *format, ...)
Part of the Stable ABI since version 3.6.
Function similar to PyErr_WarnFormat(), but category is ResourceWarning and it passes source to warnings.WarningMessage().

New in version 3.6.

Querying the error indicator
PyObject *PyErr_Occurred()
Return value: Borrowed reference. Part of the Stable ABI.
Test whether the error indicator is set. If set, return the exception type (the first argument to the last call to one of the PyErr_Set* functions or to PyErr_Restore()). If not set, return NULL. You do not own a reference to the return value, so you do not need to Py_DECREF() it.

The caller must hold the GIL.

Note Do not compare the return value to a specific exception; use PyErr_ExceptionMatches() instead, shown below. (The comparison could easily fail since the exception may be an instance instead of a class, in the case of a class exception, or it may be a subclass of the expected exception.)
int PyErr_ExceptionMatches(PyObject *exc)
Part of the Stable ABI.
Equivalent to PyErr_GivenExceptionMatches(PyErr_Occurred(), exc). This should only be called when an exception is actually set; a memory access violation will occur if no exception has been raised.

int PyErr_GivenExceptionMatches(PyObject *given, PyObject *exc)
Part of the Stable ABI.
Return true if the given exception matches the exception type in exc. If exc is a class object, this also returns true when given is an instance of a subclass. If exc is a tuple, all exception types in the tuple (and recursively in subtuples) are searched for a match.

void PyErr_Fetch(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI.
Retrieve the error indicator into three variables whose addresses are passed. If the error indicator is not set, set all three variables to NULL. If it is set, it will be cleared and you own a reference to each object retrieved. The value and traceback object may be NULL even when the type object is not.

Note This function is normally only used by code that needs to catch exceptions or by code that needs to save and restore the error indicator temporarily, e.g.:
{
   PyObject *type, *value, *traceback;
   PyErr_Fetch(&type, &value, &traceback);

   /* ... code that might produce other errors ... */

   PyErr_Restore(type, value, traceback);
}
void PyErr_Restore(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI.
Set the error indicator from the three objects. If the error indicator is already set, it is cleared first. If the objects are NULL, the error indicator is cleared. Do not pass a NULL type and non-NULL value or traceback. The exception type should be a class. Do not pass an invalid exception type or value. (Violating these rules will cause subtle problems later.) This call takes away a reference to each object: you must own a reference to each object before the call and after the call you no longer own these references. (If you don’t understand this, don’t use this function. I warned you.)

Note This function is normally only used by code that needs to save and restore the error indicator temporarily. Use PyErr_Fetch() to save the current error indicator.
void PyErr_NormalizeException(PyObject **exc, PyObject **val, PyObject **tb)
Part of the Stable ABI.
Under certain circumstances, the values returned by PyErr_Fetch() below can be “unnormalized”, meaning that *exc is a class object but *val is not an instance of the same class. This function can be used to instantiate the class in that case. If the values are already normalized, nothing happens. The delayed normalization is implemented to improve performance.

Note This function does not implicitly set the __traceback__ attribute on the exception value. If setting the traceback appropriately is desired, the following additional snippet is needed:
if (tb != NULL) {
  PyException_SetTraceback(val, tb);
}
void PyErr_GetExcInfo(PyObject **ptype, PyObject **pvalue, PyObject **ptraceback)
Part of the Stable ABI since version 3.7.
Retrieve the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. Returns new references for the three objects, any of which may be NULL. Does not modify the exception info state.

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_SetExcInfo() to restore or clear the exception state.
New in version 3.3.

void PyErr_SetExcInfo(PyObject *type, PyObject *value, PyObject *traceback)
Part of the Stable ABI since version 3.7.
Set the exception info, as known from sys.exc_info(). This refers to an exception that was already caught, not to an exception that was freshly raised. This function steals the references of the arguments. To clear the exception state, pass NULL for all three arguments. For general rules about the three arguments, see PyErr_Restore().

Note This function is not normally used by code that wants to handle exceptions. Rather, it can be used when code needs to save and restore the exception state temporarily. Use PyErr_GetExcInfo() to read the exception state.
New in version 3.3.

Signal Handling
int PyErr_CheckSignals()
Part of the Stable ABI.
This function interacts with Python’s signal handling.

If the function is called from the main thread and under the main Python interpreter, it checks whether a signal has been sent to the processes and if so, invokes the corresponding signal handler. If the signal module is supported, this can invoke a signal handler written in Python.

The function attempts to handle all pending signals, and then returns 0. However, if a Python signal handler raises an exception, the error indicator is set and the function returns -1 immediately (such that other pending signals may not have been handled yet: they will be on the next PyErr_CheckSignals() invocation).

If the function is called from a non-main thread, or under a non-main Python interpreter, it does nothing and returns 0.

This function can be called by long-running C code that wants to be interruptible by user requests (such as by pressing Ctrl-C).

Note The default Python signal handler for SIGINT raises the KeyboardInterrupt exception.
void PyErr_SetInterrupt()
Part of the Stable ABI.
Simulate the effect of a SIGINT signal arriving. This is equivalent to PyErr_SetInterruptEx(SIGINT).

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
int PyErr_SetInterruptEx(int signum)
Part of the Stable ABI since version 3.10.
Simulate the effect of a signal arriving. The next time PyErr_CheckSignals() is called, the Python signal handler for the given signal number will be called.

This function can be called by C code that sets up its own signal handling and wants Python signal handlers to be invoked as expected when an interruption is requested (for example when the user presses Ctrl-C to interrupt an operation).

If the given signal isn’t handled by Python (it was set to signal.SIG_DFL or signal.SIG_IGN), it will be ignored.

If signum is outside of the allowed range of signal numbers, -1 is returned. Otherwise, 0 is returned. The error indicator is never changed by this function.

Note This function is async-signal-safe. It can be called without the GIL and from a C signal handler.
New in version 3.10.

int PySignal_SetWakeupFd(int fd)
This utility function specifies a file descriptor to which the signal number is written as a single byte whenever a signal is received. fd must be non-blocking. It returns the previous such file descriptor.

The value -1 disables the feature; this is the initial state. This is equivalent to signal.set_wakeup_fd() in Python, but without any error checking. fd should be a valid file descriptor. The function should only be called from the main thread.

Changed in version 3.5: On Windows, the function now also supports socket handles.

Exception Classes
PyObject *PyErr_NewException(const char *name, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
This utility function creates and returns a new exception class. The name argument must be the name of the new exception, a C string of the form module.classname. The base and dict arguments are normally NULL. This creates a class object derived from Exception (accessible in C as PyExc_Exception).

The __module__ attribute of the new class is set to the first part (up to the last dot) of the name argument, and the class name is set to the last part (after the last dot). The base argument can be used to specify alternate base classes; it can either be only one class or a tuple of classes. The dict argument can be used to specify a dictionary of class variables and methods.

PyObject *PyErr_NewExceptionWithDoc(const char *name, const char *doc, PyObject *base, PyObject *dict)
Return value: New reference. Part of the Stable ABI.
Same as PyErr_NewException(), except that the new exception class can easily be given a docstring: If doc is non-NULL, it will be used as the docstring for the exception class.

New in version 3.2.

Exception Objects
PyObject *PyException_GetTraceback(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the traceback associated with the exception as a new reference, as accessible from Python through __traceback__. If there is no traceback associated, this returns NULL.

int PyException_SetTraceback(PyObject *ex, PyObject *tb)
Part of the Stable ABI.
Set the traceback associated with the exception to tb. Use Py_None to clear it.

PyObject *PyException_GetContext(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the context (another exception instance during whose handling ex was raised) associated with the exception as a new reference, as accessible from Python through __context__. If there is no context associated, this returns NULL.

void PyException_SetContext(PyObject *ex, PyObject *ctx)
Part of the Stable ABI.
Set the context associated with the exception to ctx. Use NULL to clear it. There is no type check to make sure that ctx is an exception instance. This steals a reference to ctx.

PyObject *PyException_GetCause(PyObject *ex)
Return value: New reference. Part of the Stable ABI.
Return the cause (either an exception instance, or None, set by raise ... from ...) associated with the exception as a new reference, as accessible from Python through __cause__.

void PyException_SetCause(PyObject *ex, PyObject *cause)
Part of the Stable ABI.
Set the cause associated with the exception to cause. Use NULL to clear it. There is no type check to make sure that cause is either an exception instance or None. This steals a reference to cause.

__suppress_context__ is implicitly set to True by this function.

Unicode Exception Objects
The following functions are used to create and modify Unicode exceptions from C.

PyObject *PyUnicodeDecodeError_Create(const char *encoding, const char *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference. Part of the Stable ABI.
Create a UnicodeDecodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

PyObject *PyUnicodeEncodeError_Create(const char *encoding, const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeEncodeError object with the attributes encoding, object, length, start, end and reason. encoding and reason are UTF-8 encoded strings.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeEncodeError, "sOnns", ...).

PyObject *PyUnicodeTranslateError_Create(const Py_UNICODE *object, Py_ssize_t length, Py_ssize_t start, Py_ssize_t end, const char *reason)
Return value: New reference.
Create a UnicodeTranslateError object with the attributes object, length, start, end and reason. reason is a UTF-8 encoded string.

Deprecated since version 3.3: 3.11

Py_UNICODE is deprecated since Python 3.3. Please migrate to PyObject_CallFunction(PyExc_UnicodeTranslateError, "Onns", ...).

PyObject *PyUnicodeDecodeError_GetEncoding(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetEncoding(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the encoding attribute of the given exception object.

PyObject *PyUnicodeDecodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetObject(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetObject(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the object attribute of the given exception object.

int PyUnicodeDecodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeEncodeError_GetStart(PyObject *exc, Py_ssize_t *start)
int PyUnicodeTranslateError_GetStart(PyObject *exc, Py_ssize_t *start)
Part of the Stable ABI.
Get the start attribute of the given exception object and place it into *start. start must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeEncodeError_SetStart(PyObject *exc, Py_ssize_t start)
int PyUnicodeTranslateError_SetStart(PyObject *exc, Py_ssize_t start)
Part of the Stable ABI.
Set the start attribute of the given exception object to start. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeEncodeError_GetEnd(PyObject *exc, Py_ssize_t *end)
int PyUnicodeTranslateError_GetEnd(PyObject *exc, Py_ssize_t *end)
Part of the Stable ABI.
Get the end attribute of the given exception object and place it into *end. end must not be NULL. Return 0 on success, -1 on failure.

int PyUnicodeDecodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeEncodeError_SetEnd(PyObject *exc, Py_ssize_t end)
int PyUnicodeTranslateError_SetEnd(PyObject *exc, Py_ssize_t end)
Part of the Stable ABI.
Set the end attribute of the given exception object to end. Return 0 on success, -1 on failure.

PyObject *PyUnicodeDecodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeEncodeError_GetReason(PyObject *exc)
PyObject *PyUnicodeTranslateError_GetReason(PyObject *exc)
Return value: New reference. Part of the Stable ABI.
Return the reason attribute of the given exception object.

int PyUnicodeDecodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeEncodeError_SetReason(PyObject *exc, const char *reason)
int PyUnicodeTranslateError_SetReason(PyObject *exc, const char *reason)
Part of the Stable ABI.
Set the reason attribute of the given exception object to reason. Return 0 on success, -1 on failure.

Recursion Control
These two functions provide a way to perform safe recursive calls at the C level, both in the core and in extension modules. They are needed if the recursive code does not necessarily invoke Python code (which tracks its recursion depth automatically). They are also not needed for tp_call implementations because the call protocol takes care of recursion handling.

int Py_EnterRecursiveCall(const char *where)
Part of the Stable ABI since version 3.9.
Marks a point where a recursive C-level call is about to be performed.

If USE_STACKCHECK is defined, this function checks if the OS stack overflowed using PyOS_CheckStack(). In this is the case, it sets a MemoryError and returns a nonzero value.

The function then checks if the recursion limit is reached. If this is the case, a RecursionError is set and a nonzero value is returned. Otherwise, zero is returned.

where should be a UTF-8 encoded string such as " in instance check" to be concatenated to the RecursionError message caused by the recursion depth limit.

Changed in version 3.9: This function is now also available in the limited API.

void Py_LeaveRecursiveCall(void)
Part of the Stable ABI since version 3.9.
Ends a Py_EnterRecursiveCall(). Must be called once for each successful invocation of Py_EnterRecursiveCall().

Changed in version 3.9: This function is now also available in the limited API.

Properly implementing tp_repr for container types requires special recursion handling. In addition to protecting the stack, tp_repr also needs to track objects to prevent cycles. The following two functions facilitate this functionality. Effectively, these are the C equivalent to reprlib.recursive_repr().

int Py_ReprEnter(PyObject *object)
Part of the Stable ABI.
Called at the beginning of the tp_repr implementation to detect cycles.

If the object has already been processed, the function returns a positive integer. In that case the tp_repr implementation should return a string object indicating a cycle. As examples, dict objects return {...} and list objects return [...].

The function will return a negative integer if the recursion limit is reached. In that case the tp_repr implementation should typically return NULL.

Otherwise, the function returns zero and the tp_repr implementation can continue normally.

void Py_ReprLeave(PyObject *object)
Part of the Stable ABI.
Ends a Py_ReprEnter(). Must be called once for each invocation of Py_ReprEnter() that returns zero.

Standard Exceptions
All standard Python exceptions are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_BaseException

BaseException

1

PyExc_Exception

Exception

1

PyExc_ArithmeticError

ArithmeticError

1

PyExc_AssertionError

AssertionError

PyExc_AttributeError

AttributeError

PyExc_BlockingIOError

BlockingIOError

PyExc_BrokenPipeError

BrokenPipeError

PyExc_BufferError

BufferError

PyExc_ChildProcessError

ChildProcessError

PyExc_ConnectionAbortedError

ConnectionAbortedError

PyExc_ConnectionError

ConnectionError

PyExc_ConnectionRefusedError

ConnectionRefusedError

PyExc_ConnectionResetError

ConnectionResetError

PyExc_EOFError

EOFError

PyExc_FileExistsError

FileExistsError

PyExc_FileNotFoundError

FileNotFoundError

PyExc_FloatingPointError

FloatingPointError

PyExc_GeneratorExit

GeneratorExit

PyExc_ImportError

ImportError

PyExc_IndentationError

IndentationError

PyExc_IndexError

IndexError

PyExc_InterruptedError

InterruptedError

PyExc_IsADirectoryError

IsADirectoryError

PyExc_KeyError

KeyError

PyExc_KeyboardInterrupt

KeyboardInterrupt

PyExc_LookupError

LookupError

1

PyExc_MemoryError

MemoryError

PyExc_ModuleNotFoundError

ModuleNotFoundError

PyExc_NameError

NameError

PyExc_NotADirectoryError

NotADirectoryError

PyExc_NotImplementedError

NotImplementedError

PyExc_OSError

OSError

1

PyExc_OverflowError

OverflowError

PyExc_PermissionError

PermissionError

PyExc_ProcessLookupError

ProcessLookupError

PyExc_RecursionError

RecursionError

PyExc_ReferenceError

ReferenceError

PyExc_RuntimeError

RuntimeError

PyExc_StopAsyncIteration

StopAsyncIteration

PyExc_StopIteration

StopIteration

PyExc_SyntaxError

SyntaxError

PyExc_SystemError

SystemError

PyExc_SystemExit

SystemExit

PyExc_TabError

TabError

PyExc_TimeoutError

TimeoutError

PyExc_TypeError

TypeError

PyExc_UnboundLocalError

UnboundLocalError

PyExc_UnicodeDecodeError

UnicodeDecodeError

PyExc_UnicodeEncodeError

UnicodeEncodeError

PyExc_UnicodeError

UnicodeError

PyExc_UnicodeTranslateError

UnicodeTranslateError

PyExc_ValueError

ValueError

PyExc_ZeroDivisionError

ZeroDivisionError

New in version 3.3: PyExc_BlockingIOError, PyExc_BrokenPipeError, PyExc_ChildProcessError, PyExc_ConnectionError, PyExc_ConnectionAbortedError, PyExc_ConnectionRefusedError, PyExc_ConnectionResetError, PyExc_FileExistsError, PyExc_FileNotFoundError, PyExc_InterruptedError, PyExc_IsADirectoryError, PyExc_NotADirectoryError, PyExc_PermissionError, PyExc_ProcessLookupError and PyExc_TimeoutError were introduced following PEP 3151.

New in version 3.5: PyExc_StopAsyncIteration and PyExc_RecursionError.

New in version 3.6: PyExc_ModuleNotFoundError.

These are compatibility aliases to PyExc_OSError:

C Name

Notes

PyExc_EnvironmentError

PyExc_IOError

PyExc_WindowsError

2

Changed in version 3.3: These aliases used to be separate exception types.

Notes:

1(1,2,3,4,5)
This is a base class for other standard exceptions.

2
Only defined on Windows; protect code that uses this by testing that the preprocessor macro MS_WINDOWS is defined.

Standard Warning Categories
All standard Python warning categories are available as global variables whose names are PyExc_ followed by the Python exception name. These have the type PyObject*; they are all class objects. For completeness, here are all the variables:

C Name

Python Name

Notes

PyExc_Warning

Warning

3

PyExc_BytesWarning

BytesWarning

PyExc_DeprecationWarning

DeprecationWarning

PyExc_FutureWarning

FutureWarning

PyExc_ImportWarning

ImportWarning

PyExc_PendingDeprecationWarning

PendingDeprecationWarning

PyExc_ResourceWarning

ResourceWarning

PyExc_RuntimeWarning

RuntimeWarning

PyExc_SyntaxWarning

SyntaxWarning

PyExc_UnicodeWarning

UnicodeWarning

PyExc_UserWarning

UserWarning

New in version 3.2: PyExc_ResourceWarning.

Notes:

3
This is a base class for other standard warning categories.

Table of Contents
Exception Handling
Printing and clearing
Raising exceptions
Issuing warnings
Querying the error indicator
Signal Handling
Exception Classes
Exception Objects
Unicode Exception Objects
Recursion Control
Standard Exceptions
Standard Warning Categories
Previous topic
Reference Counting

Next topic
Utilities

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python/C API Reference Manual » Exception Handling
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python Module Index
Quick search
  |
Python Module Index
_ | a | b | c | d | e | f | g | h | i | j | k | l | m | n | o | p | q | r | s | t | u | v | w | x | z
 	
_	
__future__	Future statement definitions
__main__	The environment where top-level code is run. Covers command-line interfaces, import-time behavior, and ``__name__ == '__main__'``.
_thread	Low-level threading API.
 	
a	
abc	Abstract base classes according to :pep:`3119`.
aifc	Deprecated: Read and write audio files in AIFF or AIFC format.
argparse	Command-line option and argument parsing library.
array	Space efficient arrays of uniformly typed numeric values.
ast	Abstract Syntax Tree classes and manipulation.
asynchat	Deprecated: Support for asynchronous command/response protocols.
asyncio	Asynchronous I/O.
asyncore	Deprecated: A base class for developing asynchronous socket handling services.
atexit	Register and execute cleanup functions.
audioop	Deprecated: Manipulate raw audio data.
 	
b	
base64	RFC 4648: Base16, Base32, Base64 Data Encodings; Base85 and Ascii85
bdb	Debugger framework.
binascii	Tools for converting between binary and various ASCII-encoded binary representations.
binhex	Encode and decode files in binhex4 format.
bisect	Array bisection algorithms for binary searching.
builtins	The module that provides the built-in namespace.
bz2	Interfaces for bzip2 compression and decompression.
 	
c	
calendar	Functions for working with calendars, including some emulation of the Unix cal program.
cgi	Deprecated: Helpers for running Python scripts via the Common Gateway Interface.
cgitb	Deprecated: Configurable traceback handler for CGI scripts.
chunk	Deprecated: Module to read IFF chunks.
cmath	Mathematical functions for complex numbers.
cmd	Build line-oriented command interpreters.
code	Facilities to implement read-eval-print loops.
codecs	Encode and decode data and streams.
codeop	Compile (possibly incomplete) Python code.
-	collections	Container datatypes
colorsys	Conversion functions between RGB and other color systems.
compileall	Tools for byte-compiling all Python source files in a directory tree.
-	concurrent	
configparser	Configuration file parser.
contextlib	Utilities for with-statement contexts.
contextvars	Context Variables
copy	Shallow and deep copy operations.
copyreg	Register pickle support functions.
cProfile	
crypt (Unix)	Deprecated: The crypt() function used to check Unix passwords.
csv	Write and read tabular data to and from delimited files.
ctypes	A foreign function library for Python.
-	curses (Unix)	An interface to the curses library, providing portable terminal handling.
 	
d	
dataclasses	Generate special methods on user-defined classes.
datetime	Basic date and time types.
-	dbm	Interfaces to various Unix "database" formats.
decimal	Implementation of the General Decimal Arithmetic Specification.
difflib	Helpers for computing differences between objects.
dis	Disassembler for Python bytecode.
-	distutils	Support for building and installing Python modules into an existing Python installation.
doctest	Test pieces of code within docstrings.
 	
e	
-	email	Package supporting the parsing, manipulating, and generating email messages.
-	encodings	
ensurepip	Bootstrapping the "pip" installer into an existing Python installation or virtual environment.
enum	Implementation of an enumeration class.
errno	Standard errno system symbols.
 	
f	
faulthandler	Dump the Python traceback.
fcntl (Unix)	The fcntl() and ioctl() system calls.
filecmp	Compare files efficiently.
fileinput	Loop over standard input or a list of files.
fnmatch	Unix shell style filename pattern matching.
fractions	Rational numbers.
ftplib	FTP protocol client (requires sockets).
functools	Higher-order functions and operations on callable objects.
 	
g	
gc	Interface to the cycle-detecting garbage collector.
getopt	Portable parser for command line options; support both short and long option names.
getpass	Portable reading of passwords and retrieval of the userid.
gettext	Multilingual internationalization services.
glob	Unix shell style pathname pattern expansion.
graphlib	Functionality to operate with graph-like structures
grp (Unix)	The group database (getgrnam() and friends).
gzip	Interfaces for gzip compression and decompression using file objects.
 	
h	
hashlib	Secure hash and message digest algorithms.
heapq	Heap queue algorithm (a.k.a. priority queue).
hmac	Keyed-Hashing for Message Authentication (HMAC) implementation
-	html	Helpers for manipulating HTML.
-	http	HTTP status codes and messages
 	
i	
idlelib	Implementation package for the IDLE shell/editor.
imaplib	IMAP4 protocol client (requires sockets).
imghdr	Deprecated: Determine the type of image contained in a file or byte stream.
imp	Deprecated: Access the implementation of the import statement.
-	importlib	The implementation of the import machinery.
inspect	Extract information and source code from live objects.
io	Core tools for working with streams.
ipaddress	IPv4/IPv6 manipulation library.
itertools	Functions creating iterators for efficient looping.
 	
j	
-	json	Encode and decode the JSON format.
 	
k	
keyword	Test whether a string is a keyword in Python.
 	
l	
lib2to3	The 2to3 library
linecache	Provides random access to individual lines from text files.
locale	Internationalization services.
-	logging	Flexible event logging system for applications.
lzma	A Python wrapper for the liblzma compression library.
 	
m	
mailbox	Manipulate mailboxes in various formats
mailcap	Deprecated: Mailcap file handling.
marshal	Convert Python objects to streams of bytes and back (with different constraints).
math	Mathematical functions (sin() etc.).
mimetypes	Mapping of filename extensions to MIME types.
mmap	Interface to memory-mapped files for Unix and Windows.
modulefinder	Find modules used by a script.
msilib (Windows)	Deprecated: Creation of Microsoft Installer files, and CAB files.
msvcrt (Windows)	Miscellaneous useful routines from the MS VC++ runtime.
-	multiprocessing	Process-based parallelism.
 	
n	
netrc	Loading of .netrc files.
nis (Unix)	Deprecated: Interface to Sun's NIS (Yellow Pages) library.
nntplib	Deprecated: NNTP protocol client (requires sockets).
numbers	Numeric abstract base classes (Complex, Real, Integral, etc.).
 	
o	
operator	Functions corresponding to the standard operators.
optparse	Deprecated: Command-line option parsing library.
-	os	Miscellaneous operating system interfaces.
ossaudiodev (Linux, FreeBSD)	Deprecated: Access to OSS-compatible audio devices.
 	
p	
pathlib	Object-oriented filesystem paths
pdb	The Python debugger for interactive interpreters.
pickle	Convert Python objects to streams of bytes and back.
pickletools	Contains extensive comments about the pickle protocols and pickle-machine opcodes, as well as some useful functions.
pipes (Unix)	Deprecated: A Python interface to Unix shell pipelines.
pkgutil	Utilities for the import system.
platform	Retrieves as much platform identifying data as possible.
plistlib	Generate and parse Apple plist files.
poplib	POP3 protocol client (requires sockets).
posix (Unix)	The most common POSIX system calls (normally used via module os).
pprint	Data pretty printer.
profile	Python source profiler.
pstats	Statistics object for use with the profiler.
pty (Unix)	Pseudo-Terminal Handling for Unix.
pwd (Unix)	The password database (getpwnam() and friends).
py_compile	Generate byte-code files from Python source files.
pyclbr	Supports information extraction for a Python module browser.
pydoc	Documentation generator and online help system.
 	
q	
queue	A synchronized queue class.
quopri	Encode and decode files using the MIME quoted-printable encoding.
 	
r	
random	Generate pseudo-random numbers with various common distributions.
re	Regular expression operations.
readline (Unix)	GNU readline support for Python.
reprlib	Alternate repr() implementation with size limits.
resource (Unix)	An interface to provide resource usage information on the current process.
rlcompleter	Python identifier completion, suitable for the GNU readline library.
runpy	Locate and run Python modules without importing them first.
 	
s	
sched	General purpose event scheduler.
secrets	Generate secure random numbers for managing secrets.
select	Wait for I/O completion on multiple streams.
selectors	High-level I/O multiplexing.
shelve	Python object persistence.
shlex	Simple lexical analysis for Unix shell-like languages.
shutil	High-level file operations, including copying.
signal	Set handlers for asynchronous events.
site	Module responsible for site-specific configuration.
smtpd	Deprecated: A SMTP server implementation in Python.
smtplib	SMTP protocol client (requires sockets).
sndhdr	Deprecated: Determine type of a sound file.
socket	Low-level networking interface.
socketserver	A framework for network servers.
spwd (Unix)	Deprecated: The shadow password database (getspnam() and friends).
sqlite3	A DB-API 2.0 implementation using SQLite 3.x.
ssl	TLS/SSL wrapper for socket objects
stat	Utilities for interpreting the results of os.stat(), os.lstat() and os.fstat().
statistics	Mathematical statistics functions
string	Common string operations.
stringprep	String preparation, as per RFC 3453
struct	Interpret bytes as packed binary data.
subprocess	Subprocess management.
sunau	Deprecated: Provide an interface to the Sun AU sound format.
symtable	Interface to the compiler's internal symbol tables.
sys	Access system-specific parameters and functions.
sysconfig	Python's configuration information
syslog (Unix)	An interface to the Unix syslog library routines.
 	
t	
tabnanny	Tool for detecting white space related problems in Python source files in a directory tree.
tarfile	Read and write tar-format archive files.
telnetlib	Deprecated: Telnet client class.
tempfile	Generate temporary files and directories.
termios (Unix)	POSIX style tty control.
-	test	Regression tests package containing the testing suite for Python.
textwrap	Text wrapping and filling
threading	Thread-based parallelism.
time	Time access and conversions.
timeit	Measure the execution time of small code snippets.
-	tkinter	Interface to Tcl/Tk for graphical user interfaces
token	Constants representing terminal nodes of the parse tree.
tokenize	Lexical scanner for Python source code.
trace	Trace or track Python statement execution.
traceback	Print or retrieve a stack traceback.
tracemalloc	Trace memory allocations.
tty (Unix)	Utility functions that perform common terminal control operations.
turtle	An educational framework for simple graphics applications
turtledemo	A viewer for example turtle scripts
types	Names for built-in types.
typing	Support for type hints (see :pep:`484`).
 	
u	
unicodedata	Access the Unicode Database.
-	unittest	Unit testing framework for Python.
-	urllib	
uu	Deprecated: Encode and decode files in uuencode format.
uuid	UUID objects (universally unique identifiers) according to RFC 4122
 	
v	
venv	Creation of virtual environments.
 	
w	
warnings	Issue warning messages and control their disposition.
wave	Provide an interface to the WAV sound format.
weakref	Support for weak references and weak dictionaries.
webbrowser	Easy-to-use controller for web browsers.
winreg (Windows)	Routines and objects for manipulating the Windows registry.
winsound (Windows)	Access to the sound-playing machinery for Windows.
-	wsgiref	WSGI Utilities and Reference Implementation.
 	
x	
xdrlib	Deprecated: Encoders and decoders for the External Data Representation (XDR).
-	xml	Package containing XML processing modules
-	xmlrpc	
 	
z	
zipapp	Manage executable Python zip archives
zipfile	Read and write ZIP-format archive files.
zipimport	Support for importing Python modules from ZIP archives.
zlib	Low-level interface to compression and decompression routines compatible with gzip.
zoneinfo	IANA time zone support
«
indexmodules |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python Module Index
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python Documentation contents
Quick search
  |
Python Documentation contents
What’s New in Python
What’s New In Python 3.10
Summary – Release highlights
New Features
Parenthesized context managers
Better error messages
SyntaxErrors
IndentationErrors
AttributeErrors
NameErrors
PEP 626: Precise line numbers for debugging and other tools
PEP 634: Structural Pattern Matching
Syntax and operations
Declarative approach
Simple pattern: match to a literal
Behavior without the wildcard
Patterns with a literal and variable
Patterns and classes
Patterns with positional parameters
Nested patterns
Complex patterns and the wildcard
Guard
Other Key Features
Optional EncodingWarning and encoding="locale" option
New Features Related to Type Hints
PEP 604: New Type Union Operator
PEP 612: Parameter Specification Variables
PEP 613: TypeAlias
PEP 647: User-Defined Type Guards
Other Language Changes
New Modules
Improved Modules
asyncio
argparse
array
asynchat, asyncore, smtpd
base64
bdb
bisect
codecs
collections.abc
contextlib
curses
dataclasses
__slots__
Keyword-only fields
distutils
doctest
encodings
fileinput
faulthandler
gc
glob
hashlib
hmac
IDLE and idlelib
importlib.metadata
inspect
itertools
linecache
os
os.path
pathlib
platform
pprint
py_compile
pyclbr
shelve
statistics
site
socket
ssl
sqlite3
sys
_thread
threading
traceback
types
typing
unittest
urllib.parse
xml
zipimport
Optimizations
Deprecated
Removed
Porting to Python 3.10
Changes in the Python syntax
Changes in the Python API
Changes in the C API
CPython bytecode changes
Build Changes
C API Changes
PEP 652: Maintaining the Stable ABI
New Features
Porting to Python 3.10
Deprecated
Removed
Notable security feature in 3.10.7
Notable security feature in 3.10.8
What’s New In Python 3.9
Summary – Release highlights
You should check for DeprecationWarning in your code
New Features
Dictionary Merge & Update Operators
New String Methods to Remove Prefixes and Suffixes
Type Hinting Generics in Standard Collections
New Parser
Other Language Changes
New Modules
zoneinfo
graphlib
Improved Modules
ast
asyncio
compileall
concurrent.futures
curses
datetime
distutils
fcntl
ftplib
gc
hashlib
http
IDLE and idlelib
imaplib
importlib
inspect
ipaddress
math
multiprocessing
nntplib
os
pathlib
pdb
poplib
pprint
pydoc
random
signal
smtplib
socket
time
sys
tracemalloc
typing
unicodedata
venv
xml
Optimizations
Deprecated
Removed
Porting to Python 3.9
Changes in the Python API
Changes in the C API
CPython bytecode changes
Build Changes
C API Changes
New Features
Porting to Python 3.9
Removed
Notable changes in Python 3.9.1
typing
macOS 11.0 (Big Sur) and Apple Silicon Mac support
Notable changes in Python 3.9.2
collections.abc
urllib.parse
What’s New In Python 3.8
Summary – Release highlights
New Features
Assignment expressions
Positional-only parameters
Parallel filesystem cache for compiled bytecode files
Debug build uses the same ABI as release build
f-strings support = for self-documenting expressions and debugging
PEP 578: Python Runtime Audit Hooks
PEP 587: Python Initialization Configuration
PEP 590: Vectorcall: a fast calling protocol for CPython
Pickle protocol 5 with out-of-band data buffers
Other Language Changes
New Modules
Improved Modules
ast
asyncio
builtins
collections
cProfile
csv
curses
ctypes
datetime
functools
gc
gettext
gzip
IDLE and idlelib
inspect
io
itertools
json.tool
logging
math
mmap
multiprocessing
os
os.path
pathlib
pickle
plistlib
pprint
py_compile
shlex
shutil
socket
ssl
statistics
sys
tarfile
threading
tokenize
tkinter
time
typing
unicodedata
unittest
venv
weakref
xml
xmlrpc
Optimizations
Build and C API Changes
Deprecated
API and Feature Removals
Porting to Python 3.8
Changes in Python behavior
Changes in the Python API
Changes in the C API
CPython bytecode changes
Demos and Tools
Notable changes in Python 3.8.1
Notable changes in Python 3.8.8
Notable changes in Python 3.8.12
What’s New In Python 3.7
Summary – Release Highlights
New Features
PEP 563: Postponed Evaluation of Annotations
PEP 538: Legacy C Locale Coercion
PEP 540: Forced UTF-8 Runtime Mode
PEP 553: Built-in breakpoint()
PEP 539: New C API for Thread-Local Storage
PEP 562: Customization of Access to Module Attributes
PEP 564: New Time Functions With Nanosecond Resolution
PEP 565: Show DeprecationWarning in __main__
PEP 560: Core Support for typing module and Generic Types
PEP 552: Hash-based .pyc Files
PEP 545: Python Documentation Translations
Python Development Mode (-X dev)
Other Language Changes
New Modules
contextvars
dataclasses
importlib.resources
Improved Modules
argparse
asyncio
binascii
calendar
collections
compileall
concurrent.futures
contextlib
cProfile
crypt
datetime
dbm
decimal
dis
distutils
enum
functools
gc
hmac
http.client
http.server
idlelib and IDLE
importlib
io
ipaddress
itertools
locale
logging
math
mimetypes
msilib
multiprocessing
os
pathlib
pdb
py_compile
pydoc
queue
re
signal
socket
socketserver
sqlite3
ssl
string
subprocess
sys
time
tkinter
tracemalloc
types
unicodedata
unittest
unittest.mock
urllib.parse
uu
uuid
warnings
xml.etree
xmlrpc.server
zipapp
zipfile
C API Changes
Build Changes
Optimizations
Other CPython Implementation Changes
Deprecated Python Behavior
Deprecated Python modules, functions and methods
aifc
asyncio
collections
dbm
enum
gettext
importlib
locale
macpath
threading
socket
ssl
sunau
sys
wave
Deprecated functions and types of the C API
Platform Support Removals
API and Feature Removals
Module Removals
Windows-only Changes
Porting to Python 3.7
Changes in Python Behavior
Changes in the Python API
Changes in the C API
CPython bytecode changes
Windows-only Changes
Other CPython implementation changes
Notable changes in Python 3.7.1
Notable changes in Python 3.7.2
Notable changes in Python 3.7.6
Notable changes in Python 3.7.10
What’s New In Python 3.6
Summary – Release highlights
New Features
PEP 498: Formatted string literals
PEP 526: Syntax for variable annotations
PEP 515: Underscores in Numeric Literals
PEP 525: Asynchronous Generators
PEP 530: Asynchronous Comprehensions
PEP 487: Simpler customization of class creation
PEP 487: Descriptor Protocol Enhancements
PEP 519: Adding a file system path protocol
PEP 495: Local Time Disambiguation
PEP 529: Change Windows filesystem encoding to UTF-8
PEP 528: Change Windows console encoding to UTF-8
PEP 520: Preserving Class Attribute Definition Order
PEP 468: Preserving Keyword Argument Order
New dict implementation
PEP 523: Adding a frame evaluation API to CPython
PYTHONMALLOC environment variable
DTrace and SystemTap probing support
Other Language Changes
New Modules
secrets
Improved Modules
array
ast
asyncio
binascii
cmath
collections
concurrent.futures
contextlib
datetime
decimal
distutils
email
encodings
enum
faulthandler
fileinput
hashlib
http.client
idlelib and IDLE
importlib
inspect
json
logging
math
multiprocessing
os
pathlib
pdb
pickle
pickletools
pydoc
random
re
readline
rlcompleter
shlex
site
sqlite3
socket
socketserver
ssl
statistics
struct
subprocess
sys
telnetlib
time
timeit
tkinter
traceback
tracemalloc
typing
unicodedata
unittest.mock
urllib.request
urllib.robotparser
venv
warnings
winreg
winsound
xmlrpc.client
zipfile
zlib
Optimizations
Build and C API Changes
Other Improvements
Deprecated
New Keywords
Deprecated Python behavior
Deprecated Python modules, functions and methods
asynchat
asyncore
dbm
distutils
grp
importlib
os
re
ssl
tkinter
venv
Deprecated functions and types of the C API
Deprecated Build Options
Removed
API and Feature Removals
Porting to Python 3.6
Changes in ‘python’ Command Behavior
Changes in the Python API
Changes in the C API
CPython bytecode changes
Notable changes in Python 3.6.2
New make regen-all build target
Removal of make touch build target
Notable changes in Python 3.6.4
Notable changes in Python 3.6.5
Notable changes in Python 3.6.7
Notable changes in Python 3.6.10
Notable changes in Python 3.6.13
What’s New In Python 3.5
Summary – Release highlights
New Features
PEP 492 - Coroutines with async and await syntax
PEP 465 - A dedicated infix operator for matrix multiplication
PEP 448 - Additional Unpacking Generalizations
PEP 461 - percent formatting support for bytes and bytearray
PEP 484 - Type Hints
PEP 471 - os.scandir() function – a better and faster directory iterator
PEP 475: Retry system calls failing with EINTR
PEP 479: Change StopIteration handling inside generators
PEP 485: A function for testing approximate equality
PEP 486: Make the Python Launcher aware of virtual environments
PEP 488: Elimination of PYO files
PEP 489: Multi-phase extension module initialization
Other Language Changes
New Modules
typing
zipapp
Improved Modules
argparse
asyncio
bz2
cgi
cmath
code
collections
collections.abc
compileall
concurrent.futures
configparser
contextlib
csv
curses
dbm
difflib
distutils
doctest
email
enum
faulthandler
functools
glob
gzip
heapq
http
http.client
idlelib and IDLE
imaplib
imghdr
importlib
inspect
io
ipaddress
json
linecache
locale
logging
lzma
math
multiprocessing
operator
os
pathlib
pickle
poplib
re
readline
selectors
shutil
signal
smtpd
smtplib
sndhdr
socket
ssl
Memory BIO Support
Application-Layer Protocol Negotiation Support
Other Changes
sqlite3
subprocess
sys
sysconfig
tarfile
threading
time
timeit
tkinter
traceback
types
unicodedata
unittest
unittest.mock
urllib
wsgiref
xmlrpc
xml.sax
zipfile
Other module-level changes
Optimizations
Build and C API Changes
Deprecated
New Keywords
Deprecated Python Behavior
Unsupported Operating Systems
Deprecated Python modules, functions and methods
Removed
API and Feature Removals
Porting to Python 3.5
Changes in Python behavior
Changes in the Python API
Changes in the C API
Notable changes in Python 3.5.4
New make regen-all build target
Removal of make touch build target
What’s New In Python 3.4
Summary – Release Highlights
New Features
PEP 453: Explicit Bootstrapping of PIP in Python Installations
Bootstrapping pip By Default
Documentation Changes
PEP 446: Newly Created File Descriptors Are Non-Inheritable
Improvements to Codec Handling
PEP 451: A ModuleSpec Type for the Import System
Other Language Changes
New Modules
asyncio
ensurepip
enum
pathlib
selectors
statistics
tracemalloc
Improved Modules
abc
aifc
argparse
audioop
base64
collections
colorsys
contextlib
dbm
dis
doctest
email
filecmp
functools
gc
glob
hashlib
hmac
html
http
idlelib and IDLE
importlib
inspect
ipaddress
logging
marshal
mmap
multiprocessing
operator
os
pdb
pickle
plistlib
poplib
pprint
pty
pydoc
re
resource
select
shelve
shutil
smtpd
smtplib
socket
sqlite3
ssl
stat
struct
subprocess
sunau
sys
tarfile
textwrap
threading
traceback
types
urllib
unittest
venv
wave
weakref
xml.etree
zipfile
CPython Implementation Changes
PEP 445: Customization of CPython Memory Allocators
PEP 442: Safe Object Finalization
PEP 456: Secure and Interchangeable Hash Algorithm
PEP 436: Argument Clinic
Other Build and C API Changes
Other Improvements
Significant Optimizations
Deprecated
Deprecations in the Python API
Deprecated Features
Removed
Operating Systems No Longer Supported
API and Feature Removals
Code Cleanups
Porting to Python 3.4
Changes in ‘python’ Command Behavior
Changes in the Python API
Changes in the C API
Changed in 3.4.3
PEP 476: Enabling certificate verification by default for stdlib http clients
What’s New In Python 3.3
Summary – Release highlights
PEP 405: Virtual Environments
PEP 420: Implicit Namespace Packages
PEP 3118: New memoryview implementation and buffer protocol documentation
Features
API changes
PEP 393: Flexible String Representation
Functionality
Performance and resource usage
PEP 397: Python Launcher for Windows
PEP 3151: Reworking the OS and IO exception hierarchy
PEP 380: Syntax for Delegating to a Subgenerator
PEP 409: Suppressing exception context
PEP 414: Explicit Unicode literals
PEP 3155: Qualified name for classes and functions
PEP 412: Key-Sharing Dictionary
PEP 362: Function Signature Object
PEP 421: Adding sys.implementation
SimpleNamespace
Using importlib as the Implementation of Import
New APIs
Visible Changes
Other Language Changes
A Finer-Grained Import Lock
Builtin functions and types
New Modules
faulthandler
ipaddress
lzma
Improved Modules
abc
array
base64
binascii
bz2
codecs
collections
contextlib
crypt
curses
datetime
decimal
Features
API changes
email
Policy Framework
Provisional Policy with New Header API
Other API Changes
ftplib
functools
gc
hmac
http
html
imaplib
inspect
io
itertools
logging
math
mmap
multiprocessing
nntplib
os
pdb
pickle
pydoc
re
sched
select
shlex
shutil
signal
smtpd
smtplib
socket
socketserver
sqlite3
ssl
stat
struct
subprocess
sys
tarfile
tempfile
textwrap
threading
time
types
unittest
urllib
webbrowser
xml.etree.ElementTree
zlib
Optimizations
Build and C API Changes
Deprecated
Unsupported Operating Systems
Deprecated Python modules, functions and methods
Deprecated functions and types of the C API
Deprecated features
Porting to Python 3.3
Porting Python code
Porting C code
Building C extensions
Command Line Switch Changes
What’s New In Python 3.2
PEP 384: Defining a Stable ABI
PEP 389: Argparse Command Line Parsing Module
PEP 391: Dictionary Based Configuration for Logging
PEP 3148: The concurrent.futures module
PEP 3147: PYC Repository Directories
PEP 3149: ABI Version Tagged .so Files
PEP 3333: Python Web Server Gateway Interface v1.0.1
Other Language Changes
New, Improved, and Deprecated Modules
email
elementtree
functools
itertools
collections
threading
datetime and time
math
abc
io
reprlib
logging
csv
contextlib
decimal and fractions
ftp
popen
select
gzip and zipfile
tarfile
hashlib
ast
os
shutil
sqlite3
html
socket
ssl
nntp
certificates
imaplib
http.client
unittest
random
poplib
asyncore
tempfile
inspect
pydoc
dis
dbm
ctypes
site
sysconfig
pdb
configparser
urllib.parse
mailbox
turtledemo
Multi-threading
Optimizations
Unicode
Codecs
Documentation
IDLE
Code Repository
Build and C API Changes
Porting to Python 3.2
What’s New In Python 3.1
PEP 372: Ordered Dictionaries
PEP 378: Format Specifier for Thousands Separator
Other Language Changes
New, Improved, and Deprecated Modules
Optimizations
IDLE
Build and C API Changes
Porting to Python 3.1
What’s New In Python 3.0
Common Stumbling Blocks
Print Is A Function
Views And Iterators Instead Of Lists
Ordering Comparisons
Integers
Text Vs. Data Instead Of Unicode Vs. 8-bit
Overview Of Syntax Changes
New Syntax
Changed Syntax
Removed Syntax
Changes Already Present In Python 2.6
Library Changes
PEP 3101: A New Approach To String Formatting
Changes To Exceptions
Miscellaneous Other Changes
Operators And Special Methods
Builtins
Build and C API Changes
Performance
Porting To Python 3.0
What’s New in Python 2.7
The Future for Python 2.x
Changes to the Handling of Deprecation Warnings
Python 3.1 Features
PEP 372: Adding an Ordered Dictionary to collections
PEP 378: Format Specifier for Thousands Separator
PEP 389: The argparse Module for Parsing Command Lines
PEP 391: Dictionary-Based Configuration For Logging
PEP 3106: Dictionary Views
PEP 3137: The memoryview Object
Other Language Changes
Interpreter Changes
Optimizations
New and Improved Modules
New module: importlib
New module: sysconfig
ttk: Themed Widgets for Tk
Updated module: unittest
Updated module: ElementTree 1.3
Build and C API Changes
Capsules
Port-Specific Changes: Windows
Port-Specific Changes: Mac OS X
Port-Specific Changes: FreeBSD
Other Changes and Fixes
Porting to Python 2.7
New Features Added to Python 2.7 Maintenance Releases
Two new environment variables for debug mode
PEP 434: IDLE Enhancement Exception for All Branches
PEP 466: Network Security Enhancements for Python 2.7
PEP 477: Backport ensurepip (PEP 453) to Python 2.7
Bootstrapping pip By Default
Documentation Changes
PEP 476: Enabling certificate verification by default for stdlib http clients
PEP 493: HTTPS verification migration tools for Python 2.7
New make regen-all build target
Removal of make touch build target
Acknowledgements
What’s New in Python 2.6
Python 3.0
Changes to the Development Process
New Issue Tracker: Roundup
New Documentation Format: reStructuredText Using Sphinx
PEP 343: The ‘with’ statement
Writing Context Managers
The contextlib module
PEP 366: Explicit Relative Imports From a Main Module
PEP 370: Per-user site-packages Directory
PEP 371: The multiprocessing Package
PEP 3101: Advanced String Formatting
PEP 3105: print As a Function
PEP 3110: Exception-Handling Changes
PEP 3112: Byte Literals
PEP 3116: New I/O Library
PEP 3118: Revised Buffer Protocol
PEP 3119: Abstract Base Classes
PEP 3127: Integer Literal Support and Syntax
PEP 3129: Class Decorators
PEP 3141: A Type Hierarchy for Numbers
The fractions Module
Other Language Changes
Optimizations
Interpreter Changes
New and Improved Modules
The ast module
The future_builtins module
The json module: JavaScript Object Notation
The plistlib module: A Property-List Parser
ctypes Enhancements
Improved SSL Support
Deprecations and Removals
Build and C API Changes
Port-Specific Changes: Windows
Port-Specific Changes: Mac OS X
Port-Specific Changes: IRIX
Porting to Python 2.6
Acknowledgements
What’s New in Python 2.5
PEP 308: Conditional Expressions
PEP 309: Partial Function Application
PEP 314: Metadata for Python Software Packages v1.1
PEP 328: Absolute and Relative Imports
PEP 338: Executing Modules as Scripts
PEP 341: Unified try/except/finally
PEP 342: New Generator Features
PEP 343: The ‘with’ statement
Writing Context Managers
The contextlib module
PEP 352: Exceptions as New-Style Classes
PEP 353: Using ssize_t as the index type
PEP 357: The ‘__index__’ method
Other Language Changes
Interactive Interpreter Changes
Optimizations
New, Improved, and Removed Modules
The ctypes package
The ElementTree package
The hashlib package
The sqlite3 package
The wsgiref package
Build and C API Changes
Port-Specific Changes
Porting to Python 2.5
Acknowledgements
What’s New in Python 2.4
PEP 218: Built-In Set Objects
PEP 237: Unifying Long Integers and Integers
PEP 289: Generator Expressions
PEP 292: Simpler String Substitutions
PEP 318: Decorators for Functions and Methods
PEP 322: Reverse Iteration
PEP 324: New subprocess Module
PEP 327: Decimal Data Type
Why is Decimal needed?
The Decimal type
The Context type
PEP 328: Multi-line Imports
PEP 331: Locale-Independent Float/String Conversions
Other Language Changes
Optimizations
New, Improved, and Deprecated Modules
cookielib
doctest
Build and C API Changes
Port-Specific Changes
Porting to Python 2.4
Acknowledgements
What’s New in Python 2.3
PEP 218: A Standard Set Datatype
PEP 255: Simple Generators
PEP 263: Source Code Encodings
PEP 273: Importing Modules from ZIP Archives
PEP 277: Unicode file name support for Windows NT
PEP 278: Universal Newline Support
PEP 279: enumerate()
PEP 282: The logging Package
PEP 285: A Boolean Type
PEP 293: Codec Error Handling Callbacks
PEP 301: Package Index and Metadata for Distutils
PEP 302: New Import Hooks
PEP 305: Comma-separated Files
PEP 307: Pickle Enhancements
Extended Slices
Other Language Changes
String Changes
Optimizations
New, Improved, and Deprecated Modules
Date/Time Type
The optparse Module
Pymalloc: A Specialized Object Allocator
Build and C API Changes
Port-Specific Changes
Other Changes and Fixes
Porting to Python 2.3
Acknowledgements
What’s New in Python 2.2
Introduction
PEPs 252 and 253: Type and Class Changes
Old and New Classes
Descriptors
Multiple Inheritance: The Diamond Rule
Attribute Access
Related Links
PEP 234: Iterators
PEP 255: Simple Generators
PEP 237: Unifying Long Integers and Integers
PEP 238: Changing the Division Operator
Unicode Changes
PEP 227: Nested Scopes
New and Improved Modules
Interpreter Changes and Fixes
Other Changes and Fixes
Acknowledgements
What’s New in Python 2.1
Introduction
PEP 227: Nested Scopes
PEP 236: __future__ Directives
PEP 207: Rich Comparisons
PEP 230: Warning Framework
PEP 229: New Build System
PEP 205: Weak References
PEP 232: Function Attributes
PEP 235: Importing Modules on Case-Insensitive Platforms
PEP 217: Interactive Display Hook
PEP 208: New Coercion Model
PEP 241: Metadata in Python Packages
New and Improved Modules
Other Changes and Fixes
Acknowledgements
What’s New in Python 2.0
Introduction
What About Python 1.6?
New Development Process
Unicode
List Comprehensions
Augmented Assignment
String Methods
Garbage Collection of Cycles
Other Core Changes
Minor Language Changes
Changes to Built-in Functions
Porting to 2.0
Extending/Embedding Changes
Distutils: Making Modules Easy to Install
XML Modules
SAX2 Support
DOM Support
Relationship to PyXML
Module changes
New modules
IDLE Improvements
Deleted and Deprecated Modules
Acknowledgements
Changelog
Python next
Security
Library
IDLE
Tools/Demos
Python 3.10.8 final
Security
Core and Builtins
Library
Documentation
Build
Windows
macOS
Python 3.10.7 final
Security
Core and Builtins
Library
Documentation
Tests
Build
IDLE
Python 3.10.6 final
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
IDLE
Tools/Demos
C API
Python 3.10.5 final
Core and Builtins
Library
Documentation
Tests
Build
Windows
Tools/Demos
Python 3.10.4 final
Core and Builtins
Library
Python 3.10.3 final
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
C API
Python 3.10.2 final
Core and Builtins
Library
Documentation
Tests
Build
macOS
C API
Python 3.10.1 final
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.10.0 final
Core and Builtins
Library
Documentation
Tests
Build
IDLE
C API
Python 3.10.0 release candidate 2
Security
Core and Builtins
Library
Documentation
Tests
Windows
macOS
Python 3.10.0 release candidate 1
Security
Core and Builtins
Library
Documentation
Tests
Windows
macOS
Tools/Demos
C API
Python 3.10.0 beta 4
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
C API
Python 3.10.0 beta 3
Core and Builtins
Library
Documentation
Tests
Build
IDLE
C API
Python 3.10.0 beta 2
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.10.0 beta 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
C API
Python 3.10.0 alpha 7
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
IDLE
C API
Python 3.10.0 alpha 6
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
C API
Python 3.10.0 alpha 5
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
C API
Python 3.10.0 alpha 4
Core and Builtins
Library
Documentation
Tests
Build
macOS
Tools/Demos
C API
Python 3.10.0 alpha 3
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.10.0 alpha 2
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
C API
Python 3.10.0 alpha 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
C API
Python 3.9.0 beta 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
Tools/Demos
C API
Python 3.9.0 alpha 6
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.9.0 alpha 5
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.9.0 alpha 4
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
IDLE
C API
Python 3.9.0 alpha 3
Core and Builtins
Library
Documentation
Build
IDLE
C API
Python 3.9.0 alpha 2
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
C API
Python 3.9.0 alpha 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.8.0 beta 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.8.0 alpha 4
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.8.0 alpha 3
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
IDLE
Tools/Demos
C API
Python 3.8.0 alpha 2
Core and Builtins
Library
Documentation
Tests
Windows
IDLE
Python 3.8.0 alpha 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.7.0 final
Library
C API
Python 3.7.0 release candidate 1
Core and Builtins
Library
Documentation
Build
Windows
IDLE
Python 3.7.0 beta 5
Core and Builtins
Library
Documentation
Tests
Build
macOS
IDLE
Python 3.7.0 beta 4
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
Python 3.7.0 beta 3
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.7.0 beta 2
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
Python 3.7.0 beta 1
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
C API
Python 3.7.0 alpha 4
Core and Builtins
Library
Documentation
Tests
Windows
Tools/Demos
C API
Python 3.7.0 alpha 3
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.7.0 alpha 2
Core and Builtins
Library
Documentation
Build
IDLE
C API
Python 3.7.0 alpha 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
IDLE
Tools/Demos
C API
Python 3.6.6 final
Python 3.6.6 release candidate 1
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.6.5 final
Tests
Build
Python 3.6.5 release candidate 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.6.4 final
Python 3.6.4 release candidate 1
Core and Builtins
Library
Documentation
Tests
Build
Windows
macOS
IDLE
Tools/Demos
C API
Python 3.6.3 final
Library
Build
Python 3.6.3 release candidate 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
IDLE
Tools/Demos
Python 3.6.2 final
Python 3.6.2 release candidate 2
Security
Python 3.6.2 release candidate 1
Security
Core and Builtins
Library
IDLE
C API
Build
Documentation
Tools/Demos
Tests
Windows
Python 3.6.1 final
Core and Builtins
Build
Python 3.6.1 release candidate 1
Core and Builtins
Library
IDLE
Windows
C API
Documentation
Tests
Build
Python 3.6.0 final
Python 3.6.0 release candidate 2
Core and Builtins
Tools/Demos
Windows
Build
Python 3.6.0 release candidate 1
Core and Builtins
Library
C API
Documentation
Tools/Demos
Python 3.6.0 beta 4
Core and Builtins
Library
Documentation
Tests
Build
Python 3.6.0 beta 3
Core and Builtins
Library
Windows
Build
Tests
Python 3.6.0 beta 2
Core and Builtins
Library
Windows
C API
Build
Tests
Python 3.6.0 beta 1
Core and Builtins
Library
IDLE
C API
Tests
Build
Tools/Demos
Windows
Python 3.6.0 alpha 4
Core and Builtins
Library
IDLE
Tests
Windows
Build
Python 3.6.0 alpha 3
Security
Core and Builtins
Library
IDLE
C API
Build
Tools/Demos
Documentation
Tests
Python 3.6.0 alpha 2
Security
Core and Builtins
Library
IDLE
Documentation
Tests
Windows
Build
C API
Tools/Demos
Python 3.6.0 alpha 1
Security
Core and Builtins
Library
IDLE
Documentation
Tests
Build
Windows
Tools/Demos
C API
Python 3.5.5 final
Python 3.5.5 release candidate 1
Security
Core and Builtins
Library
Python 3.5.4 final
Library
Python 3.5.4 release candidate 1
Security
Core and Builtins
Library
Documentation
Tests
Build
Windows
C API
Python 3.5.3 final
Python 3.5.3 release candidate 1
Security
Core and Builtins
Library
IDLE
C API
Documentation
Tests
Tools/Demos
Windows
Build
Python 3.5.2 final
Core and Builtins
Tests
IDLE
Python 3.5.2 release candidate 1
Security
Core and Builtins
Library
IDLE
Documentation
Tests
Build
Windows
Tools/Demos
Python 3.5.1 final
Core and Builtins
Windows
Python 3.5.1 release candidate 1
Core and Builtins
Library
IDLE
Documentation
Tests
Build
Windows
Tools/Demos
Python 3.5.0 final
Build
Python 3.5.0 release candidate 4
Library
Build
Python 3.5.0 release candidate 3
Core and Builtins
Library
Python 3.5.0 release candidate 2
Core and Builtins
Library
Python 3.5.0 release candidate 1
Core and Builtins
Library
IDLE
Documentation
Tests
Python 3.5.0 beta 4
Core and Builtins
Library
Build
Python 3.5.0 beta 3
Core and Builtins
Library
Tests
Documentation
Build
Python 3.5.0 beta 2
Core and Builtins
Library
Python 3.5.0 beta 1
Core and Builtins
Library
IDLE
Tests
Documentation
Tools/Demos
Python 3.5.0 alpha 4
Core and Builtins
Library
Build
Tests
Tools/Demos
C API
Python 3.5.0 alpha 3
Core and Builtins
Library
Build
Tests
Tools/Demos
Python 3.5.0 alpha 2
Core and Builtins
Library
Build
C API
Windows
Python 3.5.0 alpha 1
Core and Builtins
Library
IDLE
Build
C API
Documentation
Tests
Tools/Demos
Windows
The Python Tutorial
1. Whetting Your Appetite
2. Using the Python Interpreter
2.1. Invoking the Interpreter
2.1.1. Argument Passing
2.1.2. Interactive Mode
2.2. The Interpreter and Its Environment
2.2.1. Source Code Encoding
3. An Informal Introduction to Python
3.1. Using Python as a Calculator
3.1.1. Numbers
3.1.2. Strings
3.1.3. Lists
3.2. First Steps Towards Programming
4. More Control Flow Tools
4.1. if Statements
4.2. for Statements
4.3. The range() Function
4.4. break and continue Statements, and else Clauses on Loops
4.5. pass Statements
4.6. match Statements
4.7. Defining Functions
4.8. More on Defining Functions
4.8.1. Default Argument Values
4.8.2. Keyword Arguments
4.8.3. Special parameters
4.8.3.1. Positional-or-Keyword Arguments
4.8.3.2. Positional-Only Parameters
4.8.3.3. Keyword-Only Arguments
4.8.3.4. Function Examples
4.8.3.5. Recap
4.8.4. Arbitrary Argument Lists
4.8.5. Unpacking Argument Lists
4.8.6. Lambda Expressions
4.8.7. Documentation Strings
4.8.8. Function Annotations
4.9. Intermezzo: Coding Style
5. Data Structures
5.1. More on Lists
5.1.1. Using Lists as Stacks
5.1.2. Using Lists as Queues
5.1.3. List Comprehensions
5.1.4. Nested List Comprehensions
5.2. The del statement
5.3. Tuples and Sequences
5.4. Sets
5.5. Dictionaries
5.6. Looping Techniques
5.7. More on Conditions
5.8. Comparing Sequences and Other Types
6. Modules
6.1. More on Modules
6.1.1. Executing modules as scripts
6.1.2. The Module Search Path
6.1.3. “Compiled” Python files
6.2. Standard Modules
6.3. The dir() Function
6.4. Packages
6.4.1. Importing * From a Package
6.4.2. Intra-package References
6.4.3. Packages in Multiple Directories
7. Input and Output
7.1. Fancier Output Formatting
7.1.1. Formatted String Literals
7.1.2. The String format() Method
7.1.3. Manual String Formatting
7.1.4. Old string formatting
7.2. Reading and Writing Files
7.2.1. Methods of File Objects
7.2.2. Saving structured data with json
8. Errors and Exceptions
8.1. Syntax Errors
8.2. Exceptions
8.3. Handling Exceptions
8.4. Raising Exceptions
8.5. Exception Chaining
8.6. User-defined Exceptions
8.7. Defining Clean-up Actions
8.8. Predefined Clean-up Actions
9. Classes
9.1. A Word About Names and Objects
9.2. Python Scopes and Namespaces
9.2.1. Scopes and Namespaces Example
9.3. A First Look at Classes
9.3.1. Class Definition Syntax
9.3.2. Class Objects
9.3.3. Instance Objects
9.3.4. Method Objects
9.3.5. Class and Instance Variables
9.4. Random Remarks
9.5. Inheritance
9.5.1. Multiple Inheritance
9.6. Private Variables
9.7. Odds and Ends
9.8. Iterators
9.9. Generators
9.10. Generator Expressions
10. Brief Tour of the Standard Library
10.1. Operating System Interface
10.2. File Wildcards
10.3. Command Line Arguments
10.4. Error Output Redirection and Program Termination
10.5. String Pattern Matching
10.6. Mathematics
10.7. Internet Access
10.8. Dates and Times
10.9. Data Compression
10.10. Performance Measurement
10.11. Quality Control
10.12. Batteries Included
11. Brief Tour of the Standard Library — Part II
11.1. Output Formatting
11.2. Templating
11.3. Working with Binary Data Record Layouts
11.4. Multi-threading
11.5. Logging
11.6. Weak References
11.7. Tools for Working with Lists
11.8. Decimal Floating Point Arithmetic
12. Virtual Environments and Packages
12.1. Introduction
12.2. Creating Virtual Environments
12.3. Managing Packages with pip
13. What Now?
14. Interactive Input Editing and History Substitution
14.1. Tab Completion and History Editing
14.2. Alternatives to the Interactive Interpreter
15. Floating Point Arithmetic: Issues and Limitations
15.1. Representation Error
16. Appendix
16.1. Interactive Mode
16.1.1. Error Handling
16.1.2. Executable Python Scripts
16.1.3. The Interactive Startup File
16.1.4. The Customization Modules
Python Setup and Usage
1. Command line and environment
1.1. Command line
1.1.1. Interface options
1.1.2. Generic options
1.1.3. Miscellaneous options
1.1.4. Options you shouldn’t use
1.2. Environment variables
1.2.1. Debug-mode variables
2. Using Python on Unix platforms
2.1. Getting and installing the latest version of Python
2.1.1. On Linux
2.1.2. On FreeBSD and OpenBSD
2.1.3. On OpenSolaris
2.2. Building Python
2.3. Python-related paths and files
2.4. Miscellaneous
2.5. Custom OpenSSL
3. Configure Python
3.1. Configure Options
3.1.1. General Options
3.1.2. Install Options
3.1.3. Performance options
3.1.4. Python Debug Build
3.1.5. Debug options
3.1.6. Linker options
3.1.7. Libraries options
3.1.8. Security Options
3.1.9. macOS Options
3.2. Python Build System
3.2.1. Main files of the build system
3.2.2. Main build steps
3.2.3. Main Makefile targets
3.2.4. C extensions
3.3. Compiler and linker flags
3.3.1. Preprocessor flags
3.3.2. Compiler flags
3.3.3. Linker flags
4. Using Python on Windows
4.1. The full installer
4.1.1. Installation steps
4.1.2. Removing the MAX_PATH Limitation
4.1.3. Installing Without UI
4.1.4. Installing Without Downloading
4.1.5. Modifying an install
4.2. The Microsoft Store package
4.2.1. Known issues
4.2.1.1. Redirection of local data, registry, and temporary paths
4.3. The nuget.org packages
4.4. The embeddable package
4.4.1. Python Application
4.4.2. Embedding Python
4.5. Alternative bundles
4.6. Configuring Python
4.6.1. Excursus: Setting environment variables
4.6.2. Finding the Python executable
4.7. UTF-8 mode
4.8. Python Launcher for Windows
4.8.1. Getting started
4.8.1.1. From the command-line
4.8.1.2. Virtual environments
4.8.1.3. From a script
4.8.1.4. From file associations
4.8.2. Shebang Lines
4.8.3. Arguments in shebang lines
4.8.4. Customization
4.8.4.1. Customization via INI files
4.8.4.2. Customizing default Python versions
4.8.5. Diagnostics
4.9. Finding modules
4.10. Additional modules
4.10.1. PyWin32
4.10.2. cx_Freeze
4.11. Compiling Python on Windows
4.12. Other Platforms
5. Using Python on a Mac
5.1. Getting and Installing MacPython
5.1.1. How to run a Python script
5.1.2. Running scripts with a GUI
5.1.3. Configuration
5.2. The IDE
5.3. Installing Additional Python Packages
5.4. GUI Programming on the Mac
5.5. Distributing Python Applications on the Mac
5.6. Other Resources
6. Editors and IDEs
The Python Language Reference
1. Introduction
1.1. Alternate Implementations
1.2. Notation
2. Lexical analysis
2.1. Line structure
2.1.1. Logical lines
2.1.2. Physical lines
2.1.3. Comments
2.1.4. Encoding declarations
2.1.5. Explicit line joining
2.1.6. Implicit line joining
2.1.7. Blank lines
2.1.8. Indentation
2.1.9. Whitespace between tokens
2.2. Other tokens
2.3. Identifiers and keywords
2.3.1. Keywords
2.3.2. Soft Keywords
2.3.3. Reserved classes of identifiers
2.4. Literals
2.4.1. String and Bytes literals
2.4.2. String literal concatenation
2.4.3. Formatted string literals
2.4.4. Numeric literals
2.4.5. Integer literals
2.4.6. Floating point literals
2.4.7. Imaginary literals
2.5. Operators
2.6. Delimiters
3. Data model
3.1. Objects, values and types
3.2. The standard type hierarchy
3.3. Special method names
3.3.1. Basic customization
3.3.2. Customizing attribute access
3.3.2.1. Customizing module attribute access
3.3.2.2. Implementing Descriptors
3.3.2.3. Invoking Descriptors
3.3.2.4. __slots__
3.3.2.4.1. Notes on using __slots__
3.3.3. Customizing class creation
3.3.3.1. Metaclasses
3.3.3.2. Resolving MRO entries
3.3.3.3. Determining the appropriate metaclass
3.3.3.4. Preparing the class namespace
3.3.3.5. Executing the class body
3.3.3.6. Creating the class object
3.3.3.7. Uses for metaclasses
3.3.4. Customizing instance and subclass checks
3.3.5. Emulating generic types
3.3.5.1. The purpose of __class_getitem__
3.3.5.2. __class_getitem__ versus __getitem__
3.3.6. Emulating callable objects
3.3.7. Emulating container types
3.3.8. Emulating numeric types
3.3.9. With Statement Context Managers
3.3.10. Customizing positional arguments in class pattern matching
3.3.11. Special method lookup
3.4. Coroutines
3.4.1. Awaitable Objects
3.4.2. Coroutine Objects
3.4.3. Asynchronous Iterators
3.4.4. Asynchronous Context Managers
4. Execution model
4.1. Structure of a program
4.2. Naming and binding
4.2.1. Binding of names
4.2.2. Resolution of names
4.2.3. Builtins and restricted execution
4.2.4. Interaction with dynamic features
4.3. Exceptions
5. The import system
5.1. importlib
5.2. Packages
5.2.1. Regular packages
5.2.2. Namespace packages
5.3. Searching
5.3.1. The module cache
5.3.2. Finders and loaders
5.3.3. Import hooks
5.3.4. The meta path
5.4. Loading
5.4.1. Loaders
5.4.2. Submodules
5.4.3. Module spec
5.4.4. Import-related module attributes
5.4.5. module.__path__
5.4.6. Module reprs
5.4.7. Cached bytecode invalidation
5.5. The Path Based Finder
5.5.1. Path entry finders
5.5.2. Path entry finder protocol
5.6. Replacing the standard import system
5.7. Package Relative Imports
5.8. Special considerations for __main__
5.8.1. __main__.__spec__
5.9. References
6. Expressions
6.1. Arithmetic conversions
6.2. Atoms
6.2.1. Identifiers (Names)
6.2.2. Literals
6.2.3. Parenthesized forms
6.2.4. Displays for lists, sets and dictionaries
6.2.5. List displays
6.2.6. Set displays
6.2.7. Dictionary displays
6.2.8. Generator expressions
6.2.9. Yield expressions
6.2.9.1. Generator-iterator methods
6.2.9.2. Examples
6.2.9.3. Asynchronous generator functions
6.2.9.4. Asynchronous generator-iterator methods
6.3. Primaries
6.3.1. Attribute references
6.3.2. Subscriptions
6.3.3. Slicings
6.3.4. Calls
6.4. Await expression
6.5. The power operator
6.6. Unary arithmetic and bitwise operations
6.7. Binary arithmetic operations
6.8. Shifting operations
6.9. Binary bitwise operations
6.10. Comparisons
6.10.1. Value comparisons
6.10.2. Membership test operations
6.10.3. Identity comparisons
6.11. Boolean operations
6.12. Assignment expressions
6.13. Conditional expressions
6.14. Lambdas
6.15. Expression lists
6.16. Evaluation order
6.17. Operator precedence
7. Simple statements
7.1. Expression statements
7.2. Assignment statements
7.2.1. Augmented assignment statements
7.2.2. Annotated assignment statements
7.3. The assert statement
7.4. The pass statement
7.5. The del statement
7.6. The return statement
7.7. The yield statement
7.8. The raise statement
7.9. The break statement
7.10. The continue statement
7.11. The import statement
7.11.1. Future statements
7.12. The global statement
7.13. The nonlocal statement
8. Compound statements
8.1. The if statement
8.2. The while statement
8.3. The for statement
8.4. The try statement
8.5. The with statement
8.6. The match statement
8.6.1. Overview
8.6.2. Guards
8.6.3. Irrefutable Case Blocks
8.6.4. Patterns
8.6.4.1. OR Patterns
8.6.4.2. AS Patterns
8.6.4.3. Literal Patterns
8.6.4.4. Capture Patterns
8.6.4.5. Wildcard Patterns
8.6.4.6. Value Patterns
8.6.4.7. Group Patterns
8.6.4.8. Sequence Patterns
8.6.4.9. Mapping Patterns
8.6.4.10. Class Patterns
8.7. Function definitions
8.8. Class definitions
8.9. Coroutines
8.9.1. Coroutine function definition
8.9.2. The async for statement
8.9.3. The async with statement
9. Top-level components
9.1. Complete Python programs
9.2. File input
9.3. Interactive input
9.4. Expression input
10. Full Grammar specification
The Python Standard Library
Introduction
Notes on availability
Built-in Functions
Built-in Constants
Constants added by the site module
Built-in Types
Truth Value Testing
Boolean Operations — and, or, not
Comparisons
Numeric Types — int, float, complex
Bitwise Operations on Integer Types
Additional Methods on Integer Types
Additional Methods on Float
Hashing of numeric types
Iterator Types
Generator Types
Sequence Types — list, tuple, range
Common Sequence Operations
Immutable Sequence Types
Mutable Sequence Types
Lists
Tuples
Ranges
Text Sequence Type — str
String Methods
printf-style String Formatting
Binary Sequence Types — bytes, bytearray, memoryview
Bytes Objects
Bytearray Objects
Bytes and Bytearray Operations
printf-style Bytes Formatting
Memory Views
Set Types — set, frozenset
Mapping Types — dict
Dictionary view objects
Context Manager Types
Type Annotation Types — Generic Alias, Union
Generic Alias Type
Standard Generic Classes
Special Attributes of GenericAlias objects
Union Type
Other Built-in Types
Modules
Classes and Class Instances
Functions
Methods
Code Objects
Type Objects
The Null Object
The Ellipsis Object
The NotImplemented Object
Boolean Values
Internal Objects
Special Attributes
Integer string conversion length limitation
Affected APIs
Configuring the limit
Recommended configuration
Built-in Exceptions
Exception context
Inheriting from built-in exceptions
Base classes
Concrete exceptions
OS exceptions
Warnings
Exception hierarchy
Text Processing Services
string — Common string operations
String constants
Custom String Formatting
Format String Syntax
Format Specification Mini-Language
Format examples
Template strings
Helper functions
re — Regular expression operations
Regular Expression Syntax
Module Contents
Flags
Functions
Exceptions
Regular Expression Objects
Match Objects
Regular Expression Examples
Checking for a Pair
Simulating scanf()
search() vs. match()
Making a Phonebook
Text Munging
Finding all Adverbs
Finding all Adverbs and their Positions
Raw String Notation
Writing a Tokenizer
difflib — Helpers for computing deltas
SequenceMatcher Objects
SequenceMatcher Examples
Differ Objects
Differ Example
A command-line interface to difflib
textwrap — Text wrapping and filling
unicodedata — Unicode Database
stringprep — Internet String Preparation
readline — GNU readline interface
Init file
Line buffer
History file
History list
Startup hooks
Completion
Example
rlcompleter — Completion function for GNU readline
Completer Objects
Binary Data Services
struct — Interpret bytes as packed binary data
Functions and Exceptions
Format Strings
Byte Order, Size, and Alignment
Format Characters
Examples
Classes
codecs — Codec registry and base classes
Codec Base Classes
Error Handlers
Stateless Encoding and Decoding
Incremental Encoding and Decoding
IncrementalEncoder Objects
IncrementalDecoder Objects
Stream Encoding and Decoding
StreamWriter Objects
StreamReader Objects
StreamReaderWriter Objects
StreamRecoder Objects
Encodings and Unicode
Standard Encodings
Python Specific Encodings
Text Encodings
Binary Transforms
Text Transforms
encodings.idna — Internationalized Domain Names in Applications
encodings.mbcs — Windows ANSI codepage
encodings.utf_8_sig — UTF-8 codec with BOM signature
Data Types
datetime — Basic date and time types
Aware and Naive Objects
Constants
Available Types
Common Properties
Determining if an Object is Aware or Naive
timedelta Objects
Examples of usage: timedelta
date Objects
Examples of Usage: date
datetime Objects
Examples of Usage: datetime
time Objects
Examples of Usage: time
tzinfo Objects
timezone Objects
strftime() and strptime() Behavior
strftime() and strptime() Format Codes
Technical Detail
zoneinfo — IANA time zone support
Using ZoneInfo
Data sources
Configuring the data sources
Compile-time configuration
Environment configuration
Runtime configuration
The ZoneInfo class
String representations
Pickle serialization
Functions
Globals
Exceptions and warnings
calendar — General calendar-related functions
collections — Container datatypes
ChainMap objects
ChainMap Examples and Recipes
Counter objects
deque objects
deque Recipes
defaultdict objects
defaultdict Examples
namedtuple() Factory Function for Tuples with Named Fields
OrderedDict objects
OrderedDict Examples and Recipes
UserDict objects
UserList objects
UserString objects
collections.abc — Abstract Base Classes for Containers
Collections Abstract Base Classes
Collections Abstract Base Classes – Detailed Descriptions
Examples and Recipes
heapq — Heap queue algorithm
Basic Examples
Priority Queue Implementation Notes
Theory
bisect — Array bisection algorithm
Performance Notes
Searching Sorted Lists
Examples
array — Efficient arrays of numeric values
weakref — Weak references
Weak Reference Objects
Example
Finalizer Objects
Comparing finalizers with __del__() methods
types — Dynamic type creation and names for built-in types
Dynamic Type Creation
Standard Interpreter Types
Additional Utility Classes and Functions
Coroutine Utility Functions
copy — Shallow and deep copy operations
pprint — Data pretty printer
PrettyPrinter Objects
Example
reprlib — Alternate repr() implementation
Repr Objects
Subclassing Repr Objects
enum — Support for enumerations
Module Contents
Creating an Enum
Programmatic access to enumeration members and their attributes
Duplicating enum members and values
Ensuring unique enumeration values
Using automatic values
Iteration
Comparisons
Allowed members and attributes of enumerations
Restricted Enum subclassing
Pickling
Functional API
Derived Enumerations
IntEnum
IntFlag
Flag
Others
When to use __new__() vs. __init__()
Interesting examples
Omitting values
Using auto
Using object
Using a descriptive string
Using a custom __new__()
OrderedEnum
DuplicateFreeEnum
Planet
TimePeriod
How are Enums different?
Enum Classes
Enum Members (aka instances)
Finer Points
Supported __dunder__ names
Supported _sunder_ names
_Private__names
Enum member type
Boolean value of Enum classes and members
Enum classes with methods
Combining members of Flag
graphlib — Functionality to operate with graph-like structures
Exceptions
Numeric and Mathematical Modules
numbers — Numeric abstract base classes
The numeric tower
Notes for type implementors
Adding More Numeric ABCs
Implementing the arithmetic operations
math — Mathematical functions
Number-theoretic and representation functions
Power and logarithmic functions
Trigonometric functions
Angular conversion
Hyperbolic functions
Special functions
Constants
cmath — Mathematical functions for complex numbers
Conversions to and from polar coordinates
Power and logarithmic functions
Trigonometric functions
Hyperbolic functions
Classification functions
Constants
decimal — Decimal fixed point and floating point arithmetic
Quick-start Tutorial
Decimal objects
Logical operands
Context objects
Constants
Rounding modes
Signals
Floating Point Notes
Mitigating round-off error with increased precision
Special values
Working with threads
Recipes
Decimal FAQ
fractions — Rational numbers
random — Generate pseudo-random numbers
Bookkeeping functions
Functions for bytes
Functions for integers
Functions for sequences
Real-valued distributions
Alternative Generator
Notes on Reproducibility
Examples
Recipes
statistics — Mathematical statistics functions
Averages and measures of central location
Measures of spread
Statistics for relations between two inputs
Function details
Exceptions
NormalDist objects
NormalDist Examples and Recipes
Functional Programming Modules
itertools — Functions creating iterators for efficient looping
Itertool functions
Itertools Recipes
functools — Higher-order functions and operations on callable objects
partial Objects
operator — Standard operators as functions
Mapping Operators to Functions
In-place Operators
File and Directory Access
pathlib — Object-oriented filesystem paths
Basic use
Pure paths
General properties
Operators
Accessing individual parts
Methods and properties
Concrete paths
Methods
Correspondence to tools in the os module
os.path — Common pathname manipulations
fileinput — Iterate over lines from multiple input streams
stat — Interpreting stat() results
filecmp — File and Directory Comparisons
The dircmp class
tempfile — Generate temporary files and directories
Examples
Deprecated functions and variables
glob — Unix style pathname pattern expansion
fnmatch — Unix filename pattern matching
linecache — Random access to text lines
shutil — High-level file operations
Directory and files operations
Platform-dependent efficient copy operations
copytree example
rmtree example
Archiving operations
Archiving example
Archiving example with base_dir
Querying the size of the output terminal
Data Persistence
pickle — Python object serialization
Relationship to other Python modules
Comparison with marshal
Comparison with json
Data stream format
Module Interface
What can be pickled and unpickled?
Pickling Class Instances
Persistence of External Objects
Dispatch Tables
Handling Stateful Objects
Custom Reduction for Types, Functions, and Other Objects
Out-of-band Buffers
Provider API
Consumer API
Example
Restricting Globals
Performance
Examples
copyreg — Register pickle support functions
Example
shelve — Python object persistence
Restrictions
Example
marshal — Internal Python object serialization
dbm — Interfaces to Unix “databases”
dbm.gnu — GNU’s reinterpretation of dbm
dbm.ndbm — Interface based on ndbm
dbm.dumb — Portable DBM implementation
sqlite3 — DB-API 2.0 interface for SQLite databases
Tutorial
Reference
Module functions
Module constants
Connection objects
Cursor objects
Row objects
PrepareProtocol objects
Exceptions
SQLite and Python types
Default adapters and converters
How-to guides
How to use placeholders to bind values in SQL queries
How to adapt custom Python types to SQLite values
How to write adaptable objects
How to register adapter callables
How to convert SQLite values to custom Python types
Adapter and converter recipes
How to use connection shortcut methods
How to use the connection context manager
How to work with SQLite URIs
Explanation
Transaction control
Data Compression and Archiving
zlib — Compression compatible with gzip
gzip — Support for gzip files
Examples of usage
Command Line Interface
Command line options
bz2 — Support for bzip2 compression
(De)compression of files
Incremental (de)compression
One-shot (de)compression
Examples of usage
lzma — Compression using the LZMA algorithm
Reading and writing compressed files
Compressing and decompressing data in memory
Miscellaneous
Specifying custom filter chains
Examples
zipfile — Work with ZIP archives
ZipFile Objects
Path Objects
PyZipFile Objects
ZipInfo Objects
Command-Line Interface
Command-line options
Decompression pitfalls
From file itself
File System limitations
Resources limitations
Interruption
Default behaviors of extraction
tarfile — Read and write tar archive files
TarFile Objects
TarInfo Objects
Command-Line Interface
Command-line options
Examples
Supported tar formats
Unicode issues
File Formats
csv — CSV File Reading and Writing
Module Contents
Dialects and Formatting Parameters
Reader Objects
Writer Objects
Examples
configparser — Configuration file parser
Quick Start
Supported Datatypes
Fallback Values
Supported INI File Structure
Interpolation of values
Mapping Protocol Access
Customizing Parser Behaviour
Legacy API Examples
ConfigParser Objects
RawConfigParser Objects
Exceptions
netrc — netrc file processing
netrc Objects
plistlib — Generate and parse Apple .plist files
Examples
Cryptographic Services
hashlib — Secure hashes and message digests
Hash algorithms
SHAKE variable length digests
Key derivation
BLAKE2
Creating hash objects
Constants
Examples
Simple hashing
Using different digest sizes
Keyed hashing
Randomized hashing
Personalization
Tree mode
Credits
hmac — Keyed-Hashing for Message Authentication
secrets — Generate secure random numbers for managing secrets
Random numbers
Generating tokens
How many bytes should tokens use?
Other functions
Recipes and best practices
Generic Operating System Services
os — Miscellaneous operating system interfaces
File Names, Command Line Arguments, and Environment Variables
Python UTF-8 Mode
Process Parameters
File Object Creation
File Descriptor Operations
Querying the size of a terminal
Inheritance of File Descriptors
Files and Directories
Linux extended attributes
Process Management
Interface to the scheduler
Miscellaneous System Information
Random numbers
io — Core tools for working with streams
Overview
Text I/O
Binary I/O
Raw I/O
Text Encoding
Opt-in EncodingWarning
High-level Module Interface
Class hierarchy
I/O Base Classes
Raw File I/O
Buffered Streams
Text I/O
Performance
Binary I/O
Text I/O
Multi-threading
Reentrancy
time — Time access and conversions
Functions
Clock ID Constants
Timezone Constants
argparse — Parser for command-line options, arguments and sub-commands
Example
Creating a parser
Adding arguments
Parsing arguments
ArgumentParser objects
prog
usage
description
epilog
parents
formatter_class
prefix_chars
fromfile_prefix_chars
argument_default
allow_abbrev
conflict_handler
add_help
exit_on_error
The add_argument() method
name or flags
action
nargs
const
default
type
choices
required
help
metavar
dest
Action classes
The parse_args() method
Option value syntax
Invalid arguments
Arguments containing -
Argument abbreviations (prefix matching)
Beyond sys.argv
The Namespace object
Other utilities
Sub-commands
FileType objects
Argument groups
Mutual exclusion
Parser defaults
Printing help
Partial parsing
Customizing file parsing
Exiting methods
Intermixed parsing
Upgrading optparse code
getopt — C-style parser for command line options
logging — Logging facility for Python
Logger Objects
Logging Levels
Handler Objects
Formatter Objects
Filter Objects
LogRecord Objects
LogRecord attributes
LoggerAdapter Objects
Thread Safety
Module-Level Functions
Module-Level Attributes
Integration with the warnings module
logging.config — Logging configuration
Configuration functions
Security considerations
Configuration dictionary schema
Dictionary Schema Details
Incremental Configuration
Object connections
User-defined objects
Access to external objects
Access to internal objects
Import resolution and custom importers
Configuration file format
logging.handlers — Logging handlers
StreamHandler
FileHandler
NullHandler
WatchedFileHandler
BaseRotatingHandler
RotatingFileHandler
TimedRotatingFileHandler
SocketHandler
DatagramHandler
SysLogHandler
NTEventLogHandler
SMTPHandler
MemoryHandler
HTTPHandler
QueueHandler
QueueListener
getpass — Portable password input
curses — Terminal handling for character-cell displays
Functions
Window Objects
Constants
curses.textpad — Text input widget for curses programs
Textbox objects
curses.ascii — Utilities for ASCII characters
curses.panel — A panel stack extension for curses
Functions
Panel Objects
platform — Access to underlying platform’s identifying data
Cross Platform
Java Platform
Windows Platform
macOS Platform
Unix Platforms
Linux Platforms
errno — Standard errno system symbols
ctypes — A foreign function library for Python
ctypes tutorial
Loading dynamic link libraries
Accessing functions from loaded dlls
Calling functions
Fundamental data types
Calling functions, continued
Calling functions with your own custom data types
Specifying the required argument types (function prototypes)
Return types
Passing pointers (or: passing parameters by reference)
Structures and unions
Structure/union alignment and byte order
Bit fields in structures and unions
Arrays
Pointers
Type conversions
Incomplete Types
Callback functions
Accessing values exported from dlls
Surprises
Variable-sized data types
ctypes reference
Finding shared libraries
Loading shared libraries
Foreign functions
Function prototypes
Utility functions
Data types
Fundamental data types
Structured data types
Arrays and pointers
Concurrent Execution
threading — Thread-based parallelism
Thread-Local Data
Thread Objects
Lock Objects
RLock Objects
Condition Objects
Semaphore Objects
Semaphore Example
Event Objects
Timer Objects
Barrier Objects
Using locks, conditions, and semaphores in the with statement
multiprocessing — Process-based parallelism
Introduction
The Process class
Contexts and start methods
Exchanging objects between processes
Synchronization between processes
Sharing state between processes
Using a pool of workers
Reference
Process and exceptions
Pipes and Queues
Miscellaneous
Connection Objects
Synchronization primitives
Shared ctypes Objects
The multiprocessing.sharedctypes module
Managers
Customized managers
Using a remote manager
Proxy Objects
Cleanup
Process Pools
Listeners and Clients
Address Formats
Authentication keys
Logging
The multiprocessing.dummy module
Programming guidelines
All start methods
The spawn and forkserver start methods
Examples
multiprocessing.shared_memory — Shared memory for direct access across processes
The concurrent package
concurrent.futures — Launching parallel tasks
Executor Objects
ThreadPoolExecutor
ThreadPoolExecutor Example
ProcessPoolExecutor
ProcessPoolExecutor Example
Future Objects
Module Functions
Exception classes
subprocess — Subprocess management
Using the subprocess Module
Frequently Used Arguments
Popen Constructor
Exceptions
Security Considerations
Popen Objects
Windows Popen Helpers
Windows Constants
Older high-level API
Replacing Older Functions with the subprocess Module
Replacing /bin/sh shell command substitution
Replacing shell pipeline
Replacing os.system()
Replacing the os.spawn family
Replacing os.popen(), os.popen2(), os.popen3()
Replacing functions from the popen2 module
Legacy Shell Invocation Functions
Notes
Converting an argument sequence to a string on Windows
sched — Event scheduler
Scheduler Objects
queue — A synchronized queue class
Queue Objects
SimpleQueue Objects
contextvars — Context Variables
Context Variables
Manual Context Management
asyncio support
_thread — Low-level threading API
Networking and Interprocess Communication
asyncio — Asynchronous I/O
Coroutines and Tasks
Coroutines
Awaitables
Running an asyncio Program
Creating Tasks
Sleeping
Running Tasks Concurrently
Shielding From Cancellation
Timeouts
Waiting Primitives
Running in Threads
Scheduling From Other Threads
Introspection
Task Object
Generator-based Coroutines
Streams
StreamReader
StreamWriter
Examples
TCP echo client using streams
TCP echo server using streams
Get HTTP headers
Register an open socket to wait for data using streams
Synchronization Primitives
Lock
Event
Condition
Semaphore
BoundedSemaphore
Subprocesses
Creating Subprocesses
Constants
Interacting with Subprocesses
Subprocess and Threads
Examples
Queues
Queue
Priority Queue
LIFO Queue
Exceptions
Examples
Exceptions
Event Loop
Event Loop Methods
Running and stopping the loop
Scheduling callbacks
Scheduling delayed callbacks
Creating Futures and Tasks
Opening network connections
Creating network servers
Transferring files
TLS Upgrade
Watching file descriptors
Working with socket objects directly
DNS
Working with pipes
Unix signals
Executing code in thread or process pools
Error Handling API
Enabling debug mode
Running Subprocesses
Callback Handles
Server Objects
Event Loop Implementations
Examples
Hello World with call_soon()
Display the current date with call_later()
Watch a file descriptor for read events
Set signal handlers for SIGINT and SIGTERM
Futures
Future Functions
Future Object
Transports and Protocols
Transports
Transports Hierarchy
Base Transport
Read-only Transports
Write-only Transports
Datagram Transports
Subprocess Transports
Protocols
Base Protocols
Base Protocol
Streaming Protocols
Buffered Streaming Protocols
Datagram Protocols
Subprocess Protocols
Examples
TCP Echo Server
TCP Echo Client
UDP Echo Server
UDP Echo Client
Connecting Existing Sockets
loop.subprocess_exec() and SubprocessProtocol
Policies
Getting and Setting the Policy
Policy Objects
Process Watchers
Custom Policies
Platform Support
All Platforms
Windows
Subprocess Support on Windows
macOS
High-level API Index
Tasks
Queues
Subprocesses
Streams
Synchronization
Exceptions
Low-level API Index
Obtaining the Event Loop
Event Loop Methods
Transports
Protocols
Event Loop Policies
Developing with asyncio
Debug Mode
Concurrency and Multithreading
Running Blocking Code
Logging
Detect never-awaited coroutines
Detect never-retrieved exceptions
socket — Low-level networking interface
Socket families
Module contents
Exceptions
Constants
Functions
Creating sockets
Other functions
Socket Objects
Notes on socket timeouts
Timeouts and the connect method
Timeouts and the accept method
Example
ssl — TLS/SSL wrapper for socket objects
Functions, Constants, and Exceptions
Socket creation
Context creation
Exceptions
Random generation
Certificate handling
Constants
SSL Sockets
SSL Contexts
Certificates
Certificate chains
CA certificates
Combined key and certificate
Self-signed certificates
Examples
Testing for SSL support
Client-side operation
Server-side operation
Notes on non-blocking sockets
Memory BIO Support
SSL session
Security considerations
Best defaults
Manual settings
Verifying certificates
Protocol versions
Cipher selection
Multi-processing
TLS 1.3
select — Waiting for I/O completion
/dev/poll Polling Objects
Edge and Level Trigger Polling (epoll) Objects
Polling Objects
Kqueue Objects
Kevent Objects
selectors — High-level I/O multiplexing
Introduction
Classes
Examples
signal — Set handlers for asynchronous events
General rules
Execution of Python signal handlers
Signals and threads
Module contents
Example
Note on SIGPIPE
Note on Signal Handlers and Exceptions
mmap — Memory-mapped file support
MADV_* Constants
MAP_* Constants
Internet Data Handling
email — An email and MIME handling package
email.message: Representing an email message
email.parser: Parsing email messages
FeedParser API
Parser API
Additional notes
email.generator: Generating MIME documents
email.policy: Policy Objects
email.errors: Exception and Defect classes
email.headerregistry: Custom Header Objects
email.contentmanager: Managing MIME Content
Content Manager Instances
email: Examples
email.message.Message: Representing an email message using the compat32 API
email.mime: Creating email and MIME objects from scratch
email.header: Internationalized headers
email.charset: Representing character sets
email.encoders: Encoders
email.utils: Miscellaneous utilities
email.iterators: Iterators
json — JSON encoder and decoder
Basic Usage
Encoders and Decoders
Exceptions
Standard Compliance and Interoperability
Character Encodings
Infinite and NaN Number Values
Repeated Names Within an Object
Top-level Non-Object, Non-Array Values
Implementation Limitations
Command Line Interface
Command line options
mailbox — Manipulate mailboxes in various formats
Mailbox objects
Maildir
mbox
MH
Babyl
MMDF
Message objects
MaildirMessage
mboxMessage
MHMessage
BabylMessage
MMDFMessage
Exceptions
Examples
mimetypes — Map filenames to MIME types
MimeTypes Objects
base64 — Base16, Base32, Base64, Base85 Data Encodings
Security Considerations
binhex — Encode and decode binhex4 files
Notes
binascii — Convert between binary and ASCII
quopri — Encode and decode MIME quoted-printable data
Structured Markup Processing Tools
html — HyperText Markup Language support
html.parser — Simple HTML and XHTML parser
Example HTML Parser Application
HTMLParser Methods
Examples
html.entities — Definitions of HTML general entities
XML Processing Modules
XML vulnerabilities
The defusedxml Package
xml.etree.ElementTree — The ElementTree XML API
Tutorial
XML tree and elements
Parsing XML
Pull API for non-blocking parsing
Finding interesting elements
Modifying an XML File
Building XML documents
Parsing XML with Namespaces
XPath support
Example
Supported XPath syntax
Reference
Functions
XInclude support
Example
Reference
Functions
Element Objects
ElementTree Objects
QName Objects
TreeBuilder Objects
XMLParser Objects
XMLPullParser Objects
Exceptions
xml.dom — The Document Object Model API
Module Contents
Objects in the DOM
DOMImplementation Objects
Node Objects
NodeList Objects
DocumentType Objects
Document Objects
Element Objects
Attr Objects
NamedNodeMap Objects
Comment Objects
Text and CDATASection Objects
ProcessingInstruction Objects
Exceptions
Conformance
Type Mapping
Accessor Methods
xml.dom.minidom — Minimal DOM implementation
DOM Objects
DOM Example
minidom and the DOM standard
xml.dom.pulldom — Support for building partial DOM trees
DOMEventStream Objects
xml.sax — Support for SAX2 parsers
SAXException Objects
xml.sax.handler — Base classes for SAX handlers
ContentHandler Objects
DTDHandler Objects
EntityResolver Objects
ErrorHandler Objects
LexicalHandler Objects
xml.sax.saxutils — SAX Utilities
xml.sax.xmlreader — Interface for XML parsers
XMLReader Objects
IncrementalParser Objects
Locator Objects
InputSource Objects
The Attributes Interface
The AttributesNS Interface
xml.parsers.expat — Fast XML parsing using Expat
XMLParser Objects
ExpatError Exceptions
Example
Content Model Descriptions
Expat error constants
Internet Protocols and Support
webbrowser — Convenient web-browser controller
Browser Controller Objects
wsgiref — WSGI Utilities and Reference Implementation
wsgiref.util – WSGI environment utilities
wsgiref.headers – WSGI response header tools
wsgiref.simple_server – a simple WSGI HTTP server
wsgiref.validate — WSGI conformance checker
wsgiref.handlers – server/gateway base classes
Examples
urllib — URL handling modules
urllib.request — Extensible library for opening URLs
Request Objects
OpenerDirector Objects
BaseHandler Objects
HTTPRedirectHandler Objects
HTTPCookieProcessor Objects
ProxyHandler Objects
HTTPPasswordMgr Objects
HTTPPasswordMgrWithPriorAuth Objects
AbstractBasicAuthHandler Objects
HTTPBasicAuthHandler Objects
ProxyBasicAuthHandler Objects
AbstractDigestAuthHandler Objects
HTTPDigestAuthHandler Objects
ProxyDigestAuthHandler Objects
HTTPHandler Objects
HTTPSHandler Objects
FileHandler Objects
DataHandler Objects
FTPHandler Objects
CacheFTPHandler Objects
UnknownHandler Objects
HTTPErrorProcessor Objects
Examples
Legacy interface
urllib.request Restrictions
urllib.response — Response classes used by urllib
urllib.parse — Parse URLs into components
URL Parsing
Parsing ASCII Encoded Bytes
Structured Parse Results
URL Quoting
urllib.error — Exception classes raised by urllib.request
urllib.robotparser — Parser for robots.txt
http — HTTP modules
HTTP status codes
http.client — HTTP protocol client
HTTPConnection Objects
HTTPResponse Objects
Examples
HTTPMessage Objects
ftplib — FTP protocol client
FTP Objects
FTP_TLS Objects
poplib — POP3 protocol client
POP3 Objects
POP3 Example
imaplib — IMAP4 protocol client
IMAP4 Objects
IMAP4 Example
smtplib — SMTP protocol client
SMTP Objects
SMTP Example
uuid — UUID objects according to RFC 4122
Example
socketserver — A framework for network servers
Server Creation Notes
Server Objects
Request Handler Objects
Examples
socketserver.TCPServer Example
socketserver.UDPServer Example
Asynchronous Mixins
http.server — HTTP servers
Security Considerations
http.cookies — HTTP state management
Cookie Objects
Morsel Objects
Example
http.cookiejar — Cookie handling for HTTP clients
CookieJar and FileCookieJar Objects
FileCookieJar subclasses and co-operation with web browsers
CookiePolicy Objects
DefaultCookiePolicy Objects
Cookie Objects
Examples
xmlrpc — XMLRPC server and client modules
xmlrpc.client — XML-RPC client access
ServerProxy Objects
DateTime Objects
Binary Objects
Fault Objects
ProtocolError Objects
MultiCall Objects
Convenience Functions
Example of Client Usage
Example of Client and Server Usage
xmlrpc.server — Basic XML-RPC servers
SimpleXMLRPCServer Objects
SimpleXMLRPCServer Example
CGIXMLRPCRequestHandler
Documenting XMLRPC server
DocXMLRPCServer Objects
DocCGIXMLRPCRequestHandler
ipaddress — IPv4/IPv6 manipulation library
Convenience factory functions
IP Addresses
Address objects
Conversion to Strings and Integers
Operators
Comparison operators
Arithmetic operators
IP Network definitions
Prefix, net mask and host mask
Network objects
Operators
Logical operators
Iteration
Networks as containers of addresses
Interface objects
Operators
Logical operators
Other Module Level Functions
Custom Exceptions
Multimedia Services
wave — Read and write WAV files
Wave_read Objects
Wave_write Objects
colorsys — Conversions between color systems
Internationalization
gettext — Multilingual internationalization services
GNU gettext API
Class-based API
The NullTranslations class
The GNUTranslations class
Solaris message catalog support
The Catalog constructor
Internationalizing your programs and modules
Localizing your module
Localizing your application
Changing languages on the fly
Deferred translations
Acknowledgements
locale — Internationalization services
Background, details, hints, tips and caveats
For extension writers and programs that embed Python
Access to message catalogs
Program Frameworks
turtle — Turtle graphics
Introduction
Overview of available Turtle and Screen methods
Turtle methods
Methods of TurtleScreen/Screen
Methods of RawTurtle/Turtle and corresponding functions
Turtle motion
Tell Turtle’s state
Settings for measurement
Pen control
Drawing state
Color control
Filling
More drawing control
Turtle state
Visibility
Appearance
Using events
Special Turtle methods
Compound shapes
Methods of TurtleScreen/Screen and corresponding functions
Window control
Animation control
Using screen events
Input methods
Settings and special methods
Methods specific to Screen, not inherited from TurtleScreen
Public classes
Help and configuration
How to use help
Translation of docstrings into different languages
How to configure Screen and Turtles
turtledemo — Demo scripts
Changes since Python 2.6
Changes since Python 3.0
cmd — Support for line-oriented command interpreters
Cmd Objects
Cmd Example
shlex — Simple lexical analysis
shlex Objects
Parsing Rules
Improved Compatibility with Shells
Graphical User Interfaces with Tk
tkinter — Python interface to Tcl/Tk
Architecture
Tkinter Modules
Tkinter Life Preserver
A Hello World Program
Important Tk Concepts
Understanding How Tkinter Wraps Tcl/Tk
How do I…? What option does…?
Navigating the Tcl/Tk Reference Manual
Threading model
Handy Reference
Setting Options
The Packer
Packer Options
Coupling Widget Variables
The Window Manager
Tk Option Data Types
Bindings and Events
The index Parameter
Images
File Handlers
tkinter.colorchooser — Color choosing dialog
tkinter.font — Tkinter font wrapper
Tkinter Dialogs
tkinter.simpledialog — Standard Tkinter input dialogs
tkinter.filedialog — File selection dialogs
Native Load/Save Dialogs
tkinter.commondialog — Dialog window templates
tkinter.messagebox — Tkinter message prompts
tkinter.scrolledtext — Scrolled Text Widget
tkinter.dnd — Drag and drop support
tkinter.ttk — Tk themed widgets
Using Ttk
Ttk Widgets
Widget
Standard Options
Scrollable Widget Options
Label Options
Compatibility Options
Widget States
ttk.Widget
Combobox
Options
Virtual events
ttk.Combobox
Spinbox
Options
Virtual events
ttk.Spinbox
Notebook
Options
Tab Options
Tab Identifiers
Virtual Events
ttk.Notebook
Progressbar
Options
ttk.Progressbar
Separator
Options
Sizegrip
Platform-specific notes
Bugs
Treeview
Options
Item Options
Tag Options
Column Identifiers
Virtual Events
ttk.Treeview
Ttk Styling
Layouts
tkinter.tix — Extension widgets for Tk
Using Tix
Tix Widgets
Basic Widgets
File Selectors
Hierarchical ListBox
Tabular ListBox
Manager Widgets
Image Types
Miscellaneous Widgets
Form Geometry Manager
Tix Commands
IDLE
Menus
File menu (Shell and Editor)
Edit menu (Shell and Editor)
Format menu (Editor window only)
Run menu (Editor window only)
Shell menu (Shell window only)
Debug menu (Shell window only)
Options menu (Shell and Editor)
Window menu (Shell and Editor)
Help menu (Shell and Editor)
Context menus
Editing and Navigation
Editor windows
Key bindings
Automatic indentation
Search and Replace
Completions
Calltips
Code Context
Shell window
Text colors
Startup and Code Execution
Command line usage
Startup failure
Running user code
User output in Shell
Developing tkinter applications
Running without a subprocess
Help and Preferences
Help sources
Setting preferences
IDLE on macOS
Extensions
idlelib
Development Tools
typing — Support for type hints
Relevant PEPs
Type aliases
NewType
Callable
Generics
User-defined generic types
The Any type
Nominal vs structural subtyping
Module contents
Special typing primitives
Special types
Special forms
Building generic types
Other special directives
Generic concrete collections
Corresponding to built-in types
Corresponding to types in collections
Other concrete types
Abstract Base Classes
Corresponding to collections in collections.abc
Corresponding to other types in collections.abc
Asynchronous programming
Context manager types
Protocols
Functions and decorators
Introspection helpers
Constant
pydoc — Documentation generator and online help system
Python Development Mode
Effects of the Python Development Mode
ResourceWarning Example
Bad file descriptor error example
doctest — Test interactive Python examples
Simple Usage: Checking Examples in Docstrings
Simple Usage: Checking Examples in a Text File
How It Works
Which Docstrings Are Examined?
How are Docstring Examples Recognized?
What’s the Execution Context?
What About Exceptions?
Option Flags
Directives
Warnings
Basic API
Unittest API
Advanced API
DocTest Objects
Example Objects
DocTestFinder objects
DocTestParser objects
DocTestRunner objects
OutputChecker objects
Debugging
Soapbox
unittest — Unit testing framework
Basic example
Command-Line Interface
Command-line options
Test Discovery
Organizing test code
Re-using old test code
Skipping tests and expected failures
Distinguishing test iterations using subtests
Classes and functions
Test cases
Deprecated aliases
Grouping tests
Loading and running tests
load_tests Protocol
Class and Module Fixtures
setUpClass and tearDownClass
setUpModule and tearDownModule
Signal Handling
unittest.mock — mock object library
Quick Guide
The Mock Class
Calling
Deleting Attributes
Mock names and the name attribute
Attaching Mocks as Attributes
The patchers
patch
patch.object
patch.dict
patch.multiple
patch methods: start and stop
patch builtins
TEST_PREFIX
Nesting Patch Decorators
Where to patch
Patching Descriptors and Proxy Objects
MagicMock and magic method support
Mocking Magic Methods
Magic Mock
Helpers
sentinel
DEFAULT
call
create_autospec
ANY
FILTER_DIR
mock_open
Autospeccing
Sealing mocks
unittest.mock — getting started
Using Mock
Mock Patching Methods
Mock for Method Calls on an Object
Mocking Classes
Naming your mocks
Tracking all Calls
Setting Return Values and Attributes
Raising exceptions with mocks
Side effect functions and iterables
Mocking asynchronous iterators
Mocking asynchronous context manager
Creating a Mock from an Existing Object
Patch Decorators
Further Examples
Mocking chained calls
Partial mocking
Mocking a Generator Method
Applying the same patch to every test method
Mocking Unbound Methods
Checking multiple calls with mock
Coping with mutable arguments
Nesting Patches
Mocking a dictionary with MagicMock
Mock subclasses and their attributes
Mocking imports with patch.dict
Tracking order of calls and less verbose call assertions
More complex argument matching
2to3 — Automated Python 2 to 3 code translation
Using 2to3
Fixers
lib2to3 — 2to3’s library
test — Regression tests package for Python
Writing Unit Tests for the test package
Running tests using the command-line interface
test.support — Utilities for the Python test suite
test.support.socket_helper — Utilities for socket tests
test.support.script_helper — Utilities for the Python execution tests
test.support.bytecode_helper — Support tools for testing correct bytecode generation
test.support.threading_helper — Utilities for threading tests
test.support.os_helper — Utilities for os tests
test.support.import_helper — Utilities for import tests
test.support.warnings_helper — Utilities for warnings tests
Debugging and Profiling
Audit events table
bdb — Debugger framework
faulthandler — Dump the Python traceback
Dumping the traceback
Fault handler state
Dumping the tracebacks after a timeout
Dumping the traceback on a user signal
Issue with file descriptors
Example
pdb — The Python Debugger
Debugger Commands
The Python Profilers
Introduction to the profilers
Instant User’s Manual
profile and cProfile Module Reference
The Stats Class
What Is Deterministic Profiling?
Limitations
Calibration
Using a custom timer
timeit — Measure execution time of small code snippets
Basic Examples
Python Interface
Command-Line Interface
Examples
trace — Trace or track Python statement execution
Command-Line Usage
Main options
Modifiers
Filters
Programmatic Interface
tracemalloc — Trace memory allocations
Examples
Display the top 10
Compute differences
Get the traceback of a memory block
Pretty top
Record the current and peak size of all traced memory blocks
API
Functions
DomainFilter
Filter
Frame
Snapshot
Statistic
StatisticDiff
Trace
Traceback
Software Packaging and Distribution
distutils — Building and installing Python modules
ensurepip — Bootstrapping the pip installer
Command line interface
Module API
venv — Creation of virtual environments
Creating virtual environments
How venvs work
API
An example of extending EnvBuilder
zipapp — Manage executable Python zip archives
Basic Example
Command-Line Interface
Python API
Examples
Specifying the Interpreter
Creating Standalone Applications with zipapp
Making a Windows executable
Caveats
The Python Zip Application Archive Format
Python Runtime Services
sys — System-specific parameters and functions
sysconfig — Provide access to Python’s configuration information
Configuration variables
Installation paths
Other functions
Using sysconfig as a script
builtins — Built-in objects
__main__ — Top-level code environment
__name__ == '__main__'
What is the “top-level code environment”?
Idiomatic Usage
Packaging Considerations
__main__.py in Python Packages
Idiomatic Usage
import __main__
warnings — Warning control
Warning Categories
The Warnings Filter
Describing Warning Filters
Default Warning Filter
Overriding the default filter
Temporarily Suppressing Warnings
Testing Warnings
Updating Code For New Versions of Dependencies
Available Functions
Available Context Managers
dataclasses — Data Classes
Module contents
Post-init processing
Class variables
Init-only variables
Frozen instances
Inheritance
Re-ordering of keyword-only parameters in __init__()
Default factory functions
Mutable default values
Descriptor-typed fields
contextlib — Utilities for with-statement contexts
Utilities
Examples and Recipes
Supporting a variable number of context managers
Catching exceptions from __enter__ methods
Cleaning up in an __enter__ implementation
Replacing any use of try-finally and flag variables
Using a context manager as a function decorator
Single use, reusable and reentrant context managers
Reentrant context managers
Reusable context managers
abc — Abstract Base Classes
atexit — Exit handlers
atexit Example
traceback — Print or retrieve a stack traceback
TracebackException Objects
StackSummary Objects
FrameSummary Objects
Traceback Examples
__future__ — Future statement definitions
gc — Garbage Collector interface
inspect — Inspect live objects
Types and members
Retrieving source code
Introspecting callables with the Signature object
Classes and functions
The interpreter stack
Fetching attributes statically
Current State of Generators and Coroutines
Code Objects Bit Flags
Command Line Interface
site — Site-specific configuration hook
Readline configuration
Module contents
Command Line Interface
Custom Python Interpreters
code — Interpreter base classes
Interactive Interpreter Objects
Interactive Console Objects
codeop — Compile Python code
Importing Modules
zipimport — Import modules from Zip archives
zipimporter Objects
Examples
pkgutil — Package extension utility
modulefinder — Find modules used by a script
Example usage of ModuleFinder
runpy — Locating and executing Python modules
importlib — The implementation of import
Introduction
Functions
importlib.abc – Abstract base classes related to import
importlib.resources – Resources
importlib.machinery – Importers and path hooks
importlib.util – Utility code for importers
Examples
Importing programmatically
Checking if a module can be imported
Importing a source file directly
Implementing lazy imports
Setting up an importer
Approximating importlib.import_module()
Using importlib.metadata
Overview
Functional API
Entry points
Distribution metadata
Distribution versions
Distribution files
Distribution requirements
Package distributions
Distributions
Extending the search algorithm
Python Language Services
ast — Abstract Syntax Trees
Abstract Grammar
Node classes
Literals
Variables
Expressions
Subscripting
Comprehensions
Statements
Imports
Control flow
Pattern matching
Function and class definitions
Async and await
ast Helpers
Compiler Flags
Command-Line Usage
symtable — Access to the compiler’s symbol tables
Generating Symbol Tables
Examining Symbol Tables
token — Constants used with Python parse trees
keyword — Testing for Python keywords
tokenize — Tokenizer for Python source
Tokenizing Input
Command-Line Usage
Examples
tabnanny — Detection of ambiguous indentation
pyclbr — Python module browser support
Function Objects
Class Objects
py_compile — Compile Python source files
Command-Line Interface
compileall — Byte-compile Python libraries
Command-line use
Public functions
dis — Disassembler for Python bytecode
Bytecode analysis
Analysis functions
Python Bytecode Instructions
Opcode collections
pickletools — Tools for pickle developers
Command line usage
Command line options
Programmatic Interface
MS Windows Specific Services
msvcrt — Useful routines from the MS VC++ runtime
File Operations
Console I/O
Other Functions
winreg — Windows registry access
Functions
Constants
HKEY_* Constants
Access Rights
64-bit Specific
Value Types
Registry Handle Objects
winsound — Sound-playing interface for Windows
Unix Specific Services
posix — The most common POSIX system calls
Large File Support
Notable Module Contents
pwd — The password database
grp — The group database
termios — POSIX style tty control
Example
tty — Terminal control functions
pty — Pseudo-terminal utilities
Example
fcntl — The fcntl and ioctl system calls
resource — Resource usage information
Resource Limits
Resource Usage
syslog — Unix syslog library routines
Examples
Simple example
Superseded Modules
aifc — Read and write AIFF and AIFC files
asynchat — Asynchronous socket command/response handler
asynchat Example
asyncore — Asynchronous socket handler
asyncore Example basic HTTP client
asyncore Example basic echo server
audioop — Manipulate raw audio data
cgi — Common Gateway Interface support
Introduction
Using the cgi module
Higher Level Interface
Functions
Caring about security
Installing your CGI script on a Unix system
Testing your CGI script
Debugging CGI scripts
Common problems and solutions
cgitb — Traceback manager for CGI scripts
chunk — Read IFF chunked data
crypt — Function to check Unix passwords
Hashing Methods
Module Attributes
Module Functions
Examples
imghdr — Determine the type of an image
imp — Access the import internals
Examples
mailcap — Mailcap file handling
msilib — Read and write Microsoft Installer files
Database Objects
View Objects
Summary Information Objects
Record Objects
Errors
CAB Objects
Directory Objects
Features
GUI classes
Precomputed tables
nis — Interface to Sun’s NIS (Yellow Pages)
nntplib — NNTP protocol client
NNTP Objects
Attributes
Methods
Utility functions
optparse — Parser for command line options
Background
Terminology
What are options for?
What are positional arguments for?
Tutorial
Understanding option actions
The store action
Handling boolean (flag) options
Other actions
Default values
Generating help
Grouping Options
Printing a version string
How optparse handles errors
Putting it all together
Reference Guide
Creating the parser
Populating the parser
Defining options
Option attributes
Standard option actions
Standard option types
Parsing arguments
Querying and manipulating your option parser
Conflicts between options
Cleanup
Other methods
Option Callbacks
Defining a callback option
How callbacks are called
Raising errors in a callback
Callback example 1: trivial callback
Callback example 2: check option order
Callback example 3: check option order (generalized)
Callback example 4: check arbitrary condition
Callback example 5: fixed arguments
Callback example 6: variable arguments
Extending optparse
Adding new types
Adding new actions
ossaudiodev — Access to OSS-compatible audio devices
Audio Device Objects
Mixer Device Objects
pipes — Interface to shell pipelines
Template Objects
smtpd — SMTP Server
SMTPServer Objects
DebuggingServer Objects
PureProxy Objects
MailmanProxy Objects
SMTPChannel Objects
sndhdr — Determine type of sound file
spwd — The shadow password database
sunau — Read and write Sun AU files
AU_read Objects
AU_write Objects
telnetlib — Telnet client
Telnet Objects
Telnet Example
uu — Encode and decode uuencode files
xdrlib — Encode and decode XDR data
Packer Objects
Unpacker Objects
Exceptions
Security Considerations
Extending and Embedding the Python Interpreter
Recommended third party tools
Creating extensions without third party tools
1. Extending Python with C or C++
1.1. A Simple Example
1.2. Intermezzo: Errors and Exceptions
1.3. Back to the Example
1.4. The Module’s Method Table and Initialization Function
1.5. Compilation and Linkage
1.6. Calling Python Functions from C
1.7. Extracting Parameters in Extension Functions
1.8. Keyword Parameters for Extension Functions
1.9. Building Arbitrary Values
1.10. Reference Counts
1.10.1. Reference Counting in Python
1.10.2. Ownership Rules
1.10.3. Thin Ice
1.10.4. NULL Pointers
1.11. Writing Extensions in C++
1.12. Providing a C API for an Extension Module
2. Defining Extension Types: Tutorial
2.1. The Basics
2.2. Adding data and methods to the Basic example
2.3. Providing finer control over data attributes
2.4. Supporting cyclic garbage collection
2.5. Subclassing other types
3. Defining Extension Types: Assorted Topics
3.1. Finalization and De-allocation
3.2. Object Presentation
3.3. Attribute Management
3.3.1. Generic Attribute Management
3.3.2. Type-specific Attribute Management
3.4. Object Comparison
3.5. Abstract Protocol Support
3.6. Weak Reference Support
3.7. More Suggestions
4. Building C and C++ Extensions
4.1. Building C and C++ Extensions with distutils
4.2. Distributing your extension modules
5. Building C and C++ Extensions on Windows
5.1. A Cookbook Approach
5.2. Differences Between Unix and Windows
5.3. Using DLLs in Practice
Embedding the CPython runtime in a larger application
1. Embedding Python in Another Application
1.1. Very High Level Embedding
1.2. Beyond Very High Level Embedding: An overview
1.3. Pure Embedding
1.4. Extending Embedded Python
1.5. Embedding Python in C++
1.6. Compiling and Linking under Unix-like systems
Python/C API Reference Manual
Introduction
Coding standards
Include Files
Useful macros
Objects, Types and Reference Counts
Reference Counts
Reference Count Details
Types
Exceptions
Embedding Python
Debugging Builds
C API Stability
Stable Application Binary Interface
Limited API Scope and Performance
Limited API Caveats
Platform Considerations
Contents of Limited API
The Very High Level Layer
Reference Counting
Exception Handling
Printing and clearing
Raising exceptions
Issuing warnings
Querying the error indicator
Signal Handling
Exception Classes
Exception Objects
Unicode Exception Objects
Recursion Control
Standard Exceptions
Standard Warning Categories
Utilities
Operating System Utilities
System Functions
Process Control
Importing Modules
Data marshalling support
Parsing arguments and building values
Parsing arguments
Strings and buffers
Numbers
Other objects
API Functions
Building values
String conversion and formatting
Reflection
Codec registry and support functions
Codec lookup API
Registry API for Unicode encoding error handlers
Abstract Objects Layer
Object Protocol
Call Protocol
The tp_call Protocol
The Vectorcall Protocol
Recursion Control
Vectorcall Support API
Object Calling API
Call Support API
Number Protocol
Sequence Protocol
Mapping Protocol
Iterator Protocol
Buffer Protocol
Buffer structure
Buffer request types
request-independent fields
readonly, format
shape, strides, suboffsets
contiguity requests
compound requests
Complex arrays
NumPy-style: shape and strides
PIL-style: shape, strides and suboffsets
Buffer-related functions
Old Buffer Protocol
Concrete Objects Layer
Fundamental Objects
Type Objects
Creating Heap-Allocated Types
The None Object
Numeric Objects
Integer Objects
Boolean Objects
Floating Point Objects
Complex Number Objects
Complex Numbers as C Structures
Complex Numbers as Python Objects
Sequence Objects
Bytes Objects
Byte Array Objects
Type check macros
Direct API functions
Macros
Unicode Objects and Codecs
Unicode Objects
Unicode Type
Unicode Character Properties
Creating and accessing Unicode strings
Deprecated Py_UNICODE APIs
Locale Encoding
File System Encoding
wchar_t Support
Built-in Codecs
Generic Codecs
UTF-8 Codecs
UTF-32 Codecs
UTF-16 Codecs
UTF-7 Codecs
Unicode-Escape Codecs
Raw-Unicode-Escape Codecs
Latin-1 Codecs
ASCII Codecs
Character Map Codecs
MBCS codecs for Windows
Methods & Slots
Methods and Slot Functions
Tuple Objects
Struct Sequence Objects
List Objects
Container Objects
Dictionary Objects
Set Objects
Function Objects
Function Objects
Instance Method Objects
Method Objects
Cell Objects
Code Objects
Other Objects
File Objects
Module Objects
Initializing C modules
Single-phase initialization
Multi-phase initialization
Low-level module creation functions
Support functions
Module lookup
Iterator Objects
Descriptor Objects
Slice Objects
Ellipsis Object
MemoryView objects
Weak Reference Objects
Capsules
Generator Objects
Coroutine Objects
Context Variables Objects
DateTime Objects
Objects for Type Hinting
Initialization, Finalization, and Threads
Before Python Initialization
Global configuration variables
Initializing and finalizing the interpreter
Process-wide parameters
Thread State and the Global Interpreter Lock
Releasing the GIL from extension code
Non-Python created threads
Cautions about fork()
High-level API
Low-level API
Sub-interpreter support
Bugs and caveats
Asynchronous Notifications
Profiling and Tracing
Advanced Debugger Support
Thread Local Storage Support
Thread Specific Storage (TSS) API
Dynamic Allocation
Methods
Thread Local Storage (TLS) API
Python Initialization Configuration
Example
PyWideStringList
PyStatus
PyPreConfig
Preinitialize Python with PyPreConfig
PyConfig
Initialization with PyConfig
Isolated Configuration
Python Configuration
Python Path Configuration
Py_RunMain()
Py_GetArgcArgv()
Multi-Phase Initialization Private Provisional API
Memory Management
Overview
Allocator Domains
Raw Memory Interface
Memory Interface
Object allocators
Default Memory Allocators
Customize Memory Allocators
Debug hooks on the Python memory allocators
The pymalloc allocator
Customize pymalloc Arena Allocator
tracemalloc C API
Examples
Object Implementation Support
Allocating Objects on the Heap
Common Object Structures
Base object types and macros
Implementing functions and methods
Accessing attributes of extension types
Type Objects
Quick Reference
“tp slots”
sub-slots
slot typedefs
PyTypeObject Definition
PyObject Slots
PyVarObject Slots
PyTypeObject Slots
Static Types
Heap Types
Number Object Structures
Mapping Object Structures
Sequence Object Structures
Buffer Object Structures
Async Object Structures
Slot Type typedefs
Examples
Supporting Cyclic Garbage Collection
Controlling the Garbage Collector State
API and ABI Versioning
Distributing Python Modules
Key terms
Open source licensing and collaboration
Installing the tools
Reading the Python Packaging User Guide
How do I…?
… choose a name for my project?
… create and distribute binary extensions?
Installing Python Modules
Key terms
Basic usage
How do I …?
… install pip in versions of Python prior to Python 3.4?
… install packages just for the current user?
… install scientific Python packages?
… work with multiple versions of Python installed in parallel?
Common installation issues
Installing into the system Python on Linux
Pip not installed
Installing binary extensions
Python HOWTOs
Porting Python 2 Code to Python 3
The Short Explanation
Details
Drop support for Python 2.6 and older
Make sure you specify the proper version support in your setup.py file
Have good test coverage
Learn the differences between Python 2 & 3
Update your code
Division
Text versus binary data
Use feature detection instead of version detection
Prevent compatibility regressions
Check which dependencies block your transition
Update your setup.py file to denote Python 3 compatibility
Use continuous integration to stay compatible
Consider using optional static type checking
Porting Extension Modules to Python 3
Curses Programming with Python
What is curses?
The Python curses module
Starting and ending a curses application
Windows and Pads
Displaying Text
Attributes and Color
User Input
For More Information
Descriptor HowTo Guide
Primer
Simple example: A descriptor that returns a constant
Dynamic lookups
Managed attributes
Customized names
Closing thoughts
Complete Practical Example
Validator class
Custom validators
Practical application
Technical Tutorial
Abstract
Definition and introduction
Descriptor protocol
Overview of descriptor invocation
Invocation from an instance
Invocation from a class
Invocation from super
Summary of invocation logic
Automatic name notification
ORM example
Pure Python Equivalents
Properties
Functions and methods
Kinds of methods
Static methods
Class methods
Member objects and __slots__
Functional Programming HOWTO
Introduction
Formal provability
Modularity
Ease of debugging and testing
Composability
Iterators
Data Types That Support Iterators
Generator expressions and list comprehensions
Generators
Passing values into a generator
Built-in functions
The itertools module
Creating new iterators
Calling functions on elements
Selecting elements
Combinatoric functions
Grouping elements
The functools module
The operator module
Small functions and the lambda expression
Revision History and Acknowledgements
References
General
Python-specific
Python documentation
Logging HOWTO
Basic Logging Tutorial
When to use logging
A simple example
Logging to a file
Logging from multiple modules
Logging variable data
Changing the format of displayed messages
Displaying the date/time in messages
Next Steps
Advanced Logging Tutorial
Logging Flow
Loggers
Handlers
Formatters
Configuring Logging
What happens if no configuration is provided
Configuring Logging for a Library
Logging Levels
Custom Levels
Useful Handlers
Exceptions raised during logging
Using arbitrary objects as messages
Optimization
Logging Cookbook
Using logging in multiple modules
Logging from multiple threads
Multiple handlers and formatters
Logging to multiple destinations
Custom handling of levels
Configuration server example
Dealing with handlers that block
Sending and receiving logging events across a network
Running a logging socket listener in production
Adding contextual information to your logging output
Using LoggerAdapters to impart contextual information
Using objects other than dicts to pass contextual information
Using Filters to impart contextual information
Use of contextvars
Imparting contextual information in handlers
Logging to a single file from multiple processes
Using concurrent.futures.ProcessPoolExecutor
Deploying Web applications using Gunicorn and uWSGI
Using file rotation
Use of alternative formatting styles
Customizing LogRecord
Subclassing QueueHandler - a ZeroMQ example
Subclassing QueueListener - a ZeroMQ example
An example dictionary-based configuration
Using a rotator and namer to customize log rotation processing
A more elaborate multiprocessing example
Inserting a BOM into messages sent to a SysLogHandler
Implementing structured logging
Customizing handlers with dictConfig()
Using particular formatting styles throughout your application
Using LogRecord factories
Using custom message objects
Configuring filters with dictConfig()
Customized exception formatting
Speaking logging messages
Buffering logging messages and outputting them conditionally
Sending logging messages to email, with buffering
Formatting times using UTC (GMT) via configuration
Using a context manager for selective logging
A CLI application starter template
A Qt GUI for logging
Logging to syslog with RFC5424 support
How to treat a logger like an output stream
Patterns to avoid
Opening the same log file multiple times
Using loggers as attributes in a class or passing them as parameters
Adding handlers other than NullHandler to a logger in a library
Creating a lot of loggers
Other resources
Regular Expression HOWTO
Introduction
Simple Patterns
Matching Characters
Repeating Things
Using Regular Expressions
Compiling Regular Expressions
The Backslash Plague
Performing Matches
Module-Level Functions
Compilation Flags
More Pattern Power
More Metacharacters
Grouping
Non-capturing and Named Groups
Lookahead Assertions
Modifying Strings
Splitting Strings
Search and Replace
Common Problems
Use String Methods
match() versus search()
Greedy versus Non-Greedy
Using re.VERBOSE
Feedback
Socket Programming HOWTO
Sockets
History
Creating a Socket
IPC
Using a Socket
Binary Data
Disconnecting
When Sockets Die
Non-blocking Sockets
Sorting HOW TO
Sorting Basics
Key Functions
Operator Module Functions
Ascending and Descending
Sort Stability and Complex Sorts
The Old Way Using Decorate-Sort-Undecorate
The Old Way Using the cmp Parameter
Odd and Ends
Unicode HOWTO
Introduction to Unicode
Definitions
Encodings
References
Python’s Unicode Support
The String Type
Converting to Bytes
Unicode Literals in Python Source Code
Unicode Properties
Comparing Strings
Unicode Regular Expressions
References
Reading and Writing Unicode Data
Unicode filenames
Tips for Writing Unicode-aware Programs
Converting Between File Encodings
Files in an Unknown Encoding
References
Acknowledgements
HOWTO Fetch Internet Resources Using The urllib Package
Introduction
Fetching URLs
Data
Headers
Handling Exceptions
URLError
HTTPError
Error Codes
Wrapping it Up
Number 1
Number 2
info and geturl
Openers and Handlers
Basic Authentication
Proxies
Sockets and Layers
Footnotes
Argparse Tutorial
Concepts
The basics
Introducing Positional arguments
Introducing Optional arguments
Short options
Combining Positional and Optional arguments
Getting a little more advanced
Conflicting options
Conclusion
An introduction to the ipaddress module
Creating Address/Network/Interface objects
A Note on IP Versions
IP Host Addresses
Defining Networks
Host Interfaces
Inspecting Address/Network/Interface Objects
Networks as lists of Addresses
Comparisons
Using IP Addresses with other modules
Getting more detail when instance creation fails
Argument Clinic How-To
The Goals Of Argument Clinic
Basic Concepts And Usage
Converting Your First Function
Advanced Topics
Symbolic default values
Renaming the C functions and variables generated by Argument Clinic
Converting functions using PyArg_UnpackTuple
Optional Groups
Using real Argument Clinic converters, instead of “legacy converters”
Py_buffer
Advanced converters
Parameter default values
The NULL default value
Expressions specified as default values
Using a return converter
Cloning existing functions
Calling Python code
Using a “self converter”
Using a “defining class” converter
Writing a custom converter
Writing a custom return converter
METH_O and METH_NOARGS
tp_new and tp_init functions
Changing and redirecting Clinic’s output
The #ifdef trick
Using Argument Clinic in Python files
Instrumenting CPython with DTrace and SystemTap
Enabling the static markers
Static DTrace probes
Static SystemTap markers
Available static markers
SystemTap Tapsets
Examples
Annotations Best Practices
Accessing The Annotations Dict Of An Object In Python 3.10 And Newer
Accessing The Annotations Dict Of An Object In Python 3.9 And Older
Manually Un-Stringizing Stringized Annotations
Best Practices For __annotations__ In Any Python Version
__annotations__ Quirks
Python Frequently Asked Questions
General Python FAQ
General Information
Python in the real world
Programming FAQ
General Questions
Core Language
Numbers and strings
Performance
Sequences (Tuples/Lists)
Objects
Modules
Design and History FAQ
Why does Python use indentation for grouping of statements?
Why am I getting strange results with simple arithmetic operations?
Why are floating-point calculations so inaccurate?
Why are Python strings immutable?
Why must ‘self’ be used explicitly in method definitions and calls?
Why can’t I use an assignment in an expression?
Why does Python use methods for some functionality (e.g. list.index()) but functions for other (e.g. len(list))?
Why is join() a string method instead of a list or tuple method?
How fast are exceptions?
Why isn’t there a switch or case statement in Python?
Can’t you emulate threads in the interpreter instead of relying on an OS-specific thread implementation?
Why can’t lambda expressions contain statements?
Can Python be compiled to machine code, C or some other language?
How does Python manage memory?
Why doesn’t CPython use a more traditional garbage collection scheme?
Why isn’t all memory freed when CPython exits?
Why are there separate tuple and list data types?
How are lists implemented in CPython?
How are dictionaries implemented in CPython?
Why must dictionary keys be immutable?
Why doesn’t list.sort() return the sorted list?
How do you specify and enforce an interface spec in Python?
Why is there no goto?
Why can’t raw strings (r-strings) end with a backslash?
Why doesn’t Python have a “with” statement for attribute assignments?
Why don’t generators support the with statement?
Why are colons required for the if/while/def/class statements?
Why does Python allow commas at the end of lists and tuples?
Library and Extension FAQ
General Library Questions
Common tasks
Threads
Input and Output
Network/Internet Programming
Databases
Mathematics and Numerics
Extending/Embedding FAQ
Can I create my own functions in C?
Can I create my own functions in C++?
Writing C is hard; are there any alternatives?
How can I execute arbitrary Python statements from C?
How can I evaluate an arbitrary Python expression from C?
How do I extract C values from a Python object?
How do I use Py_BuildValue() to create a tuple of arbitrary length?
How do I call an object’s method from C?
How do I catch the output from PyErr_Print() (or anything that prints to stdout/stderr)?
How do I access a module written in Python from C?
How do I interface to C++ objects from Python?
I added a module using the Setup file and the make fails; why?
How do I debug an extension?
I want to compile a Python module on my Linux system, but some files are missing. Why?
How do I tell “incomplete input” from “invalid input”?
How do I find undefined g++ symbols __builtin_new or __pure_virtual?
Can I create an object class with some methods implemented in C and others in Python (e.g. through inheritance)?
Python on Windows FAQ
How do I run a Python program under Windows?
How do I make Python scripts executable?
Why does Python sometimes take so long to start?
How do I make an executable from a Python script?
Is a *.pyd file the same as a DLL?
How can I embed Python into a Windows application?
How do I keep editors from inserting tabs into my Python source?
How do I check for a keypress without blocking?
How do I solve the missing api-ms-win-crt-runtime-l1-1-0.dll error?
Graphic User Interface FAQ
General GUI Questions
What GUI toolkits exist for Python?
Tkinter questions
“Why is Python Installed on my Computer?” FAQ
What is Python?
Why is Python installed on my machine?
Can I delete Python?
Glossary
About these documents
Contributors to the Python Documentation
Dealing with Bugs
Documentation bugs
Using the Python issue tracker
Getting started contributing to Python yourself
Copyright
History and License
History of the software
Terms and conditions for accessing or otherwise using Python
PSF LICENSE AGREEMENT FOR PYTHON 3.10.8
BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0
CNRI LICENSE AGREEMENT FOR PYTHON 1.6.1
CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2
ZERO-CLAUSE BSD LICENSE FOR CODE IN THE PYTHON 3.10.8 DOCUMENTATION
Licenses and Acknowledgements for Incorporated Software
Mersenne Twister
Sockets
Asynchronous socket services
Cookie management
Execution tracing
UUencode and UUdecode functions
XML Remote Procedure Calls
test_epoll
Select kqueue
SipHash24
strtod and dtoa
OpenSSL
expat
libffi
zlib
cfuhash
libmpdec
W3C C14N test suite
Next topic
What’s New in Python

This Page
Report a Bug
Show Source
«
indexmodules |next |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Python Documentation contents
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Glossary
Quick search
  |
Glossary
>>>
The default Python prompt of the interactive shell. Often seen for code examples which can be executed interactively in the interpreter.

...
Can refer to:

The default Python prompt of the interactive shell when entering the code for an indented code block, when within a pair of matching left and right delimiters (parentheses, square brackets, curly braces or triple quotes), or after specifying a decorator.

The Ellipsis built-in constant.

2to3
A tool that tries to convert Python 2.x code to Python 3.x code by handling most of the incompatibilities which can be detected by parsing the source and traversing the parse tree.

2to3 is available in the standard library as lib2to3; a standalone entry point is provided as Tools/scripts/2to3. See 2to3 — Automated Python 2 to 3 code translation.

abstract base class
Abstract base classes complement duck-typing by providing a way to define interfaces when other techniques like hasattr() would be clumsy or subtly wrong (for example with magic methods). ABCs introduce virtual subclasses, which are classes that don’t inherit from a class but are still recognized by isinstance() and issubclass(); see the abc module documentation. Python comes with many built-in ABCs for data structures (in the collections.abc module), numbers (in the numbers module), streams (in the io module), import finders and loaders (in the importlib.abc module). You can create your own ABCs with the abc module.

annotation
A label associated with a variable, a class attribute or a function parameter or return value, used by convention as a type hint.

Annotations of local variables cannot be accessed at runtime, but annotations of global variables, class attributes, and functions are stored in the __annotations__ special attribute of modules, classes, and functions, respectively.

See variable annotation, function annotation, PEP 484 and PEP 526, which describe this functionality. Also see Annotations Best Practices for best practices on working with annotations.

argument
A value passed to a function (or method) when calling the function. There are two kinds of argument:

keyword argument: an argument preceded by an identifier (e.g. name=) in a function call or passed as a value in a dictionary preceded by **. For example, 3 and 5 are both keyword arguments in the following calls to complex():

complex(real=3, imag=5)
complex(**{'real': 3, 'imag': 5})
positional argument: an argument that is not a keyword argument. Positional arguments can appear at the beginning of an argument list and/or be passed as elements of an iterable preceded by *. For example, 3 and 5 are both positional arguments in the following calls:

complex(3, 5)
complex(*(3, 5))
Arguments are assigned to the named local variables in a function body. See the Calls section for the rules governing this assignment. Syntactically, any expression can be used to represent an argument; the evaluated value is assigned to the local variable.

See also the parameter glossary entry, the FAQ question on the difference between arguments and parameters, and PEP 362.

asynchronous context manager
An object which controls the environment seen in an async with statement by defining __aenter__() and __aexit__() methods. Introduced by PEP 492.

asynchronous generator
A function which returns an asynchronous generator iterator. It looks like a coroutine function defined with async def except that it contains yield expressions for producing a series of values usable in an async for loop.

Usually refers to an asynchronous generator function, but may refer to an asynchronous generator iterator in some contexts. In cases where the intended meaning isn’t clear, using the full terms avoids ambiguity.

An asynchronous generator function may contain await expressions as well as async for, and async with statements.

asynchronous generator iterator
An object created by a asynchronous generator function.

This is an asynchronous iterator which when called using the __anext__() method returns an awaitable object which will execute the body of the asynchronous generator function until the next yield expression.

Each yield temporarily suspends processing, remembering the location execution state (including local variables and pending try-statements). When the asynchronous generator iterator effectively resumes with another awaitable returned by __anext__(), it picks up where it left off. See PEP 492 and PEP 525.

asynchronous iterable
An object, that can be used in an async for statement. Must return an asynchronous iterator from its __aiter__() method. Introduced by PEP 492.

asynchronous iterator
An object that implements the __aiter__() and __anext__() methods. __anext__ must return an awaitable object. async for resolves the awaitables returned by an asynchronous iterator’s __anext__() method until it raises a StopAsyncIteration exception. Introduced by PEP 492.

attribute
A value associated with an object which is usually referenced by name using dotted expressions. For example, if an object o has an attribute a it would be referenced as o.a.

It is possible to give an object an attribute whose name is not an identifier as defined by Identifiers and keywords, for example using setattr(), if the object allows it. Such an attribute will not be accessible using a dotted expression, and would instead need to be retrieved with getattr().

awaitable
An object that can be used in an await expression. Can be a coroutine or an object with an __await__() method. See also PEP 492.

BDFL
Benevolent Dictator For Life, a.k.a. Guido van Rossum, Python’s creator.

binary file
A file object able to read and write bytes-like objects. Examples of binary files are files opened in binary mode ('rb', 'wb' or 'rb+'), sys.stdin.buffer, sys.stdout.buffer, and instances of io.BytesIO and gzip.GzipFile.

See also text file for a file object able to read and write str objects.

borrowed reference
In Python’s C API, a borrowed reference is a reference to an object. It does not modify the object reference count. It becomes a dangling pointer if the object is destroyed. For example, a garbage collection can remove the last strong reference to the object and so destroy it.

Calling Py_INCREF() on the borrowed reference is recommended to convert it to a strong reference in-place, except when the object cannot be destroyed before the last usage of the borrowed reference. The Py_NewRef() function can be used to create a new strong reference.

bytes-like object
An object that supports the Buffer Protocol and can export a C-contiguous buffer. This includes all bytes, bytearray, and array.array objects, as well as many common memoryview objects. Bytes-like objects can be used for various operations that work with binary data; these include compression, saving to a binary file, and sending over a socket.

Some operations need the binary data to be mutable. The documentation often refers to these as “read-write bytes-like objects”. Example mutable buffer objects include bytearray and a memoryview of a bytearray. Other operations require the binary data to be stored in immutable objects (“read-only bytes-like objects”); examples of these include bytes and a memoryview of a bytes object.

bytecode
Python source code is compiled into bytecode, the internal representation of a Python program in the CPython interpreter. The bytecode is also cached in .pyc files so that executing the same file is faster the second time (recompilation from source to bytecode can be avoided). This “intermediate language” is said to run on a virtual machine that executes the machine code corresponding to each bytecode. Do note that bytecodes are not expected to work between different Python virtual machines, nor to be stable between Python releases.

A list of bytecode instructions can be found in the documentation for the dis module.

callable
A callable is an object that can be called, possibly with a set of arguments (see argument), with the following syntax:

callable(argument1, argument2, ...)
A function, and by extension a method, is a callable. An instance of a class that implements the __call__() method is also a callable.

callback
A subroutine function which is passed as an argument to be executed at some point in the future.

class
A template for creating user-defined objects. Class definitions normally contain method definitions which operate on instances of the class.

class variable
A variable defined in a class and intended to be modified only at class level (i.e., not in an instance of the class).

coercion
The implicit conversion of an instance of one type to another during an operation which involves two arguments of the same type. For example, int(3.15) converts the floating point number to the integer 3, but in 3+4.5, each argument is of a different type (one int, one float), and both must be converted to the same type before they can be added or it will raise a TypeError. Without coercion, all arguments of even compatible types would have to be normalized to the same value by the programmer, e.g., float(3)+4.5 rather than just 3+4.5.

complex number
An extension of the familiar real number system in which all numbers are expressed as a sum of a real part and an imaginary part. Imaginary numbers are real multiples of the imaginary unit (the square root of -1), often written i in mathematics or j in engineering. Python has built-in support for complex numbers, which are written with this latter notation; the imaginary part is written with a j suffix, e.g., 3+1j. To get access to complex equivalents of the math module, use cmath. Use of complex numbers is a fairly advanced mathematical feature. If you’re not aware of a need for them, it’s almost certain you can safely ignore them.

context manager
An object which controls the environment seen in a with statement by defining __enter__() and __exit__() methods. See PEP 343.

context variable
A variable which can have different values depending on its context. This is similar to Thread-Local Storage in which each execution thread may have a different value for a variable. However, with context variables, there may be several contexts in one execution thread and the main usage for context variables is to keep track of variables in concurrent asynchronous tasks. See contextvars.

contiguous
A buffer is considered contiguous exactly if it is either C-contiguous or Fortran contiguous. Zero-dimensional buffers are C and Fortran contiguous. In one-dimensional arrays, the items must be laid out in memory next to each other, in order of increasing indexes starting from zero. In multidimensional C-contiguous arrays, the last index varies the fastest when visiting items in order of memory address. However, in Fortran contiguous arrays, the first index varies the fastest.

coroutine
Coroutines are a more generalized form of subroutines. Subroutines are entered at one point and exited at another point. Coroutines can be entered, exited, and resumed at many different points. They can be implemented with the async def statement. See also PEP 492.

coroutine function
A function which returns a coroutine object. A coroutine function may be defined with the async def statement, and may contain await, async for, and async with keywords. These were introduced by PEP 492.

CPython
The canonical implementation of the Python programming language, as distributed on python.org. The term “CPython” is used when necessary to distinguish this implementation from others such as Jython or IronPython.

decorator
A function returning another function, usually applied as a function transformation using the @wrapper syntax. Common examples for decorators are classmethod() and staticmethod().

The decorator syntax is merely syntactic sugar, the following two function definitions are semantically equivalent:

def f(arg):
    ...
f = staticmethod(f)

@staticmethod
def f(arg):
    ...
The same concept exists for classes, but is less commonly used there. See the documentation for function definitions and class definitions for more about decorators.

descriptor
Any object which defines the methods __get__(), __set__(), or __delete__(). When a class attribute is a descriptor, its special binding behavior is triggered upon attribute lookup. Normally, using a.b to get, set or delete an attribute looks up the object named b in the class dictionary for a, but if b is a descriptor, the respective descriptor method gets called. Understanding descriptors is a key to a deep understanding of Python because they are the basis for many features including functions, methods, properties, class methods, static methods, and reference to super classes.

For more information about descriptors’ methods, see Implementing Descriptors or the Descriptor How To Guide.

dictionary
An associative array, where arbitrary keys are mapped to values. The keys can be any object with __hash__() and __eq__() methods. Called a hash in Perl.

dictionary comprehension
A compact way to process all or part of the elements in an iterable and return a dictionary with the results. results = {n: n ** 2 for n in range(10)} generates a dictionary containing key n mapped to value n ** 2. See Displays for lists, sets and dictionaries.

dictionary view
The objects returned from dict.keys(), dict.values(), and dict.items() are called dictionary views. They provide a dynamic view on the dictionary’s entries, which means that when the dictionary changes, the view reflects these changes. To force the dictionary view to become a full list use list(dictview). See Dictionary view objects.

docstring
A string literal which appears as the first expression in a class, function or module. While ignored when the suite is executed, it is recognized by the compiler and put into the __doc__ attribute of the enclosing class, function or module. Since it is available via introspection, it is the canonical place for documentation of the object.

duck-typing
A programming style which does not look at an object’s type to determine if it has the right interface; instead, the method or attribute is simply called or used (“If it looks like a duck and quacks like a duck, it must be a duck.”) By emphasizing interfaces rather than specific types, well-designed code improves its flexibility by allowing polymorphic substitution. Duck-typing avoids tests using type() or isinstance(). (Note, however, that duck-typing can be complemented with abstract base classes.) Instead, it typically employs hasattr() tests or EAFP programming.

EAFP
Easier to ask for forgiveness than permission. This common Python coding style assumes the existence of valid keys or attributes and catches exceptions if the assumption proves false. This clean and fast style is characterized by the presence of many try and except statements. The technique contrasts with the LBYL style common to many other languages such as C.

expression
A piece of syntax which can be evaluated to some value. In other words, an expression is an accumulation of expression elements like literals, names, attribute access, operators or function calls which all return a value. In contrast to many other languages, not all language constructs are expressions. There are also statements which cannot be used as expressions, such as while. Assignments are also statements, not expressions.

extension module
A module written in C or C++, using Python’s C API to interact with the core and with user code.

f-string
String literals prefixed with 'f' or 'F' are commonly called “f-strings” which is short for formatted string literals. See also PEP 498.

file object
An object exposing a file-oriented API (with methods such as read() or write()) to an underlying resource. Depending on the way it was created, a file object can mediate access to a real on-disk file or to another type of storage or communication device (for example standard input/output, in-memory buffers, sockets, pipes, etc.). File objects are also called file-like objects or streams.

There are actually three categories of file objects: raw binary files, buffered binary files and text files. Their interfaces are defined in the io module. The canonical way to create a file object is by using the open() function.

file-like object
A synonym for file object.

filesystem encoding and error handler
Encoding and error handler used by Python to decode bytes from the operating system and encode Unicode to the operating system.

The filesystem encoding must guarantee to successfully decode all bytes below 128. If the file system encoding fails to provide this guarantee, API functions can raise UnicodeError.

The sys.getfilesystemencoding() and sys.getfilesystemencodeerrors() functions can be used to get the filesystem encoding and error handler.

The filesystem encoding and error handler are configured at Python startup by the PyConfig_Read() function: see filesystem_encoding and filesystem_errors members of PyConfig.

See also the locale encoding.

finder
An object that tries to find the loader for a module that is being imported.

Since Python 3.3, there are two types of finder: meta path finders for use with sys.meta_path, and path entry finders for use with sys.path_hooks.

See PEP 302, PEP 420 and PEP 451 for much more detail.

floor division
Mathematical division that rounds down to nearest integer. The floor division operator is //. For example, the expression 11 // 4 evaluates to 2 in contrast to the 2.75 returned by float true division. Note that (-11) // 4 is -3 because that is -2.75 rounded downward. See PEP 238.

function
A series of statements which returns some value to a caller. It can also be passed zero or more arguments which may be used in the execution of the body. See also parameter, method, and the Function definitions section.

function annotation
An annotation of a function parameter or return value.

Function annotations are usually used for type hints: for example, this function is expected to take two int arguments and is also expected to have an int return value:

def sum_two_numbers(a: int, b: int) -> int:
   return a + b
Function annotation syntax is explained in section Function definitions.

See variable annotation and PEP 484, which describe this functionality. Also see Annotations Best Practices for best practices on working with annotations.

__future__
A future statement, from __future__ import <feature>, directs the compiler to compile the current module using syntax or semantics that will become standard in a future release of Python. The __future__ module documents the possible values of feature. By importing this module and evaluating its variables, you can see when a new feature was first added to the language and when it will (or did) become the default:

>>>
>>> import __future__
>>> __future__.division
_Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192)
garbage collection
The process of freeing memory when it is not used anymore. Python performs garbage collection via reference counting and a cyclic garbage collector that is able to detect and break reference cycles. The garbage collector can be controlled using the gc module.

generator
A function which returns a generator iterator. It looks like a normal function except that it contains yield expressions for producing a series of values usable in a for-loop or that can be retrieved one at a time with the next() function.

Usually refers to a generator function, but may refer to a generator iterator in some contexts. In cases where the intended meaning isn’t clear, using the full terms avoids ambiguity.

generator iterator
An object created by a generator function.

Each yield temporarily suspends processing, remembering the location execution state (including local variables and pending try-statements). When the generator iterator resumes, it picks up where it left off (in contrast to functions which start fresh on every invocation).

generator expression
An expression that returns an iterator. It looks like a normal expression followed by a for clause defining a loop variable, range, and an optional if clause. The combined expression generates values for an enclosing function:

>>>
>>> sum(i*i for i in range(10))         # sum of squares 0, 1, 4, ... 81
285
generic function
A function composed of multiple functions implementing the same operation for different types. Which implementation should be used during a call is determined by the dispatch algorithm.

See also the single dispatch glossary entry, the functools.singledispatch() decorator, and PEP 443.

generic type
A type that can be parameterized; typically a container class such as list or dict. Used for type hints and annotations.

For more details, see generic alias types, PEP 483, PEP 484, PEP 585, and the typing module.

GIL
See global interpreter lock.

global interpreter lock
The mechanism used by the CPython interpreter to assure that only one thread executes Python bytecode at a time. This simplifies the CPython implementation by making the object model (including critical built-in types such as dict) implicitly safe against concurrent access. Locking the entire interpreter makes it easier for the interpreter to be multi-threaded, at the expense of much of the parallelism afforded by multi-processor machines.

However, some extension modules, either standard or third-party, are designed so as to release the GIL when doing computationally intensive tasks such as compression or hashing. Also, the GIL is always released when doing I/O.

Past efforts to create a “free-threaded” interpreter (one which locks shared data at a much finer granularity) have not been successful because performance suffered in the common single-processor case. It is believed that overcoming this performance issue would make the implementation much more complicated and therefore costlier to maintain.

hash-based pyc
A bytecode cache file that uses the hash rather than the last-modified time of the corresponding source file to determine its validity. See Cached bytecode invalidation.

hashable
An object is hashable if it has a hash value which never changes during its lifetime (it needs a __hash__() method), and can be compared to other objects (it needs an __eq__() method). Hashable objects which compare equal must have the same hash value.

Hashability makes an object usable as a dictionary key and a set member, because these data structures use the hash value internally.

Most of Python’s immutable built-in objects are hashable; mutable containers (such as lists or dictionaries) are not; immutable containers (such as tuples and frozensets) are only hashable if their elements are hashable. Objects which are instances of user-defined classes are hashable by default. They all compare unequal (except with themselves), and their hash value is derived from their id().

IDLE
An Integrated Development and Learning Environment for Python. IDLE is a basic editor and interpreter environment which ships with the standard distribution of Python.

immutable
An object with a fixed value. Immutable objects include numbers, strings and tuples. Such an object cannot be altered. A new object has to be created if a different value has to be stored. They play an important role in places where a constant hash value is needed, for example as a key in a dictionary.

import path
A list of locations (or path entries) that are searched by the path based finder for modules to import. During import, this list of locations usually comes from sys.path, but for subpackages it may also come from the parent package’s __path__ attribute.

importing
The process by which Python code in one module is made available to Python code in another module.

importer
An object that both finds and loads a module; both a finder and loader object.

interactive
Python has an interactive interpreter which means you can enter statements and expressions at the interpreter prompt, immediately execute them and see their results. Just launch python with no arguments (possibly by selecting it from your computer’s main menu). It is a very powerful way to test out new ideas or inspect modules and packages (remember help(x)).

interpreted
Python is an interpreted language, as opposed to a compiled one, though the distinction can be blurry because of the presence of the bytecode compiler. This means that source files can be run directly without explicitly creating an executable which is then run. Interpreted languages typically have a shorter development/debug cycle than compiled ones, though their programs generally also run more slowly. See also interactive.

interpreter shutdown
When asked to shut down, the Python interpreter enters a special phase where it gradually releases all allocated resources, such as modules and various critical internal structures. It also makes several calls to the garbage collector. This can trigger the execution of code in user-defined destructors or weakref callbacks. Code executed during the shutdown phase can encounter various exceptions as the resources it relies on may not function anymore (common examples are library modules or the warnings machinery).

The main reason for interpreter shutdown is that the __main__ module or the script being run has finished executing.

iterable
An object capable of returning its members one at a time. Examples of iterables include all sequence types (such as list, str, and tuple) and some non-sequence types like dict, file objects, and objects of any classes you define with an __iter__() method or with a __getitem__() method that implements Sequence semantics.

Iterables can be used in a for loop and in many other places where a sequence is needed (zip(), map(), …). When an iterable object is passed as an argument to the built-in function iter(), it returns an iterator for the object. This iterator is good for one pass over the set of values. When using iterables, it is usually not necessary to call iter() or deal with iterator objects yourself. The for statement does that automatically for you, creating a temporary unnamed variable to hold the iterator for the duration of the loop. See also iterator, sequence, and generator.

iterator
An object representing a stream of data. Repeated calls to the iterator’s __next__() method (or passing it to the built-in function next()) return successive items in the stream. When no more data are available a StopIteration exception is raised instead. At this point, the iterator object is exhausted and any further calls to its __next__() method just raise StopIteration again. Iterators are required to have an __iter__() method that returns the iterator object itself so every iterator is also iterable and may be used in most places where other iterables are accepted. One notable exception is code which attempts multiple iteration passes. A container object (such as a list) produces a fresh new iterator each time you pass it to the iter() function or use it in a for loop. Attempting this with an iterator will just return the same exhausted iterator object used in the previous iteration pass, making it appear like an empty container.

More information can be found in Iterator Types.

CPython implementation detail: CPython does not consistently apply the requirement that an iterator define __iter__().

key function
A key function or collation function is a callable that returns a value used for sorting or ordering. For example, locale.strxfrm() is used to produce a sort key that is aware of locale specific sort conventions.

A number of tools in Python accept key functions to control how elements are ordered or grouped. They include min(), max(), sorted(), list.sort(), heapq.merge(), heapq.nsmallest(), heapq.nlargest(), and itertools.groupby().

There are several ways to create a key function. For example. the str.lower() method can serve as a key function for case insensitive sorts. Alternatively, a key function can be built from a lambda expression such as lambda r: (r[0], r[2]). Also, the operator module provides three key function constructors: attrgetter(), itemgetter(), and methodcaller(). See the Sorting HOW TO for examples of how to create and use key functions.

keyword argument
See argument.

lambda
An anonymous inline function consisting of a single expression which is evaluated when the function is called. The syntax to create a lambda function is lambda [parameters]: expression

LBYL
Look before you leap. This coding style explicitly tests for pre-conditions before making calls or lookups. This style contrasts with the EAFP approach and is characterized by the presence of many if statements.

In a multi-threaded environment, the LBYL approach can risk introducing a race condition between “the looking” and “the leaping”. For example, the code, if key in mapping: return mapping[key] can fail if another thread removes key from mapping after the test, but before the lookup. This issue can be solved with locks or by using the EAFP approach.

locale encoding
On Unix, it is the encoding of the LC_CTYPE locale. It can be set with locale.setlocale(locale.LC_CTYPE, new_locale).

On Windows, it is the ANSI code page (ex: cp1252).

locale.getpreferredencoding(False) can be used to get the locale encoding.

Python uses the filesystem encoding and error handler to convert between Unicode filenames and bytes filenames.

list
A built-in Python sequence. Despite its name it is more akin to an array in other languages than to a linked list since access to elements is O(1).

list comprehension
A compact way to process all or part of the elements in a sequence and return a list with the results. result = ['{:#04x}'.format(x) for x in range(256) if x % 2 == 0] generates a list of strings containing even hex numbers (0x..) in the range from 0 to 255. The if clause is optional. If omitted, all elements in range(256) are processed.

loader
An object that loads a module. It must define a method named load_module(). A loader is typically returned by a finder. See PEP 302 for details and importlib.abc.Loader for an abstract base class.

magic method
An informal synonym for special method.

mapping
A container object that supports arbitrary key lookups and implements the methods specified in the Mapping or MutableMapping abstract base classes. Examples include dict, collections.defaultdict, collections.OrderedDict and collections.Counter.

meta path finder
A finder returned by a search of sys.meta_path. Meta path finders are related to, but different from path entry finders.

See importlib.abc.MetaPathFinder for the methods that meta path finders implement.

metaclass
The class of a class. Class definitions create a class name, a class dictionary, and a list of base classes. The metaclass is responsible for taking those three arguments and creating the class. Most object oriented programming languages provide a default implementation. What makes Python special is that it is possible to create custom metaclasses. Most users never need this tool, but when the need arises, metaclasses can provide powerful, elegant solutions. They have been used for logging attribute access, adding thread-safety, tracking object creation, implementing singletons, and many other tasks.

More information can be found in Metaclasses.

method
A function which is defined inside a class body. If called as an attribute of an instance of that class, the method will get the instance object as its first argument (which is usually called self). See function and nested scope.

method resolution order
Method Resolution Order is the order in which base classes are searched for a member during lookup. See The Python 2.3 Method Resolution Order for details of the algorithm used by the Python interpreter since the 2.3 release.

module
An object that serves as an organizational unit of Python code. Modules have a namespace containing arbitrary Python objects. Modules are loaded into Python by the process of importing.

See also package.

module spec
A namespace containing the import-related information used to load a module. An instance of importlib.machinery.ModuleSpec.

MRO
See method resolution order.

mutable
Mutable objects can change their value but keep their id(). See also immutable.

named tuple
The term “named tuple” applies to any type or class that inherits from tuple and whose indexable elements are also accessible using named attributes. The type or class may have other features as well.

Several built-in types are named tuples, including the values returned by time.localtime() and os.stat(). Another example is sys.float_info:

>>>
>>> sys.float_info[1]                   # indexed access
1024
>>> sys.float_info.max_exp              # named field access
1024
>>> isinstance(sys.float_info, tuple)   # kind of tuple
True
Some named tuples are built-in types (such as the above examples). Alternatively, a named tuple can be created from a regular class definition that inherits from tuple and that defines named fields. Such a class can be written by hand or it can be created with the factory function collections.namedtuple(). The latter technique also adds some extra methods that may not be found in hand-written or built-in named tuples.

namespace
The place where a variable is stored. Namespaces are implemented as dictionaries. There are the local, global and built-in namespaces as well as nested namespaces in objects (in methods). Namespaces support modularity by preventing naming conflicts. For instance, the functions builtins.open and os.open() are distinguished by their namespaces. Namespaces also aid readability and maintainability by making it clear which module implements a function. For instance, writing random.seed() or itertools.islice() makes it clear that those functions are implemented by the random and itertools modules, respectively.

namespace package
A PEP 420 package which serves only as a container for subpackages. Namespace packages may have no physical representation, and specifically are not like a regular package because they have no __init__.py file.

See also module.

nested scope
The ability to refer to a variable in an enclosing definition. For instance, a function defined inside another function can refer to variables in the outer function. Note that nested scopes by default work only for reference and not for assignment. Local variables both read and write in the innermost scope. Likewise, global variables read and write to the global namespace. The nonlocal allows writing to outer scopes.

new-style class
Old name for the flavor of classes now used for all class objects. In earlier Python versions, only new-style classes could use Python’s newer, versatile features like __slots__, descriptors, properties, __getattribute__(), class methods, and static methods.

object
Any data with state (attributes or value) and defined behavior (methods). Also the ultimate base class of any new-style class.

package
A Python module which can contain submodules or recursively, subpackages. Technically, a package is a Python module with an __path__ attribute.

See also regular package and namespace package.

parameter
A named entity in a function (or method) definition that specifies an argument (or in some cases, arguments) that the function can accept. There are five kinds of parameter:

positional-or-keyword: specifies an argument that can be passed either positionally or as a keyword argument. This is the default kind of parameter, for example foo and bar in the following:

def func(foo, bar=None): ...
positional-only: specifies an argument that can be supplied only by position. Positional-only parameters can be defined by including a / character in the parameter list of the function definition after them, for example posonly1 and posonly2 in the following:

def func(posonly1, posonly2, /, positional_or_keyword): ...
keyword-only: specifies an argument that can be supplied only by keyword. Keyword-only parameters can be defined by including a single var-positional parameter or bare * in the parameter list of the function definition before them, for example kw_only1 and kw_only2 in the following:

def func(arg, *, kw_only1, kw_only2): ...
var-positional: specifies that an arbitrary sequence of positional arguments can be provided (in addition to any positional arguments already accepted by other parameters). Such a parameter can be defined by prepending the parameter name with *, for example args in the following:

def func(*args, **kwargs): ...
var-keyword: specifies that arbitrarily many keyword arguments can be provided (in addition to any keyword arguments already accepted by other parameters). Such a parameter can be defined by prepending the parameter name with **, for example kwargs in the example above.

Parameters can specify both optional and required arguments, as well as default values for some optional arguments.

See also the argument glossary entry, the FAQ question on the difference between arguments and parameters, the inspect.Parameter class, the Function definitions section, and PEP 362.

path entry
A single location on the import path which the path based finder consults to find modules for importing.

path entry finder
A finder returned by a callable on sys.path_hooks (i.e. a path entry hook) which knows how to locate modules given a path entry.

See importlib.abc.PathEntryFinder for the methods that path entry finders implement.

path entry hook
A callable on the sys.path_hook list which returns a path entry finder if it knows how to find modules on a specific path entry.

path based finder
One of the default meta path finders which searches an import path for modules.

path-like object
An object representing a file system path. A path-like object is either a str or bytes object representing a path, or an object implementing the os.PathLike protocol. An object that supports the os.PathLike protocol can be converted to a str or bytes file system path by calling the os.fspath() function; os.fsdecode() and os.fsencode() can be used to guarantee a str or bytes result instead, respectively. Introduced by PEP 519.

PEP
Python Enhancement Proposal. A PEP is a design document providing information to the Python community, or describing a new feature for Python or its processes or environment. PEPs should provide a concise technical specification and a rationale for proposed features.

PEPs are intended to be the primary mechanisms for proposing major new features, for collecting community input on an issue, and for documenting the design decisions that have gone into Python. The PEP author is responsible for building consensus within the community and documenting dissenting opinions.

See PEP 1.

portion
A set of files in a single directory (possibly stored in a zip file) that contribute to a namespace package, as defined in PEP 420.

positional argument
See argument.

provisional API
A provisional API is one which has been deliberately excluded from the standard library’s backwards compatibility guarantees. While major changes to such interfaces are not expected, as long as they are marked provisional, backwards incompatible changes (up to and including removal of the interface) may occur if deemed necessary by core developers. Such changes will not be made gratuitously – they will occur only if serious fundamental flaws are uncovered that were missed prior to the inclusion of the API.

Even for provisional APIs, backwards incompatible changes are seen as a “solution of last resort” - every attempt will still be made to find a backwards compatible resolution to any identified problems.

This process allows the standard library to continue to evolve over time, without locking in problematic design errors for extended periods of time. See PEP 411 for more details.

provisional package
See provisional API.

Python 3000
Nickname for the Python 3.x release line (coined long ago when the release of version 3 was something in the distant future.) This is also abbreviated “Py3k”.

Pythonic
An idea or piece of code which closely follows the most common idioms of the Python language, rather than implementing code using concepts common to other languages. For example, a common idiom in Python is to loop over all elements of an iterable using a for statement. Many other languages don’t have this type of construct, so people unfamiliar with Python sometimes use a numerical counter instead:

for i in range(len(food)):
    print(food[i])
As opposed to the cleaner, Pythonic method:

for piece in food:
    print(piece)
qualified name
A dotted name showing the “path” from a module’s global scope to a class, function or method defined in that module, as defined in PEP 3155. For top-level functions and classes, the qualified name is the same as the object’s name:

>>>
>>> class C:
...     class D:
...         def meth(self):
...             pass
...
>>> C.__qualname__
'C'
>>> C.D.__qualname__
'C.D'
>>> C.D.meth.__qualname__
'C.D.meth'
When used to refer to modules, the fully qualified name means the entire dotted path to the module, including any parent packages, e.g. email.mime.text:

>>>
>>> import email.mime.text
>>> email.mime.text.__name__
'email.mime.text'
reference count
The number of references to an object. When the reference count of an object drops to zero, it is deallocated. Reference counting is generally not visible to Python code, but it is a key element of the CPython implementation. The sys module defines a getrefcount() function that programmers can call to return the reference count for a particular object.

regular package
A traditional package, such as a directory containing an __init__.py file.

See also namespace package.

__slots__
A declaration inside a class that saves memory by pre-declaring space for instance attributes and eliminating instance dictionaries. Though popular, the technique is somewhat tricky to get right and is best reserved for rare cases where there are large numbers of instances in a memory-critical application.

sequence
An iterable which supports efficient element access using integer indices via the __getitem__() special method and defines a __len__() method that returns the length of the sequence. Some built-in sequence types are list, str, tuple, and bytes. Note that dict also supports __getitem__() and __len__(), but is considered a mapping rather than a sequence because the lookups use arbitrary immutable keys rather than integers.

The collections.abc.Sequence abstract base class defines a much richer interface that goes beyond just __getitem__() and __len__(), adding count(), index(), __contains__(), and __reversed__(). Types that implement this expanded interface can be registered explicitly using register().

set comprehension
A compact way to process all or part of the elements in an iterable and return a set with the results. results = {c for c in 'abracadabra' if c not in 'abc'} generates the set of strings {'r', 'd'}. See Displays for lists, sets and dictionaries.

single dispatch
A form of generic function dispatch where the implementation is chosen based on the type of a single argument.

slice
An object usually containing a portion of a sequence. A slice is created using the subscript notation, [] with colons between numbers when several are given, such as in variable_name[1:3:5]. The bracket (subscript) notation uses slice objects internally.

special method
A method that is called implicitly by Python to execute a certain operation on a type, such as addition. Such methods have names starting and ending with double underscores. Special methods are documented in Special method names.

statement
A statement is part of a suite (a “block” of code). A statement is either an expression or one of several constructs with a keyword, such as if, while or for.

strong reference
In Python’s C API, a strong reference is a reference to an object which increments the object’s reference count when it is created and decrements the object’s reference count when it is deleted.

The Py_NewRef() function can be used to create a strong reference to an object. Usually, the Py_DECREF() function must be called on the strong reference before exiting the scope of the strong reference, to avoid leaking one reference.

See also borrowed reference.

text encoding
A string in Python is a sequence of Unicode code points (in range U+0000–U+10FFFF). To store or transfer a string, it needs to be serialized as a sequence of bytes.

Serializing a string into a sequence of bytes is known as “encoding”, and recreating the string from the sequence of bytes is known as “decoding”.

There are a variety of different text serialization codecs, which are collectively referred to as “text encodings”.

text file
A file object able to read and write str objects. Often, a text file actually accesses a byte-oriented datastream and handles the text encoding automatically. Examples of text files are files opened in text mode ('r' or 'w'), sys.stdin, sys.stdout, and instances of io.StringIO.

See also binary file for a file object able to read and write bytes-like objects.

triple-quoted string
A string which is bound by three instances of either a quotation mark (”) or an apostrophe (‘). While they don’t provide any functionality not available with single-quoted strings, they are useful for a number of reasons. They allow you to include unescaped single and double quotes within a string and they can span multiple lines without the use of the continuation character, making them especially useful when writing docstrings.

type
The type of a Python object determines what kind of object it is; every object has a type. An object’s type is accessible as its __class__ attribute or can be retrieved with type(obj).

type alias
A synonym for a type, created by assigning the type to an identifier.

Type aliases are useful for simplifying type hints. For example:

def remove_gray_shades(
        colors: list[tuple[int, int, int]]) -> list[tuple[int, int, int]]:
    pass
could be made more readable like this:

Color = tuple[int, int, int]

def remove_gray_shades(colors: list[Color]) -> list[Color]:
    pass
See typing and PEP 484, which describe this functionality.

type hint
An annotation that specifies the expected type for a variable, a class attribute, or a function parameter or return value.

Type hints are optional and are not enforced by Python but they are useful to static type analysis tools, and aid IDEs with code completion and refactoring.

Type hints of global variables, class attributes, and functions, but not local variables, can be accessed using typing.get_type_hints().

See typing and PEP 484, which describe this functionality.

universal newlines
A manner of interpreting text streams in which all of the following are recognized as ending a line: the Unix end-of-line convention '\n', the Windows convention '\r\n', and the old Macintosh convention '\r'. See PEP 278 and PEP 3116, as well as bytes.splitlines() for an additional use.

variable annotation
An annotation of a variable or a class attribute.

When annotating a variable or a class attribute, assignment is optional:

class C:
    field: 'annotation'
Variable annotations are usually used for type hints: for example this variable is expected to take int values:

count: int = 0
Variable annotation syntax is explained in section Annotated assignment statements.

See function annotation, PEP 484 and PEP 526, which describe this functionality. Also see Annotations Best Practices for best practices on working with annotations.

virtual environment
A cooperatively isolated runtime environment that allows Python users and applications to install and upgrade Python distribution packages without interfering with the behaviour of other Python applications running on the same system.

See also venv.

virtual machine
A computer defined entirely in software. Python’s virtual machine executes the bytecode emitted by the bytecode compiler.

Zen of Python
Listing of Python design principles and philosophies that are helpful in understanding and using the language. The listing can be found by typing “import this” at the interactive prompt.

Previous topic
“Why is Python Installed on my Computer?” FAQ

Next topic
About these documents

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Glossary
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Dealing with Bugs
Quick search
  |
Dealing with Bugs
Python is a mature programming language which has established a reputation for stability. In order to maintain this reputation, the developers would like to know of any deficiencies you find in Python.

It can be sometimes faster to fix bugs yourself and contribute patches to Python as it streamlines the process and involves less people. Learn how to contribute.

Documentation bugs
If you find a bug in this documentation or would like to propose an improvement, please submit a bug report on the tracker. If you have a suggestion on how to fix it, include that as well.

If you’re short on time, you can also email documentation bug reports to docs@python.org (behavioral bugs can be sent to python-list@python.org). ‘docs@’ is a mailing list run by volunteers; your request will be noticed, though it may take a while to be processed.

See also
Documentation bugs
A list of documentation bugs that have been submitted to the Python issue tracker.

Issue Tracking
Overview of the process involved in reporting an improvement on the tracker.

Helping with Documentation
Comprehensive guide for individuals that are interested in contributing to Python documentation.

Documentation Translations
A list of GitHub pages for documentation translation and their primary contacts.

Using the Python issue tracker
Issue reports for Python itself should be submitted via the GitHub issues tracker (https://github.com/python/cpython/issues). The GitHub issues tracker offers a web form which allows pertinent information to be entered and submitted to the developers.

The first step in filing a report is to determine whether the problem has already been reported. The advantage in doing so, aside from saving the developers’ time, is that you learn what has been done to fix it; it may be that the problem has already been fixed for the next release, or additional information is needed (in which case you are welcome to provide it if you can!). To do this, search the tracker using the search box at the top of the page.

If the problem you’re reporting is not already in the list, log in to GitHub. If you don’t already have a GitHub account, create a new account using the “Sign up” link. It is not possible to submit a bug report anonymously.

Being now logged in, you can submit an issue. Click on the “New issue” button in the top bar to report a new issue.

The submission form has two fields, “Title” and “Comment”.

For the “Title” field, enter a very short description of the problem; less than ten words is good.

In the “Comment” field, describe the problem in detail, including what you expected to happen and what did happen. Be sure to include whether any extension modules were involved, and what hardware and software platform you were using (including version information as appropriate).

Each issue report will be reviewed by a developer who will determine what needs to be done to correct the problem. You will receive an update each time an action is taken on the issue.

See also
How to Report Bugs Effectively
Article which goes into some detail about how to create a useful bug report. This describes what kind of information is useful and why it is useful.

Bug Writing Guidelines
Information about writing a good bug report. Some of this is specific to the Mozilla project, but describes general good practices.

Getting started contributing to Python yourself
Beyond just reporting bugs that you find, you are also welcome to submit patches to fix them. You can find more information on how to get started patching Python in the Python Developer’s Guide. If you have questions, the core-mentorship mailing list is a friendly place to get answers to any and all questions pertaining to the process of fixing issues in Python.

Table of Contents
Dealing with Bugs
Documentation bugs
Using the Python issue tracker
Getting started contributing to Python yourself
Previous topic
About these documents

Next topic
Copyright

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Dealing with Bugs
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
Hide navigation sidebarHide table of contents sidebar
Logo
Python Developer's Guide
Search
Getting StartedToggle child pages in navigation
Development WorkflowToggle child pages in navigation
Issues and TriagingToggle child pages in navigation
DocumentationToggle child pages in navigation
Getting Started
Helping with Documentation
Style Guide
reStructuredText Markup
Translating
Helping with the Developer’s Guide
Testing and BuildbotsToggle child pages in navigation
Core DevelopersToggle child pages in navigation
CPython’s InternalsToggle child pages in navigation
Advanced ToolsToggle child pages in navigation
Status of Python Versions
Toggle Light / Dark / Auto color theme
Toggle table of contents sidebar
Helping with Documentation
Python is known for having well-written documentation. Maintaining the documentation’s accuracy and keeping a high level of quality takes a lot of effort. Community members, like you, help with writing, editing, and updating content, and these contributions are appreciated and welcomed.

This high-level Helping with Documentation section provides:

an overview of Python’s documentation

how to help with documentation issues

information on proofreading

You will find extensive and detailed information on how to write documentation and submit changes on the Documenting Python page.

Python Documentation
The Documenting Python section covers the details of how Python’s documentation works. It includes information about the markup language used, specific formats, and style recommendations. Looking at pre-existing documentation source files can be very helpful when getting started. How to build the documentation walks you through the steps to create a draft build which lets you see how your changes will look and validates that your new markup is correct.

You can view the documentation built from in-development and maintenance branches at https://docs.python.org/dev/. The in-development and recent maintenance branches are rebuilt once per day.

If you would like to be more involved with documentation, consider subscribing to the docs@python.org mailing list. The issue tracker sends new documentation issues to this mailing list, and, less frequently, the list receives some directly mailed bug reports. The docs-sig@python.org mailing list discusses the documentation toolchain, projects, and standards.

Helping with documentation issues
If you look at documentation issues on the issue tracker, you will find various documentation problems that may need work. Issues vary from typos to unclear documentation and items lacking documentation.

If you see a documentation issue that you would like to tackle, you can:

check to see if there is a paperclip or octocat icon at the end of the issue’s title column. If there is, then someone has already created a pull request for the issue.

leave a comment on the issue saying you are going to try and create a pull request and roughly how long you think you will take to do so (this allows others to take on the issue if you happen to forget or lose interest).

submit a pull request for the issue.

By following the steps in the Quick Guide to Pull Requests, you will learn the workflow for documentation pull requests.

Proofreading
While an issue filed on the issue tracker means there is a known issue somewhere, that does not mean there are not other issues lurking about in the documentation. Proofreading a part of the documentation, such as a “How to” or OS specific document, can often uncover problems (e.g., documentation that needs updating for Python 3).

If you decide to proofread, read a section of the documentation from start to finish, filing issues in the issue tracker for each major type of problem you find. Simple typos don’t require issues of their own, but, instead, submit a pull request directly. It’s best to avoid filing a single issue for an entire section containing multiple problems; instead, file several issues so that it is easier to break the work up for multiple people and more efficient review.

Next
Style Guide
Previous
Getting Started
Copyright © 2011-2022, Python Software Foundation
Made with Sphinx and @pradyunsg's Furo
ON THIS PAGE
Python Documentation
Helping with documentation issues
Proofreading
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » About these documents
Quick search
  |
About these documents
These documents are generated from reStructuredText sources by Sphinx, a document processor specifically written for the Python documentation.

Development of the documentation and its toolchain is an entirely volunteer effort, just like Python itself. If you want to contribute, please take a look at the Dealing with Bugs page for information on how to do so. New volunteers are always welcome!

Many thanks go to:

Fred L. Drake, Jr., the creator of the original Python documentation toolset and writer of much of the content;

the Docutils project for creating reStructuredText and the Docutils suite;

Fredrik Lundh for his Alternative Python Reference project from which Sphinx got many good ideas.

Contributors to the Python Documentation
Many people have contributed to the Python language, the Python standard library, and the Python documentation. See Misc/ACKS in the Python source distribution for a partial list of contributors.

It is only with the input and contributions of the Python community that Python has such wonderful documentation – Thank You!

Table of Contents
About these documents
Contributors to the Python Documentation
Previous topic
Glossary

Next topic
Dealing with Bugs

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » About these documents
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » History and License
Quick search
  |
History and License
History of the software
Python was created in the early 1990s by Guido van Rossum at Stichting Mathematisch Centrum (CWI, see https://www.cwi.nl/) in the Netherlands as a successor of a language called ABC. Guido remains Python’s principal author, although it includes many contributions from others.

In 1995, Guido continued his work on Python at the Corporation for National Research Initiatives (CNRI, see https://www.cnri.reston.va.us/) in Reston, Virginia where he released several versions of the software.

In May 2000, Guido and the Python core development team moved to BeOpen.com to form the BeOpen PythonLabs team. In October of the same year, the PythonLabs team moved to Digital Creations (now Zope Corporation; see https://www.zope.org/). In 2001, the Python Software Foundation (PSF, see https://www.python.org/psf/) was formed, a non-profit organization created specifically to own Python-related Intellectual Property. Zope Corporation is a sponsoring member of the PSF.

All Python releases are Open Source (see https://opensource.org/ for the Open Source Definition). Historically, most, but not all, Python releases have also been GPL-compatible; the table below summarizes the various releases.

Release

Derived from

Year

Owner

GPL compatible?

0.9.0 thru 1.2

n/a

1991-1995

CWI

yes

1.3 thru 1.5.2

1.2

1995-1999

CNRI

yes

1.6

1.5.2

2000

CNRI

no

2.0

1.6

2000

BeOpen.com

no

1.6.1

1.6

2001

CNRI

no

2.1

2.0+1.6.1

2001

PSF

no

2.0.1

2.0+1.6.1

2001

PSF

yes

2.1.1

2.1+2.0.1

2001

PSF

yes

2.1.2

2.1.1

2002

PSF

yes

2.1.3

2.1.2

2002

PSF

yes

2.2 and above

2.1.1

2001-now

PSF

yes

Note GPL-compatible doesn’t mean that we’re distributing Python under the GPL. All Python licenses, unlike the GPL, let you distribute a modified version without making your changes open source. The GPL-compatible licenses make it possible to combine Python with other software that is released under the GPL; the others don’t.
Thanks to the many outside volunteers who have worked under Guido’s direction to make these releases possible.

Terms and conditions for accessing or otherwise using Python
Python software and documentation are licensed under the PSF License Agreement.

Starting with Python 3.8.6, examples, recipes, and other code in the documentation are dual licensed under the PSF License Agreement and the Zero-Clause BSD license.

Some software incorporated into Python is under different licenses. The licenses are listed with code falling under that license. See Licenses and Acknowledgements for Incorporated Software for an incomplete list of these licenses.

PSF LICENSE AGREEMENT FOR PYTHON 3.10.8
1. This LICENSE AGREEMENT is between the Python Software Foundation ("PSF"), and
   the Individual or Organization ("Licensee") accessing and otherwise using Python
   3.10.8 software in source or binary form and its associated documentation.

2. Subject to the terms and conditions of this License Agreement, PSF hereby
   grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,
   analyze, test, perform and/or display publicly, prepare derivative works,
   distribute, and otherwise use Python 3.10.8 alone or in any derivative
   version, provided, however, that PSF's License Agreement and PSF's notice of
   copyright, i.e., "Copyright © 2001-2022 Python Software Foundation; All Rights
   Reserved" are retained in Python 3.10.8 alone or in any derivative version
   prepared by Licensee.

3. In the event Licensee prepares a derivative work that is based on or
   incorporates Python 3.10.8 or any part thereof, and wants to make the
   derivative work available to others as provided herein, then Licensee hereby
   agrees to include in any such work a brief summary of the changes made to Python
   3.10.8.

4. PSF is making Python 3.10.8 available to Licensee on an "AS IS" basis.
   PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED.  BY WAY OF
   EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND DISCLAIMS ANY REPRESENTATION OR
   WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE
   USE OF PYTHON 3.10.8 WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.

5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON 3.10.8
   FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF
   MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON 3.10.8, OR ANY DERIVATIVE
   THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.

6. This License Agreement will automatically terminate upon a material breach of
   its terms and conditions.

7. Nothing in this License Agreement shall be deemed to create any relationship
   of agency, partnership, or joint venture between PSF and Licensee.  This License
   Agreement does not grant permission to use PSF trademarks or trade name in a
   trademark sense to endorse or promote products or services of Licensee, or any
   third party.

8. By copying, installing or otherwise using Python 3.10.8, Licensee agrees
   to be bound by the terms and conditions of this License Agreement.
BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0
BEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1

1. This LICENSE AGREEMENT is between BeOpen.com ("BeOpen"), having an office at
   160 Saratoga Avenue, Santa Clara, CA 95051, and the Individual or Organization
   ("Licensee") accessing and otherwise using this software in source or binary
   form and its associated documentation ("the Software").

2. Subject to the terms and conditions of this BeOpen Python License Agreement,
   BeOpen hereby grants Licensee a non-exclusive, royalty-free, world-wide license
   to reproduce, analyze, test, perform and/or display publicly, prepare derivative
   works, distribute, and otherwise use the Software alone or in any derivative
   version, provided, however, that the BeOpen Python License is retained in the
   Software, alone or in any derivative version prepared by Licensee.

3. BeOpen is making the Software available to Licensee on an "AS IS" basis.
   BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED.  BY WAY OF
   EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND DISCLAIMS ANY REPRESENTATION OR
   WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE
   USE OF THE SOFTWARE WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.

4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE SOFTWARE FOR
   ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF USING,
   MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY DERIVATIVE THEREOF, EVEN IF
   ADVISED OF THE POSSIBILITY THEREOF.

5. This License Agreement will automatically terminate upon a material breach of
   its terms and conditions.

6. This License Agreement shall be governed by and interpreted in all respects
   by the law of the State of California, excluding conflict of law provisions.
   Nothing in this License Agreement shall be deemed to create any relationship of
   agency, partnership, or joint venture between BeOpen and Licensee.  This License
   Agreement does not grant permission to use BeOpen trademarks or trade names in a
   trademark sense to endorse or promote products or services of Licensee, or any
   third party.  As an exception, the "BeOpen Python" logos available at
   http://www.pythonlabs.com/logos.html may be used according to the permissions
   granted on that web page.

7. By copying, installing or otherwise using the software, Licensee agrees to be
   bound by the terms and conditions of this License Agreement.
CNRI LICENSE AGREEMENT FOR PYTHON 1.6.1
1. This LICENSE AGREEMENT is between the Corporation for National Research
   Initiatives, having an office at 1895 Preston White Drive, Reston, VA 20191
   ("CNRI"), and the Individual or Organization ("Licensee") accessing and
   otherwise using Python 1.6.1 software in source or binary form and its
   associated documentation.

2. Subject to the terms and conditions of this License Agreement, CNRI hereby
   grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,
   analyze, test, perform and/or display publicly, prepare derivative works,
   distribute, and otherwise use Python 1.6.1 alone or in any derivative version,
   provided, however, that CNRI's License Agreement and CNRI's notice of copyright,
   i.e., "Copyright © 1995-2001 Corporation for National Research Initiatives; All
   Rights Reserved" are retained in Python 1.6.1 alone or in any derivative version
   prepared by Licensee.  Alternately, in lieu of CNRI's License Agreement,
   Licensee may substitute the following text (omitting the quotes): "Python 1.6.1
   is made available subject to the terms and conditions in CNRI's License
   Agreement.  This Agreement together with Python 1.6.1 may be located on the
   internet using the following unique, persistent identifier (known as a handle):
   1895.22/1013.  This Agreement may also be obtained from a proxy server on the
   internet using the following URL: http://hdl.handle.net/1895.22/1013."

3. In the event Licensee prepares a derivative work that is based on or
   incorporates Python 1.6.1 or any part thereof, and wants to make the derivative
   work available to others as provided herein, then Licensee hereby agrees to
   include in any such work a brief summary of the changes made to Python 1.6.1.

4. CNRI is making Python 1.6.1 available to Licensee on an "AS IS" basis.  CNRI
   MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED.  BY WAY OF EXAMPLE,
   BUT NOT LIMITATION, CNRI MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY
   OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF
   PYTHON 1.6.1 WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.

5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON 1.6.1 FOR
   ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF
   MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON 1.6.1, OR ANY DERIVATIVE
   THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.

6. This License Agreement will automatically terminate upon a material breach of
   its terms and conditions.

7. This License Agreement shall be governed by the federal intellectual property
   law of the United States, including without limitation the federal copyright
   law, and, to the extent such U.S. federal law does not apply, by the law of the
   Commonwealth of Virginia, excluding Virginia's conflict of law provisions.
   Notwithstanding the foregoing, with regard to derivative works based on Python
   1.6.1 that incorporate non-separable material that was previously distributed
   under the GNU General Public License (GPL), the law of the Commonwealth of
   Virginia shall govern this License Agreement only as to issues arising under or
   with respect to Paragraphs 4, 5, and 7 of this License Agreement.  Nothing in
   this License Agreement shall be deemed to create any relationship of agency,
   partnership, or joint venture between CNRI and Licensee.  This License Agreement
   does not grant permission to use CNRI trademarks or trade name in a trademark
   sense to endorse or promote products or services of Licensee, or any third
   party.

8. By clicking on the "ACCEPT" button where indicated, or by copying, installing
   or otherwise using Python 1.6.1, Licensee agrees to be bound by the terms and
   conditions of this License Agreement.
CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2
Copyright © 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The
Netherlands.  All rights reserved.

Permission to use, copy, modify, and distribute this software and its
documentation for any purpose and without fee is hereby granted, provided that
the above copyright notice appear in all copies and that both that copyright
notice and this permission notice appear in supporting documentation, and that
the name of Stichting Mathematisch Centrum or CWI not be used in advertising or
publicity pertaining to distribution of the software without specific, written
prior permission.

STICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS
SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN NO
EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE FOR ANY SPECIAL, INDIRECT
OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,
DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS
SOFTWARE.
ZERO-CLAUSE BSD LICENSE FOR CODE IN THE PYTHON 3.10.8 DOCUMENTATION
Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
Licenses and Acknowledgements for Incorporated Software
This section is an incomplete, but growing list of licenses and acknowledgements for third-party software incorporated in the Python distribution.

Mersenne Twister
The _random module includes code based on a download from http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/MT2002/emt19937ar.html. The following are the verbatim comments from the original code:

A C-program for MT19937, with initialization improved 2002/1/26.
Coded by Takuji Nishimura and Makoto Matsumoto.

Before using, initialize the state by using init_genrand(seed)
or init_by_array(init_key, key_length).

Copyright (C) 1997 - 2002, Makoto Matsumoto and Takuji Nishimura,
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:

 1. Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

 2. Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

 3. The names of its contributors may not be used to endorse or promote
    products derived from this software without specific prior written
    permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


Any feedback is very welcome.
http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html
email: m-mat @ math.sci.hiroshima-u.ac.jp (remove space)
Sockets
The socket module uses the functions, getaddrinfo(), and getnameinfo(), which are coded in separate source files from the WIDE Project, https://www.wide.ad.jp/.

Copyright (C) 1995, 1996, 1997, and 1998 WIDE Project.
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:
1. Redistributions of source code must retain the above copyright
   notice, this list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright
   notice, this list of conditions and the following disclaimer in the
   documentation and/or other materials provided with the distribution.
3. Neither the name of the project nor the names of its contributors
   may be used to endorse or promote products derived from this software
   without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
SUCH DAMAGE.
Asynchronous socket services
The asynchat and asyncore modules contain the following notice:

Copyright 1996 by Sam Rushing

                        All Rights Reserved

Permission to use, copy, modify, and distribute this software and
its documentation for any purpose and without fee is hereby
granted, provided that the above copyright notice appear in all
copies and that both that copyright notice and this permission
notice appear in supporting documentation, and that the name of Sam
Rushing not be used in advertising or publicity pertaining to
distribution of the software without specific, written prior
permission.

SAM RUSHING DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE,
INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN
NO EVENT SHALL SAM RUSHING BE LIABLE FOR ANY SPECIAL, INDIRECT OR
CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,
NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
Cookie management
The http.cookies module contains the following notice:

Copyright 2000 by Timothy O'Malley <timo@alum.mit.edu>

               All Rights Reserved

Permission to use, copy, modify, and distribute this software
and its documentation for any purpose and without fee is hereby
granted, provided that the above copyright notice appear in all
copies and that both that copyright notice and this permission
notice appear in supporting documentation, and that the name of
Timothy O'Malley  not be used in advertising or publicity
pertaining to distribution of the software without specific, written
prior permission.

Timothy O'Malley DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS
SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS, IN NO EVENT SHALL Timothy O'Malley BE LIABLE FOR
ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
Execution tracing
The trace module contains the following notice:

portions copyright 2001, Autonomous Zones Industries, Inc., all rights...
err...  reserved and offered to the public under the terms of the
Python 2.2 license.
Author: Zooko O'Whielacronx
http://zooko.com/
mailto:zooko@zooko.com

Copyright 2000, Mojam Media, Inc., all rights reserved.
Author: Skip Montanaro

Copyright 1999, Bioreason, Inc., all rights reserved.
Author: Andrew Dalke

Copyright 1995-1997, Automatrix, Inc., all rights reserved.
Author: Skip Montanaro

Copyright 1991-1995, Stichting Mathematisch Centrum, all rights reserved.


Permission to use, copy, modify, and distribute this Python software and
its associated documentation for any purpose without fee is hereby
granted, provided that the above copyright notice appears in all copies,
and that both that copyright notice and this permission notice appear in
supporting documentation, and that the name of neither Automatrix,
Bioreason or Mojam Media be used in advertising or publicity pertaining to
distribution of the software without specific, written prior permission.
UUencode and UUdecode functions
The uu module contains the following notice:

Copyright 1994 by Lance Ellinghouse
Cathedral City, California Republic, United States of America.
                       All Rights Reserved
Permission to use, copy, modify, and distribute this software and its
documentation for any purpose and without fee is hereby granted,
provided that the above copyright notice appear in all copies and that
both that copyright notice and this permission notice appear in
supporting documentation, and that the name of Lance Ellinghouse
not be used in advertising or publicity pertaining to distribution
of the software without specific, written prior permission.
LANCE ELLINGHOUSE DISCLAIMS ALL WARRANTIES WITH REGARD TO
THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS, IN NO EVENT SHALL LANCE ELLINGHOUSE CENTRUM BE LIABLE
FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

Modified by Jack Jansen, CWI, July 1995:
- Use binascii module to do the actual line-by-line conversion
  between ascii and binary. This results in a 1000-fold speedup. The C
  version is still 5 times faster, though.
- Arguments more compliant with Python standard
XML Remote Procedure Calls
The xmlrpc.client module contains the following notice:

    The XML-RPC client interface is

Copyright (c) 1999-2002 by Secret Labs AB
Copyright (c) 1999-2002 by Fredrik Lundh

By obtaining, using, and/or copying this software and/or its
associated documentation, you agree that you have read, understood,
and will comply with the following terms and conditions:

Permission to use, copy, modify, and distribute this software and
its associated documentation for any purpose and without fee is
hereby granted, provided that the above copyright notice appears in
all copies, and that both that copyright notice and this permission
notice appear in supporting documentation, and that the name of
Secret Labs AB or the author not be used in advertising or publicity
pertaining to distribution of the software without specific, written
prior permission.

SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
OF THIS SOFTWARE.
test_epoll
The test_epoll module contains the following notice:

Copyright (c) 2001-2006 Twisted Matrix Laboratories.

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Select kqueue
The select module contains the following notice for the kqueue interface:

Copyright (c) 2000 Doug White, 2006 James Knight, 2007 Christian Heimes
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:
1. Redistributions of source code must retain the above copyright
   notice, this list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright
   notice, this list of conditions and the following disclaimer in the
   documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
SUCH DAMAGE.
SipHash24
The file Python/pyhash.c contains Marek Majkowski’ implementation of Dan Bernstein’s SipHash24 algorithm. It contains the following note:

<MIT License>
Copyright (c) 2013  Marek Majkowski <marek@popcount.org>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.
</MIT License>

Original location:
   https://github.com/majek/csiphash/

Solution inspired by code from:
   Samuel Neves (supercop/crypto_auth/siphash24/little)
   djb (supercop/crypto_auth/siphash24/little2)
   Jean-Philippe Aumasson (https://131002.net/siphash/siphash24.c)
strtod and dtoa
The file Python/dtoa.c, which supplies C functions dtoa and strtod for conversion of C doubles to and from strings, is derived from the file of the same name by David M. Gay, currently available from https://web.archive.org/web/20220517033456/http://www.netlib.org/fp/dtoa.c. The original file, as retrieved on March 16, 2009, contains the following copyright and licensing notice:

/****************************************************************
 *
 * The author of this software is David M. Gay.
 *
 * Copyright (c) 1991, 2000, 2001 by Lucent Technologies.
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose without fee is hereby granted, provided that this entire notice
 * is included in all copies of any software which is or includes a copy
 * or modification of this software and in all copies of the supporting
 * documentation for such software.
 *
 * THIS SOFTWARE IS BEING PROVIDED "AS IS", WITHOUT ANY EXPRESS OR IMPLIED
 * WARRANTY.  IN PARTICULAR, NEITHER THE AUTHOR NOR LUCENT MAKES ANY
 * REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY
 * OF THIS SOFTWARE OR ITS FITNESS FOR ANY PARTICULAR PURPOSE.
 *
 ***************************************************************/
OpenSSL
The modules hashlib, posix, ssl, crypt use the OpenSSL library for added performance if made available by the operating system. Additionally, the Windows and macOS installers for Python may include a copy of the OpenSSL libraries, so we include a copy of the OpenSSL license here:

 LICENSE ISSUES
 ==============

 The OpenSSL toolkit stays under a dual license, i.e. both the conditions of
 the OpenSSL License and the original SSLeay license apply to the toolkit.
 See below for the actual license texts. Actually both licenses are BSD-style
 Open Source licenses. In case of any license issues related to OpenSSL
 please contact openssl-core@openssl.org.

 OpenSSL License
 ---------------

   /* ====================================================================
    * Copyright (c) 1998-2008 The OpenSSL Project.  All rights reserved.
    *
    * Redistribution and use in source and binary forms, with or without
    * modification, are permitted provided that the following conditions
    * are met:
    *
    * 1. Redistributions of source code must retain the above copyright
    *    notice, this list of conditions and the following disclaimer.
    *
    * 2. Redistributions in binary form must reproduce the above copyright
    *    notice, this list of conditions and the following disclaimer in
    *    the documentation and/or other materials provided with the
    *    distribution.
    *
    * 3. All advertising materials mentioning features or use of this
    *    software must display the following acknowledgment:
    *    "This product includes software developed by the OpenSSL Project
    *    for use in the OpenSSL Toolkit. (http://www.openssl.org/)"
    *
    * 4. The names "OpenSSL Toolkit" and "OpenSSL Project" must not be used to
    *    endorse or promote products derived from this software without
    *    prior written permission. For written permission, please contact
    *    openssl-core@openssl.org.
    *
    * 5. Products derived from this software may not be called "OpenSSL"
    *    nor may "OpenSSL" appear in their names without prior written
    *    permission of the OpenSSL Project.
    *
    * 6. Redistributions of any form whatsoever must retain the following
    *    acknowledgment:
    *    "This product includes software developed by the OpenSSL Project
    *    for use in the OpenSSL Toolkit (http://www.openssl.org/)"
    *
    * THIS SOFTWARE IS PROVIDED BY THE OpenSSL PROJECT ``AS IS'' AND ANY
    * EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
    * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
    * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE OpenSSL PROJECT OR
    * ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
    * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
    * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
    * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
    * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
    * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED
    * OF THE POSSIBILITY OF SUCH DAMAGE.
    * ====================================================================
    *
    * This product includes cryptographic software written by Eric Young
    * (eay@cryptsoft.com).  This product includes software written by Tim
    * Hudson (tjh@cryptsoft.com).
    *
    */

Original SSLeay License
-----------------------

   /* Copyright (C) 1995-1998 Eric Young (eay@cryptsoft.com)
    * All rights reserved.
    *
    * This package is an SSL implementation written
    * by Eric Young (eay@cryptsoft.com).
    * The implementation was written so as to conform with Netscapes SSL.
    *
    * This library is free for commercial and non-commercial use as long as
    * the following conditions are aheared to.  The following conditions
    * apply to all code found in this distribution, be it the RC4, RSA,
    * lhash, DES, etc., code; not just the SSL code.  The SSL documentation
    * included with this distribution is covered by the same copyright terms
    * except that the holder is Tim Hudson (tjh@cryptsoft.com).
    *
    * Copyright remains Eric Young's, and as such any Copyright notices in
    * the code are not to be removed.
    * If this package is used in a product, Eric Young should be given attribution
    * as the author of the parts of the library used.
    * This can be in the form of a textual message at program startup or
    * in documentation (online or textual) provided with the package.
    *
    * Redistribution and use in source and binary forms, with or without
    * modification, are permitted provided that the following conditions
    * are met:
    * 1. Redistributions of source code must retain the copyright
    *    notice, this list of conditions and the following disclaimer.
    * 2. Redistributions in binary form must reproduce the above copyright
    *    notice, this list of conditions and the following disclaimer in the
    *    documentation and/or other materials provided with the distribution.
    * 3. All advertising materials mentioning features or use of this software
    *    must display the following acknowledgement:
    *    "This product includes cryptographic software written by
    *     Eric Young (eay@cryptsoft.com)"
    *    The word 'cryptographic' can be left out if the rouines from the library
    *    being used are not cryptographic related :-).
    * 4. If you include any Windows specific code (or a derivative thereof) from
    *    the apps directory (application code) you must include an acknowledgement:
    *    "This product includes software written by Tim Hudson (tjh@cryptsoft.com)"
    *
    * THIS SOFTWARE IS PROVIDED BY ERIC YOUNG ``AS IS'' AND
    * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
    * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
    * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
    * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
    * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
    * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
    * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
    * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
    * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
    * SUCH DAMAGE.
    *
    * The licence and distribution terms for any publically available version or
    * derivative of this code cannot be changed.  i.e. this code cannot simply be
    * copied and put under another distribution licence
    * [including the GNU Public Licence.]
    */
expat
The pyexpat extension is built using an included copy of the expat sources unless the build is configured --with-system-expat:

Copyright (c) 1998, 1999, 2000 Thai Open Source Software Center Ltd
                               and Clark Cooper

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be included
in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
libffi
The _ctypes extension is built using an included copy of the libffi sources unless the build is configured --with-system-libffi:

Copyright (c) 1996-2008  Red Hat, Inc and others.

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
``Software''), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be included
in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ``AS IS'', WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT.  IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
DEALINGS IN THE SOFTWARE.
zlib
The zlib extension is built using an included copy of the zlib sources if the zlib version found on the system is too old to be used for the build:

Copyright (C) 1995-2011 Jean-loup Gailly and Mark Adler

This software is provided 'as-is', without any express or implied
warranty.  In no event will the authors be held liable for any damages
arising from the use of this software.

Permission is granted to anyone to use this software for any purpose,
including commercial applications, and to alter it and redistribute it
freely, subject to the following restrictions:

1. The origin of this software must not be misrepresented; you must not
   claim that you wrote the original software. If you use this software
   in a product, an acknowledgment in the product documentation would be
   appreciated but is not required.

2. Altered source versions must be plainly marked as such, and must not be
   misrepresented as being the original software.

3. This notice may not be removed or altered from any source distribution.

Jean-loup Gailly        Mark Adler
jloup@gzip.org          madler@alumni.caltech.edu
cfuhash
The implementation of the hash table used by the tracemalloc is based on the cfuhash project:

Copyright (c) 2005 Don Owens
All rights reserved.

This code is released under the BSD license:

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above
    copyright notice, this list of conditions and the following
    disclaimer in the documentation and/or other materials provided
    with the distribution.

  * Neither the name of the author nor the names of its
    contributors may be used to endorse or promote products derived
    from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED
OF THE POSSIBILITY OF SUCH DAMAGE.
libmpdec
The _decimal module is built using an included copy of the libmpdec library unless the build is configured --with-system-libmpdec:

Copyright (c) 2008-2020 Stefan Krah. All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:

1. Redistributions of source code must retain the above copyright
   notice, this list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright
   notice, this list of conditions and the following disclaimer in the
   documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
SUCH DAMAGE.
W3C C14N test suite
The C14N 2.0 test suite in the test package (Lib/test/xmltestdata/c14n-20/) was retrieved from the W3C website at https://www.w3.org/TR/xml-c14n2-testcases/ and is distributed under the 3-clause BSD license:

Copyright (c) 2013 W3C(R) (MIT, ERCIM, Keio, Beihang),
All Rights Reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:

* Redistributions of works must retain the original copyright notice,
  this list of conditions and the following disclaimer.
* Redistributions in binary form must reproduce the original copyright
  notice, this list of conditions and the following disclaimer in the
  documentation and/or other materials provided with the distribution.
* Neither the name of the W3C nor the names of its contributors may be
  used to endorse or promote products derived from this work without
  specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
Table of Contents
History and License
History of the software
Terms and conditions for accessing or otherwise using Python
PSF LICENSE AGREEMENT FOR PYTHON 3.10.8
BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0
CNRI LICENSE AGREEMENT FOR PYTHON 1.6.1
CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2
ZERO-CLAUSE BSD LICENSE FOR CODE IN THE PYTHON 3.10.8 DOCUMENTATION
Licenses and Acknowledgements for Incorporated Software
Mersenne Twister
Sockets
Asynchronous socket services
Cookie management
Execution tracing
UUencode and UUdecode functions
XML Remote Procedure Calls
test_epoll
Select kqueue
SipHash24
strtod and dtoa
OpenSSL
expat
libffi
zlib
cfuhash
libmpdec
W3C C14N test suite
Previous topic
Copyright

Next topic
Distributing Python Modules (Legacy version)

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » History and License
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Copyright
Quick search
  |
Copyright
Python and this documentation is:

Copyright © 2001-2022 Python Software Foundation. All rights reserved.

Copyright © 2000 BeOpen.com. All rights reserved.

Copyright © 1995-2000 Corporation for National Research Initiatives. All rights reserved.

Copyright © 1991-1995 Stichting Mathematisch Centrum. All rights reserved.

See History and License for complete license and permissions information.

Previous topic
Dealing with Bugs

Next topic
History and License

This Page
Report a Bug
Show Source
«
indexmodules |next |previous |python logo Python » 

English

3.10.8
 3.10.8 Documentation » Copyright
Quick search
  |
© Copyright 2001-2022, Python Software Foundation.
This page is licensed under the Python Software Foundation License Version 2.
Examples, recipes, and other code in the documentation are additionally licensed under the Zero Clause BSD License.
See History and License for more information.

The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Oct 21, 2022. Found a bug?
Created using Sphinx 3.4.3.